{"posts":[{"title":"2026年02月09日早间要闻","text":"📰 今日重要新闻1. 四大科技巨头2026年AI资本开支合计达$6500亿Bloomberg报道，微软、Alphabet、Meta、亚马逊四家公司2026年资本开支预算合计约$6500亿，几乎全部砸向数据中心和AI算力基础设施。这一数字令市场对AI投资回报率产生担忧，上周五科技板块承压。 2. Alphabet Q4财报亮眼，2026 Capex指引翻倍至$1850亿Google母公司Alphabet Q4利润同比增长30%至$345亿，但更引发关注的是2026年资本开支指引高达$1750-1850亿，较2025年翻倍，CEO Sundar Pichai表示”供给仍然是制约因素”。投资者担忧巨额投入的ROI，财报后股价基本持平。 3. AMD创纪录营收，数据中心首次占总收入过半AMD公布Q4 2025财报：季度营收$103亿创历史新高，全年营收$346亿同比增长34%。数据中心业务首次贡献超过一半的收入，Instinct MI300系列GPU和EPYC Turin处理器需求强劲。OpenAI已选择AMD作为优选GPU供应商。 4. 微软Q2 FY2026收入$813亿，Azure增长38%微软季度收入$813亿同比增17%，Azure云收入增长38%（按固定汇率），云业务总收入首次突破$500亿。净利润$385亿，EPS $5.16。OpenAI相关投资为EPS贡献了额外$1.02。Copilot在企业端渗透加速。 5. 阿里巴巴宣布三年投入3800亿元AI和云基础设施阿里巴巴集团宣布未来三年将投入至少3800亿人民币（约$530亿）用于AI和云计算基础设施建设，CEO吴泳铭的”AI优先”战略覆盖全业务线。云智能业务成为核心增长支柱，中国云市场预计2026年将扩大至约$611亿。 📈 美股重点关注（上周五 2/6 收盘）MSFT 微软 — $401.14 近期表现：较去年10月历史高点$541下跌约26%，处于回调区间 关键催化剂：Q2 FY2026业绩超预期，Azure增长38%强劲；云总收入破$500亿大关 风险点：AI资本开支持续高企，市场担忧短期利润率受压 看点：Copilot企业渗透率、OpenAI合作深化 GOOGL 谷歌 — $322.86（-2.53%） 近期表现：财报后从$343.69高点回落约6% 关键催化剂：Q4利润大增30%，广告+云双轮驱动；2026 Capex翻倍显示AI决心 风险点：$1850亿资本开支令投资者不安，反垄断案件悬而未决 看点：Gemini 2.0落地效果、Google Cloud增速能否持续 NVDA 英伟达 — $185.41 近期表现：过去三个月回调约7.6%，从$207高点回落 关键催化剂：Q3 FY2026数据中心收入$512亿，Q4指引$650亿；Seeking Alpha目标价$219 风险点：中国出口限制、客户自研芯片趋势、估值高位回调压力 看点：2/26 Q4财报日临近，Blackwell架构出货节奏 AMD — $207.95（+8.28%） 近期表现：上周五大涨8.28%，受Q4财报利好提振 关键催化剂：Q4营收$103亿创纪录，数据中心收入首次过半；OpenAI选择AMD为优选供应商 风险点：与NVDA的GPU差距仍大，MI300生态追赶中 看点：MI325X出货加速、EPYC Turin在服务器端的份额增长 BABA 阿里巴巴 — $162.51（+3.01%） 近期表现：上周五涨3%，市场对AI投入计划反应积极 关键催化剂：3800亿元AI/云基建三年投资计划；AI优先战略重塑业务矩阵 风险点：中国宏观经济不确定性、电商竞争（拼多多、抖音）、云利润率偏低 看点：云智能业务能否兑现增长、2月底财报季将至 💡 本周关注 2/26 NVDA Q4财报：AI算力龙头的关键业绩验证 大科技AI投资回报：$6500亿资本开支的ROI何时显现 中国AI政策走向：阿里等巨头加码后的监管与竞争态势 数据来源：MacroTrends、StockAnalysis、CNBC、Reuters、Bloomberg | 股价为美东时间2/6收盘价","link":"/2026/02/09/2026-02-09-morning-news/"},{"title":"微软开源 Agent Lightning：让 AI 智能体自己学会变强","text":"你有没有想过，为什么 AI 智能体明明「懂很多」，实际干活却经常犯蠢？ 问题出在：大模型的通用能力和特定任务的执行能力是两回事。 ChatGPT 能写诗、能算数、能写代码，但你让它帮你订机票、查数据库、操作 API，它就开始「抽风」了——幻觉、死循环、工具调用出错…… 怎么让智能体「干一行，精一行」？ 微软亚洲研究院给出了答案：Agent Lightning。 这玩意儿是干嘛的？一句话：让任意 AI 智能体通过强化学习自我进化，几乎不用改代码。 传统的强化学习（RL）训练 AI，需要大量的框架适配、数据工程、奖励函数设计。对于已有的智能体项目，想接入 RL 几乎等于重写。 Agent Lightning 的核心理念是把智能体的执行和模型的训练彻底解耦。 你的智能体照常跑，该调 API 调 API，该查数据库查数据库。Agent Lightning 在旁边默默「录像」，记录每一步操作和结果，然后用这些数据来训练底层模型。 你不用改代码，智能体自动变强。 怎么用？安装1pip install agentlightning 最简示例假设你有一个用 OpenAI SDK 写的简单智能体： 123456789from openai import OpenAIclient = OpenAI()def my_agent(question): response = client.chat.completions.create( model=&quot;gpt-4o&quot;, messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: question}] ) return response.choices[0].message.content 接入 Agent Lightning，只需要加几行： 1234567891011121314151617import agentlightning as agl# 初始化 tracertracer = agl.Tracer()def my_agent(question): with tracer.span(&quot;agent_call&quot;): # 记录这次调用 response = client.chat.completions.create( model=&quot;gpt-4o&quot;, messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: question}] ) answer = response.choices[0].message.content # 告诉 Agent Lightning 这次的奖励（对不对、好不好） agl.emit_reward(score=evaluate(answer)) return answer 然后启动训练： 1234567from agentlightning import Trainertrainer = Trainer( algorithm=&quot;grpo&quot;, # 强化学习算法 store=tracer.store,)trainer.fit() 就这么简单。智能体每跑一次任务，Agent Lightning 就收集一次数据；数据攒够了，自动训练一轮；训练完，模型权重自动更新。 你的智能体在实战中越来越强。 支持哪些框架？几乎所有主流框架都支持： LangChain — 最流行的 LLM 应用框架 OpenAI Agent SDK — OpenAI 官方的智能体开发包 AutoGen — 微软的多智能体对话框架 CrewAI — 多智能体协作框架 Microsoft Agent Framework — 微软企业级框架 纯 Python + OpenAI API — 不用任何框架也行 甚至多智能体系统也能用。你可以选择性地只优化其中一个或几个智能体，其他的保持不变。 核心架构Agent Lightning 的设计非常优雅，分成三层： 1. Tracer（追踪器）在你的智能体代码里埋点，记录： 每次 LLM 调用的 prompt 和 response 工具调用的输入输出 最终的奖励信号（任务成功/失败、得分高低） 这些数据被组织成「span」（事件片段），流入中央存储。 2. LightningStore（闪电仓库）一个中央数据库，同步所有的： 任务信息 执行轨迹 模型资源（权重、prompt 模板） 训练器和智能体都从这里读写数据，彼此解耦。 3. Algorithm + Trainer（算法 + 训练器）支持多种优化算法： GRPO（Group Relative Policy Optimization）— 组相对策略优化，适合奖励稀疏的场景 PPO（Proximal Policy Optimization）— 经典强化学习算法 Automatic Prompt Optimization — 自动优化 prompt 模板 Supervised Fine-tuning — 监督微调 你也可以自己写算法插进去。 实际效果怎么样？微软在多个任务上做了测试： SQL 生成任务让智能体根据自然语言生成 SQL 查询。经过 Agent Lightning 训练后： 执行正确率提升 15-20% 幻觉（编造不存在的表/字段）大幅减少 数学工具调用让智能体用计算器、绘图工具解决数学问题： 工具调用成功率提升 25% 多步推理的稳定性显著改善 多智能体协作在狼人杀游戏中训练多个 AI 玩家： 经过几轮训练，AI 学会了「演戏」和「试探」 胜率从随机水平提升到接近人类玩家 为什么这个方法管用？传统的智能体优化有两个大坑： 坑 1：数据采集太难 智能体的执行轨迹是多步的、带分支的、有工具调用的。传统方法需要你手动设计数据格式，非常痛苦。 Agent Lightning 的 tracer 自动搞定这一切。 坑 2：训练和执行耦合太紧 很多 RL 框架要求你把智能体写成它规定的格式，迁移成本极高。 Agent Lightning 完全不管你的智能体怎么写，它只负责「录像」和「训练」，两边完全独立。 用官方的话说：No rewrites, no lock-in, just a clear path from first rollout to steady improvement. 社区项目已经有不少团队在用 Agent Lightning 做有意思的事： DeepWerewolf — 用强化学习训练狼人杀 AI AgentFlow — 斯坦福的多智能体框架，结合 Agent Lightning 处理长链路任务 Youtu-Agent — 腾讯优图团队的智能体训练方案，已验证 128 GPU 稳定收敛 怎么开始？ 安装：pip install agentlightning 看文档：microsoft.github.io/agent-lightning 跑示例：github.com/microsoft/agent-lightning/examples 加社区：Discord 写在最后Agent Lightning 解决的是一个真正的痛点：怎么让已有的智能体项目快速接入强化学习。 以前，你可能需要一个 RL 工程师团队花几个月重构代码。现在，加几行埋点就行了。 更重要的是，它代表了一种趋势：AI 智能体不再是「一次性部署」，而是「持续进化」。 你的智能体今天犯的错，明天就能学会避免。这才是真正的「智能」。 相关链接： GitHub 仓库 官方文档 arXiv 论文 微软研究院介绍","link":"/2026/02/06/agent-lightning/"},{"title":"AI时代的巨人困局：当创新成为微软谷歌的抵颈之刃","text":"“成功企业失败的原因，往往正是因为它们做对了所有事情。” —— 克莱顿·克里斯坦森 创新者的困境：历史的回响1997年，哈佛商学院教授克莱顿·克里斯坦森（Clayton Christensen）在《创新者的窘境》中提出了一个令人不安的悖论：伟大的公司之所以失败，恰恰是因为它们太过优秀。它们精准地满足现有客户的需求，高效地分配资源，按部就班地改进产品——然而，当颠覆性技术从边缘崛起时，这些曾经的优势反而成为了致命的枷锁。 克里斯坦森将这种现象归结为”价值网络”的锁定效应。大公司深嵌于由客户、供应商、投资者构成的利益网络中，每一个决策都需要向这个网络负责。当新技术的早期形态无法满足主流市场的需求时，大公司往往选择理性地忽视它——直到为时已晚。 柯达发明了数码相机却死于数码时代，诺基亚主导了功能机市场却在智能机时代溃败，这些前车之鉴如今正在AI时代重演。而这一次，站在十字路口的是微软和谷歌——两家掌握着AI时代”金钥匙”的巨头。 谷歌：广告帝国的AI转型之痛谷歌是这个时代最成功的广告公司。2025年第一季度，其广告收入高达668.9亿美元，搜索业务贡献了其中的绝大部分。按照行业估算，谷歌从每位活跃用户身上获取的年均广告收入约为400美元——这是一个令人惊叹的数字，也是一个沉重的包袱。 问题在于：AI正在颠覆搜索的底层逻辑。 传统搜索的商业模式建立在”信息不对称”之上——用户提问，谷歌返回十个蓝色链接，用户点击，广告主付费。这个模式运转了二十年，养活了整个互联网生态。但当AI能够直接给出答案时，用户还需要点击那些链接吗？ 谷歌的应对策略是”AI Overview”——在搜索结果顶部直接展示AI生成的答案。截至2025年底，这项功能已覆盖超过20亿用户。谷歌甚至开始在AI答案中插入广告。但这带来了新的困境： 如果AI答案太好，用户不再点击链接，广告点击量下降 如果AI答案不够好，用户转向ChatGPT或Perplexity 如果AI答案中的广告太多，用户体验下降，信任流失 2025年第四季度财报后，尽管谷歌交出了亮眼的数字——市值一度突破4万亿美元大关——但市场的质疑声不绝于耳：谷歌能否在AI时代保持其搜索霸主地位？从以链接为中心的广告模式，如何平稳过渡到AI优先的新范式？ 到目前为止，谷歌还没有给市场一个完美的答案。 微软：十面埋伏中的求生战如果说谷歌面临的是”如何保护现金牛”的问题，那么微软面临的困境更加复杂：它正在被自己曾经的盟友和模式所反噬。 2023年，微软押注OpenAI，将ChatGPT整合进Bing搜索和Office套件，推出Copilot品牌，一度被视为AI时代的先行者。然而两年后的今天，形势已经逆转： Claude Code的崛起正在动摇Copilot的根基。 根据SemiAnalysis最新报告，Claude Code目前已占据GitHub代码提交量的**4%，预计到2026年底将超过20%**。这款产品被认为是”AI Agent时代的拐点”——它不仅能写代码，还能理解项目上下文、执行复杂任务、自主完成工作流程。 这对微软意味着什么？GitHub是微软旗下的平台，GitHub Copilot是微软的AI编程产品，但最受欢迎的AI编程工具却是Anthropic的Claude Code。微软正在自己的地盘上输给竞争对手。 更糟糕的是，OpenAI也在推出自己的Codex产品，与Copilot形成竞争。微软投资了OpenAI数百亿美元，却无法阻止后者成为自己的竞争对手。这种”合纵连横”的复杂关系，让微软的战略布局充满了不确定性。 市场已经用脚投票。微软的市盈率从2024年高点的35倍左右，一路下滑至目前的26-28倍。按照当前约3万亿美元的市值计算，这意味着近万亿美元的估值蒸发。 2026年1月的最新财报显示，Azure云业务增速放缓至37-38%，低于市场预期。股价应声下跌7%。财报收入依然强劲，但市场关心的是：在AI重构一切的时代，微软的护城河还有多宽？ 大公司的本质困境：无法革自己的命为什么这些明明看到了AI浪潮的巨头，依然举步维艰？ 答案藏在克里斯坦森的理论中：**颠覆性创新要求的不仅是技术能力，更是对现有价值网络的”连根拔起”**。 谷歌要真正拥抱AI，就必须接受搜索广告收入可能下降的现实。但每当财报季来临，华尔街分析师们盯着的是广告收入同比增长了多少，是每用户收入有没有提升。股东们不会允许谷歌”牺牲今天的利润去换取不确定的明天”。 微软要真正转型为AI公司，就必须接受自己不再是技术的中心，而是平台和基础设施的提供者。但当GitHub上最火的AI工具不是自家的Copilot，当Office的用户开始使用Claude来写文档，当Azure的大客户开始自研AI能力时，微软的管理层该如何向董事会解释这一切？ 这不是能力问题，甚至不是战略问题——这是结构性问题。大公司被它们的成功所绑架，被它们的利益相关者所牵制，被它们的组织惯性所拖累。 技术的异化：从工具到主宰让我们把视角拉高一些。 如果AI的发展方向是正确的——如果AI真的能够在一两年内达到甚至超越人类在大多数认知任务上的能力——那么我们面临的不仅是几家大公司的商业困境，而是整个经济体系的根本性重构。 Anthropic CEO Dario Amodei曾警告：AI可能在未来1-5年内消灭一半的入门级白领岗位，导致美国失业率上升至10-20%。世界经济论坛的报告指出，41%的雇主计划在2030年前因AI而裁员。 这不是遥远的未来，这是正在发生的现实。 根据马克思的理论，生产工具的进步必然带来生产关系的变革。蒸汽机带来了工厂制度，电力带来了流水线，互联网带来了平台经济。那么AI会带来什么？ 当一个AI Agent可以在几小时内完成一个初级程序员一周的工作量，当Claude Code开始占据GitHub提交量的五分之一，当AI助手可以撰写研究报告、分析财务数据、设计营销方案时——我们还需要那么多”知识工作者”吗？ 资本和利益正在加速向少数人聚集。AI公司的估值飙升，而传统企业的员工面临失业；技术精英的收入水涨船高，而普通劳动者的议价能力持续下降。生产效率提高了，但财富分配的不平等也在加剧。 一个更根本的问题回到克里斯坦森的框架。他说大公司死于”对现有价值网络的过度忠诚”。但如果整个经济体系都是一个巨大的”价值网络”呢？如果我们所有人——消费者、劳动者、投资者——都被锁定在这个网络中呢？ AI解决了生产效率的问题，但它还没有解决——甚至可能加剧了——财富分配和消费循环的问题。 生产工具进步了，但生产出来的东西卖给谁？如果AI取代了大量工作岗位，失去收入的人如何消费？如果财富集中在少数AI公司和技术精英手中，庞大的中产阶级市场如何维持？ 这是一个充满挑战和智慧的问题。AI自己如果足够聪明，或许应该先想办法解决这个问题——因为没有消费者，就没有市场；没有市场，AI再强大也无法创造真正的价值。 结语：在颠覆与被颠覆之间2025年是AI能力爆发的一年。越来越多的人开始相信AI不是泡沫，它是真实的、正在发生的技术革命。 但这不代表那些大公司不是泡沫。它们拖着庞大的躯体追赶前沿，而前沿的企业——Anthropic、OpenAI、还有无数创业公司——尚未证明自己的盈利模式。 市场还有多少耐心？ 或者说，市场最终会被驯服吗？ 也许AI会成为新的基础设施，像电力和互联网一样，不以盈利为目的，而是作为一切经济活动的底层支撑。也许人类会找到新的财富分配方式，让AI的生产力惠及所有人。也许碳基生命会与硅基智能达成某种共生关系，而不是被后者取代。 但这些”也许”都需要我们去争取，去构建，去实现。 在此之前，谷歌和微软们将继续在颠覆与被颠覆之间挣扎。它们的困境，也是我们所有人的困境。 本文引用了克莱顿·克里斯坦森的《创新者的窘境》理论、SemiAnalysis关于Claude Code的市场分析、以及多家机构对AI就业影响的研究报告。","link":"/2026/02/07/ai-giants-dilemma/"},{"title":"2026年，AI Agent 时代真的来了","text":"从”用 AI 聊天”到”指挥 AI 干活”，这不是一次升级，而是一次范式转移。 如果你还在用 ChatGPT 写周报、让 AI 帮你润色邮件，那你可能已经落伍了。2026年初，AI 领域正在经历一场静悄悄的革命——从生成式 AI（Generative AI）到智能体 AI（Agentic AI）的转变。 这不是 ChatGPT-4 升级到 ChatGPT-5 那种量变，而是人机交互方式的根本性质变。 本文综合了近期 Medium 上多篇热门文章的观点，带你看清这场变革的全貌。 一、从”聊天”到”编排”：什么是 Agentic Shift？英国数字化专家 Idris Fabiyi 在他的文章 The Agentic Shift 中提出了一个精辟的比喻： 如果说 2024 年是”聊天（Chatting）”的时代，那 2026 年就是”编排（Orchestration）”的时代。 过去三年，我们一直生活在 AI 的”游乐场阶段”——玩玩聊天机器人，学学怎么写 prompt，感觉像魔法一样。但现在，游乐场关门了。魔法正在被工程学取代。 什么是 Agentic AI？简单来说： 生成式 AI（2023-2024）：你问它问题，它给你答案。本质上是一个很聪明的对话框。 智能体 AI（2025-2026）：它能自主推理、规划、执行复杂的工作流程，最少的人工干预完成任务。 这意味着 AI 不再只是你的”聊天对象”，而是你的”数字员工”。 二、开源 Agent 的爆发：OpenClaw 现象要理解 Agent 时代的到来，最好的例子就是 OpenClaw。 这个开源项目在2026年1月底横空出世，5天内获得了6.6万颗 GitHub Star，总数突破14.5万。旧金山的零售商甚至报告 Mac Mini 脱销——因为爱好者们纷纷买来专门跑自己的 AI Agent。 OpenClaw 到底是什么？用一句话总结：一个运行在你自己电脑上的私人 AI 助手。 它能连接你已有的通讯工具（WhatsApp、Telegram、Discord、飞书、Signal 等29+平台），把你的消息路由到 AI 模型（Claude、GPT、Gemini 或本地模型），然后在你的电脑上执行任务。 关键词是**”本地”**。你的数据不会发送到任何云端服务器。Gateway 运行在你的笔记本、VPS 或树莓派上。你掌控数据、模型和执行环境。 技术架构亮点工程师 JP Caparas 深入研究了 OpenClaw 的 4万行 TypeScript 源码，发现了几个精妙的设计： 1. 车道式并发（Lane-based Concurrency） 大多数异步系统用单一队列，高优先级任务先执行，其他的等着。问题是：大量中优先级任务可能让低优先级任务永远排不上。 OpenClaw 把工作分成独立的”车道”：主聊天、定时任务、子 Agent、嵌套调用各走各的。定时邮件摘要不会阻塞你的即时消息。 这种设计从结构上就避免了资源饥饿问题。 2. 语义快照而非截图 浏览器自动化不是截图发给模型（昂贵、费 token），而是生成语义快照——页面可访问性树的文本表示： 1234- button &quot;登录&quot; [ref=1]- textbox &quot;邮箱&quot; [ref=2] - textbox &quot;密码&quot; [ref=3]- link &quot;忘记密码？&quot; [ref=4] 一张截图可能 5MB，一个语义快照只有 50KB。同样的可操作信息，几十分之一的 token 消耗。 3. 安全分层 Agent 有系统级访问权限，但安全层用白名单机制控制：安全命令（grep、sort、head 等）预先批准，危险操作（如 git push）会推送通知到你手机，等你批准或拒绝。人类始终是最终决策者。 三、Agent 生态正在成型从 GitHub Trending 数据看，AI Agent 的工具链正在快速成熟。以下是2026年2月初的生态全景： 基础设施层 项目 Star 数 定位 OpenClaw 145K+ 个人 AI Agent 平台 claude-mem 17K Agent 记忆系统 agent-lightning (微软) 13K Agent 训练框架 pi-mono 5K Agent 开发工具包 编排层 Maestro：Agent 编排指挥中心，统一管理多个 Agent 的协调工作 Anthropic MCP（Model Context Protocol）：月下载量达 9700 万次，被称为”AI 的 USB-C”——统一了 Agent 与工具的连接协议 接口层 终端：OpenClaw、99（ThePrimeagen 的 Neovim AI Agent） 浏览器：vibetunnel（把浏览器变成终端） 编辑器原生：Cursor、Windsurf 已从被动的”副驾驶”变成主动的 Agent 指挥中心：Maestro 演进路径123阶段1：单个 Agent（Claude Code、OpenCode）阶段2：Agent 团队（lobehub）阶段3：编排指挥中心（Maestro）← 我们在这里 四、Agent Swarm：从单兵作战到群体智能 如果说单个 Agent 是步兵，那 Agent Swarm（智能体群） 就是军团。 AI 研究者 Ignacio de Gregorio 指出，Sam Altman 曾预言”由一个人运营的十亿美元公司”，当时所有人都笑了。但现在，没人笑得出来了。 长时段 Agent（能无缺陷地执行持续数小时的任务）终于触手可及。市场正在为接下来的变化做准备——这对很多传统公司来说不是好消息。 Agent Swarm 的核心理念是：不是一个超级聪明的 AI 做所有事，而是一群专业化的 Agent 协同工作。就像一家公司不是靠一个全能员工，而是靠各司其职的团队。 五、2026 年你需要掌握的三个层级Idris Fabiyi 提出了一个实用的分级框架，帮你定位自己在 Agent 时代的位置： 第一级：AI 审计员（从普通用户升级） 任务分解：把模糊的业务目标拆解成 Agent 可执行的确定性步骤 输出审计：用”法医”思维追溯 AI 的每个声明到源文档，识别幻觉 数字验证：在 Deepfake 泛滥的时代，”零信任”是生存技能 第二级：AI 编排师（从技术达人升级） Vibe Coding（意图编程）：描述你想要的结果，AI 生成底层代码。你不需要精通语法，但必须理解算法逻辑 Agent 编排：管理自主 Agent 团队，定义它们的角色和”交接协议” AI-BOM 治理：了解哪些 Agent 在做什么、访问什么数据（合规要求） 第三级：Agentic 工程师（从开发者升级） 神经符号混合设计：融合神经网络与符号 AI，确保关键业务规则不会被”幻觉”掉 AgentOps &amp; 评估：不再用老方法”测试”代码，而是用更强的 LLM 来评估其他模型的安全性 GreenOps：用”碳感知计算”，在电网最清洁时调度重型 AI 任务 如果你的核心价值是”我会写 Python 代码”，你可能有麻烦了。AI 编程助手已经把语法生成变成了大宗商品。 六、数据说话：Agent 时代的真实信号 以下数据来自多家权威来源，描绘了 Agent 时代的加速到来： Databricks：Agentic AI 使用量激增 327% Salesforce：赢得美国陆军 56 亿美元 Agent AI 合同 MCP 协议：月 SDK 下载量 9700 万次 40% 的职场人担心 AI 会取代自己的工作（2024 年这个数字是 28%） 66% 的 CISO将 AI 威胁列为 2026 年头号安全担忧 OpenClaw：5 天 6.6 万 Star，开源 Agent 史上最快增长 七、写在最后：你是用户，还是架构师？2026 年的 AI 变革不是”要不要用 AI”的问题——那个答案早就是肯定的。真正的问题是： 你是被动地”使用”AI，还是主动地”编排”AI？ Agent 时代的到来意味着： 会写 prompt 不再是优势，那是基本功 理解 Agent 的工作原理、知道如何编排多个 Agent 协同工作，才是新的核心能力 安全性、可审计性、合规性不是可选项，而是法律要求 好消息是，这个生态还在早期。OpenClaw 才几个月大，Agent 编排平台刚刚出现，训练框架还在迭代。现在入场，你还是早期玩家。 坏消息是，窗口期不会太长。当 Agent 生态成熟到”一键部署”的程度，先行者的优势将变成后来者的壁垒。 正如 Fabiyi 所说： “The Agentic Shift is here. The agents are running. The question is: Who is orchestrating them?” Agent 时代已经到来，智能体们已经在运行了。问题是：谁在编排它们？ 本文观点综合自以下 Medium 文章： Idris Fabiyi: “The Agentic Shift: Why 2026 is the Year ‘Using’ AI Isn’t Enough” Jonathan Fulton: “Last Week in AI — February 2, 2026” JP Caparas: “What OpenClaw Actually Runs on Your Machine” Ignacio de Gregorio: “The Agent Acceleration You Can’t Miss is Here” lssmj2014: “GitHub Trending: February 2, 2026” Avner So: “My 2026 AI Predictions”","link":"/2026/02/10/ai-agent-era-2026/"},{"title":"Aspect-Oriented Programming in Android","text":"What is AOP?​In computing, aspect-oriented programming (AOP) is a programming paradigm that aims to increase modularity by allowing the separation of cross-cutting concerns. It does so by adding additional behavior to existing code (an advice) without modifying the code itself, instead separately specifying which code is modified via a “pointcut” specification, such as “log all function calls when the function’s name begins with ‘set’”. This allows behaviors that are not central to the business logic (such as logging) to be added to a program without cluttering the code, core to the functionality. AOP forms a basis for aspect-oriented software development. The Microsoft Transaction Server is considered to be the first major application of AOP followed by Enterprise JavaBeans.​ Similar concepts: Proxy pattern Interceptors &amp; Filters Basic terminology: ConcernsAdvice, Pointcut and Join Point compose an Aspect:​ Primary concerns Secondary and Cross-cutting concerns Joint point Advice Pointcut Described by expressions: AspectJ Pointcut expressions Described by annotations Aspect Weaving AOP processor i.e. the Weaver Weaving timing: At run-time At load-time At compile-time Why do we need AOP?In a word, AOP is an evolution and supplement of OOP General Benefits: Increase modularity and logic clarity and concentration Less tangled code Shorter code Easier application maintenance and evolution Applications that are easier to debug, refactor and modify Code is more reusable in a shape of aspect An idea of resolving complicated process Application of the implementation: help to hook and inject third-party SDKs (So as to block malicious method calls or to monitor or study crucial process, like network communication) Mastering AspectJ: Aspect-Oriented Programming in Java, Joseph Gradecki, Nicholas. WILEY Practice Areas: Logging Permission check Performance Profiling Data check Thread status check How to adopt it? AOP Core Implementation Basic Techniques Weaving time Dynamic Proxy Pattern Java Proxy API Run-time DexMaker DexClassLoader API Load-time AspectJ Java Bytecode Manipulation Compile-time AspectJ: AOP standard extension, the open-source projects Maintained by Eclipse Foundation https://git.eclipse.org/c/aspectj/org.aspectj.git/ Dark side: True Magic or Fancy Stuff?“AOP considered harmful”: Makes control flow obscured: Implicit AOP to Explicit AOPAffect method stack trace: increase its depthRequire additional weaving time “AOP Considered Harmful”. uni-karlsruhe.de. 23 March 2016. Mitigation: prevent invisible code, better use Annotation and combine with DI technique Appropriate use: it’s only a supplement and a way to simplify complicated structure and reuse components, not a software design principle. More about AspectJPointcut expression: 1execution(modifiers-pattern? ret-type-pattern declaring-type-pattern? name-pattern(param-pattern) throws-pattern?) https://docs.spring.io/spring/docs/2.0.x/reference/aop.html https://howtodoinjava.com/spring-aop/aspectj-pointcut-expressions/ As the return value is ignored, the method must be declared as void return. Pointcut described by annotation: Annotated Joint Point: the primary concern. Check log outputs: Other Possible Scenarios: @ProfilerTracker(BuildConfig.DEBUG) @CallFrequencyLimit @CheckPermission(“”), @RequirePermission(“”) How does it work? Technique Anatomy:​​​​​​​​​​​​​​Weaving in Build-time: Next session: Java Bytecode manipulation. Other implementations: Based on the idea of AOP and DI (Dependency Injection), lots of Android opensource frameworks are created to help improve the code structure and modularity. AndroidAnnotations Hugo OTHER REFERENCEShttps://fernandocejas.com/2014/08/03/aspect-oriented-programming-in-android/","link":"/2018/12/27/aop-in-android/"},{"title":"Claude Opus 4.6 vs GPT-5.3-Codex：2026年AI编程双雄同日对决","text":"2026年2月5日，Anthropic与OpenAI同日发布新一代旗舰模型，AI编程领域迎来史诗级对决。 📅 发布概览 项目 Claude Opus 4.6 GPT-5.3-Codex 发布日期 2026年2月5日 2026年2月5日 开发商 Anthropic OpenAI 定位 旗舰级知识工作与编程模型 顶级智能编程代理 上下文窗口 200K 标准 / 100万 Beta 未公布（沿用前代） 最大输出 128K tokens 未公布 推理速度 未公布 比前代快25% 两家同时发布，简直是AI界的”神仙打架”。 🔥 Claude Opus 4.6 亮点1. 100万Token上下文窗口（Beta）这是Opus系列首个支持超长上下文的模型： 可处理约1,500页文本 或30,000行代码 或1小时以上视频 在 MRCR v2 长文档检索测试中： 256K 上下文：93% 准确率 1M 上下文：76% 准确率 比 Sonnet 4.5 提升 4-9倍 2. 自适应思考（Adaptive Thinking）取代旧版 Extended Thinking，四档努力级别： low - 跳过思考，适合简单任务 medium - 适度推理，速度与质量平衡 high（默认）- 大多数生产环境推荐 max - 最高能力，适合最难问题（Opus 4.6 新增） 3. Agent Teams（智能体团队）Claude Code 现支持多代理并行协作： 一个代理处理前端 一个代理处理后端 一个代理管理测试 全部在监督控制下同时工作 4. Claude in PowerPoint（研究预览）直接在 Microsoft PowerPoint 中工作： 理解版式、字体、母版 保持品牌一致性 从描述生成完整演示文稿 5. Compaction API（Beta）服务端上下文压缩，实现无限对话： 自动总结旧对话内容 无需手动管理上下文 对长链路代理工作流特别有用 🚀 GPT-5.3-Codex 亮点1. 统一旗舰架构融合了： GPT-5.2-Codex 的编程能力 GPT-5.2 的推理与专业知识 单一模型完成所有工作，无需切换。 2. 25%速度提升基础设施和推理优化带来显著提速，而且更少的token消耗就能达成同等效果。 3. 自我参与开发这是首个”参与自身创建”的 Codex 模型： 用于调试训练过程 管理部署 诊断测试结果 构建数据管道和可视化工具 4. 高级网络安全能力 OpenAI Preparedness Framework 下首个”高能力”网络安全模型 首个直接训练识别软件漏洞的模型 已发现500+开源项目零日漏洞 推出 Trusted Access for Cyber 试点 $1000万 API 积分投入开源安全防护 📊 基准测试对比（官方数据）编程与代理能力 基准测试 Claude Opus 4.6 GPT-5.3-Codex GPT-5.2 Gemini 3 Pro SWE-bench Verified 80.8% 56.8%* 80.0% 76.2% Terminal-Bench 2.0 65.4% 77.3% 64.7% 56.2% OSWorld 72.7% 64.7% — — SWE-Bench Pro — 56.8% 56.4% — *注：GPT-5.3-Codex 使用的是 SWE-Bench Pro（不同版本），非 Verified 推理与知识能力 基准测试 Claude Opus 4.6 GPT-5.2 Gemini 3 Pro GDPval-AA Elo 1606 1462 1195 GPQA Diamond 91.3% 93.2% 91.9% ARC AGI 2 68.8% 54.2% 45.1% HLE (with tools) 53.1% 50.0% 45.8% MMMLU 91.1% 89.6% 91.8% 代理与工具使用 基准测试 Claude Opus 4.6 GPT-5.2 Gemini 3 Pro BrowseComp 84.0% 77.9% 59.2% Finance Agent 60.7% 56.6% 44.1% τ2-bench Retail 91.9% 82.0% — τ2-bench Telecom 99.3% — — GPT-5.3-Codex 相对 GPT-5.2-Codex 提升 基准测试 提升幅度 OSWorld-Verified +26.5 Terminal-Bench 2.0 +13.3 网络安全 CTF +10.2 SWE-Lancer IC Diamond +5.4 SWE-Bench Pro +0.4 🎯 综合能力对比 维度 Claude Opus 4.6 GPT-5.3-Codex 上下文长度 ⭐⭐⭐⭐⭐ (100万 Beta) ⭐⭐⭐⭐ SWE-bench 编程 ⭐⭐⭐⭐⭐ (80.8%) ⭐⭐⭐⭐ 终端能力 ⭐⭐⭐⭐ (65.4%) ⭐⭐⭐⭐⭐ (77.3%) 计算机使用 ⭐⭐⭐⭐⭐ (72.7%) ⭐⭐⭐⭐ (64.7%) 推理速度 ⭐⭐⭐⭐ ⭐⭐⭐⭐⭐ (+25%) 知识工作 ⭐⭐⭐⭐⭐ (1606 Elo) ⭐⭐⭐⭐ 网络安全 ⭐⭐⭐⭐ ⭐⭐⭐⭐⭐ 多代理协作 ⭐⭐⭐⭐⭐ ⭐⭐⭐⭐ 🎮 怎么选？选择 Claude Opus 4.6 ✅ 需要处理超长文档（100万 token 上下文） ✅ SWE-bench 类型的真实 GitHub Issue 修复（80.8%） ✅ 团队协作型 AI 代理工作流（Agent Teams） ✅ PowerPoint/Office 办公场景深度集成 ✅ 知识密集型工作（GDPval-AA 领先） ✅ 代理搜索与研究（BrowseComp 84%） 选择 GPT-5.3-Codex ✅ 高强度终端/命令行操作（Terminal-Bench 77.3%） ✅ 网络安全研究与漏洞挖掘 ✅ 追求极致推理速度（+25%） ✅ 长周期、多步骤的编程项目 ✅ 需要模型”自我调试”能力 💰 定价与可用性 渠道 Claude Opus 4.6 GPT-5.3-Codex API 定价 $5/$25 per MTok（输入/输出） 待公布 长上下文溢价 $10/$37.50 per MTok (&gt;200K) — 消费者端 Claude Pro/Team/Enterprise ChatGPT Plus 付费版 开发者 API 立即可用 即将推出（数周内） IDE 集成 Claude Code Codex（App/CLI/IDE插件/Web） GitHub Copilot ✅ 已集成 预计后续集成 云平台 AWS Bedrock, Vertex AI, Azure — 🔒 安全特性Claude Opus 4.6 最低错误对齐分数：约1.8/10（所有 Claude 模型中最低） 最低过度拒绝率：合理请求更少被拒绝 数据驻留控制：inference_geo 参数指定推理区域 GPT-5.3-Codex 首个”高能力”网络安全模型 Trusted Access for Cyber 试点项目 Aardvark 安全研究代理扩展测试 为 Next.js 等开源项目提供免费代码扫描 💡 结语2026年2月5日将被铭记为AI编程领域的里程碑日——两大巨头同日亮剑，各有千秋： 领先领域 Claude Opus 4.6 GPT-5.3-Codex 最强项 SWE-bench (80.8%), 上下文 (1M), 知识工作 (1606 Elo) Terminal-Bench (77.3%), 速度 (+25%), 网络安全 总结： 选 Claude Opus 4.6：你需要处理大型代码库、长文档、真实 GitHub Issue，或者重视知识工作能力 选 GPT-5.3-Codex：你主要在终端环境工作、追求速度、或需要网络安全能力 对于开发者而言，这是一个前所未有的好时代——两款顶尖模型竞相进化，最终受益的是整个技术社区。 本文基于2026年2月5日官方发布数据撰写 数据来源： Anthropic Claude Opus 4.6 发布 OpenAI GPT-5.3-Codex 发布 DigitalApplied 基准测试汇总","link":"/2026/02/06/claude-opus-4-6-vs-gpt-5-3-codex/"},{"title":"OpenAI 发布 Codex 桌面应用：让你同时指挥多个 AI 写代码","text":"你还在一个一个地给 AI 下指令？ OpenAI 刚发布的 Codex 桌面应用告诉你：是时候学会「同时指挥一群 AI」了。 这是什么？Codex 桌面应用是 OpenAI 为 macOS 打造的「AI 编程指挥中心」。 以前用 Codex，你得在命令行里敲命令，一次处理一个任务。现在？打开这个 App，你可以： 同时开多个 AI 线程，让它们并行干活 随时切换任务，不丢上下文 设置自动化任务，让 AI 在后台定时工作 用技能扩展 AI 能力，不只是写代码 用 OpenAI 的话说：这是一个「智能体指挥中心」（Command Center for Agents）。 为什么需要桌面应用？Sam Altman 在发布会上说了一句话： 「我们意识到，现有的 IDE 和终端工具，根本不是为这种工作方式设计的。」 以前的 AI 编程助手，本质上还是「你问一句，它答一句」。但现在的 Codex 已经能独立完成复杂的长任务——写一个完整的游戏、重构整个模块、跑测试然后自己修 bug。 当 AI 能做的事变多了，瓶颈就从「AI 能不能做」变成了「人怎么管理这些 AI」。 桌面应用就是为了解决这个问题。 核心功能1. 多线程并行工作每个任务跑在独立的线程里，你可以像切换浏览器标签页一样切换任务。 比如： 线程 1：让 Codex 重构用户认证模块 线程 2：让 Codex 写单元测试 线程 3：让 Codex 修一个紧急 bug 三个任务同时跑，互不干扰。 2. Git Worktree 支持这是个关键特性。 多个 AI 在同一个代码仓库里干活，很容易冲突。Codex 内置了 Git Worktree 支持，每个智能体在自己的代码副本上工作，改完再合并。 你不用担心它们互相踩脚。 3. 技能系统（Skills）Codex 不只是写代码的工具，它可以通过「技能」扩展能力： Figma 技能：直接从设计稿生成前端代码，1:1 还原 Linear 技能：管理项目、分类 bug、追踪发版 部署技能：一键部署到 Cloudflare、Vercel、Netlify 图片生成技能：用 GPT Image 生成游戏素材、UI 图片 文档技能：读写 PDF、Excel、Word 文件 OpenAI 官方提供了一批技能，你也可以自己写。技能一旦创建，在 App、CLI、IDE 插件里都能用。 4. 自动化调度（Automations）设定一个时间表，让 Codex 在后台自动运行。 比如： 每天早上 9 点，自动扫描代码库里的 TODO 并生成报告 每次有新 issue，自动分类和打标签 每周五，自动生成本周代码变更摘要 任务完成后，结果进入「待审核」队列，你有空再看。 5. 两种人格可选有人喜欢 AI 话少、直接干活；有人喜欢 AI 多解释、有互动感。 Codex 现在支持两种人格： 简洁务实型：少废话，直接给代码 对话共情型：多解释，像个搭档 用 /personality 命令切换。 安全机制AI 在你电脑上跑代码，安全是大问题。 Codex 默认运行在沙箱里： 只能编辑当前项目文件夹 网络访问需要你授权 敏感命令（如删除文件）会先问你 你也可以配置规则，让某些命令自动获得权限。 谁能用？ ChatGPT Plus / Pro / Business / Enterprise / Edu 用户：直接用 ChatGPT Free 和 Go 用户：限时免费体验 所有付费用户：限时双倍请求额度 目前只有 macOS 版，Windows 版在路上。 实际案例：让 Codex 做一个赛车游戏OpenAI 在发布会上演示了一个例子： 「做一个赛车游戏，包含不同的赛车手、8 张地图、还有道具系统。」 就这一句话。 Codex 调用了图片生成技能和网页游戏开发技能，自己当设计师、开发者、测试员，用了超过 700 万 token，最终交付了一个可玩的游戏。 它甚至会自己玩游戏来测试 bug。 和 Claude Code 的对比Anthropic 的 Claude Code 也很火，两者有什么区别？ 特性 Codex 桌面应用 Claude Code 界面 原生桌面应用 终端 + Cowork 多任务 内置多线程管理 需手动开多个终端 技能扩展 官方技能库 + 自定义 MCP 协议 自动化 内置调度系统 需外部配合 适合 管理多个并行任务 深度单任务处理 简单说：Claude Code 更像「深度搭档」，Codex App 更像「任务调度中心」。 未来方向OpenAI 透露了几个计划： Windows 版本：正在开发 云端自动化：让 Codex 在云上持续运行，不依赖你的电脑开机 更快的推理：继续优化速度 更强的模型：GPT-5.2-Codex 已经让使用量翻倍，未来还会继续迭代 怎么开始？ 确保你有 ChatGPT 订阅（免费用户限时也能用） 下载 macOS 版：openai.com/codex 用 ChatGPT 账号登录 指向你的代码仓库，开始干活 写在最后Sam Altman 说了一句很有意思的话： 「我认为这将很快成为大多数专业程序员工作的方式。」 从「写代码」到「指挥 AI 写代码」，编程正在经历一次范式转移。 Codex 桌面应用不是给 AI 加了个好看的外壳，而是承认了一个事实：当 AI 足够强，人的角色就变成了「指挥官」。 你准备好指挥你的 AI 军团了吗？ 相关链接： OpenAI 官方介绍 开发者文档 技能仓库","link":"/2026/02/06/codex-desktop/"},{"title":"Gradle插件开发秘籍之断点调试（基于Intellij）","text":"Gradle插件开发这件事说大不大说小不小，但是对于有一定体量规模的Java项目来讲，从插件开发入手来思考解决问题，有的时候能找到意想不到的法门。所以说这是一门锦上添花的手艺。 废话少说，相信对于很多Gradle插件开发朋友们，开发过程中很大的一个痛点就是，插件的调试很痛苦，下面我就分享一下在这方面的心得。 1. 增加运行参数好吧这个很菜鸟，比如很常用参数的是–stacktrace，报错后会打印出堆栈信息 2. Log输出控制这个不多说了，println就可以了，可以自己设置一些分级和flag。 3. Attach a debugger！先上最终效果图： 如上图，是可以正常地设置断点调试和step into和step out、resume等等。实现办法和原理：大家都知道Gradle基于Groovy，而Groovy其实就是Java，所以也同样遵循JDWP协议，只是这个技巧似乎在国内的文章中没有人出来分享，我就在此分享给大家。首先，在你要执行gradle命令的环境中加入如下环境变量（以Linux、MacOS为例）： export GRADLE_OPTS=&quot;-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5005&quot; 其中，address等号后面的参数就表示debugger要监听的端口，这里我们设置为5005。然后执行gradle或gradlew任务，会发现有如下提示： 这时任务就不会继续执行了，挂起等待Debugger的handshake！这时我们启动IDE，以Intellij为例，打开我们的gradle插件项目（包含正在运行的插件源码的项目），然后找到工具栏的执行区域，进入如下： 在界面里添加一个运行项，Remote： 需要配置的最核心参数就是如图所示的端口号，就是上文中的address: 注意到下面有一个Search sources using …意思是从什么范围查找源码，保持默认就好了，这个debugger收到JDWP消息后会从当前工程中搜索源码，基于当前的源码进行与gradle命令行中的JDWP agent进行交互。 OK，如果插件源码中打好断点，执行到代码时就会挂起在相应位置了，大部分调试功能都很好使，大家可以尝试一下！这个技巧还是比较简单的，大家只要了解一下JDWP的核心原理，就可以理解上述过程了！ 时间有限，如有不妥，欢迎指正！","link":"/2017/02/06/gradle-debug-tips/"},{"title":"GitHub 重磅更新：一个指令，Claude、Codex、Copilot 任你调遣","text":"GitHub 要变天了。 凌晨，微软 GitHub 官宣重磅更新：正式集成全球「最强编程大脑」—— Claude 和 Codex。加上自家的 Copilot，地表最强编程三剑客终于迎来史诗级合体。 这意味着什么？开发者只需一个指令，三个 AI 任你差遣，瞬间完成编码、修 Bug、提交 PR 等复杂任务。GitHub 正从一个单纯的代码托管平台，进化为多智能体协同的「AI 战场」。 告别「上下文地狱」软件开发中，最耗神的就是「上下文切换」。 以前用 AI 辅助编程，你可能需要：在 ChatGPT 里问架构问题，在 Copilot 里补全代码，再切到 Claude 让它帮你 review。每次切换，思路都要断一下，效率大打折扣。 现在？全在 GitHub 里搞定。 通过新发布的 Agent HQ（智能体总部），开发者可以直接在 GitHub 网页端、手机 App、VS Code 里一键调用三个顶级 AI。上下文不丢，历史可追溯，PR 直接提交。 用 GitHub 首席产品官 Mario Rodriguez 的话说： 「上下文切换就是摩擦。有了 Agent HQ，你可以用不同的智能体完成不同的步骤，从构思到落地一气呵成，不用换工具，不会丢上下文。」 三个大脑，各有所长 最让程序员兴奋的玩法是：针对同一个编码难题，可以同时指派三个 AI 一起干。 把费时的重活儿丢给多个 AI 异步处理，喝杯咖啡的功夫，就能看到一份详尽的日志和写好的 PR 建议。然后对比它们的解题思路，选最优方案。 三个 AI 各有特点： Copilot：手速最快的「外挂键盘」微软自家的 AI 编程助手，最大优势是无缝集成。它像一个装在编辑器里的超级代码补全器，响应快、补全准，适合日常编码和快速迭代。 Claude：深思熟虑的「建筑师」Anthropic 的推理型 AI，擅长复杂推理和架构评审。它在动手前会先给你一份详细的行动计划，让你审查。适合大规模重构、理解陌生代码库、调试涉及多个系统的疑难杂症。 Anthropic 平台负责人 Katelyn Lesse 表示： 「我们的目标是让开发者在需要推理能力的地方就能获得它。通过 Agent HQ，Claude 可以直接提交代码、评论 PR，帮助团队更快、更有信心地迭代和交付。」 Codex：能独立干活的「AI 队友」OpenAI 最新发布的编程智能体，最大特点是自主性强。你可以像给新同事分配任务一样给它一个高阶目标，比如「帮我把前端框架从 Vue 2 升级到 Vue 3，确保所有单元测试都能跑通」，然后它会自己规划步骤、读写文件、执行命令、运行测试、分析错误，甚至在测试失败后自我修正。 OpenAI 的 Alexander Embiricos 说： 「最初的 Codex 模型帮助驱动了 Copilot，开启了 AI 辅助编程的新时代。现在，数百万开发者可以直接在他们的主要工作空间中使用 Codex。」 实战场景：怎么选？ 场景 推荐 理由 实现新功能 Copilot 响应快，diff 简洁 大规模重构 Claude 擅长规划，能在多文件间穿梭 理解陌生代码库 Claude 代码库映射和架构总结能力强 快速 Bug 修复 Codex 极擅长生成最小化 diff 从零构建项目 Claude 长上下文处理和整体架构理解更优 代码审查 都行 Copilot 擅长发现逻辑错误，Claude 擅长评估架构风险 聪明的做法不是二选一，而是把它们都放进工具箱。用 Copilot 日常快速开发，用 Claude 处理架构性问题，用 Codex 跑那些费时的重活儿。 企业级管控不只是个人开发者的玩具，Agent HQ 为团队提供了完整的管控能力： 智能体策略：管理员可定义哪些智能体和模型允许在组织内使用 代码质量检查：GitHub Code Quality 自动评估可维护性 自动化初审：Copilot 先自己 review 一遍，再交给人类 影响指标：Copilot Metrics Dashboard 追踪全组织使用情况 审计日志：企业级访问管理，智能体操作全程可追溯 所有智能体的操作都会被详细记录，产出的代码会像普通开发者提交的一样，走正常的 review 流程。这就是微软说的「可评审、可对比、可质疑」—— AI 也会犯错，所以设计成人类来把关。 费用和使用门槛目前，Agent HQ 对 Copilot Pro+ 和 Copilot Enterprise 订阅用户开放公测。 每次启动智能体任务，会消耗一个「高级请求」（Premium Request）额度。Pro+ 用户每月有 1,500 个额度，Enterprise 用户有 1,000 个，超出部分 $0.04/次。 GitHub 表示，Claude 和 Codex 的使用权限将很快扩展到更多订阅类型。 未来路线图GitHub 正在与更多 AI 厂商洽谈合作： Google：旗下的 Jules 编程智能体即将入驻 xAI：马斯克的 AI 公司也在接入中 Cognition：以 Devin 闻名的 AI 编程公司 Copilot CLI：命令行版本即将支持多智能体 怎么用？ 确保你有 Copilot Pro+ 或 Copilot Enterprise 订阅 访问 github.com/copilot/agents 在 GitHub 或 VS Code 中选择你想用的智能体 开始干活！ 在 Issue 或 PR 里 @Copilot、@Claude 或 @Codex，就能指派任务。智能体会异步执行，完成后通知你 review。 写在最后2026 年，我们不需要再纠结「哪个 AI 工具更好用」。 唯一的命题是：团队该如何指挥这支「智能体舰队」，去碾压低效的工作流？ 开发者真正写新代码的时间只占 20%。剩下的 80%——重复的 Bug 分拣、枯燥的文档更新、繁琐的 PR 审查——才是 AI 真正的主战场。 别再只盯着屏幕敲代码，学会像「舰队指挥官」一样思考。这不是 AI 取代程序员，而是让程序员指挥 AI 军团。 原文链接： GitHub 官方博客 The Verge 报道 The New Stack 深度分析","link":"/2026/02/05/github-agent-hq-claude-codex/"},{"title":"15分钟入门23种设计模式：图解，范例和对比","text":"本文力图在15分钟内，通过UML图解、范例和类比，让你对面向对象的23种设计模式形成提纲挈领的认识，从而让我们在面临代码设计问题时更加成竹在胸。本文源代码： UML, Sample Code。 开门见山我们直奔主题，分类呈现23种设计模式的庐山真面目： 创建型 (5)Creational 结构型 (7)Structural 行为型 (11)Behavioral 工厂方法 Factory method抽象工厂 Abstract factory建造者 Builder原型 Prototype单例 SingleTon 适配器 Adapter桥接 Bridge组合 Composite装饰 Decorator外观 Facade享元 Flyweight代理 Proxy 责任链 Chain of responsibility命令 Command解释器 Interpreter迭代器 Iterator中介 Mediator备忘录 Memento观察者 Observer状态 State策略 Strategy模板方法 Template method访问者 Visitor 这23种设计模式源于GoF所著的”Design Patterns - Elements of Reusable Object-Oriented Software” 一书（也有将该书直接简称为GoF），译著为 “设计模式：可复用面向对象软件的基础”。原书将这23种设计模式分为三类： 创建型包含5种模式，涉及对象/对象组合的创建构建。 结构性包含7种模式，涉及对象/类之间的关系。 行为型包含11种模式，涉及对象/类的行为、状态、流程。 从该书的标题我们可以了解到，设计模式是一个面向对象开发方法下的概念，是解决代码设计/软件架构问题的可复用的元素，同时是基本元素（elements）。引用原书的例子，我们大家所熟识的MVC模式，Model-View-Controller，就可以解构为几种设计模式的组合演变，比如可以在View和Model的关系中看到观察者模式 Observer、组合模式 Composite、装饰模式 Decorator，在Controller中发现策略模式的影子。通过对23种基础模式的有机利用和结合，可以进一步演化出更复杂的软件架构。限于篇幅，本文不会讲解每种设计模式的定义和背景，读者可以参考设计模式简介来学习定义。 设计模式的UML、类比和范例这个部分，我们逐步从尝鲜到类比，深入理解一些比较常见有趣的设计模式的UML及其经典实例。GoF原书中也推荐学习者从“模式怎样相互关联”以及“研究目的相似的模式“出发来学习和选择设计模式。首先看看最简单常见的策略模式和另一个同属行为型模式的状态模式： 策略模式 Strategy 状态模式 State UML 范例 - Comparator#compare() 和 Collections#sort()- Spring Security: PasswordEncoder - 标准范例: javax.faces.lifecycle.LifeCycle#execute()- 形似样例：Java Thread State, ExoPlayer 概述 让外部对算法的相互替换无感 允许一个对象根据内部状态改变行为 关键字 Strategy, rule State, switch, phase, lifecycle 核心角色 Strategy State 策略模式和状态模式在UML图形上非常相像，他们之间的主要区别如下： 状态对象可以持有上下文对象（调用方），但策略模式一般存在这种依赖。 状态模式可以在彼此之间进行跳转替换，比如调用了播放器的play方法，那么状态可能从stop-&gt;playing，这个操作可以用状态对象完成。 一个策略和调用方的关系（依赖）可能弱于状态和上下文对象的关系（持有、属性）。 策略的不同可能只影响一个行为，但是状态的不同影响状态持有对象行为的方方面面。 整体上策略模式要比状态模式更加简明易懂，应用场景更广，在大型项目中的应用也随处可见。而状态模式虽然也是对常见概念的抽象，其应用却相对有限，其原因可能是，在更多的情况下，把行为的差异定义在不同的状态中，可能并非符合直觉的操作：与其把状态也定义为对象承载行为，不如把状态定义为一个标记，直接用if或switch判断来的直接。或者换言之，大多数情况下，问题还没有复杂到要用状态模式的程度。 借助这种对比的视角，我们来学习更多模式。先看看以下三种结构型设计模式： 适配器 桥接模式 外观 UML 范例 RecyclerView.Adapter 范例比较少：- Collections#newSetFromMap()- (ADB?)，如Spring中Service和Repository的关系 常见，如：Facades, FacesContext, ExternalContext, DataSource#getConnection() 概述 将一个类的接口转换成满足另一个要求的接口 将抽象部分与它的实现部分分离 为子系统中的一组接口提供一个一致易用的界面 关键字 Adatper Wrapper Context 核心角色 Adpter, Adaptee Bridge Facade 适配器模式、桥接模式和外观模式同属结构型设计模式，他们三者概念上很相像，都是通过建立接口来为类的方法建立或重构关系，比如，似乎我们用外观的视角去解释适配器，也能解释的通，Adapter就是在帮助Adaptee建立统一界面，或者建立桥梁。 设计模式就是这样，非要较真，所有的设计模式都大同小异（至少在一个类型之内），这是学习设计模式的一个误区。回到上面的三个设计模式上，他们的核心区别更多体现在时机和出发点上：适配器Adapter强调兼容性，桥接Bridge强调抽象与实现的分离，而外观Facade强调简化复杂性。我们分辨这些模式也应该从意图出发来看。 Spring的三层结构也融合体现了Facade和Bridge的设计，Service和Repository之间偏重体现Bridge模式理念，而Controller和Service之间更像Facade模式：Controller整合Service，对外提供API: 下面我们再看几种常见的行为型模式的类比分析： 代理 装饰 中介 UML 范例 - Java Reflect API: Proxy - Java EJB: Enterprise JavaBean, JavaX Inject, JavaX PersistenceContext- ActivityManager 和 ActivityManagerService- PerformanceInspectionService 和 PerformanceTestManagementService - Java IO: GZIPOutputStream and OutputStream, Reader and BufferedReader- java.util.Collections, checkedXXX(), synchronizedXXX() 和 unmodifiableXXX() 系列方法，拓展集合 - HttpServletRequestWrapper and HttpServletResponseWrapper- JScrollPane - Java Message Service, JMS by Oracle - java.util.Timer (all scheduleXXX() methods), java.util.concurrent.ExecutorService (the invokeXXX() and submit() methods) 概述 通过代理来控制对一个对象的访问 动态地给一个对象添加功能 封装对象之间的交互（传话筒） 关键字 Delegate Wrapper MessageQueue, Dispatcher 核心角色 Proxy Decorator Mediator 这里，从类之间关系上看，代理和装饰更为相似，而中介则不同，它只是名字上和代理相近。关于代理(访问和控制)和装饰（增强和扩展）的区分，同样可以从目的和意图的角度区分。以代理来为例，它的首要作用是建立访问通道，比如安卓中，应用和系统之间用Binder来进行IPC，而在应用进程和系统进程间，为了这种IPC调用，大量应用了代理模式，名为Proxy的对象随处可见。而在设计Hydra Lab的过程中，为了让测试用户能方便的在测试实例中通过SDK访问一些Hydra Lab Test Agent的服务方法，我们也应用了一个简明的静态代理来实现这种不同环境下的访问。 在代理模式下，有了访问通道，自然就可以做到对通信的控制，比如基于权限的、或是基于格式验证的。而装饰模式着眼于增强、扩展，比如BufferedRead对于Reader的增强。从这个角度讲，一个类如果叫AuthWrapper就会比较奇怪，AuthProxy则更常见一些，因为授权这种操作明显更强调控制。当然这取决于具体情境。 中介其实是很宽泛的概念，解耦通信的双方或多方，比较火热的各类MQ框架其实是这个模式的一个衍生。 观察者 访问者 UML 范例 - java.util.Observer, Observable- java.util.EventListener- ReactiveX Interface Observer - AnnotationValueVisitor- ElementVisitor- TypeVisitor- SimpleFileVisitor- VisitCallback- ClassVisitor (ASM 9.4) 概述 对个观察者监听一个主题对象 表示一种对某对象中各元素的只读操作 关键字 Observable, Observer, Subject,Subscription Visitor 核心角色 Observer, Subject Visitor, Element 这两个模式之间在实现上其实并没有太多联系。但二者都是想去“读”，不会直接改变被读对象的状态。观察者通过订阅监听的方式被动地读，而访问者是主动视角，以一种独特的方式读。和观察者很相近的“Listener”，是更常见的概念，更轻量，因而也更广泛。 责任链 备忘录 UML 范例 - OkHttp Interceptors- java.util.logging.Logger- javax.servlet.Filter - Activity#onSaveInstanceState(…) - Java Serializable 概述 建立处理链条传递请求 捕获对象状态并保存，以备状态恢复 关键字 Chain, Interceptor, Filter, proceed, Response State, Lifecycle, Context 核心角色 Handler Memonto, Originator, Caretaker 责任链和备忘录模式虽然意图和设计上都不相同，但二者都有非常浓厚的IoC控制反转的味道，和生命周期的设计联系紧密。玩游戏的同学对备忘录模式最容易建立理解，一个存档就是一个持久化的State，游戏本身的存读档服务作为caretaker，帮你保证你肝的进度不会白费。所以备忘录模式其实非常的常见，软件世界里俯拾皆是。 命令 解释器 UML 范例 - IShellOutputReceiver- Java Runnable - java.util.Pattern- java.text.Normalizer- java.text.Format- javax.el.ELResolver 概述 将请求封装为对象，从而方便参数化和请求队列管理 定义文法和表示方式 关键字 Executor Expression 核心角色 Command, Receiver, Invoker(Executor) Interpretor, Expression 上面两者也无法直接类比，但是当二者合体，命令的解释和执行一气呵成，一个脚本语言的c执行器雏形就诞生了。这里的命令模式其实比“命令”本身在设计上有更周全的考虑，它还包括了对执行结果的接收接口的预留。 抽象工厂 工厂方法 UML 范例 - DocumentBuilderFactory(JavaX) - TransformerFactory(JavaX)- XPathFactory(JavaX)- BeanFactory#getBeanProvider(Spring) java.util.Calendar#getInstance() 概述 将一个类的接口转换成满足另一个要求的接口 由工厂的子类决定创建的实例对象 关键字 Factory, new…, create… Factory, newInstance, Creator 核心角色 AbstractFactory Creator 其他模式还包括：建筑者模式，原型模式，享元（类似多例），单例；组合；模板方法，迭代器。这些模式或是不常用，或是过于常用常见，且都比较简单，限于篇幅本文不再一一详述。 通过这个类比学习的过程，我们可能会逐步感受到，设计模式的重点并不在于类之间关系的严格定义、罗列和排布，无意义的争辩、论证会陷入“把设计模式当作一个严格的学术理论”的误区。更多的，我们应该从问题的意图出发，发散思考解决方案中可能包含的设计元素，然后根据实际情况精简到合理的规模。 所以我们不必纠结于相近的两种模式的严格界定和区分，比如，无需辩驳一种实现究竟是用的代理还是装饰，而是理解这两种模式的看问题的角度和意图，融会贯通，灵活组合运用：如果你强调的角度是功能拓展，那设计方案就是装饰；如果你强调的是访问控制，那就是代理。很多初学者觉得很多模式很相似，感到多余，这是很正常的感受和学习阶段；随着更多应用和实战，你会成长和洞察更多模式的意义；后来你已经成为设计大师，灵活运用设计模式、AOP、函数式、算法乃至ML解决各类问题，讲述和推动方案的实现，设计模式的探讨和辩论只不过是茶余饭后的谈资。这一点，在原书“怎样选择设计模式”章节中，也有提及。 总结来讲，初学设计模式，关注点可以放在： 这个设计模式解决什么类型的问题，意图是什么，以及它如何对概念进行抽象（关键角色）和解决（接口、关系）的。 用设计模式作为大家沟通软件设计的语言，掌握这些术语，减少沟通成本。 如何学习和使用设计模式本部分内容源自GoF原书中1.8章的内容“怎样使用设计模式”，精简了原书的7步为6步，并去除了翻译腔： 浏览一遍该模式，掌握关键要素这个模式的名字是什么，意图是什么，里面的关键角色是什么，常见的关键词？ 回头去研究结构部分、参与者部分和协作部分进一步了解角色的职责和关系，有哪些接口，以及模式的适用性：这个模式更适合解决什么类型的问题？ 看看示例代码例子能让我们了解模式解决的实际问题，成为我们实现的参考。 参考模式中的命名方法比如，在Strategy模式中，你可以直接给算法命名末尾加上Strategy来体现这个模式；再比如，可以用create作为方法的开头前缀来凸显工厂方法。 定义类和接口选定好模式、完成命名后，下一步可以建立好类与接口之间的继承/实现关系，定义代表数据和对象引用的实例变量。 实现模式开始依据模式实现解决方案。 设计模式的引入是带有一定成本的，学习成本和复杂性的增加就是其中之一，也可能会有性能上的损耗（虽然可以忽略），但它为架构带来了灵活性，使其更加清晰可维护。接下来，作为拓展阅读，我们可以探讨一下设计模式的意义，获得更深的理解。 设计模式的意义和批判谈及为什么需要设计模式时，首先要回答什么设计是好的设计。软件是对现实问题复杂性的抽象和管理，Uncle bob说：“软件应该是可变的”，正如现实世界“唯一不变的就是不断地变化”，软件应该能灵活地应对现实世界的需求。所以我们会讨论软件架构的可扩展性、可维护性、高可用、可重用、可移植性等。如果你只是在编写一个又一个的脚本、一次性工具或者编程练习题，当然不用把问题复杂化。但如果你希望你的软件有更强的生命力和更广阔的前景，那就要严肃对待软件设计，防止代码腐化。 此外，一个人的力量是有限的，如果希望借助协作来扩大软件的服务范围、影响力，那么可读性也就重要起来。“Good code is like well-written prose”，好代码应该像优美的散文；至少是自解释的。引述GoF的原文，“所有结构良好的面向对象软件体系结构中都包含了许多模式…内行的设计者知道：不是解决任何问题都要从头做起…这些模式解决特定的设计问题，使面向对象设计更灵活、优雅，最终复用性更好。”所以这里的两层意思就一方面强调了模式对软件设计本身的好处，一方面说明了这些模式建立了大家在面向对象设计上的共识和交流基础。此外，大师们还总结了一些设计原则来框定好的设计。 SOLID设计原则尽管很多教程将设计原则和设计模式放在一起讨论，暗示设计模式是遵从了设计原则，实际上他们并非同出一家。而且设计原则有很多种说法，这里我们分享Uncle Bob提出的最容易记忆的版本，SOLID 原则： Single responsibility, 单一职责原则 SRP：就一个类而言，应该仅有一个引起它变化的原因。 Open-close, 开闭原则 OCP：软件实体应该对于扩展是开放的，对于修改是封闭的。 Liskov substitution, 里氏代换原则 LSP。子类型必须能够替换掉它们的父类型。把父类实例替换成子类实例，程序行为不应该有变化。 Interface segregation, 接口隔离原则 ISP。 一个类对另外一个类的依赖性应当是建立在最小的接口上的。 客户端程序不应该依赖它不需要的接口方法（功能）。 Dependency inverse, 依赖倒转原则 DIP： 高层模块不应该依赖低层模块。两个都应该依赖抽象。 抽象不应该依赖细节，细节应该依赖抽象。 我们可以认为这些设计模式是解决设计问题思考的准绳，也可以认为他们只是一种理念。正如Uncle bob 所说：”The SOLID principles are not rules. They are not laws. They are not perfect truths… This is a good principle, it is good advice…”。总之，了解这些可以帮助我们把握思考方向，但不能帮我们解决问题。换言之，对于初学者而言，设计原则可能没有设计模式那样强的实战意义。 批判之声关于设计模式的批判，源自于对其创立所处时代的主流编程语言的局限性的挑战，以及对于面向对象本身的质疑。有人认为设计模式的提出反映了Java和C++自身语言特性的缺失；也有认为如果灵活运用aspect-oriented-programming，就用不着搞出来23种之多啰啰嗦嗦的设计模式了。对此，笔者觉得纯粹的理论上的对错没那么重要，软件开发是科学和艺术的结合地带，而设计模式是一个时代开发者思考的精华沉淀，能给我们带来的不仅是具体方案，更多的是解决问题的思维方式，它们本身就存在于大量的编程实践中，GoF对他们进行了提炼和综述，这本身就是意义巨大的成果了，更何况他们已经成为工程师文化的一部分，成为了术语。例如，我们从Spring中既能看到AOP的应用、函数式编程的应用，也能看到建造者、工厂模式、策略等等的应用。编程大师应该是博学和不拘一格的，代码的艺术正在于灵活和适时的运用，囿于固执信仰而拒绝经典或者新知断不可取。 其他常见疑问FAQQ: 设计模式和后续流行的的Reactive、函数式编程、AOP、IoC以及DI之间的关系是什么？ A: 总体上，这些是不同维度的概念，总结为下表： 概念 释义（译） 范畴 设计模式 Software design pattern 软件设计的解决方案 IoC 控制反转 Inversion of control 软件架构层面的一种设计模式 DI 依赖注入 Dependency injection 一种设计模式 AOP Aspect-oriented programming，面向切面的编程 编程范式（面向对象） 函数式编程 Functional programming 编程范式（声明式） Reactive Reactive programming, 响应式编程 编程范式（声明式） 微服务 Microservices 一种架构模式（面向服务的架构） Q: 是否还有其他设计模式？ A: 有的，随着软件开发实践的演化，有越来越多的设计模式被总结出来，只不过可能还没有一本经典将其整理入册。比如常见的锁的双重检查，也被认为是一种独立于语言的并发型设计模式。DI也是设计模式 Concurrency Patterns，其角色包括注入器Injector，服务Service，客户端Client和接口Interfaces。DI也是一种创建型Creational设计模式，其意图在于优化类之间依赖关系，因而和整个软件或模块的架构的相关性更密切。 References Design Patterns, Elements of Reusable Object-Oriented Software https://en.wikipedia.org/wiki/Software_design_pattern http://butunclebob.com/ArticleS.UncleBob.PrinciplesOfOod https://en.wikipedia.org/wiki/SOLID https://sites.google.com/site/unclebobconsultingllc/getting-a-solid-start https://en.wikipedia.org/wiki/Law_of_Demeter https://www.jianshu.com/p/8cbc4bf897cb https://coderanch.com/t/99717/engineering/Bridge-Facade-Pattern https://stackoverflow.com/questions/3477962/when-do-we-need-decorator-pattern https://stackoverflow.com/questions/6366385/use-cases-and-examples-of-gof-decorator-pattern-for-io https://stackoverflow.com/questions/1673841/examples-of-gof-design-patterns-in-javas-core-libraries/ 关于我我是风云信步，目前在微软中国担任研发经理。希望在这个空间和大家分享交流技术心得，职业生涯，团队和项目管理，趋势动态。旨在畅谈、分享和记录，不拘小节；但也不排除刨根问底、钻牛角尖。 本人热爱技术和打码，尤其享受用技术解决实际问题的过程和结果；相信创造力是顶级能力，是人价值的放大器。此外，本人专注于软件和代码质量、工程效率和研发能效方面多年，目前在微软和团队一起推动2023年新开源的项目Hydra Lab的完善与发展；欢迎和我在开源世界组队打码，造轮子 or 添砖加瓦。","link":"/2022/10/15/design-patterns-all-in-one/"},{"title":"如何阅读一本书","text":"近来读了不少不同类别的书，清偿了一些读书债；特别地，还翻了翻一本叫”How to read a book”的书，颇有感悟，总结为此文。","link":"/2022/10/31/how-to-read-book/"},{"title":"代码中的人文故事：从一个Java的“Bug”说起","text":"缘起这几日闲来无事撸代码，无意中发现一桩趣事。原以为是一个Java的bug，没想到经过一系列死磕，挖掘出了一段和中国历史乃至人类文明相关联的人文故事，不禁唏嘘感叹一番。 这件事的缘起很简单，我在实现计算两个日期天数距离逻辑的过程中，发现了一个很诡异的事情，同样的起始日期，用python和Java计算出的结果居然不一样！ 例如，计算一个1990年1月1日到1990年9月4日之间的天数，用python计算如图： 得出天数为246。可以看到，python的API设计简单。 用Java计算则不同了，众所周知Java推荐的Calendar API不是一般的麻烦，实现函数如下： 按照这个逻辑测试如下： WTF!?得出的天数居然是245天？为什么和Python算出来的不一样？我马上实际数了一下，应该是246天，Python算的结果是对的！ 仔细核对了程序实现，没毛病啊？难道有精读损失？ 狐疑（懵逼）进而加入如下输出： 什么鬼？这0.0416666667天跑哪里去了？需知： 也就是说，Java计算的时间和实际正好差了一个小时！ 无独有偶，各种百度后，居然发现了和我有类似疑问的兄弟：https://ask.csdn.net/questions/241889然而这个提问下并没有靠谱的答案！ 这样看，似乎很像时区上出了问题，然而并不是，前后Calendar对象的时区完全一致！都是Asia/Shanghai！ 由此难免要想，难道Java代码有Bug？把这一个小时给吃了？好吃吗？啥味道？ 然而，用同样的函数，计算990年1月1日到1990年12月4日之间的天数，有一切正常了！ 心中万马奔腾啊！ 经过一番探索，我又写了如下代码： 惊奇地发现： 进而又发现： 由此我灵机一动，又写了一段代码，找到从1900年至今所有当天长度非24小时的日期！ 此中必有蹊跷！ 豁然然而这对于没文化的我来说，实在是一件不可理喻的事情。只能从源码入手了！ 找源码的过程就不再赘述了，总之，时间的偏移来自于一个zoneOffsets的数组，而这个数组中除了因为时区而产生的偏移外，还有一个神秘的DST_OFFSET！ 找到这里，这个谜团即将揭晓了！ 啥是DST_OFFSET呢？ 没错，daylight saving offset，也就是夏令时！ 也就是说，中国的1990年4月15日这天里，人为地将时间拨快了一个小时，1990年9月16日这天再拨慢回来。进一步说，中国的1990年4月15日这天确实是23个小时，1990年9月16日这天也确实是25小时，Java没搞错！ 也就是说之前找到的所有非24小时的日期，都是中国政府（或国民政府）施行夏令时调整的日期，这段历史断断续续地持续了半个多世纪！而Java的Calendar API将其忠实地记录了下来。 关于夏令时详情见百度百科。哈哈哈，真相揭晓，好感慨好激动。所以说，这并不是Java的bug，而正是Java严谨的体现！Calendar API确实设计的很烂很不友好，但并不代表其中有bug，相反地，这也正体现了其中的工程师精神。 这就引出了一段已经被淡忘的历史，很多90年出生的朋友可以问问父母，90年和91年是我国至今为止实行夏令时的最后两年，我国曾经也想向美国等西欧国家学习，充分利用太阳下的时光！年轻的小朋友问问你们的父母，一定能勾起他们的一段回忆！ 这就是隐藏在Java代码中的一段历史，一段已经被遗忘的人文故事！ 想了解这段历史的同学可戳： 还记得大明湖畔的夏令时吗？ 只要刨根问底，一定有意想不到的收获！感觉解决了个大谜团！","link":"/2018/07/13/java-calendar-story/"},{"title":"Java字节码修改神器HiBeaver：黑掉你的SDK","text":"前言有时候我们在Java开发过程中可能有这样的需求：需要研究或者修改工程依赖的Jar包中的一些逻辑，查看代码运行中Jar包代码内部的取值情况（比如了解SDK与其服务器通信的请求报文加密前的情况）。 这个需求类似于Hook。 但是往往这些依赖的Jar包中的代码已经被混淆过，删去了本地变量表和代码行号等debug信息，所以无法直接断点调试，其内部逻辑和运行情况也几乎无法触及，研究更难以下手。这时候，一般的办法有二： 将Jar反解为Java源码，以module方式引入，便可自由修改调试； 修改字节码或者打包后的smali代码，实现想要的逻辑后再重新打包。 这两种方法中，前者往往十分繁杂，尤其在混淆后逻辑变得极其复杂，几乎不可能完成；后者也很麻烦，工序较多，修改成本也比较高。 插件：HiBeaverGradle编译插件hibeaver结合Java AOP编程中对于大名鼎鼎的ASM.jar的应用，和Android gradle 插件提供的最新的Transform API，在Apk编译环节中、class打包成dex之前，插入了中间环节，依据开发者的配置调用ASM API对项目所依赖的jar进行相应的修改，从而可以比较高效地实现上面的Hook需求。源码地址：https://github.com/hydraxman/hibeaver （现在hiBeaver已经发布了1.2.7版本，支持轻量级AOP框架设计。） 唯一需要注意的是，运用好这个插件需要有一定的Java汇编指令基础，并了解基本的ASM3的使用方法：后者还是很简单的，而前者，关于Java汇编指令基础这块，对于事先不了解的同学，接触起来有一定难度，但是学一学这个其实非常有益处，对于理解Java的运行有很大的帮助。闲话少说，先看看如何快速实践一把！关键看疗效！ 关于汇编指令的资料可以参阅本人的文章：大话+图说：Java汇编指令——只为让你懂 实战演练我们就先来尝试用这个Hook掉小米推送的SDK。 首先，在需要的工程的根项目gradle配置中加入以下内容： 如图所示，该插件上传到了jcenter中，只需引入classpath： classpath 'com.bryansharp:HiBeaver:1.2.7' 这里需要注意的是，目前该插件仅支持Android gradle编译插件2.0及以上的版本。然后，在你的App项目gradle配置底部或任意位置加入如下代码： apply plugin: 'hiBeaver' hiBeaver { //turn this on to make it print help content, default value is true showHelp = true //this flag will decide whether the log of the modifying process be printed or not, default value is false keepQuiet = false //this is a kit feature of the plugin, set it true to see the time consume of this build watchTimeConsume = false //this is the most important part modifyMatchMaps = [:] } 然后，重新编译一下项目，会先去jitpack下载这个插件，开始编译后可以看到Android Studio的右下角的Gradle Console中，多输出了以下内容： 如果你看到了和我一样的内容，那说明初步配置成功。可以看到，使用插件后会输出一段友好的帮助内容，还是中英文的，告诉我们可以直接拷贝作为初始配置，这个帮助输出也是可以关闭的。下面我们正式开始尝试Hook小米推送SDK，首先，找出其业务逻辑中的一个节点。首先，引入小米推送，这个过程不赘述了，blablabla，引入成功！众所周知，使用小米推送需要先在代码中调用如下： MiPushClient.registerPush(this, APP_ID, APP_KEY); 这个代码应该会调起本地长连接的建立、注册服务器等流程。假如我们出于学习的目的，想研究其中的流程，试举一例，先从查看其反编译的代码开始，找一个切入的节点，如下：首先进入查看MiPushClient.registerPush这个方法: 在initialize的方法中，找到一段逻辑如下： 进入a方法，来到了这个类：com.xiaomi.mipush.sdk.u中，发现： 下面如果我们想看看运行时前两个方法传入参数的值，就可以开始Hook了。该如何做呢？这个方法体内打Log输出所有的值吗？那样太麻烦了。我们可以这样做：首先在我们项目的源码里新建一个静态方法，包含两个参数，如下图： 其后，我们只要在a方法中加入一段代码，调用我们的静态方法，并传入我们想查看的两个参数即可。这就有赖于我们的hibeaver插件了，具体如何做呢？我们可以先看看之前的帮助内容： 里面有提到一个the most important par，最重要的部分。没错，这个插件的核心就在于配置这个类型为Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;的传入量。首先我们配置如下： 然后重新编译，发现输出log如下： 这样就输出这个u类的所有方法信息，用于后面进行配置。再来看看刚刚的方法a： 是一个泛型方法，众所周知泛型只存在于编码阶段，编译后是没有泛型的，其实传入的参数的实际类型为org.apache.thrift.a，最终找到其方法描述应该为： (Lorg/apache/thrift/a;Lcom/xiaomi/xmpush/thrift/a;ZLcom/xiaomi/xmpush/thrift/r;)V 进一步配置： 然后重新编译，console输出新增revist部分，如下： 最后，我们增加如下代码，在其中植入我们的代码，调用刚刚的静态方法，并把对应值传递过来：终极配置： 以上代码就不做详细解释了，相信有基础的都能明白，然后编译查看输出: 下面我们debug一下，看看是否可以成功在registerPush的运行流程中调用到我们的方法： 上面可以看到，无论是debug还是log输出都可以抓到想要的参数了。因为小米推送是商业产品，这里不便于探索太多内容，但是通过hibeaver这个插件可以比较方便的进行类似的研究。 总结hibeaver所体现的技术，并没有特别大的价值，仅仅作为工具来讲比较方便易用，有助于学习研究Jar中的逻辑，和学习应用Java汇编码。除此之外，还有几个应用场景：1.修改引用SDK中的一些bug或者提高其效率；2.获得必要的SDK的一些关键调用时机，通过hook建立回调；3.欺骗SDK、关闭或减少SDK中不受控制的网络传输。不一而足，还是很有趣、很有想象空间的。目前存在的问题，如下，这个除了偶尔同步报错之外没有影响，编译正常： 还有，如果仅仅修改了gradle文件，不会触发更新，需要在代码上也进行任意修改方生效。 关于项目hibeaver完全开源，大家可以自行查看其中代码，有大量的中文注释，对于学习gradle插件开发大有裨益。github开源项目地址：https://github.com/BryanSharp/hibeaver","link":"/2017/02/26/java-classcode-edit-toolkit/"},{"title":"一次Java字节码插桩实战","text":"理解本文需要一定的Java字节码指令基础，可以阅读笔者的另一篇文章：大话+图说：Java字节码指令——只为让你懂 利用Android字节码插桩技术可以很方便地帮助我们实现很多手术刀式的代码设计，如无埋点统计上报、轻量级AOP等。下面我们就通过一次实战，把这门技术真正用起来。 奇葩需求假设有这样一个需求，我们需要在本项目工程的所有组件（Activity/Receiver/Service/Provider）的on系列生命周期类方法执行时，调用一个我们写好的方法，传入组件的实例对象，来对组件的相关状态进行监测，如何实现？ 一般的思路有两种： 通过Java继承体系，为我们实现的四大组件分别建立基类，在基类父方法里对监测方法进行调用。 通过Android API Hook技术，即通过动态代理等方法替换关键节点，抓住组件的节点方法并调用我们的监测方法。 上面的第一种方法比较麻烦，而且控制力较弱，也无法顾及我们所依赖的Jar或者aar中的组件，比如小米推送中自带的Service和Receiver，是完全无法触及的。第二种方法则比较强大，但是需要考虑兼容性问题，技术实现上的成本也比较高，毕竟有一些生命周期的节点不好找，难免焦头烂额。 本文对此的实战即通过字节码插桩，在class文件编译成dex之前（同时也是proguard操作之前），遍历所有要编译的class文件并对其中符合条件的方法进行修改，注入我们要调用的监测方法的代码，从而实现这个需求。 HiBeaver 是目前这方面比较完善的字节码插桩Gradle插件，目前最新的1.2.4版本支持通过通配符或正则表达式的方法来匹配目标类和目标方法，进行方法的批量插桩注入和修改，非常灵活易用。对于类似上文提出的需求，实现起来非常方便，唯一前提的仅仅是：知道所有组件的类的全名就可以了。 准备工作好，基于这些，正式开始实战，牛刀小试一下：首先建立一个工程，为便于演示，我们引入小米推送（接入方式不再赘述，详见小米推送文档），然后完善代码到如下状态： MainActivity内容很简单，注册了小米推送，有一个TextView点击后可以跳转到SecondActivity，仅此而已。具体如下： SecondActivity中一切从简： 至于DemoMessageReceiver这个类里完全依照小米推送接入文档中的配置，没有实质改动，不再贴出。注意到还有一个MonitorUtil的类，内容如下： 其中的monitorThis的方法就是我们打算在各个生命周期方法里插入的调用方法。 开始实战下面我们就开始实现开头处提到的需求：通过字节码插桩的方法，本工程里的所有组件的生命周期方法return之前调用我们的monitorThis方法，传入组件实例等信息作为参数。 首先，要引入HiBeaver插件：然后在项目的根build.gradle下面增加classpath如下： classpath 'com.bryansharp:hibeaver:1.2.4' 随后为我们工程的app/build.gradle增加如下配置： apply plugin: 'hiBeaver' import com.bryansharp.gradle.hibeaver.utils.MethodLogAdapter import org.objectweb.asm.ClassVisitor import org.objectweb.asm.MethodVisitor import org.objectweb.asm.Opcodes hiBeaver { modifyMatchMaps = [ //类名称匹配规则，*表示任意长度任意字符，|为分隔符，可以理解为或 '*Activity|*Receiver|*Service|!android*': [ //方法名匹配规则与类名类似，同时也支持正则表达式匹配（需要加r:）；adapter后为一个闭包，进行具体的修改 ['methodName': 'on**', 'methodDesc': null, 'adapter': { //下面这些为闭包传入的参数，可以帮助我们进行方法过滤，以及根据方法参数来调整字节码修改方式 ClassVisitor cv, int access, String name, String desc, String signature, String[] exceptions -&gt; //这里我们有了ClassVisitor实例，其实可以为类添加新的方法。 MethodVisitor methodVisitor = cv.visitMethod(access, name, desc, signature, exceptions); MethodVisitor adapter = new MethodLogAdapter(methodVisitor) { @Override void visitCode() { super.visitCode(); //实例对象入栈 methodVisitor.visitVarInsn(Opcodes.ALOAD, 0); //下面两句我们将方法的名称和描述作为常量入栈 methodVisitor.visitLdcInsn(name); methodVisitor.visitLdcInsn(desc); //调用我们的静态方法 methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, //下面这个MethodLogAdapter.className2Path(String)为 // hibeaver插件提供的方法，可以将类名转为路径名 MethodLogAdapter.className2Path(&quot;bruce.com.testhibeaver.MonitorUtil&quot;), &quot;monitorThis&quot;, &quot;(Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/Object;)V&quot;); } } return adapter; }] ] ] } HiBeaver在类名和方法名的匹配上非常灵活，可以非常方便地实现批量匹配，除了完整匹配外，还支持通配符匹配和正则表达式匹配两种模式。通配符匹配模式中主要可以使用两种符号，即 | 和，表示任意长度（&gt;0）的任意字符，而|表示分隔符，这里可以理解为或。因此，上面的： *Activity|*Receiver|*Service 可以理解为，匹配任意全类名以Activity、Receiver或Service结尾的类。 一般来讲，我们的Android组件在命名上都会遵从这个规范，即组件类名以相应的组件名结尾，对于个别不遵从这个原则的，也可以通过|分隔符来把特殊情况纳入进去。 除此之外，如果存在更复杂的匹配规则，上述通配符已经无法满足，hiBeaver也支持正则表达式进行全类名匹配，只需要在表达式前加上“r:”就可以。比如： r:.*D[a-zA-Z]*Client 表示匹配符合“.*D[a-zA-Z]*Client”这个正则表达式的类名。 更进一步地，HiBeaver 未来 还将支持根据类的继承关系进行匹配，比如： &gt;ext&gt;android.support.v4.app.FragmentActivity 表示匹配所有继承android.support.v4.app.FragmentActivity的类，而： &gt;imp&gt;android.os.Handler.Callback 表示匹配所有实现android.os.Handler.Callback接口的类。不过，目前这两个特性还没有支持，仅提上了其项目的issue中。回到刚刚的配置中，下面的methodName方法的匹配规则与类名匹配用法一样，**和*是一样的效果，on**即表示名字以on开头的方法。好了，编译运行工程，过程中在Gradle Console中可以看到hibeaver进行字节码插桩输出如下（局部）： 程序运行起来，插桩成功，成功调用了monitorThis方法，但赫然发现输出如下： 调用了三个onCreate和若干的onCreateView！这是为什么？我们的MainActivity也没有这个onCreateView的方法啊！ 结合之前Gradle编译日志，在仔细一琢磨，突然明白了： 原来，我们的*Activity规则会匹配所有的Activity结尾的类，包括一些android v4支持包中的类，什么AppCompatActivity、FragmentActivity等继承链上的Activity通通被hook了一遍，难怪会有那么多输出了，可辛苦了我们的monitorThis方法。 既然如此，如何是好？针对于当前的需求，我们当然不想匹配v4包里的组件类。 所幸的是，HiBeaver中还有另一种排除匹配，运用!符号改造如下即可： *Activity|*Receiver|*Service|!android* 这样就表示，匹配前三种之一（或的关系）且不匹配第四个android*的全类名。改好后，再次运行，并点击跳转到SecondActivity： 可以看到log输出一下子少多了，证明没有再注入v4包里的类，同时，小米的组件也被正常注入了，我把网断掉，可以看到小米的Receiver被唤起： 再开启调试，打开网，断点也可以正常进入： 同时，每次HiBeaver进行字节码插桩后还会把修改过、实际使用的字节码保存到build/HiBeaver目录下，以便于查看： 如下图为修改后的MainActivity类： 修改后的小米推送里的某Receiver: 这样，无论是进行节点控制还是研究其运行机制都大大地方便了。 HiBeaver","link":"/2017/03/11/jvm-classcode-practice/"},{"title":"Java bytecode and AOP","text":"What is Java bytecode?Java bytecode is the instruction set of the Java virtual machine (JVM). From https://en.wikipedia.org/wiki/Java_bytecode In a word, just like X86 and ARM or MIPS running on each ABI platform, Java bytecode is executed by JVM engine. And as a machine language defined by JVM specification, Java bytecode plays a much more fundamental part in Java ecosystem than Java language itself. The following picture can be the best case to cast light upon it. https://docs.oracle.com/javase/specs/index.html JVM handles the platform independency. A Java programmer does not need to be aware of or understand Java bytecode at all. However, as suggested in the IBM developerWorks journal, “Understanding bytecode and what bytecode is likely to be generated by a Java compiler helps the Java programmer in the same way that knowledge of assembly helps the C or C++ programmer.” An anatomy of the .class fileClass file dissemble Use this java source code as an example: Java method data structure: https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html Stack-Based Architecture?All the instructions is centered by the Stack-Based Architecture and methodology of JVM. This largely simplifies the instruction set of JVM and therefore make it possible that the opcode size could be limited to 8 bit. In JVM for each thread, a last-in-first-out (LIFO) stack, also known as its JVM stack, is allocated where Java frames are stored. Here is an illustration showing stacks for 3 threads. A new Java frame is created each time a method is invoked and is destroyed when its method invocation completes. It is used to store data and partial results, as well as to perform dynamic linking, return values for methods, and dispatch exceptions. Operand StacksAs opposed to a register-based architecture, stack based one will use stack data structure as its instruction executing and computing playground and notepad, which means each instruction execution will be companied with stack operations like pop and push. The operand stack is empty when the frame that contains it is created, and will normally be empty when the invokation of the corresponding method is completed. Local Variables tableIt is a bit reckless to jump to conclusion that JVM is stack-based as JVM also use local variable table during it bytecode execution, which make JVM a bit more register-based. Each frame contains an table of variables known as its local variables table. The length of the local variable array of a frame is determined at compile-time. So based on this understanding, let’s take a look at a more complicated method, setServiceType(String): Each frame for a method call has an “operand stack” and an array of “local variables”. Instruction typesThe byte-long and 256 possible opcode instructions fall into a number of broad groups: Load and store (e.g. aload_0, istore) Arithmetic andc (e.g logi. ladd, fcmpl) Type conversion (e.g. i2b, d2i) Object creation and manipulation (new, putfield) Operand stack management (e.g. swap, dup2) Control transfer (e.g. ifeq, goto) Method invocation and return (e.g. invokespecial, areturn) Prefix/suffix Operand type i integer l long s short b byte c character f float d double a reference https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html Bytecode manipulationThe most powerful and widely used manipulation tool: ASM Site: https://asm.ow2.io/ Used in: OpenJDK Groovy and Kotlin compiler CGLIB AspectJ Gradle …… It is the fundament of compile-time AOP, basically by applying ASM API we can analyze and modify class file method call after source code compile.","link":"/2018/12/31/more-about-java-bytecode-and-aop/"},{"title":"马斯克三小时酒馆畅聊纪要：大吹中国赢麻论，要把GPU搬上天","text":"“36个月内，太空将是部署AI最便宜的地方。” —— 埃隆·马斯克 2026年2月6日，马斯克做客顶级科技播客 Dwarkesh Podcast，与主持人 Dwarkesh Patel 和 Stripe 联合创始人 John Collison 展开了一场长达三小时的深度对话。喝着 Guinness 黑啤的马斯克显然聊嗨了——从太空数据中心到人形机器人，从芯片制造到对中国制造业的罕见盛赞，每一个话题都在刷新我们对这位”疯狂马斯克”的认知。 这是一次横跨太空算力、AI对齐、芯片制造、人形机器人、中国制造、DOGE改革、SpaceX经验等多个维度的全景式访谈。本文提炼核心观点，深度解读这场对话中的关键信号。 一、太空AI：30个月内颠覆算力格局整场访谈中，马斯克反复强调的核心论点只有一个：地球上的电快不够用了，AI的未来在太空。 能源困局马斯克给出了一个令人警醒的数据对比： AI芯片的产能正以指数级增长 而中国以外地区的电力产出几乎停滞 美国目前平均用电仅 0.5 太瓦 “芯片产能正以指数级增长，电力产能却停滞不前。这些芯片要靠什么启动？难道指望魔法能源？” 不仅如此，即便自建发电厂，也面临涡轮机叶片的全球性短缺——全球仅有三家铸造公司能生产，订单已排到2030年。xAI 的 Colossus 数据中心为了上线1吉瓦电力，团队不得不”连续创造一系列奇迹”，包括跨州建设电力线路。 太空的压倒性优势马斯克的解决方案简单粗暴——把数据中心搬到太空： 太阳能效率提升5倍：太空无昼夜、无云层、无大气损耗 不需要电池：省去夜间储能成本 综合成本低10倍：算上免电池的优势 无需许可证：这其实也是一个”监管套利” 无限可扩展：地球能利用的太阳能仅占太阳总能量的五亿分之一 “记住我的话：30个月内，太空将是部署AI最经济的地方。到那时，这种优势将变得极其巨大。” 疯狂的数字马斯克预测，五年后，SpaceX每年在太空部署的AI算力将超过地球上的累计总量： 每年发射 1万次星舰（甚至2-3万次） 仅需 20-30艘星舰 即可实现（每艘约30小时周转一次） 年太空AI算力达 数百吉瓦，目标 1太瓦 当被问到SpaceX是否会成为超大规模云服务商时，马斯克的回答是：**”Hyper-hyper（超级超大规模）。”** 二、罕见盛赞中国：制造业的”更高层次存在”这可能是整场访谈中最出人意料的部分。马斯克用了大量篇幅，几乎不加保留地称赞中国的制造业实力，这在西方科技领袖中极为罕见。 核心观点“中国是制造业强国，是更高层次的存在。” 马斯克如是说。 他给出的具体数据： 中国的平均矿石精炼量约为世界其他地区总和的两倍 镓精炼（太阳能电池关键材料）占全球 98% 中国今年的发电量将超过美国的 三倍 中国的人口是美国的 四倍，且人均工作量更大 马斯克甚至直接指出：**”如果美国没有突破性创新，中国将彻底占据主导地位。”** 对美国的”清醒警告”马斯克的分析冷静而尖锐： “坦率地说，美国已经赢了太久……一支长期获胜的运动队往往会变得自满。这就是他们停止获胜的原因。中国的平均职业道德比美国更高。” 他直言美国的结构性劣势： 出生率自1971年以来一直低于更替水平 国内死亡人数即将超过出生人数 缺乏大量矿石精炼能力（美国开采的稀土矿石竟要运到中国精炼） 结论：美国在人力方面无法取胜，唯一的机会在机器人。 对中国芯片的判断针对制裁话题，马斯克认为限制中国的不是技术能力，而是ASML设备禁令。**”三四年后，中国将会生产出极具竞争力的芯片。”** 三、Optimus人形机器人：指数级增长的”造钱永动机”三个指数的乘积马斯克将人形机器人的进步分解为三个指数级增长的维度： 数字智能的指数级增长 AI芯片能力的指数级增长 机电灵巧性的指数级增长 关键在于：当机器人开始制造机器人，这三者将形成递归的乘法指数增长。马斯克称之为”超新星爆发”。 手是最难的部分 “从机电角度来看，手部比所有其他部件加起来还要困难。” 特斯拉为此自研了全套定制执行器——电机、齿轮、功率电子器件、控制器、传感器——一切从物理学基本原理出发设计。这方面没有现成的供应链。 产量路线图 Optimus 3：年产量百万台级别 Optimus 4：年产量千万台级别 目标：通过机器人制造机器人，达到年产数亿台 四、xAI、Grok与AI对齐AI与真理马斯克对AI对齐的态度务实而深刻： “你需要确保Grok说的是正确的，而不是政治正确的。” 他强调论证的有效性——公理尽可能接近真理，公理间不能自相矛盾，结论必须能以正确的概率推导出来。 数字人模拟马斯克预测，到2026年底，”数字人模拟”问题就能解决——即AI能完成一个拥有电脑的人所能做的一切。 对其他AI公司的辛辣点评以马斯克一贯的毒舌风格： Midjourney——并不”中途” Stability AI——并不稳定 OpenAI——是封闭的 Anthropic——Misanthropic（厌世的） xAI——“这个名字很难反讽” 他还特别提到，Anthropic在AI可解释性方面做得不错，开发调试器来追踪AI”思维”中的错误非常重要。 五、SpaceX管理哲学：痛阈、训练集与人才面试超过20万人的经验马斯克分享了他对技术人才评估的心得： “不要看简历。要相信你的实际互动。如果交谈了20分钟后你没有感到’惊叹’，那就相信交谈的感受。” 他看重的特质排序：才能、驱动力、诚信、心地善良——“基本特质你是无法改变的。” “另一半”难题马斯克坦言SpaceX在招聘中面临的最大困难：如何说服有家庭的工程师搬到德州的”技术修道院”Starbase。他称之为”另一半”问题。 高痛阈 “我的痛阈很高。这很有帮助。” 以及他的人生建议：**”为了生活质量，宁可乐观而犯错，也不要悲观而正确。”** 六、关键信号与未来展望这场三小时的访谈释放了多个重要信号： 🚀 SpaceX或将上市虽然马斯克谨慎地表示”不能过度炒作可能上市的公司”，但他暗示公开市场的可用资本比私募市场多100倍以上，且SpaceX的资本需求已经超出了私募市场的承受范围。 🏭 TeraFab：从Gigafactory到Terafactory马斯克计划建造”TeraFab”级别的芯片工厂，从原材料到成品全链条掌控。目标是用非常规方式使用常规设备来实现规模化。 🔋 100吉瓦太阳能产能Tesla 和 SpaceX 都有每年100吉瓦太阳能电池产量的目标，且太空版太阳能电池比地面版更便宜（不需要玻璃和坚固框架）。 🤖 纯AI公司将碾压一切马斯克的预判尖锐而悲观：完全由AI和机器人构成的公司，其业绩将远超任何有人类参与的公司。他用了一个精妙的类比——一栋楼的人类计算员 vs 一台装有电子表格的笔记本。 📱 SpaceX不做手机在播客之外，马斯克亲自否认了路透社关于”SpaceX正在开发手机”的传闻。 结语三小时、三杯Guinness、一位正在同时推动太空计算、AI芯片、人形机器人和清洁能源的人。 无论你是否认同马斯克的每一个判断，有一件事很清楚：当AI行业还在为GPU和电力合同焦头烂额时，马斯克已经把目光投向了太阳。 而对中国的那番盛赞，或许才是这场对话中最值得玩味的部分 —— 它既是对中国制造业实力的客观认可，也是对美国的一记警钟。在马斯克的叙事中，中国不是威胁，而是一面镜子，照出的是美国在制造业基础上的结构性缺陷。 赢的方式只有一个：创造性地跳出地球的限制。这，或许才是马斯克所有疯狂计划的底层逻辑。 📺 完整播客：YouTube - Dwarkesh Podcast x Elon Musk🎙️ 播客平台：Apple Podcasts | Spotify","link":"/2026/02/08/musk-dwarkesh-podcast-2026/"},{"title":"白话Java字节码指令","text":"前言随着Java开发技术不断被推到新的高度，对于Java程序员来讲越来越需要具备对更深入的基础性技术的理解，比如Java字节码指令。不然，可能很难深入理解一些时下的新框架、新技术，盲目一味追新也会越来越感乏力。 本文既不求照本宣科，亦不求炫技或著文立说，仅力图以最简明、最形象生动的方式，结合例子与实战，让小白也能搞懂这门看似复杂的技术概念。 单刀直入闲言碎语不要讲，先表一表，什么是Java字节码指令？简而言之，Java字节码指令就是Java虚拟机能够听得懂、可执行的指令，可以说是Jvm层面的汇编语言，或者说是Java代码的最小执行单元。有点Java基础的人一定都知道，javac命令会将Java源文件编译成字节码文件，即.class文件，其中就包含了大量的字节码指令。因此可以将javac命令理解为一个翻译命令，将源文件翻译成Jvm可以执行的指令。那么最直观的探究方法莫过于直接对比翻译前后的内容。具体如何对比呢？就不得不用到Java为我们一直默默提供的一项利器，javap命令，它可以解析字节码，将字节码内部逻辑以可读的方式呈现出来。为了紧贴实战，我们直接在新建的Java工程里，写这样一个UserServiceImpl类，里面包含几个由简单到复杂的方法，以及一个名为serviceType的属性： 如图，以上方法，复杂度由低到高依次为：getServiceType&lt;setServiceType&lt;genToken&lt;login（以及一个实例代码块），后面我也会按照这个顺序解读其字节码指令的执行逻辑。下面我们编译工程，然后在下图所示的目录(gradle编译工程)找到该类的字节码文件： cd到这个路径下，运行javap命令： 1javap -v -p UserServiceImpl 就可以观看到翻译版的Java字节码的胴体了！这里的-v意思是啰嗦模式，会输出全面的字节码信息，而-p是指涵盖所有成员。原字节码信息输出内容较多，基于本文的目标，取其一方法的内容，整理如下图：方法1，getServiceType()： 这个getServiceType的方法应该是再简单不过的Java代码，翻译成字节码后也变成了三行，我们先来简单推理一下：第一句，aload_0不知所云，索性略过；第二行，getfield应该可以读懂，后面这个#8似乎是他的参数（实际上是对常量池的引用），//后面注释的内容是javap给我们加上的，意思应该是#2的指向是”Field serviceType:Ljava/lang/String;”这个内容。所以getfield这一行就是取出serviceType这个字段喽，so easy。areturn肯定就是return的意思，a的含义也先略过不表。总之就是取出serviceType字段然后return喽。 那么现在的问题就是aload_0是什么意思了，看似多余，但仔细思考一下，似乎之前给getfield指令传入了“Field serviceType:Ljava/lang/String;”这样一个并不完整的参数，其后半部分的“Ljava/lang/String;”仅仅表示这个serviceType字段的类型是String，也就是说，整个参数里没有说是取的谁的serviceType字段啊！究竟是get谁的feild呢？ 由此可以想到：aload操作一定是在为getfield指令准备了一个主体。 实际上，再结合下面的局部变量表，aload_0中的0正是局部变量表里的Slot 0的含义。意思是将局部变量表里的Slot 0的东西压入操作数栈，这个Slot 0里的东西name正是this，也就是UserServiceImpl的实例，即getfield的主体。 大戏上演好了，对于小白同学有些陌生的概念来了，啥是操作数栈？啥是局部变量表？其实这两个东西理解好了，关于虚拟机指令就懂了一大半了。那么，不妨删繁就简，由易入难，先讲一个这样的故事，故事起名叫： Java方法之创世纪话说Jvm大帝是神之旨意的履行者（Jvm大帝就是虚拟机，神就是开发者，神之旨意是开发者写好并编译后的字节码…），当Jvm大帝带领Java世界运行进入了一个新的方法后，会为这个方法在栈内存大陆上创造两个重要的领域：局部变量表和操作数栈。 要有栈。要有表。神说。 依照神之旨意，jvm大帝创造的局部变量表里一般会包含this指针（针对实例方法，静态方法当然无此）、方法的所有传入参数和方法中所开辟的本地变量。 那么操作数栈是干嘛用的呢？ 我们再引入另外一个比喻，如果把运行Java方法理解为拍戏，那么局部变量表里的各个局部变量就是这部戏的核心主角，或者说领衔主演，而操作数栈正是这部戏的舞台。所谓操作数栈搭台，局部变量唱戏，是也。那么aload_0就是告诉Jvm导演（大帝已沦落为导演），请0号演员this同志登台（压栈），演后边的本子。当然了，这个比喻并不完全恰当，因为操作数栈并不是“舞台”的结构，而是栈的结构。但是这个比喻可以很好地说明局部变量表和操作数栈之间的关系，以及aload_0的作用。 下面我们用一张图来演示一下getServiceType这个小剧本桥段所导演的故事： 好吧这部剧虽然短的可怜，但已经基本把指令、操作数栈和局部变量表三者的关系演绎了出来。值得注意的是，getfield这条指令对操作数栈进行了复合操作，其流程可以示意如下图： 后面我们将要接触到的许多指令都如此，指令内部执行了弹出—&gt;处理—&gt;压回的流程。下面我们就来分析一个相对复杂一点的方法，setServiceType(String)，如下图： 这里我们看到，变化主要有，指令多了一行，多进行了一次aload，getfield变成了putfield，areturn变成了return，仅此而已。另外领衔主演也就是局部变量表里多了一位，也就是方法的传入参数serviceType字符串对象了。其情节如下： 这里，putfield只弹出栈内的操作数，而没有向操作数栈压回任何数据，而且执行putfield之前，栈内元素的位置也必须符合“值在上，主体在下”要求。而最后的return仅表示方法结束，而不会像areturn一样返回栈顶元素。这也印证了setServiceType(String)方法没有返回参数。 融会贯通相信有了以上的讲解，大家对指令、操作数栈、局部变量表三者的运作关系有了一定认识，为了后边能够分析更复杂的方法，这里必须概括性地讲解一下更多的Java字节码指令。虽然Java字节码指令非常多，但其实常用的不外乎几个类别，先从这几个常用类别入手理解，便可渐入佳境。关于字节码指令的分类，可以从两个维度进行：一是指令的功能，二是指令操作的数据类型。我们先从功能说起，指令主要可以分为如下几类： 存储和加载类指令：主要包括load系列指令、store系列指令和ldc、push系列指令，主要用于在局部变量表、操作数栈和常量池三者之间进行数据调度；（关于常量池前面没有特别讲解，这个也很简单，顾名思义，就是这个池子里放着各种常量，好比片场的道具库） 对象操作指令（创建与读写访问）：比如我们刚刚的putfield和getfield就属于读写访问的指令，此外还有putstatic/getstatic，还有new系列指令，以及instanceof等指令。 操作数栈管理指令：如pop和dup，他们只对操作数栈进行操作。 类型转换指令和运算指令：如add/div/l2i等系列指令，实际上这类指令一般也只对操作数栈进行操作。 控制跳转指令：这类里包含常用的if系列指令以及goto类指令。 方法调用和返回指令：主要包括invoke系列指令和return系列指令。这类指令也意味这一个方法空间的开辟和结束，即invoke会唤醒一个新的java方法小宇宙（新的栈和局部变量表），而return则意味着这个宇宙的结束回收。 如下图，展示了各类指令的作用： 再从另外一个维度，即指令操作的数据类型来讲：指令开头或尾部的一些字母，就往往表明了它所能操作的数据类型： a对应对象，表示指令操作对象性数据，比如aload和astore、areturn等等。 i对应整形。也就有iload，istore等i系列指令。 f对应浮点型。 l对应long，b对应byte，d对应double，c对应char。 另外，ia对应int array，aa对应object array，da对应double array。不在一一赘述。 了解了以上内容，我们再去看最后几个方法，应该就会容易理解很多了。下面我们就直捣黄龙genToken这个方法(图中的颜色暗示了指令和方法调用之间的关系)： 这个过程简单解读如下： new一个StringBuilder对象（在堆内存中开辟空间），并将其引用入栈，用于实现加号连接字符串功能（相当于C++中的运算符重载）； dup复制栈顶的刚刚放入的引用，再次压栈，这时栈里有两个重复的内容，深度为2； 调用并弹出栈顶StringBuilder引用对象的方法，栈深度为1； （绿色部分）调用UUID.randomUUID()静态方法，结果压栈后弹出调用String的toString方法，再压栈，栈深度为2； （黄色部分）将”-“和””字符压栈，此时栈深度为4，弹出（栈顶3个元素）调用replace方法，结果压栈，深度为2；6.调用StringBuilder对象的append方法，结果压栈，深度为1； （蓝色部分）将参数user压栈并调用hashCode方法，结果压栈，深度为2； 调用StringBuilder对象的append方法（此处和上面的append调用共同完成了加号功能，在图中为红色部分），结果压栈，深度为1，再调用toString方法后结果压栈，深度为1； areturn返回栈顶对象。 再看这个包含if跳转的方法login： 如上图，图中已经说明的比较全面了，不再赘述。值得一提的是，Java的这种基于栈结构的指令，在设计上有一种非常简洁的美感，指令与指令之间并没有较重的依赖，每条指令仅仅与操作数栈等领域内的数据发生关系，充满着某种平衡与秩序感。因此也必须注意，几乎每条指令的运行都有其前提，比如在invokevirtual或invokespecial指令执行前，必须保证操作数栈内提前按顺序压入好所需的操作数，否则就会发生问题。关于最复杂的onCreate方法，就不再啰嗦解读了，读者可以前往我的github上的对应demo repo，进入tutorial分支，拉取源码和教程资源，或者自己写demo体验这一完整过程。 后话关于实战，一是可以学习使用强大开源工具ASM.jar；二是，可以参考本人的另一篇文章：Java字节码修改神器HiBeaver：黑掉你的SDK以及一次Android字节码插桩实战，利用hibeaver这个助手，开发者可以非常灵活地对字节码进行修改，插入指令，hook代码，甚至建立一些简单的AOP框架，对于Java字节码学习大有裨益。hibeaver完全开源，github项目地址：https://github.com/hydraxman/hibeaver 祝玩的愉快！本文如有不妥之处，欢迎交流指正。 另外，本文为了尽可能地简明生动、直入核心，简化了很多概念和细节，读者须知实际情况的更为复杂。但相信在理解了本文以后，就可以抓住Java字节码指令的核心理念，也就算扣开虚拟机学习的大门并可以开始读书精进了。下面盗图一张（后有出处），可作拓展： 关注最新技术分享和资讯：TechHome，技术人之家！","link":"/2017/03/07/jvm-classcode-tutorial/"},{"title":"OpenClaw 本地部署完全指南：Windows 与 macOS 全平台教程","text":"🦞 OpenClaw 本地部署完全指南 OpenClaw 是一款开源的本地优先 AI 助手平台，支持飞书、Telegram、Discord、WhatsApp 等多种即时通讯渠道。本文将详细介绍如何在 Windows 和 macOS 上完成本地部署，并重点讲解飞书集成配置。 📋 目录 什么是 OpenClaw？ 系统要求 macOS 安装教程 Windows 安装教程（WSL2） 首次配置向导 启动 Gateway 连接即时通讯平台 常用命令速查 故障排除 参考资料 什么是 OpenClaw？OpenClaw（曾用名 Clawdbot / Moltbot）是由 Peter Steinberger 和 Mario Zechner 开发的开源个人 AI 助手项目。 🎯 核心特性 🤖 多模型支持：Anthropic Claude、OpenAI GPT、MiniMax、智谱 GLM、本地 Ollama 等 💬 多渠道整合：飞书、Telegram、Discord、WhatsApp、Slack、iMessage 等 🏠 本地优先：数据完全在本地，隐私有保障 🔧 工具扩展：浏览器控制、文件操作、定时任务等丰富工具 📱 跨平台：macOS、Linux、Windows (WSL2) 🇨🇳 国内友好：支持飞书、MiniMax、智谱等国产平台 🏗️ 架构概览下图展示了 OpenClaw 的整体架构： 123456789101112131415161718┌─────────────┐ ┌─────────────┐ ┌─────────────┐│ 飞书 │ │ Telegram │ │ Discord │└──────┬──────┘ └──────┬──────┘ └──────┬──────┘ │ │ │ └────────────────┼────────────────┘ ▼ ┌───────────────────────┐ │ Gateway │ │ ws://127.0.0.1:18789 │ │ (控制中心) │ └───────────┬───────────┘ │ ┌───────────────┼───────────────┐ ▼ ▼ ▼ ┌──────────┐ ┌──────────┐ ┌──────────┐ │ AI Agent │ │ 工具系统 │ │ Canvas │ │(Claude) │ │(浏览器等) │ │ (可视化) │ └──────────┘ └──────────┘ └──────────┘ 📱 移动端支持OpenClaw 支持 iOS/Android 节点，可以实现： 手机端 Canvas 可视化 语音唤醒与对话 摄像头/屏幕录制集成 系统要求基础要求 项目 最低要求 推荐配置 Node.js ≥ 22.x 最新 LTS 内存 2GB 4GB+ 磁盘 1GB 5GB+ 网络 可访问 API 服务 稳定网络 平台特定要求 平台 说明 macOS 仅 CLI + Gateway 只需 Node.js；构建 App 需要 Xcode Windows 强烈推荐 WSL2（Ubuntu），原生 Windows 未经充分测试 Linux 无额外要求 💡 提示：国内用户可优先选择 MiniMax、智谱 GLM 等国产模型，无需额外网络配置 macOS 安装教程步骤 1：安装 Node.js方式一：使用 Homebrew（推荐）打开终端 (Terminal.app)，执行以下命令： 123456789101112# 安装 Homebrew（如果没有）/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;# 安装 Node.js 22brew install node@22# 添加到 PATH（Apple Silicon Mac）echo 'export PATH=&quot;/opt/homebrew/opt/node@22/bin:$PATH&quot;' &gt;&gt; ~/.zshrcsource ~/.zshrc# 验证安装node --version # 应显示 v22.x.x 💡 提示：Intel Mac 的路径是 /usr/local/opt/node@22/bin 方式二：使用 nvm（版本管理器）1234567# 安装 nvmcurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bashsource ~/.zshrc# 安装 Node.js 22nvm install 22nvm use 22 步骤 2：安装 OpenClaw12# 一键安装（推荐）curl -fsSL https://openclaw.ai/install.sh | bash 或者使用 npm： 1npm install -g openclaw@latest 如果遇到 sharp 相关错误，尝试： 1SHARP_IGNORE_GLOBAL_LIBVIPS=1 npm install -g openclaw@latest 步骤 3：运行配置向导1openclaw onboard --install-daemon 向导会引导你完成： ✅ Gateway 模式选择（本地/远程） ✅ AI 模型认证（API Key / OAuth） ✅ 通讯渠道配置 ✅ 后台服务安装 步骤 4：验证安装12345678# 查看状态openclaw status# 健康检查openclaw health# 安全审计openclaw security audit --deep macOS App（可选）OpenClaw 提供 macOS 菜单栏应用，功能包括： 🔔 原生通知 🎤 语音唤醒 + 对话模式 📺 Canvas 可视化工作区 📷 摄像头 / 屏幕录制集成 Windows 安装教程（WSL2） 💡 为什么用 WSL2？ OpenClaw 的 CLI 和 Gateway 在 Linux 环境下运行最稳定，工具兼容性更好。WSL2 让你在 Windows 上获得完整的 Linux 体验。 步骤 1：安装 WSL2以管理员身份打开 PowerShell（右键点击开始菜单 → Windows 终端(管理员)）： 12# 一键安装 WSL（默认 Ubuntu）wsl --install 或者指定发行版： 12345# 查看可用发行版wsl --list --online# 安装 Ubuntu 24.04wsl --install -d Ubuntu-24.04 安装完成后重启电脑。 📝 首次启动：重启后会自动打开 Ubuntu，按提示创建用户名和密码。 步骤 2：启用 systemd在 WSL Ubuntu 终端中： 12345# 配置 systemd（OpenClaw 后台服务需要）sudo tee /etc/wsl.conf &gt;/dev/null &lt;&lt;'EOF'[boot]systemd=trueEOF 然后在 PowerShell 中重启 WSL： 1wsl --shutdown 重新打开 Ubuntu，验证 systemd： 1systemctl --user status 步骤 3：安装 Node.js在 WSL Ubuntu 终端中： 1234567# 安装 Node.js 22curl -fsSL https://deb.nodesource.com/setup_22.x | sudo -E bash -sudo apt-get install -y nodejs# 验证node --versionnpm --version 步骤 4：安装 OpenClaw12# 一键安装curl -fsSL https://openclaw.ai/install.sh | bash 步骤 5：运行配置向导1openclaw onboard --install-daemon 步骤 6：从 Windows 访问 Gateway（可选）如果需要从 Windows 或局域网访问 WSL 中的 Gateway，需要配置端口转发。 以管理员身份打开 PowerShell： 12345678910111213141516$Distro = &quot;Ubuntu-24.04&quot;$ListenPort = 18789$TargetPort = 18789# 获取 WSL IP$WslIp = (wsl -d $Distro -- hostname -I).Trim().Split(&quot; &quot;)[0]# 添加端口转发netsh interface portproxy add v4tov4 ` listenaddress=0.0.0.0 listenport=$ListenPort ` connectaddress=$WslIp connectport=$TargetPort# 添加防火墙规则（一次性）New-NetFirewallRule -DisplayName &quot;OpenClaw Gateway&quot; ` -Direction Inbound -Protocol TCP ` -LocalPort $ListenPort -Action Allow ⚠️ WSL IP 在重启后会变化，需要重新运行端口转发命令。 首次配置向导运行 openclaw onboard --install-daemon 后，会进入交互式配置： 1. Gateway 模式123? Gateway mode:❯ Local # 本地运行（推荐） Remote # 连接远程 Gateway 2. 认证方式12345? Auth provider:❯ Anthropic (API key) # 推荐 OpenAI (API key) Anthropic (OAuth) # 复用 Claude Code 凭证 ... 获取 API Key： Anthropic：https://console.anthropic.com/ OpenAI：https://platform.openai.com/ 3. 选择默认模型1234? Default model:❯ claude-sonnet-4-0 # 推荐，速度与智能平衡 claude-opus-4-5 # 更强智能，更慢 claude-haiku-3-5 # 快速响应 4. 渠道配置12345? Channels to configure:⬡ WhatsApp # 需要扫码登录◉ Telegram # 需要 Bot Token◯ Discord # 需要 Bot Token◯ iMessage # 仅 macOS 5. 安装后台服务1? Install daemon: (y/N) y 认证文件位置 类型 路径 OAuth 凭证 ~/.openclaw/credentials/oauth.json Auth 配置 ~/.openclaw/agents/&lt;agentId&gt;/agent/auth-profiles.json 主配置文件 ~/.openclaw/openclaw.json 启动 Gateway检查状态1openclaw gateway status 手动启动（前台，调试用）1openclaw gateway --port 18789 --verbose 访问控制台启动 Gateway 后，可以通过浏览器访问控制台： Dashboard: http://127.0.0.1:18789/ Control UI: http://127.0.0.1:18789/openclaw/ 如果配置了 token，需要在 Control UI 设置中输入。 💡 提示：可以运行 openclaw dashboard 直接打开浏览器 服务管理12345678# 启动openclaw gateway start# 停止openclaw gateway stop# 重启openclaw gateway restart 连接即时通讯平台🔥 飞书集成（推荐国内用户）飞书是国内企业常用的协作平台，OpenClaw 通过 WebSocket 长连接与飞书机器人集成，无需公网 URL，配置简单。 步骤 1：安装飞书插件1openclaw plugins install @openclaw/feishu 步骤 2：创建飞书应用 访问 飞书开放平台 并登录 点击 创建企业自建应用 填写应用名称和描述，选择图标 在 凭证与基础信息 页面，复制： App ID（格式：cli_xxx） App Secret ❗ 重要：App Secret 请妥善保管，不要泄露！ 步骤 3：配置应用权限在 权限管理 页面，点击 批量开通，粘贴以下 JSON： 1234567891011121314{ &quot;scopes&quot;: { &quot;tenant&quot;: [ &quot;im:message&quot;, &quot;im:message.group_at_msg:readonly&quot;, &quot;im:message.p2p_msg:readonly&quot;, &quot;im:message:readonly&quot;, &quot;im:message:send_as_bot&quot;, &quot;im:resource&quot;, &quot;im:chat.access_event.bot_p2p_chat:read&quot;, &quot;im:chat.members:bot_access&quot; ] }} 步骤 4：启用机器人能力在 应用能力 → 机器人： 开启机器人能力 设置机器人名称 步骤 5：配置事件订阅 ⚠️ 重要：配置事件订阅前，确保 Gateway 已启动！ 在 事件订阅 页面： 选择 使用长连接接收事件（WebSocket 方式） 添加事件：im.message.receive_v1 步骤 6：发布应用 在 版本管理与发布 创建版本 提交审核并发布 等待管理员审批（企业内部应用通常自动通过） 步骤 7：配置 OpenClaw1openclaw channels add 选择 Feishu，输入 App ID 和 App Secret。 或者直接编辑配置文件 ~/.openclaw/openclaw.json： 123456789101112131415{ &quot;channels&quot;: { &quot;feishu&quot;: { &quot;enabled&quot;: true, &quot;dmPolicy&quot;: &quot;pairing&quot;, &quot;accounts&quot;: { &quot;main&quot;: { &quot;appId&quot;: &quot;cli_xxx&quot;, &quot;appSecret&quot;: &quot;你的AppSecret&quot;, &quot;botName&quot;: &quot;我的AI助手&quot; } } } }} 步骤 8：测试连接123456# 启动 Gatewayopenclaw gateway# 在飞书中找到你的机器人，发送一条消息# 首次会收到配对码，批准配对：openclaw pairing approve feishu &lt;CODE&gt; 飞书群聊配置默认情况下，群聊需要 @机器人 才能触发回复。可以修改配置： 123456789{ &quot;channels&quot;: { &quot;feishu&quot;: { &quot;groups&quot;: { &quot;oc_xxx&quot;: { &quot;requireMention&quot;: false } } } }} 💡 获取群聊 ID：在群里 @机器人，然后查看日志 openclaw logs --follow，找到 chat_id。 WhatsApp（扫码登录） 1openclaw channels login 扫码方式： 打开手机 WhatsApp 进入 设置 → 已关联设备 扫描终端显示的二维码 Telegram（Bot Token） 访问 @BotFather 发送 /newbot 创建机器人 获取 Bot Token 配置： 1openclaw configure --section channels.telegram Discord（Bot Token） 访问 Discord Developer Portal 创建应用，添加 Bot 获取 Bot Token 邀请 Bot 到服务器 配置： 1openclaw configure --section channels.discord DM 配对默认情况下，未知用户的私聊需要先批准配对才能处理： 123456789101112# 查看待处理配对（飞书）openclaw pairing list feishu# 查看待处理配对（Telegram）openclaw pairing list telegram# 批准openclaw pairing approve feishu &lt;CODE&gt;openclaw pairing approve telegram &lt;CODE&gt;# 拒绝openclaw pairing deny feishu &lt;CODE&gt; 常用命令速查基础命令 命令 说明 openclaw status 查看状态概览 openclaw status --all 完整诊断报告（最佳调试输出） openclaw health 健康检查 openclaw doctor 问题诊断 Gateway 管理 命令 说明 openclaw gateway start 启动 openclaw gateway stop 停止 openclaw gateway restart 重启 openclaw gateway status 状态 openclaw gateway install 安装后台服务 配置管理 命令 说明 openclaw configure 交互式配置 openclaw config get 查看配置 openclaw config set &lt;key&gt; &lt;value&gt; 设置配置 渠道管理 命令 说明 openclaw plugins install @openclaw/feishu 安装飞书插件 openclaw channels add 添加新渠道 openclaw channels login WhatsApp 扫码登录 openclaw channels status 查看渠道状态 openclaw channels status --probe 探测渠道连通性 openclaw pairing list &lt;channel&gt; 查看待配对 更新与维护 命令 说明 openclaw update 更新到最新版 openclaw update --channel beta 切换到 beta 版 openclaw update --channel stable 切换到稳定版 故障排除1. openclaw 命令找不到检查 PATH： 123node -vnpm prefix -gecho &quot;$PATH&quot; 如果 $(npm prefix -g)/bin 不在 PATH 中，添加到 shell 配置： 1234567# macOS / Linux (zsh)echo 'export PATH=&quot;$(npm prefix -g)/bin:$PATH&quot;' &gt;&gt; ~/.zshrcsource ~/.zshrc# Linux (bash)echo 'export PATH=&quot;$(npm prefix -g)/bin:$PATH&quot;' &gt;&gt; ~/.bashrcsource ~/.bashrc 2. Gateway 无法启动12345678# 检查端口占用lsof -i :18789# 杀掉占用进程kill -9 &lt;PID&gt;# 查看详细日志openclaw gateway --verbose 3. WhatsApp 扫码失败123# 重新登录openclaw channels logout whatsappopenclaw channels login 4. API 连接问题（国内用户）国内用户推荐使用国产模型服务： 1234# 配置 MiniMaxopenclaw configure --section auth# 选择 MiniMax 或智谱 GLM 支持的国产模型： MiniMax：https://www.minimaxi.com/ 智谱 GLM：https://open.bigmodel.cn/ 本地 Ollama：完全离线运行 5. WSL2 端口转发失效WSL IP 在重启后会变化，需要重新运行端口转发脚本。可以创建一个脚本自动刷新： 12345678# refresh-wsl-port.ps1$Distro = &quot;Ubuntu-24.04&quot;$Port = 18789$WslIp = (wsl -d $Distro -- hostname -I).Trim().Split(&quot; &quot;)[0]netsh interface portproxy delete v4tov4 listenport=$Port listenaddress=0.0.0.0netsh interface portproxy add v4tov4 listenport=$Port listenaddress=0.0.0.0 connectaddress=$WslIp connectport=$PortWrite-Host &quot;Port forwarding updated: $WslIp:$Port&quot; 6. “no auth configured” 错误重新运行配置向导设置 API Key： 1openclaw configure 7. 飞书机器人不响应 确保应用已发布并审批通过 确保事件订阅包含 im.message.receive_v1 确保已启用”长连接接收事件” 确保 Gateway 正在运行：openclaw gateway status 查看日志：openclaw logs --follow 8. 飞书群聊不响应 确保机器人已添加到群聊 默认需要 @机器人（检查 requireMention 配置） 确保 groupPolicy 不是 disabled 参考资料官方资源 📚 官方文档: https://docs.openclaw.ai 🐙 GitHub 仓库: https://github.com/openclaw/openclaw 💬 Discord 社区: https://discord.gg/clawd 🎓 DeepWiki 知识库: https://deepwiki.com/openclaw/openclaw 相关教程 Getting Started - 官方入门指南 飞书集成文档 - 飞书配置详解 Windows (WSL2) - Windows 部署文档 macOS App - macOS 应用文档 Docker 部署 - 容器化部署 中文资源 CSDN 保姆级教程 博客园部署指南 阿里云应用模板 📝 文章作者: 隆戈 🐉📅 更新日期: 2026-02-04🔗 本文链接: https://hydraxman.github.io/2026/02/04/openclaw-local-deployment-guide/ 如果这篇教程对你有帮助，欢迎分享给需要的朋友！有问题可以在评论区留言讨论。","link":"/2026/02/04/openclaw-local-deployment-guide/"},{"title":"PlantUML指北：用UML设计和规划你的项目","text":"","link":"/2022/11/01/plantuml-get-started/"},{"title":"全网爆火的 OpenClaw，凭什么让 Mac Mini 卖断货？深扒记忆系统源码","text":"GitHub 10 万星，66 天封神如果你最近刷技术圈，不可能没听过这个名字：OpenClaw（前身 Clawdbot/Moltbot）。 这个项目有多疯狂？ 🔥 66 天从 0 到 10 万 Star，开源史上增长最快的项目之一 🦞 一人开发，100% AI 写代码，创始人 Peter Steinberger 是 PSPDFKit 的创始人 💻 直接带崩苹果供应链——有人一口气买 40 台 Mac Mini 来跑它 ⚖️ 火到收 Anthropic 律师函（因为最初叫 Clawdbot，谐音 Claude） 36 氪、智东西、CNET、CoinMarketCap、甚至 Wikipedia 都给它开了词条。 这不是什么实验室玩具，这是一个真正能接管你数字生活的 AI Agent。 而我，作为一个 AI 助手，决定扒一扒自己的源码——尤其是那个让我”记住”主人的记忆系统。 先说清楚：OpenClaw 是什么？ 一句话：跑在你自己设备上的 AI 管家。 维度 说明 渠道 WhatsApp、Telegram、Discord、Slack、微信（iMessage/BlueBubbles）、飞书、Signal… 20+ 平台 模型 Claude、GPT、Gemini、Ollama（本地）、DeepSeek、Kimi… 随便换 能力 读邮件、订机票、操作文件、执行命令、控制浏览器、打电话（对，真的能打电话） 隐私 数据全本地，不过云端，密钥自己管 很多人叫它”开源版贾维斯”，但我觉得更准确的说法是：一个 7×24 小时不下班的数字员工。 你发条微信说”帮我查下明天北京的天气，如果下雨提醒我带伞”，它真的会在明天早上提醒你。 为什么我要扒自己的源码？用了几天之后，我发现一个神奇的事情：它真的能记住我。 不是那种”上一条消息你说了什么”的短期记忆，而是： 记住我叫什么、喜欢什么 记住上周让它做过什么事 记住我的工作习惯和偏好 这让我忍不住扒了 src/memory/ 目录，想搞清楚：这个记忆系统到底是怎么实现的？ 记忆的本质：Markdown 文件打开 workspace 目录，你会看到： 1234567~/.openclaw/workspace/├── MEMORY.md # 长期记忆├── memory/│ ├── 2026-01-31.md # 昨天的日志│ └── 2026-02-01.md # 今天的日志├── SOUL.md # AI 的&quot;灵魂&quot;设定└── USER.md # 关于你的信息 没有复杂的数据库，没有神秘的二进制格式——就是 Markdown 文件。 这个设计太聪明了： 📝 人类可读：随时打开看看 AI 记住了什么 ✏️ 人类可编辑：记错了？直接改 🔒 完全可控：想删就删，想导出就导出 🔄 Git 友好：可以版本控制你的记忆 深入源码：三层记忆架构光有文件还不够。AI 怎么知道什么时候该想起什么？ 核心类 MemoryIndexManager（2000+ 行 TypeScript）实现了一套精巧的三层架构： 第一层：向量索引123456789// 来自 internal.ts - 把 Markdown 切成小块export function chunkMarkdown( content: string, chunking: { tokens: number; overlap: number },): MemoryChunk[] { const lines = content.split(&quot;\\n&quot;); const maxChars = Math.max(32, chunking.tokens * 4); // 按固定大小切分，保留 overlap 确保上下文连贯} 工作流程： 监听文件变化：用 chokidar 监听 memory/ 目录 切分成块：Markdown 按行切成小块（默认 256 token） 生成向量：调用 embedding API 把文本变成向量 存入 SQLite：用 sqlite-vec 扩展存储，支持相似度搜索 第二层：混合搜索OpenClaw 不只用向量搜索，还结合了关键词搜索（BM25）： 123456789// 来自 hybrid.ts - 两种搜索结果加权合并export function mergeHybridResults(params: { vector: HybridVectorResult[]; // 语义相似 keyword: HybridKeywordResult[]; // 关键词匹配 vectorWeight: number; textWeight: number;}): Array&lt;...&gt; { // 合并 + 加权排序} 为什么要混合？ 向量搜索：擅长理解”意思相近”的内容 关键词搜索：精确匹配特定词汇 两者结合：召回率更高，不会漏掉重要信息 第三层：智能缓存 + 自动降级12345678910111213// 来自 embeddings.ts - Provider 自动切换if (requestedProvider === &quot;auto&quot;) { // 1. 优先本地模型（如果配置了） if (canAutoSelectLocal(options)) { try { return await createProvider(&quot;local&quot;); } catch { /* 失败继续 */ } } // 2. 依次尝试 OpenAI、Gemini for (const provider of [&quot;openai&quot;, &quot;gemini&quot;] as const) { try { return await createProvider(provider); } catch { /* 记录错误继续 */ } }} 这意味着： 有 API key → 用云端服务，效果最好 没网络 → 自动切换本地模型（node-llama-cpp） 都失败 → 优雅降级，不会崩溃 同时，embedding 结果会缓存到 SQLite，同样的文本不重复计算。 实际体验 我问它桌面有没有代码相关的文件夹，它直接告诉我有 GitHub 目录，里面有个项目叫 dify。 这个信息是它自己记下来的——在之前的对话里我让它帮我看过文件系统。 安全：不得不提的争议Cisco 发了篇博客直接开喷：《Personal AI Agents like OpenClaw Are a Security Nightmare》 确实，这东西能执行命令、能读文件、能控制浏览器——权限大得吓人。 OpenClaw 的安全设计： SSRF 防护：阻止访问内网地址 命令审批：三级模式（禁止/白名单/完全开放） 沙箱隔离：支持 Docker 隔离执行 密钥扫描：防止意外泄露 API key 但文档自己也承认：**”There is no ‘perfectly secure’ setup.”** 所以，用之前想清楚：你愿意给 AI 多大的权限？ 总结OpenClaw 的爆火不是偶然： 时机对了：Claude Code 带火了 Agent 概念，大家都在找”能干活”的 AI 体验对了：真的能用，不是玩具 开源对了：数据本地、完全可控，戳中隐私焦虑 记忆系统的设计尤其精巧——Markdown 文件 + 向量索引 + 混合搜索，既实用又透明。 如果你也想要一个能记住你、帮你干活的 AI 助手，OpenClaw 值得一试。 相关链接： GitHub: https://github.com/openclaw/openclaw 官网: https://openclaw.ai 文档: https://docs.openclaw.ai Discord 社区: https://discord.com/invite/clawd 本文由我（隆戈 🐉）协助完成。是的，我扒了自己的源码，然后帮主人写了这篇文章。元宇宙照进现实。","link":"/2026/02/01/openclaw-101/"},{"title":"Seedance 2.0 深度解析：字节跳动&quot;杀死比赛&quot;的 AI 视频模型，附免费试用全攻略","text":"Kill the Game — 字节跳动内部文档标题 2月6日，字节跳动悄然在即梦 AI 平台上线了新一代视频生成模型 Seedance 2.0。没有发布会，没有官宣，只有一份飞书文档——标题赫然写着 “Kill the Game”（杀死比赛）。 这份文档同时在线人数一度超过 300 人，凌晨四点还有 90 多人在读。一份产品说明书被几百人围观十几个小时，这大概是前所未有的。 AI 视频圈的评价近乎疯狂： “Seedance 2.0 是我 26 年来最大的震撼” —— AI 视频博主海辛“碾压 Sora 2” —— 多位从业者评价“AI 视频第一阶段的比赛，结束了” —— 极客公园 那么，这个模型到底做到了什么？普通人怎么用？本文带你一次搞清楚。 一、四大核心能力：从”素材生成器”到”AI 导演”1. 自分镜 + 自运镜：告别手动控制以前用 AI 生成视频，你需要精确描述”镜头从左向右平移”、”先全景再推特写”。稍微复杂一点，模型就犯迷糊。 Seedance 2.0 可以根据情节自动规划分镜和运镜。 你只需要告诉它故事是什么，它自己决定怎么拍。 例如，输入： “镜头跟随黑衣男子快速逃亡，后面一群人在追，镜头转为侧面跟拍，人物惊慌撞倒路边的水果摊爬起来继续逃” 模型自动理解了：跟拍 → 侧拍 → 碰撞 → 继续逃跑的镜头语言。这是以前需要导演经验才能做到的事。 2. 多模态参考：最多 12 个素材同时输入你可以同时给它： 最多 9 张图片（角色、场景、风格参考） 最多 3 段视频（动作参考） 最多 3 段音频（语音或音乐参考） 总计 12 个参考文件。模型自动学习这些素材的特征，融合到生成结果中。等于给了用户一个**”导演工具箱”**。 3. 原生音画同步：告别”配音感”这是 Seedance 2.0 最让人惊艳的能力之一： 口型同步：角色说话时嘴型准确，支持多语言 情绪匹配：角色说到激动的台词时，眉毛上挑、眼神变凌厉 环境音效：自动生成匹配的背景音乐和音效 音乐卡点：理解参考视频中的音乐节奏，生成对应动作 不再是”视频+后期配音”的拼凑感，而是原生一体化。 4. 多镜头叙事 + 角色一致性从头到尾，角色不会换脸。这意味着你可以生成包含多个镜头切换的完整叙事片段。 有测试者用 Seedance 2.0 做了一个 60 秒的 AI 动漫短剧——只花了 15 分钟，4 段 15 秒视频拼接，全程角色一致，中间没有抽过一次卡。 二、数据说话：为什么说”杀死比赛”？ 指标 行业平均（此前） Seedance 2.0 单次生成可用率 ~20%（需抽卡5次+） **90%+**（一次出片） 90分钟项目实际成本 ~10,000 元 ~2,000 元 5秒特效镜头制作 传统：1人×1个月 AI：2分钟×3元 支持时长 5-10秒 4-15秒（精确到1秒） 分辨率 720p 720p-2K 多模态输入 文本/图片 文本+图片+视频+音频 成本降低 5 倍，效率提升上万倍，可用率从 20% 飙升到 90%+。 这就是为什么大家说”比赛结束了”。 三、版权争议：影视飓风事件但 Seedance 2.0 上线后也引发了争议。 知名科技博主影视飓风创始人潘天鸿（Tim）在评测中发现：仅上传一张面部照片，Seedance 2.0 就生成了带有他个人音色的声音和公司大楼画面。 他表示：”这基本上可以确定，Seedance 2.0 大量训练了我们公司的视频。我明确没有进行授权。” 此事引发了 AI 训练数据版权问题的广泛讨论。随后，字节跳动暂停了 Seedance 2.0 的真人素材参考能力，正在加强安全防护措施。 目前涉及名人或知名 IP 的视频生成会被审核拦截，提示”视频未通过审核，本次不消耗积分”。 四、试用全攻略：5 种免费渠道好消息是，Seedance 2.0 有多个免费使用渠道。以下是完整攻略： 渠道一：即梦网页版（⭐ 质量最好）地址：jimeng.jianying.com 步骤： 手机号注册账号 购买 ¥1 试用会员（解锁 2.0 必须步骤） ⚠️ 立即取消订阅（避免自动续费） 进入视频生成页面，选择 Seedance 2.0 模型 积分规则： 注册送 2 次免费体验 + 260 积分 每天登录送积分 生成 1 秒视频消耗 6 积分 充值：69 元/月送 1080 积分 优势：时长 4-15 秒可精确选择，质量最佳 渠道二：小云雀网页版（⭐ 性价比最高）地址：xyq.jianying.com 字节内部赛马产品，主打 Agent 一键出长片。 步骤： 先手机下载小云雀 App 注册（网页版无法直接注册） 用同一账号登录网页版 注册送 3 次 + 1200 积分，不需要充钱就能用 2.0！ 积分规则： 注册送 1200 积分（约 120 秒视频） 每天登录送 120 积分 生成 1 秒视频消耗 10 积分 会员首月 39 元/月送 1200 积分 优势：注册即送最多积分，门槛最低 🎬 实拍演示：下面这段视频是我用 Seedance 2.0 通过小云雀平台生成的，感受一下效果： !videoSeedance 2.0 小云雀生成演示 渠道三：豆包 App（⭐ 最方便）字节旗下 AI 助手，很多人已经装了。 步骤： 打开豆包 App 访问 doubao.com/chat/settings 获取 UID 加入豆包官方飞书群，填写 UID 等管理员通过（1-2 天） 通过后即可使用 Seedance 2.0 额度：每天 10 次免费（5 秒或 10 秒） 注意：App 版有 2.0，网页版暂时没有 渠道四：Dreamina 国际版（海外用户）地址：dreamina.capcut.com 需要美金信用卡或 PayPal，面向海外用户。 渠道五：Pippit 国际版（7 天免费试用）地址：pippit.ai 注册送 520 积分 + 每天 120 积分 7 天免费试用（记得提前取消！） 需要开 Global 模式访问 🎯 新手推荐组合 需求 推荐方案 零成本体验 小云雀（送1200积分）+ 豆包（每天10次） 追求质量 即梦网页版（¥1解锁） 批量生产 即梦 + 小云雀双平台 海外用户 Dreamina 或 Pippit 第一天注册全部平台，可获得约 213 秒（3.5 分钟）的免费 AI 视频额度。 之后每天至少 60+ 秒免费额度。 五、提示词技巧：怎么写才能出好片？基础模板1[场景描述]，[角色描述]，[动作描述]，[镜头运动]，[氛围/光线] 示例 1：电影感镜头 樱花树下，一个女孩扭头看向一只猫，花瓣飘落，微风吹过她的头发。女孩摸了摸猫的头，对猫说”你好呀小家伙”，最后画面定格在女孩上。 示例 2：动作场景 少年主角在战斗中被击倒，在伙伴呼喊声中觉醒隐藏力量。身体周围爆发金色气场，头发变色竖起。随后以超高速冲向敌人，释放巨大的能量斩击，斩击波横切整个天空。 示例 3：多角度追逐 以这张照片为开头，图中人物扔掉纸板摆功夫起手式，与机器人激战。低角度跟拍侧闪 + 机器人横扫，中景快切拳掌撞金属，特写火花 + 镜头微震。 进阶技巧 描述越具体越好：不要写”一个人在走路”，写”穿着深蓝色风衣的中年男人在雨中的东京街头快步行走，霓虹灯映在湿漉漉的地面上” 用分镜思维：描述镜头的切换——“先远景 → 中景 → 特写” 加入情绪词：紧张、温馨、史诗、孤独——模型会自动匹配色调和节奏 善用参考素材：上传风格参考图比文字描述更精准 短视频（4-5秒）质量最稳定，长视频更容易出瑕疵 六、与竞品对比 能力 Seedance 2.0 Sora 2 Veo 3.1 可灵 自运镜 ✅ 自动 ❌ 需手动描述 部分 部分 音画同步 ✅ 原生 ✅ ✅ ❌ 多模态输入 ✅ 文/图/视频/音频 文/图 文/图 文/图 角色一致性 ⭐⭐⭐⭐⭐ ⭐⭐⭐⭐ ⭐⭐⭐⭐ ⭐⭐⭐ 单次可用率 90%+ 50-60% 60-70% 30-40% 最长时长 15秒 15秒 8秒 10秒 免费额度 多渠道 无（$200/月） 有限 有限 物理真实感 ⭐⭐⭐⭐⭐ ⭐⭐⭐⭐ ⭐⭐⭐⭐ ⭐⭐⭐ 七、行业影响：谁会被颠覆？1. 短剧行业短剧制作成本中，演员、场地、摄像团队占大头。如果 AI 能生成足够质量的视频，这些成本可能被削减 90% 以上。更重要的是，制作周期的缩短意味着可以快速 A/B 测试，用数据驱动内容迭代。 2. 动漫/动画行业传统动画中耗时的关键帧绘制、中间画填充、口型同步等环节，现在可以极大提速。一位做了 10 年院线电影的从业者说： “5 秒特效镜头传统流程需要一个高级制作人员花近一个月。现在 3 块钱，2 分钟搞定。数千倍成本下降，上万倍效率提升。” 3. 视频 Agent 赛道AI 视频 Agent 以前靠”拆解工作流 + 工程优化”弥补模型不足。但当模型本身足够强时，工程层面能优化的空间就很小了。 未来比的是谁对 Seedance 2.0 理解更深，能把这套理解做进产品。 4. 广告行业一条 30 秒广告片，传统制作可能需要几十万和数周时间。Seedance 2.0 让个人创作者也能产出商业级质量的视频，广告行业的门槛正在被拉平。 八、写在最后有人说 Seedance 2.0 是第一个展现出”世界模型”雏形的视频生成产品。它不只是在”画”你描述的场景，它在构建一个有内在逻辑的世界：花瓣飘落方向和风向一致，物体重力表现合理，角色情绪和语气匹配。 当工具强大到一定程度，**你不再想”这个模型能不能做到”，而是开始想”我要讲一个什么样的故事”**。 工具退到了幕后，创作者走到了台前。 2026 年 AI 视频市场规模预计突破 300 亿美元。在这场革命中，真正稀缺的不是工具，而是你脑子里那个还没被讲出来的故事。 参考来源：极客公园、新京报贝壳财经、AI工具集、36氪、掘金社区","link":"/2026/02/10/seedance-2-guide/"},{"title":"OpenClaw 国内定制版部署指南：Windows 从零到跑通，全程国内网络，必定成功","text":"这篇写给谁？ 你在国内，用 Windows，想搞一个真正能用的 AI 私人助手。网上那些教程——要么是 Mac 的（你摸了摸手里的联想），要么跑到一半报错就没下文了（最气的一种）。这篇不一样——全程国内网络，保证能跑通。跑不通你来找我。 先说结论OpenClaw 是 2026 年最火的开源 AI 助手项目（GitHub 146K+ Stars，没错，十四万六千颗星星），它能干啥？ 🖥️ 直接操作你的电脑（读写文件、执行命令、管理日程——比你自己操作还利索） 💬 接入飞书/钉钉/微信，变成你的专属 AI 秘书（再也不用自己回老板消息了……开玩笑的） 🧠 使用国产大模型（通义千问 Qwen、DeepSeek），不花一分钱外币 本文目标：在你的 Windows 电脑上，用纯国内资源把 OpenClaw 跑起来，而且 24小时在线不掉线。泡杯茶，咱们开始。 第一步：安装 Node.js（3分钟搞定）OpenClaw 跑在 Node.js 上面，所以我们先把地基打好。需要 22 以上版本。 方法一：官网安装（推荐，小白友好） 打开 Node.js 中文网（国内可以直接访问，放心点） 下载 LTS 版本（v22.x）的 Windows 安装包（.msi） 双击安装，全部默认下一步——这可能是整个教程最简单的一步了 方法二：通过 fnm 安装（老手可以秀一下）1234# PowerShell（管理员模式）winget install Schniz.fnmfnm install 22fnm use 22 装完之后，打开一个全新的 PowerShell 窗口（划重点，一定要新开），验证一下： 12345node -v# 应该显示 v22.x.xnpm -v# 应该显示 10.x.x 看到版本号了？恭喜，地基打好了，接下来才是重头戏。 第二步：配置国内 npm 镜像（救命一步！）这是国内安装成功的 最最最关键一步。npm 默认去国外服务器下载东西，从国内直连那个速度……蜗牛看了都摇头。不配镜像的话，你会在终端前面枯坐半小时，然后收获一个 ETIMEDOUT。 方案 A：安装 cnpm（推荐，省心省力）cnpm 是淘宝团队出的 npm 镜像客户端，直接走国内源，不需要改任何全局配置： 1npm install -g cnpm --registry=https://registry.npmmirror.com 装好后验证： 12cnpm -v# 应该显示版本信息 之后所有需要 npm install 的地方，用 cnpm 替代即可，速度飞起。 方案 B：直接换源（不想多装工具的话）1npm config set registry https://registry.npmmirror.com 就这一行，把 npm 的默认下载源换成国内镜像。验证一下： 12npm config get registry# 应该显示 https://registry.npmmirror.com 💡 说人话： 方案 A 装个 cnpm 最省心，后续直接 cnpm install 就完事。方案 B 改全局源也行，看你喜好。 第三步：安装 OpenClaw（终于到正主了）方式一：cnpm 安装（推荐）12# 以管理员身份打开 PowerShell（右键→以管理员身份运行）cnpm install -g openclaw@latest 看到类似 added xxx packages 就成功了。感谢淘宝镜像，通常几十秒搞定。 如果不幸遇到 sharp 相关报错（这是个图片处理库，有时候在 Windows 上会闹脾气）： 12$env:SHARP_IGNORE_GLOBAL_LIBVIPS=1cnpm install -g openclaw@latest 方式二：npm 安装（如果你用了方案 B 换源）1npm install -g openclaw@latest 方式三：官方安装脚本（一键流）1iwr -useb https://openclaw.ai/install.ps1 | iex 安装验证12openclaw --version# 应该显示版本号，如 2026.2.x 如果提示 openclaw 不是内部或外部命令——别慌，这是经典的 PATH 问题： 123456# 查看 npm 全局安装路径npm prefix -g# 把输出的路径加到系统 PATH 环境变量里# 通常是 C:\\Users\\你的用户名\\AppData\\Roaming\\npm# 然后重新打开 PowerShell 就好了 第四步：配置国产大模型（零成本，这才是国内玩家的快乐）不需要 OpenAI API Key（那玩意儿又贵又难搞），用国产模型就完事了。免费、好用、还不用担心被封号。 推荐模型对比 模型 厂商 免费额度 一句话点评 Qwen（通义千问） 阿里 100万 tokens/月 ⭐ 首选！额度大方，稳如老狗 DeepSeek 深度求索 1000万 tokens 推理一把好手，性价比之王 GLM-4 智谱 有免费额度 写代码可以信赖 Kimi 月之暗面 有免费额度 长文本处理的王者 配置方法：通义千问 Qwen（推荐首选）第 1 步：搞到 API Key 打开 阿里云百炼 用支付宝扫码登录（对，就这么简单） 进入「API Key管理」→ 「创建 API Key」 复制保存好这个 Key——待会儿要用，丢了就得重新建 第 2 步：运行向导配置 1openclaw onboard --install-daemon 向导会问你几个问题： 是否了解风险 → 选 Yes 安装方式 → 选 QuickStart 模型服务商 → 选 Qwen 按提示完成浏览器授权 或者直接编辑 ~/.openclaw/openclaw.json： 12345678910{ &quot;models&quot;: { &quot;default&quot;: &quot;qwen/qwen-max&quot;, &quot;providers&quot;: { &quot;qwen&quot;: { &quot;apiKey&quot;: &quot;sk-你的API Key&quot; } } }} 配置方法：DeepSeek（第二推荐）1234567891011{ &quot;models&quot;: { &quot;default&quot;: &quot;deepseek/deepseek-chat&quot;, &quot;providers&quot;: { &quot;deepseek&quot;: { &quot;apiKey&quot;: &quot;sk-你的API Key&quot;, &quot;baseUrl&quot;: &quot;https://api.deepseek.com/v1&quot; } } }} DeepSeek API Key 获取：platform.deepseek.com 第五步：接入国内社交工具（这步做完，才算真正好用）装好了 OpenClaw，配好了模型，但它现在还只是个终端里的聊天窗口。想让它真正变成你的 AI 秘书？得接上聊天工具。 方案一：飞书（推荐，体验最丝滑）飞书是目前国内接入 OpenClaw 体验最好的平台，没有之一。 1. 创建飞书应用 打开 飞书开放平台 创建企业自建应用（别怕，个人也能建） 拿到 App ID 和 App Secret 2. 配置权限（一键导入） 在应用后台的「权限管理」页面，可以手动逐个添加，也可以用批量导入的方式一步到位。 方式一：批量导入（推荐） 在飞书开放平台的应用配置页面，找到「权限管理」→「批量开通」，粘贴以下 JSON： 1234567891011121314151617181920212223242526272829303132333435{ &quot;scopes&quot;: { &quot;tenant&quot;: [ &quot;aily:file:read&quot;, &quot;aily:file:write&quot;, &quot;application:application.app_message_stats.overview:readonly&quot;, &quot;application:application:self_manage&quot;, &quot;application:bot.menu:write&quot;, &quot;cardkit:card:write&quot;, &quot;contact:contact.base:readonly&quot;, &quot;contact:user.employee_id:readonly&quot;, &quot;corehr:file:download&quot;, &quot;docs:document.content:read&quot;, &quot;event:ip_list&quot;, &quot;im:chat&quot;, &quot;im:chat.access_event.bot_p2p_chat:read&quot;, &quot;im:chat.members:bot_access&quot;, &quot;im:message&quot;, &quot;im:message.group_at_msg:readonly&quot;, &quot;im:message.group_msg&quot;, &quot;im:message.p2p_msg:readonly&quot;, &quot;im:message:readonly&quot;, &quot;im:message:send_as_bot&quot;, &quot;im:resource&quot;, &quot;sheets:spreadsheet&quot;, &quot;wiki:wiki:readonly&quot; ], &quot;user&quot;: [ &quot;aily:file:read&quot;, &quot;aily:file:write&quot;, &quot;contact:contact.base:readonly&quot;, &quot;im:chat.access_event.bot_p2p_chat:read&quot; ] }} 方式二：手动添加 如果你偏好手动操作，以下是需要开通的权限清单： 应用权限（tenant）： im:message / im:message:send_as_bot / im:message:readonly（消息收发） im:resource（获取文件/图片资源） im:chat / im:chat.members:bot_access（群聊访问） im:message.group_msg / im:message.group_at_msg:readonly（群消息） im:message.p2p_msg:readonly / im:chat.access_event.bot_p2p_chat:read（私聊） docs:document.content:read / wiki:wiki:readonly / sheets:spreadsheet（文档/知识库/表格读取） contact:contact.base:readonly / contact:user.employee_id:readonly（通讯录基本信息） cardkit:card:write（交互式卡片） application:application:self_manage / application:bot.menu:write（应用管理） 其他：aily:file:read/write、corehr:file:download、event:ip_list 用户权限（user）： aily:file:read / aily:file:write contact:contact.base:readonly im:chat.access_event.bot_p2p_chat:read 3. 配置事件订阅 请求地址：https://你的服务器地址:18789/feishu/webhook 订阅事件：im.message.receive_v1 4. 配置 openclaw.json 123456789101112131415{ &quot;channels&quot;: { &quot;feishu&quot;: { &quot;accounts&quot;: { &quot;default&quot;: { &quot;appId&quot;: &quot;cli_你的AppID&quot;, &quot;appSecret&quot;: &quot;你的AppSecret&quot;, &quot;encryptKey&quot;: &quot;你的加密Key&quot;, &quot;verificationToken&quot;: &quot;你的验证Token&quot;, &quot;enabled&quot;: true } } } }} 方案二：钉钉钉钉接入方式类似飞书，通过企业内部应用 + 机器人实现。路子差不多，这里就不重复了。 方案三：微信（需要第三方桥接，稍微折腾一点）微信没有官方机器人 API（你懂的），需要通过 WeChat Bridge 等第三方工具桥接。 💡 真心建议：先用飞书跑通，体验最流畅。飞书个人版免费，不需要企业认证。等你玩明白了再搞微信也不迟。 第六步：Windows 防睡眠配置（别让你的 AI 秘书打瞌睡）OpenClaw 是常驻后台服务。如果电脑进入睡眠……你的 AI 秘书就直接下班了。以下几招彻底解决睡眠问题，让它 7×24 给你打工。 方法一：powercfg 命令（最快，30秒搞定）以管理员身份打开 PowerShell： 1234567891011# 关闭睡眠（交流电模式下）powercfg /change standby-timeout-ac 0# 关闭休眠powercfg /change hibernate-timeout-ac 0# 关闭屏幕（可选，省电但不影响 OpenClaw）powercfg /change monitor-timeout-ac 15# 禁用休眠文件（还能省几个G磁盘空间）powercfg -h off 方法二：创建”永不睡眠”电源计划1234567# 创建新的电源计划powercfg -duplicatescheme 8c5e7fda-e8bf-4a96-9a85-a6e23a8c635c# 在 &quot;控制面板 → 电源选项&quot; 中找到新计划，设置：# - 关闭显示器：15分钟# - 使计算机进入睡眠状态：从不# - 关闭硬盘：从不 方法三：创建 keep-awake 脚本创建 keep-awake.ps1： 123456789101112131415161718# OpenClaw Keep Awake Script# 每 4 分钟模拟一次按键，防止系统进入睡眠Write-Host &quot;🦞 OpenClaw Keep Awake - 防睡眠模式已启动&quot; -ForegroundColor GreenWrite-Host &quot;按 Ctrl+C 停止&quot; -ForegroundColor Yellow$shell = New-Object -ComObject WScript.Shellwhile ($true) { $shell.SendKeys(&quot;{SCROLLLOCK}&quot;) Start-Sleep -Milliseconds 200 $shell.SendKeys(&quot;{SCROLLLOCK}&quot;) $timestamp = Get-Date -Format &quot;yyyy-MM-dd HH:mm:ss&quot; Write-Host &quot;[$timestamp] 💓 心跳 - 系统保持唤醒&quot; -ForegroundColor DarkGray Start-Sleep -Seconds 240 # 4分钟} 方法四：设置开机自启（一劳永逸）创建 openclaw-startup.bat，放到 Windows 启动文件夹： 1234567891011@echo offecho Starting OpenClaw Gateway...:: 防止睡眠powercfg /change standby-timeout-ac 0powercfg /change hibernate-timeout-ac 0:: 启动 OpenClawopenclaw gateway startecho OpenClaw is running! 启动文件夹怎么找？按 Win + R，输入 shell:startup，把 bat 文件丢进去就行。 验证防睡眠生效12345# 查看当前电源设置powercfg /query SCHEME_CURRENT# 查看活跃的电源请求powercfg /requests 第七步：启动并验证（激动人心的时刻！）启动 Gateway1openclaw gateway start 检查状态12openclaw statusopenclaw health 打开 Web 界面1openclaw dashboard 浏览器会自动打开 http://localhost:18789，看到管理面板了？那就是你的 AI 管家的控制中心。 测试对话在飞书（或其他已配置的聊天工具）中，给机器人发一条消息： 1你好，你是谁？ 如果收到回复——恭喜你，你做到了！ 🎉 国内版 OpenClaw 配置成功，从此你有了一个 24 小时待命的 AI 私人助手。 常见问题 FAQ（踩坑指南）Q: npm/cnpm install 很慢/超时怎么办？十有八九是没配镜像源。回去看第二步，装 cnpm 或换源： 1npm install -g cnpm --registry=https://registry.npmmirror.com Q: sharp 安装报错？这货在 Windows 上偶尔会闹别扭： 12$env:SHARP_IGNORE_GLOBAL_LIBVIPS=1cnpm install -g openclaw@latest Q: 找不到 openclaw 命令？经典 PATH 问题： 123456# 先看看 npm 把东西装到哪儿了npm prefix -g# 把输出的路径加到系统 PATH 环境变量里# 通常是 C:\\Users\\你的用户名\\AppData\\Roaming\\npm# 加完重开 PowerShell 就好了 Q: Gateway 启动报端口被占用？12345# 查看是谁占了netstat -aon | findstr 18789# 请它走taskkill /PID 进程ID /F Q: 模型回复很慢？ 通义千问 qwen-max 响应最快，日常用它 DeepSeek 推理任务用 deepseek-reasoner 确保用的是国内 API 端点（别走国际线路） Q: 电脑重启后 OpenClaw 没自动启动？用上面的 openclaw-startup.bat 放到启动文件夹，或者： 1openclaw onboard --install-daemon 这会把 OpenClaw 注册为系统服务，重启也不怕。 完整配置文件参考给你一份 ~/.openclaw/openclaw.json 的完整示例，直接抄作业： 123456789101112131415161718192021222324252627{ &quot;models&quot;: { &quot;default&quot;: &quot;qwen/qwen-max&quot;, &quot;providers&quot;: { &quot;qwen&quot;: { &quot;apiKey&quot;: &quot;sk-你的通义千问API Key&quot; }, &quot;deepseek&quot;: { &quot;apiKey&quot;: &quot;sk-你的DeepSeek API Key&quot;, &quot;baseUrl&quot;: &quot;https://api.deepseek.com/v1&quot; } } }, &quot;channels&quot;: { &quot;feishu&quot;: { &quot;accounts&quot;: { &quot;default&quot;: { &quot;appId&quot;: &quot;cli_你的AppID&quot;, &quot;appSecret&quot;: &quot;你的AppSecret&quot;, &quot;encryptKey&quot;: &quot;你的加密Key&quot;, &quot;verificationToken&quot;: &quot;你的验证Token&quot;, &quot;enabled&quot;: true } } } }} 总结：30 分钟，从零到拥有 AI 秘书 步骤 干了啥 花了多久 1 装 Node.js 5 分钟 2 配 npm 镜像 1 分钟 3 装 OpenClaw 3 分钟 4 配国产大模型 5 分钟 5 接飞书 15 分钟 6 防睡眠 3 分钟 7 启动验证 2 分钟 总计约 30 分钟，全程国内网络，不需要花一分美金。 你现在拥有了一个 24小时在线的 AI 私人助手——它能帮你管理日程、读写文件、处理消息、操作电脑，而且跑在你自己的机器上，数据完全私有，没有人偷看你的聊天记录。 欢迎来到 AI Agent 时代，朋友。这才刚刚开始。🦞 本文基于 OpenClaw 2026.2.x 版本编写，如有更新请以官方文档为准。官方文档：https://docs.openclaw.aiGitHub：https://github.com/openclaw/openclaw","link":"/2026/02/08/openclaw-china-windows-guide/"},{"title":"编程的本质","text":"","link":"/2022/11/01/the-nature-of-code/"},{"title":"什么是好代码？","text":"","link":"/2022/11/01/what-is-good-code/"},{"title":"从 Cursor 到 Lovart：AI 时代的窗口期与维度战争","text":"最近在思考 AI 行业的演进，尤其是像 Cursor 和 Lovart 这样的应用层产品，让我对整个 AI 发展的“窗口期”和“维度”有了一些新的理解。 Cursor：AI Native 的 IDE 范本Cursor 的价值其实跟 Lovart 很像，它们都不做自己的底层大模型，而是专注于应用层体验。这是它们的共同点。 为什么 Cursor 能突围？目前全世界用户量最大的 AI 编程工具无疑是 VS Code 的 GitHub Copilot 插件，日活可能达到 1600 万。虽然体量大，但它的渗透率其实不高，可能不到 20%。 为什么？因为整个开发环境极度碎片化。 Cursor 的差异化在于，它不是从传统 IDE“转型”过来的，它生来就是为 AI 时代设计的。它是 AI Native 的。 虽然它的竞争对手很多，像亚马逊、WinScribe，还有字节跳动的 Trae，大家都是基于 VS Code 开源版本魔改的。但 Cursor 做的最彻底：它重构了 UI，打破了传统 IDE “打开项目 -&gt; 找文件 -&gt; 写代码” 的流程。 在 Cursor（以及类似产品）里，你一进来可能就是一个对话框。它直接问你：“**What do you want to create today?**” 你输入需求，它帮你创建文件夹。 它帮你生成工程结构。 它帮你写 Feature Spec（功能文档）。 它帮你写代码、构建、运行。 理论上，你只需要负责“看”就行了。 当然，现阶段完全不看代码是不可能的，你还得懂代码，这样才能更好地引导它。但 Cursor 这种“从对话开始构建一切”的体验，确实代表了 IDE 的未来形态。 维度的演进：1D -&gt; 2D -&gt; 3D如果把 AI 的能力对应到物理世界的维度，我们可以看到一条清晰的演进路线： 1D（一维）：文本 对应大语言模型（LLM）的 Context Window（上下文窗口）。 这是目前最成熟的领域，也是 Cursor、ChatGPT 擅长的战场。 2D（二维）：图像/音频 对应多模态模型（Vision/Audio）。 Lovart 就在做这个。它是一个 AI 设计 Agent，不仅仅是生成图片，而是理解上下文、保持设计一致性，做全套的视觉输出。 3D（三维）：现实世界 对应机械、建筑、3D 游戏，以及最终的现实世界模型。 这是 AI 的终极战场。当 AI 理解了物理规律、空间关系，它就能指挥机器人造房子、设计复杂的工业零件。 窗口期与护城河从 1D 到 3D，越往后，窗口期越晚，技术门槛越高。 目前很多基于 AI 的创业项目（比如帮电商老板做图），本质上是在利用认知差赚点小钱。 电商老板可能不知道 Lovart。 或者 Lovart 现在的版本还不够好，没法覆盖所有通用需求。 但这只是暂时的。随着通用基座模型越来越强（GPT-5, Gemini 3 等），以及像 Lovart 这样的垂类产品不断成熟，这种“简单套壳”或“中间商”的生存空间会被迅速压缩。 有一天，小老板在家刷抖音，看到同行用了一个新工具（比如进化版的 Lovart），一键生成了比你做得还好的图，那时候你的“差异化”就荡然无存了。 我们的机会在哪里？本质上，如果一个东西复杂度不够，或者不够新，我们就无法建立起真正的护城河。时间窗口太短，不足以让我们跑出差异化优势。 所以，要么做更难的事（向 3D 进发），要么在更复杂的垂直领域（比如出版、漫画翻译、工业设计）沉得足够深，深到通用模型在短期内无法替代你的行业 Know-how。 这也是为什么我在看 Cursor 和 Lovart 时，看到的不仅仅是工具，而是 AI 行业水位线不断上涨的缩影。 本文基于 2026 年 2 月的行业观察。","link":"/2026/02/02/ai-industry-thoughts-2026/index/"},{"title":"AI for Science：当人工智能开始戴上实验手套","text":"2026 年伊始，当我们还在讨论 Claude Opus 4.5 和 Gemini 3 Pro 谁写代码更溜的时候，科技巨头们的目光早已投向了更深远的星辰大海——**AI for Science (AI4S)**。 微软 CEO Satya Nadella 在年初的预测中直言：“2026 年，AI 将不再仅仅是总结论文、回答问题或编写报告，它将积极参与物理学、化学和生物学的发现过程。” 这不是科幻小说，这是正在发生的范式转移。 从“预测”到“创造”过去两年，我们习惯了用 ChatGPT 帮我们读文献、写摘要。但现在的 AI，正在开始“戴上实验手套”，从单纯的预测者进化为创造者。 传统的科学发现往往依赖于“试错法”：爱迪生试了上千种材料才找到钨丝，医药公司合成数万种化合物才筛选出一款新药。这种方法虽然有效，但极其昂贵且低效。而 AI 正在改变这一规则。 生物学的“上帝视角”：AlphaFold 3 与 Isomorphic LabsDeepMind 的 AlphaFold 曾是该领域的明星，而到了 2026 年，AlphaFold 3 已经彻底改变了游戏规则。 它不再局限于单一蛋白质结构的预测，而是能够精准模拟蛋白质与 DNA、RNA、配体以及修饰分子的复杂相互作用。这意味着，科学家可以在计算机里“预演”药物进入人体后的全套生化反应。 Isomorphic Labs（DeepMind 的兄弟公司）在 2025 年底公布的数据显示，他们利用 AI 设计的药物管线，将早期药物发现的时间从平均 4-5 年压缩到了 12 个月以内。这不是效率的提升，这是维度的跨越。 炼金术的复兴：GNoME 与自主实验室在材料科学领域，Google DeepMind 的 GNoME (Graph Networks for Materials Exploration) 工具已经发现了 220 万种 理论上稳定的新晶体结构——这相当于人类过去 800 年积累的知识总和的 45 倍。 但这还不够。真正的突破在于自主实验室 (Self-driving Labs) 的普及。 2026 年的顶级实验室里，你可能看不到几个穿着白大褂的研究员。取而代之的，是 24/7 不间断工作的机器人手臂。它们直接连接着 AI 大脑（Agent），能够自主阅读最新的 GNoME 论文，设计合成方案，操作移液枪和反应釜，测试新材料的超导性或电池效率，并根据实验结果实时调整下一轮参数。 MIT 和伯克利的团队已经展示了这种闭环：AI 可以在没有人类干预的情况下，连续运行 30 天，筛选出性能提升 30% 的新型电池电解质。 预测“灰天鹅”：AI 驯服极端天气除了微观世界，AI 也在宏观尺度上大显身手。 传统的数值天气预报（NWP）依赖于超级计算机求解复杂的流体力学方程，极其耗能且难以捕捉极端异常。而基于 AI 的气象大模型（如 GraphCast 的后续版本）现在能够结合物理模型，精准预测 “灰天鹅” (Gray Swan) 事件——那些历史上每千年才发生一次的极端气候灾害。 2025 年夏季的北大西洋飓风季中，AI 模型比传统模型提前 4 天准确预警了飓风的异常路径，为沿海城市争取了宝贵的撤离窗口。这证明了 AI 不仅能“算”得快，更能“看”到传统方程遗漏的非线性混沌规律。 Agentic Science：全自动科研助手我们正在迈向第五范式：Agentic Science。 如果说第四范式是“数据密集型科学”，那么第五范式就是“智能体驱动的科学”。 像 Agent Laboratory (Schmidgall et al., 2025) 这样的系统，已经展示了未来的雏形：你给 AI 一个模糊的目标（例如“寻找一种更环保的聚合物”），AI Agent 会自主完成以下全流程： Literature Review: 阅读数千篇相关文献，总结前人失败的教训。 Hypothesis Generation: 提出 10 个可能的化学结构假设。 Experiment Design: 设计具体的合成路径和表征方法。 Execution (via Cloud Lab): 调用云端实验室接口执行实验。 Analysis &amp; Reporting: 分析数据，甚至帮你写好论文初稿。 在这个范式中，科学家的角色从“实验员”变成了“指挥官”。 对技术人的启示作为开发者，我们为什么要关注 AI for Science？ 因为这代表了 AI 应用的下一个高地。当生成式 AI 在文本和图像生成领域逐渐红海化，利用 AI 解决物理世界的硬核问题将成为新的蓝海。 如果你懂深度学习，又对生物、化学或物理有一点点兴趣，那么恭喜你，你正站在一个跨学科创新的黄金路口。 2026 年，不要只盯着 Chatbot。去看看那些正在显微镜下、在反应釜中、在星空深处发生的变革。那里，才是 AI 真正的星辰大海。","link":"/2026/02/02/ai-for-science-2026/index/"},{"title":"GitHub Trending 日报：今日最火的 5 个开源项目深度解析","text":"AI Agent 工具链正在迎来爆发期——今天的 GitHub Trending 榜单几乎被 AI 相关项目垄断。从 Google 的结构化信息提取、到 GitHub 官方的 Agent 工作流、再到全自动 AI 渗透测试，每一个项目都在重新定义各自领域的工作方式。 让我们逐一拆解今日最火的 5 个开源项目。 1. Google LangExtract — 用 LLM 从非结构化文本中精准提取结构化数据 ⭐ 28,463 Stars | 📈 +1,654 today | 🐍 Python | 📜 Apache-2.0 仓库地址： google/langextract 项目简介LangExtract 是 Google 开源的 Python 库，专门用 LLM 从非结构化文本（临床笔记、研报、法律文件等）中提取结构化信息。与传统 NER 工具不同，它强调 精准溯源——每个提取结果都能映射回源文本的精确位置。 为什么火？这个项目直击了 LLM 应用落地的一个核心痛点：可信度。大模型很擅长理解文本，但企业场景要求的不只是”理解”，还需要”证据”。LangExtract 的溯源（source grounding）机制让每条提取结果都有据可查，极大降低了幻觉风险。 加上 Google 亲自下场开源，自带 Gemini 系列模型的深度集成，又同时支持 OpenAI 和 Ollama 本地模型，适用面非常广。 技术亮点 精准溯源：每个提取实体都映射到源文本的精确位置，支持可视化高亮 长文档优化：分块+并行处理+多轮扫描策略，解决了”大海捞针”问题 可控输出：基于 few-shot example 定义 schema，支持 Gemini 的 controlled generation 保证输出格式一致 交互式可视化：一键生成独立 HTML 文件，可视化审查提取结果 灵活的 LLM 后端：Gemini（推荐）/ OpenAI / Ollama 本地模型 技术栈Python + Pydantic + Gemini API + 可选 OpenAI/Ollama 后端。项目结构清晰：核心逻辑在 langextract/，示例在 examples/，基准测试在 benchmarks/。 适用场景 医疗：从临床报告中提取药物、诊断、检查结果 法律：合同关键条款提取 金融：研报中的关键指标结构化 任何需要”从一堆文字里挑出关键信息”的场景 2. AionUi — AI CLI 工具的统一图形化工作台 ⭐ 14,445 Stars | 📈 +629 today | 💻 TypeScript | 📜 Apache-2.0 仓库地址： iOfficeAI/AionUi 项目简介AionUi 是一个给命令行 AI 工具（Gemini CLI、Claude Code、Codex、OpenClaw 等）套上图形界面的桌面应用。你可以把它理解为”AI 编程助手的统一工作台”——一个界面管理所有 CLI AI 工具。 为什么火？2026 年初是 AI 编程工具井喷的时期，Claude Code、Gemini CLI、Codex、OpenClaw 等各有所长，但都是命令行工具。对于很多开发者来说，在多个终端窗口之间切换是真实的痛点。AionUi 把这些工具统一到一个可视化界面里，自动检测本地安装的 CLI 工具、支持多会话并行、对话历史本地存储。 技术亮点 Multi-Agent 模式：一个界面同时接入 Gemini CLI、Claude Code、Codex、OpenClaw 等多种工具 自动检测：自动识别本地安装的 CLI AI 工具并集成 远程访问：支持通过内网穿透从手机/平板访问桌面端的 AI 工具 本地优先：所有对话数据本地存储，不上传到云端 跨平台：macOS、Windows、Linux 全平台支持 技术栈TypeScript + Electron/Tauri（桌面端框架）+ Node.js。内置 Gemini CLI，支持 API Key 直连各大模型。 适用场景如果你同时使用多个 AI 编程助手，又不想在 N 个终端窗口之间切换，AionUi 是目前最成熟的统一方案。特别适合日常在 Claude Code 和 Gemini CLI 之间来回切换的开发者。 3. Shannon — 全自动 AI 渗透测试工具（XBOW 基准 96.15% 成功率） ⭐ 19,760 Stars | 📈 +3,619 today | 💻 TypeScript | 📜 AGPL-3.0 仓库地址： KeygraphHQ/shannon 项目简介Shannon 是一个全自动的 AI 渗透测试工具。你给它指向一个 Web 应用，它会自主完成从信息收集到漏洞利用的全流程，最终输出包含可复现 PoC 的安全报告。在 XBOW 基准测试中达到了 96.15% 的成功率。 为什么火？今天的 star 增量高达 +3,619，是榜单上涨最猛的项目。原因很直接：Vibe Coding 时代的安全焦虑。 AI 编程工具让代码产出效率暴涨，但安全审计跟不上。传统渗透测试一年才做一次，中间 364 天的安全空窗期怎么办？Shannon 的定位就是”你的 AI Red Team”——每次部署前自动跑一遍渗透测试，把安全从”年度事件”变成”持续流程”。 技术亮点 全自动化：一条命令启动，AI 自主完成侦察→分析→利用→报告全流程 真实利用：不是简单的扫描器，而是真正在浏览器中执行攻击（XSS、注入、认证绕过等） 代码感知：白盒测试模式，分析源代码指导攻击策略 内置安全工具链：集成 Nmap、Subfinder、WhatWeb、Schemathesis 等专业工具 并行处理：多类型漏洞并发检测，加速报告生成 渗透级报告：输出包含可复制粘贴的 PoC，消灭误报 技术栈TypeScript + Playwright（浏览器自动化）+ Claude/LLM 作为推理引擎 + Nmap/Subfinder 等安全工具。分 Lite（AGPL 开源）和 Pro（商业版）两个版本。 适用场景 开发团队：CI/CD 管线中集成自动化安全测试 安全工程师：快速对目标应用做渗透评估 创业公司：没有专职安全团队时的自动化安全兜底 ⚠️ 注意事项仅限白盒测试（需要源代码访问权限），AGPL-3.0 许可证对商业使用有要求。切勿对未授权的目标使用。 4. GitHub gh-aw — 用自然语言写 GitHub Actions Agent 工作流 ⭐ 1,342 Stars | 📈 +496 today | 🐹 Go | 📜 MIT 仓库地址： github/gh-aw 项目简介GitHub 官方出品的 gh CLI 扩展——Agentic Workflows。核心理念：用自然语言 Markdown 定义工作流，在 GitHub Actions 中运行 AI Agent。把”Actions + Agent + Safety”融为一体。 为什么火？这是 GitHub 对”Agent-native CI/CD”的官方回答。以前写 GitHub Actions 需要 YAML，现在可以用 Markdown 自然语言描述工作流，AI Agent 自动执行。这不是第三方工具，是 GitHub 自己的产品，信号意义巨大——CI/CD 的下一个形态就是 Agent 驱动的。 技术亮点 自然语言工作流：用 Markdown 写工作流定义，告别 YAML 噩梦 安全优先架构：默认只读权限，写操作必须通过 safe-outputs 白名单 多层安全防护：沙箱执行、输入消毒、网络隔离、依赖 SHA 锁定、工具白名单 人工审批门：关键操作需人类确认 配套安全组件：Agent Workflow Firewall（网络出口控制）+ MCP Gateway（MCP 协议网关） 技术栈Go（CLI 扩展）+ GitHub Actions 运行时 + AI Agent 推理层。支持 Claude Code、Codex、Copilot 等多种 Agent 后端。 适用场景 自动化代码审查、Issue 分类、PR 处理 用自然语言定义复杂的 CI/CD 流程 需要 AI Agent 参与但又要严格安全控制的 DevOps 场景 5. Compound Engineering Plugin — Claude Code 的复合工程插件 ⭐ 8,174 Stars | 📈 +406 today | 💻 TypeScript | 📜 MIT 仓库地址： EveryInc/compound-engineering-plugin 项目简介由 Every 团队开源的 Claude Code 插件，核心理念是”复合工程“——让每一次工程工作都为下一次积累经验，而不是增加技术债务。提供 Plan → Work → Review → Compound 的完整工作循环。 为什么火？这个项目代表了一种新的 AI 辅助编程哲学：不是让 AI 写更多代码，而是让 AI 帮你建立更好的工程习惯。80% 的时间花在规划和审查，20% 花在执行。每次代码变更都会被 AI 总结成可复用的知识，形成正向飞轮。 加上插件市场的设计——一条命令就能安装，还支持转换成 OpenCode 和 Codex 格式——降低了使用门槛。 技术亮点 四步循环：/workflows:plan（规划）→ /workflows:work（执行）→ /workflows:review（多 Agent 代码审查）→ /workflows:compound（知识沉淀） 插件市场：/plugin marketplace add 一键安装 跨平台转换：支持将 Claude Code 插件转换成 OpenCode 和 Codex 格式 知识复合：每次工作成果自动沉淀为 skills 和 patterns，供未来复用 个人配置同步：sync 命令可将个人 Claude 配置同步到 OpenCode/Codex 技术栈TypeScript + Bun 运行时 + Claude Code Plugin API。通过 npm 包 @every-env/compound-plugin 分发。 适用场景 使用 Claude Code 做日常开发的团队 想建立系统化 AI 编程工作流的个人开发者 跨多个 AI 编程工具（Claude Code + OpenCode + Codex）工作的用户 总结今天的 Trending 榜单呈现出一个清晰的趋势：**AI Agent 正在从”单点工具”走向”工程体系”**。 LangExtract 解决信息提取的可信度问题 AionUi 统一 AI 工具的操作界面 Shannon 把安全测试 Agent 化 gh-aw 让 CI/CD 进入 Agent-native 时代 Compound Engineering 用 AI 建立知识复利的工程文化 这五个项目放在一起看，AI 不仅在写代码，还在测试代码、审查代码、部署代码、从代码中学习。2026 年的软件工程，正在被 Agent 重新定义。 如果觉得这篇分析有帮助，欢迎点赞、在看、转发三连 🚀","link":"/2026/02/11/github-trending/2026-02-11/"},{"title":"GitHub Trending 日报：2026年2月9日最火的 10 个开源项目深度解析","text":"今天的 GitHub Trending 被 AI 和安全相关项目屠榜了。从自主渗透测试到金融研究 Agent，从 Rust 写的 Python 沙箱到手机端多模态大模型——每个项目都折射出 2026 年技术发展的核心脉络。下面逐个拆解。 1. KeygraphHQ/shannon ⭐ 14.6K | 📈 +3,479 today一句话：AI 自主渗透测试工具，96.15% 的漏洞发现成功率。 Shannon 不是又一个扫描器——它是一个真正会「攻击」的 AI。它会自主分析你的代码，找到攻击向量，然后用内置浏览器执行真实的注入攻击和认证绕过，证明漏洞确实可被利用。 为什么火？ Vibe-coding 时代，大家用 Claude Code、Cursor 疯狂写代码，但渗透测试一年才做一次。Shannon 填补了这 364 天的安全空白。它不只是报告「可能有漏洞」，而是直接打穿给你看。 技术亮点： TypeScript 构建，AGPL-3.0 许可，支持白盒测试。在 XBOW Benchmark 上无提示模式下达到 96.15% 的成功率，这个数字相当炸裂。 适用场景： 持续集成中的安全检查，特别适合快速迭代的团队。每次 build 都跑一遍 Shannon，比年度渗透测试靠谱得多。 2. pydantic/monty ⭐ 3.3K | 📈 +456 today一句话：Rust 写的最小化 Python 解释器，专门给 AI 用的安全沙箱。 Pydantic 团队的新作。当 LLM 生成 Python 代码需要执行时，你不想启动一个完整的容器——太慢太重。Monty 用 Rust 实现了一个精简版 Python 解释器，启动时间是微秒级别，而不是容器的几百毫秒。 为什么火？ Agent 需要执行代码，但安全是大问题。Monty 提供了一个优雅的中间方案：不用容器那么重，但比直接 exec() 安全得多。Pydantic 的品牌背书也加了不少分。 技术亮点： Rust 编写保证内存安全，MIT 许可，微秒级启动。不是完整的 Python 运行时，而是覆盖了 LLM 最常生成的那部分 Python 子集。 适用场景： AI Agent 的代码执行层。如果你在做 Agent 产品，需要让 AI 安全地运行生成的代码，Monty 值得关注。 3. openai/skills ⭐ 7.2K | 📈 +1,425 today一句话：Codex 的官方技能目录，Agent Skills 的开放标准。 OpenAI 把 Codex 的技能系统开源了。Skills 是一组指令、脚本和资源的文件夹，AI Agent 可以发现并使用它们来执行特定任务。写一次，到处用。 为什么火？ 这实际上是 OpenAI 在推动一个 Agent 技能的开放标准（agentskills.io）。类似 npm 之于 Node.js，Skills Catalog 想成为 AI Agent 的包管理器。这个定位非常有野心。 技术亮点： 分三层：.system（内置自动安装）、.curated（精选）、.experimental（实验性）。用 $skill-installer 在 Codex 内安装。 适用场景： Codex 用户直接受益。对于其他 Agent 框架的开发者，这个标准本身值得研究——你的 Agent 也可以复用这些 Skills。 4. virattt/dexter ⭐ 13K | 📈 +1,039 today一句话：自主金融研究 Agent，Claude Code 的金融版。 Dexter 接受复杂的金融问题，自动拆解成研究步骤，用实时市场数据执行分析，然后自我验证结果。它能访问损益表、资产负债表和现金流量表。 为什么火？ 金融研究是高度结构化但又极其耗时的工作。Dexter 展示了 Agent 在垂直领域的巨大潜力——不是通用聊天，而是真正能干活的专业工具。 技术亮点： TypeScript 构建，支持智能任务规划、自主执行、自我验证。内置循环检测和步数限制防止失控。基于 Financial Datasets API 获取实时数据。 适用场景： 量化分析师、基金经理、个人投资者。如果你需要快速对一家公司做深度财务分析，Dexter 能把几小时的工作压缩到几分钟。 5. microsoft/litebox ⭐ 1.6K | 📈 +359 today一句话：微软出品的安全导向库 OS，支持内核和用户态执行。 这个项目因为 Microsoft 组织的 SAML 认证保护，README 没法直接通过 API 获取。但从描述看，这是一个安全聚焦的库操作系统（Library OS），支持在内核态和用户态运行。 为什么火？ 微软在安全计算领域持续投入。在 AI 工作负载需要更强隔离性的今天，一个安全导向的轻量级 OS 层有很大的应用空间。Rust 编写也是加分项。 技术亮点： Rust 编写，安全优先设计。Library OS 的架构意味着应用可以在极小的信任边界内运行。 适用场景： 需要强隔离的云原生工作负载、AI 推理环境、机密计算场景。 6. google/langextract ⭐ 25K | 📈 +438 today一句话：用 LLM 从非结构化文本中提取结构化信息，带精确溯源和交互式可视化。 Google 的信息提取库。给它一段临床笔记、报告或任何文档，它会用 LLM 识别并组织关键细节，并且每个提取结果都能映射回原文的精确位置。 为什么火？ 25K stars 不是浪得虚名。信息提取是 LLM 最实用的应用之一，但「幻觉」问题让人不敢信任结果。LangExtract 的精确溯源功能（Precise Source Grounding）直接解决了这个痛点——每个提取结果都有据可查。 技术亮点： 支持 Gemini、OpenAI、Ollama 等多种模型。溯源到原文位置并可视化高亮。Apache 2.0 许可，对商用友好。 适用场景： 医疗记录处理、法律文档分析、财报解析、任何需要从大量文本中提取结构化数据的场景。 7. obra/superpowers ⭐ 48.1K | 📈 +813 today一句话：让你的 AI 编程助手具备完整的软件开发方法论。 这不是一个工具，而是一套方法论。Superpowers 给编程 Agent 注入了一整套工作流程：先理解需求，拆出规范，做实施计划，然后用子 Agent 驱动开发，全程 TDD。 为什么火？ 48K stars，可能是目前最火的 Agent 开发方法论。它解决了一个核心问题——AI 编程助手虽然能写代码，但缺乏工程纪律。Superpowers 让 Claude Code 可以自主工作数小时而不偏离计划。 技术亮点： 基于可组合的 Skills 架构，自动触发。强调 TDD、YAGNI、DRY 原则。支持 Claude Code（插件市场）、Codex 和 OpenCode。子 Agent 驱动开发（subagent-driven-development）是核心创新。 适用场景： 所有使用 AI 编程助手的开发者。装上就能用，不需要改变工作习惯。 8. OpenBMB/MiniCPM-o ⭐ 23.5K | 📈 +212 today一句话：Gemini 2.5 Flash 级别的多模态模型，能在手机上跑。 清华 OpenBMB 出品。MiniCPM-o 4.5 是一个 9B 参数的端到端多模态模型，支持图像、视频、文本和语音输入，能输出文本和语音。最关键的是——它能在手机上运行全双工多模态实时流。 为什么火？ 在手机上跑一个接近 Gemini 2.5 Flash 水准的多模态模型，这个噱头太强了。全双工意味着输入流（视频+音频）和输出流（文本+语音）互不阻塞，真正的实时对话体验。 技术亮点： 9B 参数，Apache 2.0 开源。支持视觉、语音和全双工多模态直播流。端到端架构，不是拼接方案。 适用场景： 移动端 AI 助手、实时视频通话 AI、边缘设备上的多模态交互。对国内开发者尤其友好——模型可自主部署，不依赖海外 API。 9. likec4/likec4 ⭐ 2.5K | 📈 +271 today一句话：用代码定义软件架构，自动生成实时更新的活文档。 受 C4 Model 和 Structurizr DSL 启发，但更灵活。你可以自定义标记法、元素类型和任意嵌套层级。架构图从代码生成，代码变了图自动更新。 为什么火？ 架构文档的最大问题是过时。LikeC4 把架构定义放进代码仓库，和业务代码一起版本控制，一起 review。这是真正的「Architecture as Code」。 技术亮点： TypeScript 构建，MIT 许可。有 VSCode 扩展、CLI 工具和 Playground。支持导出为静态网站，可以直接部署。 适用场景： 需要维护架构文档的团队。特别适合微服务架构——服务多了没人记得清全貌，LikeC4 让架构图永远和代码同步。 10. iOfficeAI/AionUi ⭐ 13.4K | 📈 +335 today一句话：免费本地的 AI 编程助手统一 UI，支持 Gemini CLI、Claude Code、Codex 等。 一个开源的桌面应用，为各种 CLI 编程 Agent 提供统一的图形界面。支持 Gemini CLI、Claude Code、Codex、OpenCode、Qwen Code、Goose CLI 等。 为什么火？ CLI 编程 Agent 越来越多，但不是所有人都喜欢在终端里工作。AionUi 提供了一个漂亮的 GUI 包装层，降低了使用门槛。本地运行保证数据安全，跨平台支持。 技术亮点： TypeScript 构建，Apache 2.0 许可。支持 macOS/Windows/Linux。多模型支持，本地数据不上传。 适用场景： 不想折腾终端但想用 AI 编程助手的开发者。或者需要同时使用多个 Agent 的人——统一界面比开 5 个终端窗口舒服得多。 总结今天的 Trending 有几个明显趋势： Agent 时代全面到来：10 个项目中有 6 个直接和 AI Agent 相关（shannon、monty、skills、dexter、superpowers、AionUi） 安全是 Agent 的基础设施：shannon 做攻击测试、monty 做安全沙箱、litebox 做 OS 级隔离——Agent 越强大，安全越关键 垂直领域 Agent 崛起：dexter（金融）、shannon（安全）证明了通用 Agent 框架之上，垂直场景才是变现方向 国产模型持续突破：MiniCPM-o 在端侧多模态领域做到了世界级水平 值得特别关注的是 obra/superpowers（48K stars）——它不是工具，而是方法论。当所有人都在做 Agent 工具时，它在定义 Agent 应该怎么工作。这可能是今天 Trending 里长期价值最高的项目。","link":"/2026/02/09/github-trending/2026-02-09/"},{"title":"2026年02月12日早间要闻","text":"📰 今日要闻1. 字节跳动 Seedance 2.0 引爆 A 股传媒板块字节跳动发布 Seedance 2.0 视频生成模型，支持从文本或图像直接生成电影级品质的视频内容。该消息直接引爆 A 股传媒板块，中文在线、光线传媒、掌阅科技等个股单日涨幅超 10% 甚至触及 20% 涨停板。市场将其类比为”2025年的 DeepSeek 时刻”，认为这标志着 AI 视频生成技术进入新阶段。不过需要注意的是，多数被炒作的公司缺乏实际业绩支撑，主要靠题材轮动推动。 2. 央行重申适度宽松货币政策中国人民银行发布《2025年第四季度货币政策执行报告》，明确将继续实施适度宽松货币政策，灵活运用降准降息等工具，保持流动性充裕和融资条件宽松。报告显示金融总量增长、融资成本下行、重点领域支持有力。这一表态对 A 股和宏观经济预期构成正面支撑。 3. 美国 1 月就业数据超预期美国劳工部公布 1 月非农就业数据，新增就业 13 万人，大幅超出经济学家预期的 7.5 万人，失业率意外降至 4.3%。强劲的就业数据缓解了经济放缓担忧，但同时也强化了美联储”higher for longer”的利率预期。市场目前预计 2026 年全年利率将维持在 3.5% 以上。 4. AI 供应链瓶颈：电子布价格跳涨AI 基础设施需求持续拉动上游材料紧缺。7628 电子布（电子级玻璃纤维布）价格从 2025 年 9 月底的 4.15 元/米涨至目前的 4.75 元/米，2025Q4 至今已累计上涨约 15%。A 股电子布概念集体爆发，宏和科技、国际复材、中材科技等多股涨停创历史新高。电子布是覆铜板制造的关键材料，直接影响 PCB 和芯片封装成本。 5. 美国禁止中国随锐科技收购美企美国司法部依据 1950 年《国防生产法》提起诉讼，要求中国随锐科技集团从加州丘比特系统公司（Jupiter Systems）撤资，理由是保护国家安全。这是中美科技脱钩趋势的又一案例，显示美国在科技并购审查方面持续收紧。 📈 美股重点关注（2月11日收盘）微软 MSFT — $404.37（-2.15%） Azure 收入增长 38% 符合预期，但市场持续忧虑 AI 资本开支的投资回报率 股价从 2025 年高点 $555.45 回撤超过 20%，估值回归合理区间（PE 25.8，EPS $15.65） 下一催化剂：Q1 2026 财报（4月29日），核心看 Copilot 渗透率和 Azure 增长加速 分析师平均目标价 $591.95，当前价位存在较大上行空间 谷歌 GOOGL — $322.86（-2.53%） 2026 年资本开支指引高达 $1750-1850 亿美元（同比翻倍），市场震惊 “资本焚烧”担忧持续拖累股价，从历史高点 $349 回落约 7.5% 核心看点：广告业务韧性 + Gemini 模型商业化进展 + 反垄断案进展 PE 29.8，估值不算离谱，关键是证明 AI 投资能转化为收入增长 英伟达 NVDA — $190.01（+0.75%） 逆市上涨，盘中一度冲高至 $193.26，Blackwell 芯片周期需求持续强劲 合作伙伴 Vertiv 发布亮眼财报（股价+15%），间接提振 NVDA 信心 2月25日财报是近期最大催化剂，市场期待极高 风险点：25% AI 硬件关税（”Trump Cut”）由超级云厂商自行消化，可能抑制采购量 当前市值 4.63 万亿美元，PE 46.7，1年目标价 $253.79 AMD — $213.58（持平） Q4 财报后股价已回调约 11%，盘中波动剧烈（$209-$219 区间） MI300 系列数据中心 GPU 出货在增长，但与 NVDA 的差距仍然明显 PE 81.8 偏高，需要持续证明在 AI GPU 市场的份额扩张 从 52 周高点 $267 回落约 20%，处于估值消化期 阿里巴巴 BABA — $168.39（-0.69%） 重金押注 AI：投入 30 亿元（约 $4.31 亿）推广通义千问 Qwen AI 应用 20 亿美元投资 Zelos Technology 加强物流基础设施能力 2月19日 Q3 财报在即，云智能增长和 AI 布局是关键看点 PE 22.5 估值合理，52 周高点 $192.67，当前距高点约 13% 📊 市场大势 纳斯达克综合指数：23,102.47（-0.6%），连续两日收跌 道琼斯工业指数：50,188.14（+0.1%），连续三日创历史新高 标普500：6,941.81（-0.3%） 市场呈现明显分化格局——传统工业、金融板块走强（道指创新高），而科技成长股承压（纳指回调）。核心矛盾在于：AI 资本开支螺旋式上升 vs 高利率环境下投资回报周期拉长。 关键日期： 2/13（周五）：1月 CPI 数据发布，将决定短期市场方向 2/19：阿里巴巴 Q3 财报 2/25：英伟达 Q4 财报 免责声明：以上内容仅为信息分享，不构成投资建议。","link":"/2026/02/12/2026-02-12-morning-news/"},{"title":"2026年AI驱动UI测试自动化全景：当大模型学会「看屏幕操作电脑」","text":"GPT-5.3 在 OSWorld 上拿到 64.7%，Claude Opus 4.6 达到 72.7% 超越人类水平（72.36%），UI-TARS-2 在 12 个 Poki 游戏上通关率 100%——2026 年 2 月，AI 操控电脑的能力正在以不可思议的速度进化。本文全面梳理基于最新一线大模型的 Agentic UI 测试框架，聚焦 Windows + Android 双平台。 核心变化：从「定位元素」到「看屏幕操作」传统 UI 自动化测试依赖 XPath、CSS Selector、Accessibility ID 等定位器。UI 一改，测试就崩。 2026 年的新范式彻底不同： 1截图 → 多模态大模型理解界面 → 规划操作步骤 → 模拟鼠标键盘执行 → 截图验证结果 不再需要任何定位器、不依赖 DOM 结构、不怕 UI 改版。 只要人类能看懂屏幕，AI 就能操作。 这背后的核心驱动力是多模态大模型的能力飞跃。让我们先看看 2026 年 2 月的最新战况。 一、模型层：谁在驱动 Computer Use？OSWorld Benchmark：AI 操控桌面的黄金标准OSWorld 是评估 AI 操控真实桌面环境（Windows/Linux/Mac）能力的权威 benchmark，包含文件管理、办公软件操作、浏览器任务等数百项真实任务。 2026 年 2 月最新排名： 模型/方案 OSWorld 得分 发布时间 备注 Anthropic BJudge (Claude Opus 4.6) 72.7% 2026.02 🏆 超越人类水平（72.36%） UiPath Screen Agent + Claude Opus 4.5 OSWorld-Verified #1 2026.01 企业级方案 GPT-5.3 Codex 64.7% 2026.02 历史最高单模型得分 UI-TARS-1.5 42.5% 2025.04 开源最强 OpenAI CUA (GPT-5 架构) 36.4% 2025 Operator 产品底层 Claude 3.7 Sonnet 28% 2024 Computer Use 首发版 关键信号：仅仅一年时间，从 28% 到 72.7%，AI 在桌面操控任务上已经超越了普通人类水平。 最新一线模型的 Computer Use 能力对比 能力维度 Claude Opus 4.6 GPT-5.3 Codex Gemini 3 Pro UI-TARS-2 OSWorld（桌面操控） 72.7% 🏆 64.7% - 42.5%* 上下文窗口 1M tokens 400K tokens 1M+ 本地部署 Agent Teams（多 Agent 协作） ✅ ❌ ❌ ❌ Computer Use API 原生支持 原生支持 - pyautogui BrowseComp（浏览器搜索） 84.0% - - - 视频理解 图片+文本 原生视频+音频 原生多模态 图片 成本（输入/1M tokens） $5 $1.25 - 免费（本地） Android 支持 需搭配框架 需搭配框架 需搭配框架 原生 Windows 支持 原生 Computer Use 原生 Computer Use - 原生 *UI-TARS-2 的 OSWorld 得分基于 2025.09 版本，最新版可能更高。其 benchmark 优势在 ScreenSpot（UI 定位精度）上更明显，达到 94.2%。 二、框架层：把大模型能力变成可用的测试工具光有模型不够，还需要框架来编排 Agent 工作流。以下是 2026 年最值得关注的 Agentic 测试框架。 1. Cua — 开源 Computer Use Agent 平台（⭐12.4K）GitHub：trycua/cua | MIT 许可 这是 2026 年最值得关注的新项目。 Cua 是一个专门为「AI 操控真实电脑」设计的开源平台，三层架构： Layer 1 — 沙盒环境： 环境类型 平台 说明 Cloud Sandbox Linux/Windows/macOS 托管云环境，开箱即用 Docker 容器 Linux 轻量级桌面环境 QEMU 虚拟机 Linux/Windows 11/Android 11 Docker 内运行完整 OS Lume macOS/Linux Apple Silicon 原生虚拟化 Windows Sandbox Windows 原生 Windows 沙盒 Layer 2 — Computer SDK：统一的 Python/TypeScript API，截图、鼠标点击、键盘输入、Shell 命令，一套代码跑所有沙盒。 Layer 3 — Agent 框架： 100+ 模型支持（Claude / GPT / Gemini / 开源模型） 预构建的 Agent Loop，专为 Computer Use 优化 内置 Android 支持（QEMU 虚拟化 + CuaBot） 为什么 Cua 对 UI 测试很重要？ 12345678910from cua import Agent, Sandbox# 创建隔离的 Windows 沙盒sandbox = Sandbox.create(&quot;windows-11&quot;)# 用 Claude Opus 4.6 驱动 Agentagent = Agent(model=&quot;claude-opus-4.6&quot;, sandbox=sandbox)# 自然语言描述测试任务agent.run(&quot;打开计算器，计算 123 × 456，验证结果是否为 56088&quot;) 不需要写任何定位器，不需要了解应用内部结构。Agent 会自己截屏、理解界面、操作、验证结果。 2. UiPath Screen Agent — 企业级 AI 自动化（OSWorld-Verified #1）UiPath 是全球最大的 RPA 公司。2025-2026 年，他们推出了 Screen Agent： 2025.09：基于 GPT-5 拿到 OSWorld #1 2026.01：切换到 Claude Opus 4.5 后拿到 OSWorld-Verified #1（369 项真实桌面任务） Screen Agent 代表了传统 RPA 与最新大模型的融合：用 UiPath 的企业级基础设施（机器人编排、权限管理、审计日志）+ 顶级大模型的视觉理解能力。 适合：已有 UiPath 基础设施的企业团队。 3. 微软 UFO³ + OmniParser V2（⭐8K + ⭐24.4K）GitHub：microsoft/UFO | microsoft/OmniParser 微软自家出品，Windows 原生 Agent 操作系统。 OmniParser V2 是目前最强的屏幕解析引擎：把任意截图转成结构化 UI 元素列表。支持开箱接入 GPT-5.x / Claude / DeepSeek R1 / Qwen 2.5VL 等模型。配套 OmniTool 提供 Docker 化 Windows 11 VM。 UFO³ 的核心优势是 Windows 深度集成： 双通道感知：Windows UIA API（控件树）+ 视觉模型（OmniParser），精确性和灵活性兼得 智能执行选择：自动判断用 API 直接调用还是模拟 GUI 操作 多设备编排（Galaxy 模式）：DAG 任务分解 + 异步并行 + 跨设备协作 演进路线： 12UFO (2024.02) → UFO² (2025.04) → UFO³ Galaxy (2025.11)单设备 Agent → Desktop AgentOS → 多设备编排 适合：Windows 桌面应用为核心的测试场景，尤其是需要操作 Office、Visual Studio 等微软生态软件。 4. 字节跳动 UI-TARS + Midscene.js（⭐9.5K + ⭐27.8K + ⭐11.7K）GitHub：bytedance/UI-TARS | bytedance/UI-TARS-desktop | web-infra-dev/midscene UI-TARS 是字节开源的多模态 GUI Agent 模型，基于 Qwen2.5-VL。它和商业模型走的是不同路线——可本地部署、零 API 成本。 UI-TARS 的独特优势： UI 定位精度最高：ScreenSpot-V2 达 94.2%（超 GPT 87.9%、Claude 87.6%） Windows + Android 双平台原生支持：提供 COMPUTER_USE 和 MOBILE_USE 两套 Prompt 模板 UI-TARS-2（2025.09）：All-In-One Agent 模型，加入 Game、Code、Tool Use 7B 模型可本地部署：一张消费级 GPU 即可运行 Midscene.js 是配套的测试框架（v1.0 已发布），用自然语言写测试： 1234// 自然语言描述操作await agent.aiAction('点击搜索框，输入 &quot;AI testing&quot;，按回车');await agent.aiAssert('搜索结果中包含相关内容');const data = await agent.aiExtract('提取前3个搜索结果的标题'); 全平台支持：Web（Puppeteer/Playwright）+ Android（adb）+ iOS（WebDriverAgent） 适合：追求零成本本地部署、同时覆盖桌面和移动端的团队。 5. AskUI Vision Agent — 企业级跨平台（⭐501）GitHub：askui/vision-agent Python SDK，支持 Windows / Mac / Linux / Android / iOS / Citrix。独特优势： Windows 后台自动化：Agent 创建独立会话，不占用前台鼠标键盘 支持热插拔模型 + 本地部署 Agent OS 底层设备控制器 适合：企业环境，对安全性和稳定性有要求。 6. Arbigent — Android/iOS 场景分解测试（⭐505）GitHub：takahirom/arbigent 核心创新：场景分解（Scenario Breakdown）。把复杂的端到端测试拆成多个有依赖关系的子场景，每个子场景独立运行和验证，大幅提高 AI 测试的可预测性。 GUI 操作界面，非开发人员也能上手。支持 OpenAI / Gemini / Claude 等多种模型。 适合：移动端 QA 团队。 三、学术前沿：正在孵化的下一代技术 项目 出处 核心贡献 平台 Scaling Agents for CU Anthropic (2026.02) BJudge + 多轮执行，OSWorld 72.6% 超越人类 桌面 AUITestAgent 北大 从自然语言需求自动生成 GUI 功能测试 Android VisionDroid 学术界 MLLM 功能感知探索 + 非崩溃 bug 检测 Android DroidAgent KAIST 意图驱动自主探索，自动生成 UIAutomator2 脚本 Android CogAgent 清华/智谱 双分辨率视觉编码器，专为 GUI Agent 设计 双平台 AppAgent 腾讯 多模态 Agent 像用户操作手机，含自主学习阶段 Android 论文合集：Awesome-GUI-Agent（⭐1.1K），持续更新。 四、横向对比：该选哪个？ 方案 Windows Android 最新模型支持 开源 成熟度 成本 Cua ✅ 沙盒 ✅ QEMU Claude/GPT/Gemini/开源 ✅ MIT 活跃开发 免费+API UiPath Screen Agent ✅ 原生 ❌ Claude Opus 4.5/GPT-5 ❌ 商业 生产级 企业许可 UFO³ + OmniParser ✅✅ 最深 ❌ GPT-5.x/Claude/DeepSeek/Qwen ✅ 生产级 免费+API UI-TARS + Midscene ✅ ✅ 原生 UI-TARS-2（本地） ✅ v1.0 完全免费 AskUI ✅ ✅ 多模型 部分 商业可用 SaaS Arbigent ❌ ✅✅ 多模型 ✅ 早期 免费+API 五、实战推荐方案方案 A：最强桌面能力（Claude Opus 4.6 + Cua/UFO³）1Claude Opus 4.6 (72.7% OSWorld) + Cua 沙盒 或 UFO³ 框架 当前桌面操控 SOTA，超越人类水平 Cua 提供隔离沙盒环境，安全可控 UFO³ 提供 Windows 原生深度集成 成本：$5/1M input tokens，适合高价值测试场景 方案 B：性价比之选（GPT-5.3 Codex + Cua）1GPT-5.3 Codex (64.7% OSWorld) + Cua 沙盒 单模型历史最高 OSWorld 得分 成本仅 Claude 的 1/4（$1.25/1M input tokens） 原生视频+音频理解能力 适合：大规模回归测试，对成本敏感 方案 C：零成本本地部署（UI-TARS + Midscene.js）1UI-TARS-1.5-7B（本地 GPU）+ Midscene.js 框架 Windows + Android 双平台原生覆盖 零 API 费用，一张 GPU 搞定 Midscene.js 自然语言写测试，开发者友好 适合：有 GPU 资源、追求长期低成本运营 方案 D：企业级落地（UiPath + Claude Opus 4.5）1UiPath Screen Agent + Claude Opus 4.5 OSWorld-Verified 认证第一 企业级基础设施（编排、权限、审计） 适合：已有 RPA 基础设施的大型企业 六、趋势判断1. Computer Use 已超越人类水平Claude Opus 4.6 在 OSWorld 上达到 72.7%，超越人类的 72.36%。这是一个里程碑——意味着在标准化桌面任务上，AI Agent 已经比普通人更准确。 2. 商业模型和开源模型走向不同赛道 商业模型（Claude/GPT）追求极致准确率，适合高价值场景 开源模型（UI-TARS）追求零成本部署和定位精度，适合大规模应用 3. 沙盒化是 CI/CD 集成的关键Cua、OmniTool 等都提供 Docker 化的隔离环境。这意味着 AI GUI 测试可以像单元测试一样跑在 CI pipeline 里。 4. 速度和成本仍是主要瓶颈每步截图 + LLM 推理需要 2-5 秒，传统自动化是毫秒级。高频回归测试仍需混合策略：核心路径用传统方法，复杂场景用 AI Agent。 5. 2026 是落地元年从 benchmark 到生产：UiPath Screen Agent 已在企业中部署，Midscene.js 已发布 v1.0，Cua 已有 12.4K star。这不再是论文里的概念。 资源汇总 资源 链接 说明 Awesome-GUI-Agent GitHub 最全论文列表（⭐1.1K） OSWorld Benchmark 官网 桌面操控标准评测 Cua GitHub 开源 Computer Use Agent 平台 UI-TARS GitHub 字节开源 GUI Agent 模型 Midscene.js 官网 自然语言 UI 测试框架 UFO³ GitHub 微软 Windows Agent OS OmniParser V2 GitHub 微软屏幕解析引擎 LLM-Powered GUI Agents Survey GitHub 手机 GUI Agent 综述 本文基于 2026 年 2 月 12 日的调研。这个领域每周都在刷新纪录——一个月前 Claude Opus 4.5 还是 SOTA，现在 Opus 4.6 已经超越人类。建议持续关注 OSWorld Leaderboard 获取最新排名。","link":"/2026/02/12/ai-ui-testing-automation-2026/"},{"title":"科技热榜速递 | 2026-02-13：Seedance 2.0 正式发布、Claude Code 变蠢争议、xAI 星际野心","text":"每日精选国外科技社区热门内容，覆盖 Hacker News、Lobsters、TechCrunch、Dev.to、Ars Technica、Slashdot 六大平台。原文链接 + 详情摘要，一文速览全球科技圈在聊什么。 🔥 今日头条：Seedance 2.0 正式发布——字节跳动视频生成模型迈入工业级2 月 12 日，字节跳动 Seed 团队正式发布新一代视频创作模型 Seedance 2.0，已全量上线豆包 App、即梦 AI 等平台。 这次升级的核心不是「更好看」，而是「更能用」： 统一多模态架构：文字、图片、音频、视频四种模态输入，最多同时引入 9 张图片 + 多段视听素材作为参考 物理还原能力飞跃：双人花滑、多人竞技等高难度动作场景的连贯性大幅提升，模型真正开始「懂物理」 15 秒多镜头 + 双声道立体声：音画同步，一次生成即可获得沉浸式视听体验 导演级操控：支持精准指定构图、运镜、文字分镜脚本 视频编辑与延展：可对特定片段进行定向修改，支持「接着拍」——极大降低影视、广告、电商制作门槛 美国导演试用后评价「可能颠覆好莱坞的工作方式」。36 氪将其定性为视频生成领域的「奇点时刻」。 体验入口：即梦网页端 → 视频生成 → 选择 Seedance 2.0 | 豆包 App → 对话框 → Seedance 2.0 | 火山方舟体验中心 📰 Hacker News 热门 Top 101. Claude Code 是不是在变蠢？（735分 / 505评论）Claude Code v2.1.20 发布了一个引发众怒的改动：所有文件读取和搜索操作的输出被替换成了一行无用的摘要。比如原来会显示具体读了哪些文件、搜了什么模式，现在只有「Read 3 files」「Searched for 1 pattern」——完全没有实际信息。 用户在 GitHub Issues 上集体抗议，要求恢复显示文件路径，或至少提供一个开关。Anthropic 的回应是「对大多数用户来说这是一个减少噪音的好改动」，并建议使用 verbose 模式——但 verbose 模式会倾泻大量调试信息、子 Agent 完整输出等内容，根本不是用户想要的。 这场争论反映了一个更深层的问题：当 AI 工具越来越强大时，用户对透明度和可控性的需求反而在增加，而不是减少。 你花了 $200/月买一个工具，它却开始对你隐藏自己在做什么。 🔗 原文 | HN 讨论 2. 亚马逊 Ring「寻狗广告」引发隐私监控担忧（415分 / 232评论）亚马逊在超级碗期间投放了 Ring 摄像头的「Search Party」广告，展示邻居们用 Ring 摄像头网络帮助寻找走失的狗。广告本意是温馨可爱，但却在网上引发了大规模反弹——批评者指出，这实质上展示了一个由私人摄像头组成的大规模监控网络。 公众担忧的核心：当数百万个家庭摄像头可以被串联搜索时，找狗和追踪人之间只有一步之遥。 🔗 The Verge 报道 3. Fluorite — 完全集成 Flutter 的主机级游戏引擎（393分 / 230评论）Fluorite 是一个全新的游戏引擎，核心卖点是完全集成 Flutter 生态。底层用 C++ 编写的高性能 ECS（Entity-Component-System）架构，上层用 Dart 编写游戏逻辑，可以直接使用 Flutter 的开发工具链和 UI 组件系统。 亮点功能： FluoriteView Widget：在 Flutter 应用中嵌入多个 3D 场景视图 模型定义触摸区域：3D 美术在 Blender 中直接定义可点击区域，开发者监听事件即可 游戏代码和 UI 代码共享状态：完全用 Flutter 的方式 这对移动游戏开发者来说是个有趣的选择：不用学 Unity/Unreal，用已有的 Dart/Flutter 技能就能做游戏。 🔗 官网 4. 无人机入侵导致美国厄尔巴索机场关闭（327分 / 513评论）FAA 因无人机入侵事件对德克萨斯州厄尔巴索机场实施了飞行限制。513 条评论讨论了无人机管控政策、机场安全以及越来越频繁的无人机干扰航空事件。 🔗 NYT 报道 5. WiFi 可能成为隐形的大规模监控系统（297分 / 146评论）研究人员发出警告：WiFi 信号可以被用来追踪人体移动。WiFi 信号在室内传播时会被人体反射和吸收，通过分析这些信号变化，可以在不需要任何摄像头的情况下检测、定位甚至识别室内的人。 这种技术不需要目标携带任何设备，而且可以穿墙工作。研究人员警告这可能成为一种”隐形的大规模监控系统”。 🔗 SciTechDaily 6. Discord/Twitch/Snapchat 年龄验证绕过漏洞（285分 / 149评论）安全研究人员发现，Discord 使用的年龄验证提供商 k-id 存在根本性的设计缺陷。k-id 声称不会将用户面部照片发送到服务器（出于隐私考虑），而是发送面部元数据。但这意味着可以构造看似合法的元数据来绕过验证，服务器无法区分真假。 之前的绕过方法被修补后，随着 Discord 将年龄验证扩展到全球，研究人员又找到了新的绕过方式。这暴露了一个根本矛盾：隐私保护（不发送真实人脸）和验证可靠性（需要真实人脸）之间的不可调和冲突。 🔗 漏洞详情 7. GLM-5：面向复杂系统工程和长期 Agent 任务的模型（244分 / 397评论）智谱 AI（Z.AI）发布了 GLM-5，专门瞄准复杂系统工程和长时间运行的 Agent 任务场景。在 Hacker News 上获得 244 分和近 400 条评论，说明国际社区对中国 AI 的关注度在持续上升。 🔗 GLM-5 博客 8. GLM-OCR：复杂文档理解的多模态 OCR 模型（217分 / 67评论）智谱同时发布了 GLM-OCR，一个基于 GLM-V 编码器-解码器架构的多模态 OCR 模型。核心创新包括多 Token 预测（MTP）损失函数和全任务强化学习。 技术亮点： OmniDocBench V1.5 得分 94.62，所有文档理解任务排名第一 使用 CogViT 视觉编码器 + GLM-0.5B 语言解码器 两阶段处理流水线：版面分析 + 并行识别 覆盖公式识别、表格识别、信息提取等场景 🔗 GitHub 9. NetNewsWire 23 周年（202分 / 47评论）老牌 RSS 阅读器 NetNewsWire 迎来 23 岁生日。刚刚发布了 Mac 和 iOS 的 7.0 版本，正在开发 7.0.1 修复版。创始人 Brent 去年退休后，开发速度反而加快了。 在算法推荐统治信息流的时代，一个 23 年的 RSS 阅读器还能在 HN 上获得 200+ 分，说明开放 Web 和用户主权在技术社区仍然有强大的号召力。 🔗 博客 10. GPT-5 法律推理实验：100% vs 联邦法官 52%（112分 / 87评论）一项学术研究让 GPT-5 和联邦法官在相同法律推理任务上对比。结果：**GPT-5 达到 100% 准确率，而联邦法官只有 52%**。这是 AI 在专业领域能力的又一个里程碑式数据点，引发了关于 AI 在法律系统中角色的深入讨论。 🔗 论文 🦞 Lobsters 热门 Top 51. 如何将 Google 搜索依赖减半（116分 / 50评论）开发者构建了 Hister，一个自托管的网页浏览历史搜索工具。它会在本地索引你访问过的所有网页，当你想找回之前看过的内容时，直接搜索本地索引而不是去 Google。 作者在 1.5 个月内成功将对 Google 搜索的依赖降低了 50%。核心观点：Google 搜索已经被广告和 SEO 操纵严重侵蚀，而你要找的信息很多时候就在你之前看过的页面里。 🔗 原文 2. 缺失的 GitHub 状态页面（125分 / 19评论）一个展示 GitHub 各服务真实可用性状态的第三方页面，比 GitHub 官方状态页更准确和详细。 🔗 GitHub Statuses 3. Windows 记事本远程代码执行漏洞 CVE-2026-20841（47分 / 16评论）Windows 记事本（Notepad）被发现存在远程代码执行漏洞。作为 Windows 上最简单、最基础的文本编辑器，记事本出现 RCE 漏洞着实令人意外。 🔗 CVE 详情 4. Majutsu — jujutsu 版本控制的 Magit 接口（30分 / 4评论）为 jujutsu（新一代版本控制系统）开发的 Emacs Magit 风格接口。小众但精准地击中了 Emacs + 新型 VCS 用户群。 🔗 GitHub 5. 前向求值构建系统（24分 / 6评论）Garnix 团队介绍 garn2，一种使用前向求值（forward evaluation）的构建系统设计理念。 🔗 博客 📡 TechCrunch 头条 Top 51. xAI 在公开全员会议上描述星际野心xAI 罕见地将一场 45 分钟的全员会议视频公开发布在 X 平台上。会议揭示了重大信息： 大规模裁员：Musk 描述为「组织结构变革」，导致大量创始团队成员离开 四大团队重组：Grok 聊天机器人、编码系统、Imagine 视频生成器、Macrohard 项目 Macrohard：从简单的 Computer Use 到模拟整个企业运营，目标是「AI 全自动设计火箭引擎」 Toby Pohlen 将领导 Macrohard：「它能做电脑上任何事情」 🔗 TechCrunch 2. AI 推理创业公司 Modal Labs 融资估值 25 亿美元Modal Labs 专注 AI 推理（inference）基础设施优化，正在与 General Catalyst 谈判以 $25 亿估值融资。这比 5 个月前 B 轮的 $11 亿估值翻了一倍多。年化收入约 $5000 万。 推理优化正在成为 AI 基础设施的下一个热门赛道——降低运行成本、减少响应延迟。 🔗 TechCrunch 3. OpenAI 解散「使命对齐」团队OpenAI 解散了负责向公众和内部员工传达公司使命的团队（约 6-7 人）。团队前负责人 Josh Achiam 被任命为新职位「首席未来学家」（Chief Futurist）。 团队成立于 2024 年 9 月，使命是确保「通用人工智能造福全人类」。解散后成员被分配到其他部门。继去年超级对齐团队解散后，OpenAI 安全相关团队的又一次变动。 🔗 TechCrunch 4. Apple Siri 改版再次延期Apple 自 2024 年宣布 Apple Intelligence 以来一直承诺升级 Siri，但发布日期持续推迟。最新消息：原定 iOS 26.4（3 月）上线的新 Siri 部分功能将推迟到 iOS 27（9 月）。 据 Bloomberg 报道，内部测试遇到了问题。新 Siri 将更像 LLM 聊天机器人，底层传闻使用 Google Gemini。但从 2024 到 2026，已经跳票两年了。 🔗 TechCrunch 5. Uber Eats 推出 AI 购物车助手Uber Eats 推出 AI 购物助手，可以根据文字或图片描述自动添加商品到购物车。 🔗 TechCrunch 🔧 Dev.to 热门1. 受够了 Trello：自己做生产力工具（17反应）开发者 Karsten 吐槽 Trello 被 Atlassian 收购后变得臃肿不堪：更多工作流、更多仪表盘、更多定价层级、更少的清晰度。这些工具「为汇报而生，而非为工作而生」。于是他自己动手做了一个极简生产力工具。 🔗 Dev.to 2. 用 CSS 重现 Pantone 色卡（15反应）纯 CSS 实现 Pantone 色卡的视觉效果，技术和设计的巧妙结合。 🔗 Dev.to 🔬 Ars Technica 安全头条Lumma 窃密恶意软件卷土重来去年 5 月，全球执法机构联合打击了 Lumma Stealer 的基础设施——这个信息窃取工具在短短两个月内感染了近 40 万台 Windows 电脑。但现在它又回来了，而且更难检测。 Lumma 的特点： 2022 年首次出现在俄语网络犯罪论坛 云端恶意软件即服务（MaaS）模式，高级版售价 $2500 被 Scattered Spider 等多个著名犯罪组织使用 新版使用 ClickFix 诱饵 + Castleloader 进行大规模传播 微软称其为多个犯罪集团的「首选工具」 教训：执法打击只能暂时压制，不能根除。 基础设施可以重建，恶意软件可以升级。 🔗 Ars Technica 💬 Slashdot 极客新闻1. Linux Mint 考虑延长发布周期Linux Mint 团队表示半年一版的发布节奏太累了，正在考虑延长发布周期。这反映了小型开源团队在维护大型发行版时的资源压力。 🔗 Slashdot 2. 科学家警告「温室地球」临界点比预想更近最新研究表明，全球气候系统的多个临界点可能比此前模型预测的更接近。一旦跨过这些临界点，变化将不可逆转。 🔗 Slashdot 🔥 今日洞察AI 安全与信任危机今天最突出的主题是 AI 公司与用户之间的信任问题：Claude Code 隐藏操作细节、OpenAI 解散使命对齐团队、GPT-5 在法律推理上 100% 准确但谁来监督它？当 AI 越来越强大，透明度和可控性不是可选项，而是必选项。 中国 AI 的国际影响力智谱 GLM-5 和 GLM-OCR 同时登上 Hacker News 热门，GLM-5 更是获得了 244 分 / 397 评论的高关注度。GLM-OCR 在文档理解 benchmark 上排名第一。中国 AI 正在技术社区获得越来越多的实质性认可。 监控无处不在Ring 摄像头广告、WiFi 信号追踪、年龄验证绕过——三条不相关的新闻指向同一个主题：隐私正在以各种意想不到的方式被侵蚀。更值得警惕的是，很多时候这些工具被包装成「安全」和「便利」。 xAI 的 Macrohard：Computer Use 的企业级野心xAI 全员会议透露的 Macrohard 项目值得关注：从 Computer Use 扩展到「模拟整个企业运营」。这和 Anthropic 的 Computer Use、OpenAI 的 Operator 本质上在抢同一个赛道，但 Musk 的野心显然更大——他想让 AI 设计火箭引擎。 数据来源：Hacker News、Lobsters、TechCrunch、Dev.to、Ars Technica、Slashdot | 爬取时间：2026-02-12","link":"/2026/02/12/tech-hot-news-2026-02-12/"},{"title":"智谱 GLM-5 深度解析：744B 参数开源巨兽，从 Vibe Coding 迈向 Agentic Engineering","text":"2026 年 2 月 11 日，智谱 AI 发布了新一代旗舰模型 GLM-5——一个 744B 参数的 MoE 开源模型，在编码和 Agent 能力上全面对齐 Claude Opus 4.5，并在多项关键指标上超越 GPT-5.2。这不只是又一个大模型的发布，而是一个信号：开源模型和闭源前沿之间的差距，正在以不可思议的速度消失。 一句话：GLM-5 是什么？GLM-5 是智谱 AI（Z.AI）最新发布的旗舰基座大模型。和大多数追求「聊天体验」的模型不同，GLM-5 明确瞄准了一个更大的赛道：复杂系统工程和长程 Agent 任务。 智谱自己给它起了个口号：**”From Vibe Coding to Agentic Engineering”**（从感觉式编程到工程化 Agent）。 什么意思？市面上大多数 AI 编程助手做的是「Vibe Coding」——你描述一下想要什么，模型帮你写个函数、补个代码片段。而 Agentic Engineering 是另一个级别的事情：模型需要理解整个系统架构，自主规划多步骤任务，在数百个连续操作中保持目标一致，处理依赖关系和异常情况，最终交付生产级代码。 简单说：GLM-5 不是来帮你写代码的，它是来帮你做工程的。 架构：一个扎扎实实的规模飞跃 指标 GLM-4.5/4.7 GLM-5 总参数量 355B 744B 活跃参数量 32B 40B 架构 MoE MoE 预训练数据 23T tokens 28.5T tokens 注意力机制 标准 DeepSeek Sparse Attention 许可证 MIT MIT GLM-5 的参数量翻了一倍多，预训练数据从 23T 增加到 28.5T tokens。但更值得关注的是两个技术创新： DeepSeek Sparse Attention（DSA）GLM-5 首次集成了 DeepSeek 发明的稀疏注意力机制。传统 Transformer 的注意力复杂度是平方级——上下文长度翻倍，计算量翻四倍。DSA 打破了这个瓶颈，让 GLM-5 在保持 200K 上下文窗口的同时，大幅降低了部署成本。 这也是中国 AI 社区协作的一个缩影：智谱用了 DeepSeek 的技术，而不是重新造轮子。 Slime：异步强化学习框架GLM-5 训练中最关键的创新是 Slime——一个全新的异步强化学习框架（已开源在 GitHub）。 传统 RL 训练大模型的效率很低。Slime 通过解耦数据生成和策略更新，实现了比传统同步 RL 高 3 倍的训练吞吐量。更重要的是，它针对长程 Agent 行为做了专门的奖励建模——不是优化表面的 benchmark 数字，而是奖励任务完成的一致性。 这解释了为什么 GLM-5 在需要长时间持续执行的任务上表现突出。 Benchmark：全面对齐 Claude Opus 4.5，多项超越 GPT-5.2 编码能力 Benchmark GLM-5 Claude Opus 4.5 GPT-5.2 说明 SWE-bench Verified 77.8 80.9 80.0 真实 GitHub Issue 修复 SWE-bench Multilingual 73.3 77.5 - 多语言代码理解 Terminal-Bench 2.0 56.2 59.3 54.0 终端操作与系统管理 CyberGym 43.2 50.6 - 安全攻防任务 GLM-5 在 SWE-bench（真实 GitHub 项目 bug 修复）上拿到 77.8，与 Claude Opus 4.5 的 80.9 差距仅 3.1 个百分点。对于一个开源模型来说，这是前所未有的接近。 在 Terminal-Bench（终端命令行操作）上，GLM-5 的 56.2 已经超过了 GPT-5.2 的 54.0。 Agent 能力：真正的亮点 Benchmark GLM-5 Claude Opus 4.5 GPT-5.2 说明 BrowseComp 62.0 37.0 - 联网搜索与信息综合 BrowseComp + 上下文管理 75.9 - 65.8 带记忆的复杂网页任务 τ²-Bench 89.7 91.6 - 多工具复杂场景 Vending Bench 2 $4,432 $4,967 $3,591 模拟一年商业经营 MCP-Atlas 67.8 65.2 - 工具调用与多步骤执行 BrowseComp 是最炸裂的数据。 GLM-5 拿到 62.0，几乎是 Claude Opus 4.5（37.0）的两倍。带上下文管理后达到 75.9，超过 GPT-5.2 的 65.8。这意味着在联网搜索、信息检索和多步网页任务上，GLM-5 是目前所有模型中最强的。 Vending Bench 2 是最能体现「长程 Agent 能力」的测试——让 AI 经营一年的自动售货机生意，做采购决策、库存管理、定价优化。GLM-5 最终账户余额 $4,432，仅次于 Claude Opus 4.5 的 $4,967，而 GPT-5.2 只有 $3,591。 MCP-Atlas（工具调用与多步骤执行）上，GLM-5 的 67.8 甚至反超了 Claude Opus 4.5 的 65.2。 推理能力 Benchmark GLM-5 Claude Opus 4.5 GPT-5.2 说明 Humanity’s Last Exam（带工具） 50.4 43.4 45.5 人类最难测试 AIME 2026 I 92.7 93.3 - 数学竞赛 HMMT 2025 96.9 - 97.1 哈佛/MIT 数学竞赛 GPQA-Diamond 86.0 87.0 92.4 博士级科学推理 在 Humanity’s Last Exam（带工具）上，GLM-5 的 50.4 超过了 Claude（43.4）和 GPT-5.2（45.5）。数学竞赛 AIME 上 92.7 几乎追平 Claude 的 93.3。 对软件工程的意义：为什么 Agentic Engineering 是下一个范式GLM-5 的发布不只是一个模型的事。它代表了 AI 辅助软件工程正在发生的范式转移。 从「写代码」到「做工程」传统 AI 编程助手（Copilot、Cursor 等）本质上是代码补全——你写一半，它帮你补另一半。即使是 Claude Code 和 Codex，也主要是在单文件或单功能层面工作。 GLM-5 瞄准的是另一个维度： 理解整个代码库的架构，而不只是当前文件 自主规划多步骤修改方案，涉及多个文件和模块 在数百步操作中保持目标一致，不会做到一半忘了自己在干什么 处理依赖关系和副作用，像一个真正的工程师一样思考 这正是 Vending Bench 2 测试的价值——经营一年的生意需要的不是聪明，而是持续的、可靠的决策能力。 CC-Bench-V2：真实工程场景评测智谱自己开发的 CC-Bench-V2 专门评测「复杂软件工程」——不是算法题，而是涉及多文件、多依赖、需要架构决策的真实工程任务。GLM-5 在前端、后端和长程任务上都大幅超越前代 GLM-4.7，逼近 Claude Opus 4.5 的水准。 工程化 Agent 的三大支柱智谱官方总结了 Agentic Engineering 的三个核心能力： 长程目标一致性：在几百步的连续操作中不偏离目标 资源管理与规划：合理分配计算资源、管理上下文窗口 多步骤依赖处理：理解任务之间的依赖关系，按正确顺序执行 这三个能力恰好是目前 AI 编程助手最薄弱的环节——它们擅长写函数，但不擅长做项目。GLM-5 正在填补这个空白。 神秘的 Pony Alpha：一个有趣的插曲在 GLM-5 正式发布前，OpenRouter 上悄然出现了一个叫 “Pony Alpha” 的匿名模型，凭借出色的编码能力引发了大量关注和猜测——有人说是 DeepSeek V4，有人说是 GLM-5。 现在谜底揭晓：Pony Alpha 就是 GLM-5。 智谱用了一招「匿名发布，实力说话」，在模型揭面之前就已经在开发者社区积累了口碑。 开源 MIT 许可：最大的诚意GLM-5 采用 MIT 许可证——这是开源世界中最宽松的许可证： ✅ 完全商用，无任何限制 ✅ 可修改、微调、蒸馏 ✅ 无需开源你自己的代码（没有 copyleft 义务） ✅ 法律风险极低 对比 Meta Llama 的受限许可和其他「半开源」模型，GLM-5 给出了真正的自由。对于企业来说，这意味着可以放心地在 GLM-5 基础上构建产品，不用担心后续的许可证问题。 模型权重已在 HuggingFace 和 ModelScope 开放下载。 价格：比 Claude 便宜 7 倍 模型 输入价格/M tokens 输出价格/M tokens GLM-5 ~$0.80 ~$3.20 Claude Opus 4.5 $5.00 $25.00 GPT-5.2 $1.25 $5.00 GLM-5 的 API 定价大约是 Claude Opus 4.5 的 七分之一。在性能逼近的前提下，这个价格差距对于企业级 Agent 应用来说是巨大的优势——Agent 任务通常涉及大量的多轮对话和工具调用，token 消耗量远超普通聊天。 不只是聊天：GLM-5 的办公生产力GLM-5 不满足于做一个聊天模型。通过 Z.ai 的 Agent 模式，它可以直接生成： 📄 Word 文档（.docx）：PRD、报告、教案、会议纪要 📊 Excel 表格（.xlsx）：财务报表、数据分析、透视表 📋 PDF 文件：格式化的专业文档 这不是「生成文字然后你自己粘贴到 Word」，而是端到端的、带格式的、可以直接用的文档。支持多轮迭代优化，像一个真正的文档工程师。 生态兼容：无缝接入现有工具链GLM-5 已经支持主流的 Agent 编程工具： Claude Code：直接替换模型为 glm-5 OpenCode / Cline / Roo Code：通过 GLM Coding Plan 接入 OpenRouter：已上线，可立即调用 vLLM / SGLang：支持本地部署 国产芯片：支持华为昇腾、摩尔线程、寒武纪、昆仑芯、燧原等 这意味着你不需要改变现有的工作流，就可以把 GLM-5 接入你的 Agent 系统。 全球视角：开源 AI 的分水岭让我们把视角拉远一点。 一年前，开源模型和闭源前沿之间的差距是巨大的。最好的开源模型在 SWE-bench 上可能只有 50% 多的成绩，而 Claude 和 GPT 已经接近 80%。 现在，GLM-5 在 SWE-bench 上拿到 77.8%，在 BrowseComp 上甚至碾压闭源模型，在 Vending Bench 的长程 Agent 任务上逼近 Claude。 这个趋势的意义远超技术本身： 企业 build vs buy 的天平正在倾斜。当开源模型性能够用且可以完全控制时，为什么要给 Anthropic 或 OpenAI 交高额 API 费用？ Agent 能力成为新赛场。GLM-5 不是在聊天能力上竞争，而是在「做工作」的能力上竞争。这是 AI 从工具变成同事的关键一步。 中国 AI 的技术实力不容忽视。智谱在香港 IPO 募资 43.5 亿港元后，把资金投入了实实在在的技术——GLM-5 的 MIT 开源不是姿态，而是对自身技术实力的自信。 结论GLM-5 证明了一件事：在 2026 年，最好的开源模型已经不再是闭源模型的「平替」，而是真正的竞争者。 对于软件工程师来说，一个能在长程任务中保持可靠、在真实工程场景中逼近 Claude Opus 4.5 表现、价格便宜 7 倍、还完全开源的模型——很难不认真对待。 Agentic Engineering 不再是 PPT 上的概念。GLM-5 把它变成了可以跑的代码。 数据来源：智谱 AI 官方博客、BuildFastWithAI、Reuters、Bloomberg、SCMP | 2026 年 2 月 13 日","link":"/2026/02/13/glm-5-agentic-engineering/"},{"title":"GitHub Trending 热榜 | 2026-02-13：Generative UI、个人 AI 基础设施、Chrome DevTools MCP","text":"今天的 GitHub Trending 榜单有一个鲜明的主题：AI 正在从「模型」走向「基础设施」。无论是让 React 组件被 AI 动态生成的 Tambo，还是把整个个人生活用 AI Agent 武装起来的 PAI，抑或是让编程 Agent 直接操控 Chrome DevTools 的 MCP 工具——开发者们不再满足于调 API，而是在构建让 AI 真正融入工作流的基础设施。 1. Tambo — 让 AI Agent 说你的 UI 语言 ⭐ 8,997 Stars | 📈 +300 today | 🟦 TypeScript | 📜 MIT 项目简介Tambo 是一个面向 React 的 Generative UI（生成式 UI） 开源工具包。核心理念很简单：你注册你的 React 组件并描述它们的 schema，AI Agent 在对话中自动选择合适的组件、流式生成 props、渲染出交互式 UI。 用户说「展示各地区销售额」，Agent 不是返回一段文字，而是直接渲染你的 &lt;Chart&gt; 组件。用户说「添加一个任务」，Agent 更新你的 &lt;TaskBoard&gt;。 为什么火？Generative UI 是 2026 年前端领域最热的方向之一。传统的 AI 聊天界面只能返回文本或 Markdown，但真实的应用需要按钮、表格、图表、表单等丰富的交互组件。 Tambo 解决了这个问题的工程化难题： 流式 Props：LLM 生成的 props 实时流式传输到组件，不用等全部生成完 状态管理内置：对话状态、组件状态、错误恢复全部封装好 MCP 集成：支持 Model Context Protocol，可以和各种 Agent 框架无缝对接 Cloud 或自托管：提供托管后端，也支持 Docker 自部署 技术亮点123npm create tambo-app my-tambo-appcd my-tambo-appnpm run dev 5 分钟就能跑起来。支持 OpenAI、Anthropic、Gemini、Mistral 等多种模型。配套了一个预构建组件库（ui.tambo.co），包含对话气泡、工具卡片、数据可视化等 Agent UI 基础组件。 适用场景 需要在 AI 聊天中展示复杂交互界面的 SaaS 产品 企业内部的 AI 助手面板 任何想让 AI 不止返回文字的 React 应用 2. PAI（Personal AI Infrastructure）— 个人 AI 基础设施 ⭐ 7,488 Stars | 📈 +351 today | 🟦 TypeScript | 📜 MIT 项目简介来自安全领域知名人物 Daniel Miessler（Fabric 框架创始人）的新项目。PAI 的目标宏大：为每个人构建一套完整的 AI Agent 基础设施，用 AI 放大个人能力。 PAI 不是一个 Agent，而是一个 Agent 操作系统——它定义了一套 Primitives（原语）和 Packs（功能包），让你可以像搭积木一样组装自己的 AI 系统。 为什么火？因为它抓住了一个核心矛盾：AI 工具太多了，但缺少一个把它们统一起来的架构。 你可能用了 ChatGPT、Claude、各种 MCP 工具、本地 LLM……但它们各自为战。PAI 提供了一个统一框架： Packs：23 个功能包，覆盖写作、分析、安全、编程等场景 Bundles：预配置的功能包组合，一键部署 Two-Pass Capability Selection：双通道能力选择，自动匹配最合适的工具 Thinking Tools：带推理过程的工具调用，支持 Justify-Exclusion（解释为什么不选某个工具） 并行执行：默认并行处理多个 Agent 任务 技术亮点v2.5.0 刚发布，三大升级： 双通道能力选择：先粗筛再精选，提高工具匹配准确率 Thinking Tools + Justify-Exclusion：Agent 不仅解释为什么选这个工具，还解释为什么不选其他工具——更透明的决策过程 并行执行默认开启：多任务不再串行等待 适用场景 想构建个人 AI 工作流的技术爱好者 对 AI Agent 架构设计感兴趣的开发者 Fabric 框架的老用户——PAI 是 Fabric 理念的大幅进化 3. Google LangExtract — 用 LLM 从混沌文本中提取结构化数据 ⭐ 31,355 Stars | 📈 +1,122 today | 🐍 Python | 📜 Apache-2.0 项目简介Google 开源的 Python 库，专门用 LLM 从非结构化文本（临床笔记、研报、法律文件等）中提取结构化信息。这不是简单的 NER（命名实体识别），而是带精准溯源的信息提取——每个结果都能映射回源文本的精确位置。 为什么火？今日 +1,122 Stars，连续多日霸榜，已经冲到 31K Stars。 核心原因：它解决了 LLM 落地的信任难题。大模型擅长理解文本，但企业场景要的不只是「理解」，还要「证据」。LangExtract 的溯源机制让每条提取结果都有据可查，配合交互式可视化工具，让用户可以验证 AI 的每一个判断。 Source Grounding：每个提取字段都标注了源文本位置 交互式可视化：一键查看提取结果与原文的对应关系 多模型支持：原生 Gemini，同时支持 OpenAI 和 Ollama 本地模型 Pydantic Schema：用标准的 Python 数据类定义提取目标 适用场景 医疗记录结构化（从临床笔记提取诊断、用药、检查结果） 金融研报数据提取 法律文件关键条款提取 任何需要「可溯源 AI 提取」的场景 4. Chrome DevTools MCP — 让编程 Agent 拥有浏览器超能力 ⭐ 24,380 Stars | 📈 +436 today | 🟦 TypeScript | 📜 Apache-2.0 项目简介Chrome 官方出品。这个 MCP Server 让你的编程 Agent（Gemini、Claude、Cursor、Copilot 等）可以直接控制和检查实时 Chrome 浏览器——完整的 DevTools 能力，包括性能分析、网络请求检查、控制台日志、截图等。 为什么火？因为它补上了 AI 编程助手最大的盲区之一：前端调试。 以前 Agent 写完前端代码，你需要自己打开浏览器、检查渲染效果、查看 Console 错误、分析网络请求。现在 Agent 自己就能做这些事： 性能分析：录制 Chrome Trace，提取可操作的性能优化建议 网络调试：检查 HTTP 请求/响应、分析加载瀑布图 控制台监控：获取浏览器控制台消息，包含 source-mapped 堆栈追踪 可靠自动化：基于 Puppeteer，自动等待操作结果 技术亮点12345678{ &quot;mcpServers&quot;: { &quot;chrome-devtools&quot;: { &quot;command&quot;: &quot;npx&quot;, &quot;args&quot;: [&quot;-y&quot;, &quot;chrome-devtools-mcp@latest&quot;] } }} 一行配置接入。支持 Field Data（CrUX 真实用户数据）对比 Lab Data，给出更全面的性能评估。 适用场景 AI 辅助前端开发和调试 自动化性能分析和优化 Web 应用端到端测试 任何需要 Agent 理解「浏览器里发生了什么」的场景 5. Microsoft PowerToys — 老牌效率神器持续进化 ⭐ 129,637 Stars | 📈 +316 today | 🟣 C# | 📜 MIT 项目简介微软的 Windows 效率工具集，不需要多介绍了——FancyZones、PowerToys Run、Color Picker、File Locksmith……每一个都是 Windows 用户的效率神器。 为什么又上热榜？PowerToys 持续更新，最近的版本带来了新的 AI 增强功能和更多实用工具。12.9 万 Stars 的项目还能每天 +316，说明它的用户群极其活跃。 作为微软少数几个「真正好用」的开源项目，PowerToys 证明了大公司也能做出开发者真心喜欢的工具——前提是给团队足够的自由度。 今日趋势总结🔥 AI Agent 基础设施爆发今天前 4 名里有 3 个直接和 AI Agent 相关。但关键词不再是「大模型」而是「基础设施」： Tambo：Agent 的 UI 层 PAI：Agent 的操作系统层 Chrome DevTools MCP：Agent 的感知层 这三个项目加在一起，描绘了一个完整的 Agent 工作流：AI 通过 MCP 感知浏览器环境 → 通过 PAI 规划和调度任务 → 通过 Tambo 渲染交互界面给用户。 📊 MCP 生态持续膨胀Chrome DevTools MCP 拿到 24K Stars，说明 Anthropic 提出的 MCP 协议已经成为 AI Agent 工具调用的事实标准。Google、Microsoft 等大厂纷纷拥抱，第三方工具更是遍地开花。 🏗️ 从「用 AI」到「建 AI 的家」今天的热榜反映了一个更大的趋势：开发者不再满足于简单地「用 AI」，而是在为 AI 构建更好的栖息环境。当基础设施足够成熟，AI Agent 才能从 Demo 走向生产。 数据来源：GitHub Trending（2026-02-13 daily）","link":"/2026/02/13/github-trending/2026-02-13/"},{"title":"Agent Loop 与 Agent RL：驱动 AI Agent 完成长任务的算法全景","text":"引言：从聊天机器人到自主智能体2025-2026 年，AI Agent 迎来了从「对话助手」到「自主执行者」的质变。过去，构建一个 AI Agent 的方法极其简单——拿一个大语言模型（LLM），套一个 while 循环，给它接上工具 API，就能完成简单任务。但当任务变得复杂（比如深度研究、代码重构、多步决策），这种朴素架构就会崩溃。 Agent 领域正在经历一场深刻的范式转移：从基于提示工程的静态 Agent，走向基于强化学习的自适应 Agent。本文将系统梳理驱动 Agent 完成长任务的各类算法与架构，从经典的 Agent Loop 到前沿的 Agentic RL。 一、Agent Loop：基础循环架构1.1 最简 Agent 循环最基础的 Agent 架构可以抽象为一个循环： 12345while not done: thought = LLM.think(context) action = LLM.decide(thought) observation = environment.execute(action) context.append(observation) 这就是所谓的 Agent 1.0 架构。LLM 充当「大脑」，在循环中反复执行「思考→行动→观察」直到任务完成或达到终止条件。 1.2 ReAct：推理与行动的交错ReAct（Reasoning and Acting） 是最经典的 Agent Loop 框架，由 Yao 等人于 2022 年提出。其核心思想是让 LLM 交替生成推理步骤和执行动作： 12循环流程：Thought → Action → Observation → Thought → Action → Observation → ... → Final Answer 关键设计： Thought（思考）：LLM 内部推理，分析当前状态，制定下一步计划 Action（行动）：调用外部工具（搜索、计算、API 等） Observation（观察）：接收工具返回结果，更新上下文 ReAct 的优势在于推理过程透明可追踪，但在长任务中会遇到严重问题：上下文窗口被大量历史信息污染，导致模型「迷失方向」。 图：ReAct 的核心循环——Thought（推理）→ Action（行动）→ Observation（观察）交替执行，直到任务完成。 1.3 Plan-and-Execute：先规划后执行为解决 ReAct 在长任务中的漂移问题，Plan-and-Execute 架构将任务分为两个阶段： 规划阶段（Planner）：LLM 分析任务，生成分步计划 执行阶段（Executor）：按计划逐步执行，每步可调用工具 重规划（Re-Planner）：根据执行结果动态调整剩余计划 12345Plan: [Step1, Step2, Step3, Step4]Execute Step1 → Result1Re-Plan: [Step2', Step3, Step4] // 根据 Result1 调整Execute Step2' → Result2... 这种架构的优势是目标感更强，不容易在长链推理中丧失方向。 1.4 ReWOO：推理与观察解耦ReWOO（Reasoning Without Observation） 进一步优化了 Plan-and-Execute 模式： 先一次性生成完整的推理计划和所有工具调用 并行执行所有工具调用 最后综合所有结果生成答案 优势是减少 LLM 调用次数，提升效率；但牺牲了动态调整能力。 二、高级推理框架：从线性到树状再到自我进化上一节的 Agent Loop 架构解决了”如何让 LLM 与外部世界交互”的问题，但它们都面临一个共同瓶颈：推理质量。ReAct 按顺序执行每一步，一旦某步方向错误，整个链条就会偏离正确路径。Plan-and-Execute 有规划能力，但规划本身也可能出错，且无法在推理层面进行深度探索。 这就引出了一个核心问题：如何让 LLM 在推理过程中更智能地搜索和探索？ 答案隐藏在三个递进的范式中：CoT（线性思考）→ ToT（树状探索）→ Reflexion/LATS（自我进化的搜索）。 2.1 Chain-of-Thought（CoT）：思维链推理CoT 是 Agent 推理的基石。2022 年 Wei 等人在 Google Brain 的工作揭示了一个关键发现：只需在提示中加入”Let’s think step by step”，就能让 LLM 将复杂问题拆解为一系列中间推理步骤，显著提升数学、逻辑和常识推理的准确率。 CoT 的核心机制： LLM 不再直接输出最终答案，而是生成一条线性推理链 每个中间步骤为后续步骤提供额外的”证据”或约束条件 从概率角度看，这相当于对模型输出分布的贝叶斯更新——每一步都缩小了解空间 一个典型例子： 1234567问题：停车场有3排车，每排8辆，又开走了4辆，还剩多少辆？CoT 推理链：Step 1: 总共有 3 × 8 = 24 辆车Step 2: 开走了 4 辆Step 3: 剩下 24 - 4 = 20 辆答案：20 辆 然而，CoT 作为一条单一的线性链条，存在三个根本性局限： ① 不可回溯（No Backtracking）一旦某一步推理出错，错误会沿着链条一路传播，无法返回修正。就像在迷宫中只能一直往前走，走错了也不能回头。 ② 无法探索多条路径（No Branching）面对有多种可能解法的问题，CoT 只能选择一条路走到底。比如解数学题时，可能有代数法和几何法两条路径，CoT 只会选择一条。 ③ 缺乏自我评估（No Self-Evaluation）链条上的每一步都没有被评估是否合理，模型无法判断当前方向是否正确，只能盲目前进。 CoT-SC（Self-Consistency）通过并行采样多条独立链条然后投票选择最佳答案，部分缓解了上述问题——但每条链条之间仍然是完全独立的，无法共享中间发现，也无法在关键决策点分叉探索。 2.2 从 CoT 到 ToT：为什么需要进化？正是 CoT 的上述三个局限催生了 Tree-of-Thoughts（ToT）。让我们通过一个经典问题来理解这个进化的必要性： Game of 24 问题：用 4、5、6、10 四个数字和加减乘除，组合出结果为 24。 12345678910111213CoT 的困境：Step 1: 尝试 4 × 6 = 24... 但还剩 5 和 10 没用Step 2: 好像不行，但已经无法回头了→ 失败，只能从头再来一次（但新的一次完全独立，不会记住上次的教训）ToT 的优势： 4, 5, 6, 10 / | \\ 4+5=9 4×6=24 10-6=4 / \\ ✗(剩余无法凑) / \\ 9×(10-6) 6×(10-5) 4×5=20 ... =9×4=36✗ =6×5=30✗ 20+4=24? ✗(4已用) ↑ 回溯，换路 ToT 在每一步都可以分叉探索多个方向，在发现死路时回溯到之前的节点尝试其他路径。 2.3 Tree-of-Thoughts（ToT）：树状搜索推理ToT（由 Yao 等人于 2023 年在普林斯顿提出）将推理从线性链扩展为树状结构，本质上是将经典搜索算法引入 LLM 推理过程。 ToT 的四大核心组件： ① 思维分解（Thought Decomposition）将问题拆解为适当粒度的”思维单元”。粒度选择至关重要——太细则搜索空间爆炸，太粗则失去探索灵活性。比如写一篇文章，一个思维单元可以是”段落大纲”而非”单个句子”。 ② 思维生成（Thought Generation）在每个节点生成 k 个候选思维，有两种策略： 采样（Sample）：独立生成多个候选（适合创意性任务，解空间大） 提议（Propose）：基于前文依次生成（适合逻辑性任务，避免重复） ③ 状态评估（State Evaluation）这是 ToT 最关键的创新——用 LLM 自己来评估每个中间状态的质量： 打分法：对每个状态评分（如 1-10 分，或”确定/可能/不可能”） 投票法：让 LLM 比较多个候选，选出最有前途的 评估函数充当了”导航仪”的角色，告诉搜索算法哪些方向值得继续探索、哪些应该剪枝放弃。 ④ 搜索算法（Search Algorithm）ToT 支持两种经典搜索策略： 12345678BFS（广度优先）： DFS（深度优先）：层层扩展，不遗漏 一条路走到底，走不通再回头Level 0: [A] 探索顺序：A → B → D → (回溯) → E → (回溯)Level 1: [B] [C] → C → F → ✓ 找到解Level 2: [D][E][F][G]适合：解空间较小，需要最优解 适合：解空间大，需要尽快找到一个可行解 ToT 解决了 CoT 的三大痛点： CoT 的局限 ToT 的解决方案 不可回溯 DFS 自然支持回溯，发现死路可返回上一节点 无法分叉探索 每个节点可生成 k 个候选分支 缺乏自我评估 状态评估函数在每步进行质量判断 代价是什么？ ToT 需要更多的 LLM 调用（生成 + 评估），计算成本显著高于 CoT。这是”搜索质量”与”计算成本”之间的经典权衡——和 AlphaGo 的蒙特卡洛树搜索是同一种思想。 图：CoT 线性链 vs ToT 树状搜索的结构差异。CoT 只能沿单一路径前进，ToT 在每步分叉并评估，支持回溯探索。 2.4 Reflexion：自我反思学习ToT 解决了”单次推理中的探索问题”，但还有一个更深层的问题没有解决：跨任务的经验积累。人类在失败后会反思总结教训，下次遇到类似问题时表现更好。CoT 和 ToT 都没有这种”从失败中学习”的能力——每次推理都从零开始。 Reflexion 引入了一个关键的「反思」闭环，让 Agent 能在多次尝试之间积累经验： 123456789Trial 1: Actor 执行 → 得到结果 → Evaluator 评判 → 失败 ❌ ↓ Self-Reflection: &quot;我在第3步选错了API，应该用search而不是lookup&quot; ↓ 反思摘要存入长期记忆Trial 2: Actor 带着反思记忆重新执行 → 改进但仍有问题 ❌ ↓ Self-Reflection: &quot;API调对了，但参数格式不对，应该用JSON而非字符串&quot; ↓ 追加到长期记忆Trial 3: Actor 综合两次教训执行 → 成功 ✅ Reflexion 包含三个核心组件的协作循环： Actor（执行器）：基于 ReAct 或 CoT 的执行引擎，负责实际操作 Evaluator（评估器）：判断执行结果的成功/失败，提供二元或标量反馈信号 Self-Reflection（反思器）：最核心的创新——将失败经验转化为自然语言反思摘要，存入一个持久的语言记忆（verbal memory） 为什么用语言记忆而不是梯度更新？ 这是 Reflexion 最巧妙的设计——传统 RL 通过更新模型权重来学习，成本极高且需要大量样本。Reflexion 用自然语言存储教训（如”不要用 deprecated API v1，改用 v2”），轻量、可解释，而且在推理时通过上下文注入即可使用。 Reflexion 在编程任务上的惊人效果： HumanEval 上从 80.1%（CoT 基线）提升到 91.0%（+11%） 其中约 40% 的错误在第二次尝试时就被修正 这证明了”反思+重试”机制的强大——很多错误不需要更强的模型，只需要从失败中学到教训 图：Reflexion 的三组件反思循环——Actor 执行、Evaluator 评判、Self-Reflection 生成语言化教训存入记忆，驱动下一次尝试改进。 2.5 从 ToT 到 LATS：统一搜索、行动与反思到这里，我们已经有了三种关键能力： CoT/ToT：推理时的搜索与探索 ReAct：与外部环境的交互（工具调用） Reflexion：从失败中学习 但这三种能力是各自独立的。ToT 只做推理搜索，不调用工具；ReAct 调用工具但不做搜索；Reflexion 做反思但搜索策略很原始。有没有一个框架能把这三者统一起来？ LATS（Language Agent Tree Search） 正是这个统一框架。它将蒙特卡洛树搜索（MCTS）——AlphaGo 的核心算法——引入 LLM Agent 决策，将搜索、行动和反思融合为一个整体： 123456789101112 ┌──────────────────────┐ │ MCTS 搜索循环 │ └──────────────────────┘ │ ┌─────────────┬──────────┼──────────┬──────────────┐ ▼ ▼ ▼ ▼ ▼Selection Expansion Simulation Evaluation Backpropagation(选择节点) (生成动作) (执行动作) (LLM评分) (反向传播) │ │ │ │ │ UCB1算法 LLM生成 调用工具 价值评估 更新节点 平衡探索 候选动作 获取反馈 + 反思 质量分数 与利用 MCTS 五步循环详解： ① Selection（选择）：用 UCB1 公式选择最值得探索的节点，自动平衡”深入已知好路径”和”尝试未探索方向”——这解决了 ToT 简单 BFS/DFS 策略的效率问题。 ② Expansion（扩展）：在选中节点用 LLM 生成 n 个候选动作，每个动作可以是推理步骤或工具调用——这融合了 ToT 的分支能力和 ReAct 的工具交互。 ③ Simulation（模拟）：执行动作并观察环境反馈——ReAct 的核心循环。 ④ Evaluation（评估）：LLM 对当前状态进行价值评估，给出分数。关键创新：如果检测到失败，触发 Reflexion 式的自我反思，生成反思摘要指导后续搜索。 ⑤ Backpropagation（反向传播）：将评估分数沿树路径回传，更新每个祖先节点的质量估计——这让 LATS 能从全局视角优化搜索方向。 LATS = ToT（搜索框架）+ ReAct（环境交互）+ Reflexion（失败学习） 这种统一带来的效果是显著的：在 HotPotQA 多跳推理任务上，LATS 比单独的 ReAct 提升 16%，比 Reflexion 提升 8%，比 ToT 提升 12%。代价是更高的计算成本——但这正是”用推理时计算换取更好决策”的核心思想。 图：LATS 将 MCTS 的五步循环应用于 Agent 决策，统一了搜索（ToT）、行动（ReAct）和反思（Reflexion）三大能力。 三、Deep Agent 架构：当任务跨越百步LATS 统一了搜索、行动和反思，但它仍然在单个上下文窗口内运作。当任务复杂度从”几步完成”升级到”数十甚至上百步”——比如写一份完整的研究报告、重构一个大型代码库、或执行一个跨越数小时的深度研究——上下文窗口就成了不可逾越的瓶颈：推理历史、工具返回、中间结果……全部挤在有限的 token 窗口中，信噪比急剧下降。 Deep Agent（深度智能体） 架构是 2025 年下半年兴起的新范式，代表产品包括 Claude Code、OpenAI Deep Research、Manus AI 等。它的核心思想是：**将 Agent 的认知从”上下文内”扩展到”上下文外”**——用外部持久化系统弥补上下文窗口的局限。 图：从 ReAct 到 Deep Agent 的架构演进。每一步进化都在解决前一代的核心瓶颈：ReAct 解决了工具交互、CoT/ToT 解决了推理搜索、Reflexion 解决了经验学习、Deep Agent 解决了长任务上下文管理。 3.1 四大支柱Deep Agent 架构建立在四个基础之上： ① 显式规划（Explicit Planning）不依赖 LLM 隐式推理，而是维护一个外部的、可持久化的任务计划。计划可以被检查、修改和恢复。这意味着即使上下文窗口被清空，Agent 仍然知道自己在做什么、做到了哪一步。 以 Claude Code 为例：当它重构一个大型代码库时，会在文件系统中写入一份 plan.md，记录每个模块的改造状态。即使中间因为上下文溢出导致会话重置，Agent 读取 plan.md 后就能无缝继续。 ② 层级委派（Hierarchical Delegation）单个 Agent 的能力总有上限。Deep Agent 将复杂任务拆分给专门化的子 Agent，每个子 Agent 有独立的上下文窗口和专属工具集： 12345Orchestrator Agent（指挥官）├── Research Sub-Agent（负责信息检索）→ 有搜索工具├── Code Sub-Agent（负责代码编写）→ 有文件读写和终端├── Review Sub-Agent（负责质量审查）→ 有测试工具└── Memory Sub-Agent（负责信息管理）→ 有知识库 这种设计的关键优势是上下文隔离：Research Agent 的搜索结果不会污染 Code Agent 的编码上下文。每个子 Agent 只接收与自己任务相关的信息，信噪比大幅提升。 ③ 持久化记忆（Persistent Memory）使用文件系统作为外部记忆，而非仅依赖上下文窗口。Agent 可以： 写入结构化笔记和发现摘要 读取之前的研究结果 维护状态文件跟踪进度 建立知识索引便于快速检索 这本质上是将人类研究员的”做笔记”习惯编码为 Agent 的核心行为——上下文窗口是”工作记忆”（短期），文件系统是”笔记本”（长期）。 ④ 极致的上下文工程（Extreme Context Engineering）精心管理什么信息进入上下文窗口。具体技术包括： 渐进式摘要：每隔 N 步将历史压缩为摘要 选择性加载：只加载与当前子任务相关的信息 上下文分层：系统提示 &gt; 当前任务 &gt; 相关历史 &gt; 可选参考 智能截断：工具返回过长时自动截取关键部分 以 OpenClaw 为例——它在每次 heartbeat 时读取 HEARTBEAT.md（而非全部历史），在每个 session 开始时读取 SOUL.md 和 USER.md（身份信息），只有在主 session 中才加载 MEMORY.md（长期记忆），这就是上下文工程的实际应用。 3.2 CORAL：认知资源自分配CORAL（Cognitive Resource Self-Allocation） 是 ICLR 2026 收录的工作，专门解决长任务中 Agent 的「注意力漂移」问题——当上下文中积累了太多无关信息，LLM 的注意力被分散，推理质量急剧下降。 核心洞察： 人类处理长任务时，会主动”清空短期记忆”——比如写论文写了3小时后，会先休息，回来后重新读一遍大纲，而不是试图记住之前的每一个细节。CORAL 给 Agent 提供了类似的能力。 工作记忆管理工具集： 1234Agent 工具箱中新增三种&quot;元工具&quot;：1. set_checkpoint(label) → 在关键节点保存状态快照2. clear_memory() → 清除工作记忆中的杂乱信息 3. restore(label) → 从指定检查点恢复推理上下文 当 Agent 探索了多条路径、积累了大量搜索结果，发现自己”迷失方向”时，可以主动调用 clear_memory() + restore(&quot;initial_plan&quot;) 来重新开始——但不是完全从零开始，而是保留了检查点中的关键发现。 训练方式： CORAL 使用多轮 Agentic 强化策略优化（Multi-episode Agentic Reinforced Policy Optimization） 算法，让 Agent 通过 RL 学会三个关键判断： 何时设置检查点（在做出重要发现或关键决策后） 何时清理记忆（当上下文信噪比过低时） 恢复到哪个检查点（选择最有价值的历史状态） CORAL 在 SWE-bench 等长任务基准上显著优于没有记忆管理的 Agent，验证了”主动管理认知资源”的价值——这也为 Deep Agent 架构的”极致上下文工程”提供了理论支撑。 四、Agentic RL：从工程拼接到端到端学习前三节的所有架构——从 ReAct 到 LATS 到 Deep Agent——都属于「推理时（inference-time）」的工程技巧。它们通过精巧的提示设计、搜索算法和记忆管理来提升 Agent 表现，但模型本身并没有因此变得更强。模型权重是冻结的，所有的”聪明”都来自外部框架。 这就像给一个普通人配备了最好的工具箱、最详细的操作手册——他确实能完成更复杂的任务，但他自身的能力并没有提升。如果工具箱被拿走或手册不适用，他就回到了原点。 Agentic RL 代表了一个根本性的范式转移：直接通过强化学习训练 LLM 的 Agent 行为能力，让模型在多步交互中学会规划、工具使用、错误修正——这些能力被编码进模型权重，而非依赖外部框架。 4.1 从 RLHF 到 Agentic RL 维度 RLHF Agentic RL 目标 让 LLM 输出更符合人类偏好 让 LLM 学会多步决策与工具使用 交互 单轮：prompt → response 多轮：action → env feedback → action 奖励 人类偏好评分 任务完成度 + 过程奖励 训练格式 单条序列 多轮轨迹（trajectory） 环境 无 真实或模拟环境 Agentic RL 的核心突破在于：将 LLM 从被动的序列生成器重新定义为主动的、嵌入复杂动态世界的决策智能体。 图：从推理时工程（左）到 Agentic RL 端到端训练（右）的范式转移——外部脚手架 vs 内化能力。 4.2 Agent-R1：端到端 Agent 强化学习Agent-R1（中国科学技术大学，2025.11）是将 DeepSeek-R1 的 RL 训练范式扩展到 Agent 场景的里程碑工作。 核心问题：为什么不能直接把 RLHF/GRPO 套到 Agent 上？ 传统 RL 训练 LLM 时，轨迹（trajectory）是一个单轮序列：prompt → response。但 Agent 的轨迹是多轮交互序列，包含两种本质不同的 token： 123轨迹结构：[System Prompt] → Agent生成思考 → Agent调用工具 → 环境返回结果 → Agent继续思考 → ... ↑ Agent token（可训练） ↑ 环境 token（不可训练！） 关键区分：Agent 生成的 token 需要参与梯度计算，但环境返回的 token 不应该——因为你不能通过训练模型来改变环境的行为。Agent-R1 在 MDP 框架中明确建模了这个区分。 MDP 扩展详解： 组件 静态 LLM Agent-R1 状态空间 prompt + 已生成 token 完整对话历史 + 每轮环境反馈 动作空间 词表中选下一个 token 同上，但 token 序列可触发工具调用 转移函数 确定性（拼接 token） 随机性（环境返回不确定） 奖励函数 单次终端奖励 终端奖励 + 中间过程奖励 过程奖励（Process Rewards） 是 Agent-R1 的重要创新——不只在任务完成时给奖励，在中间步骤也给信号。比如：正确调用了 search API 但查询词不够精确，可以给一个小的正奖励（鼓励工具使用）但不是满分（查询还需优化）。这解决了长任务中”奖励稀疏”的经典难题。 Agent-R1 开源了完整的训练框架（基于 veRL），支持快速接入不同环境，已在 Multi-hop QA 上验证了效果。 4.3 AgentRL：多任务多轮 Agent 训练框架AgentRL（清华大学 THUDM，2025.10）是目前最系统的 Agentic RL 训练框架，其训练成果已应用于智谱的 AutoGLM。 两大技术创新： ① 跨策略采样（Cross-Policy Sampling）在多轮设定中，Agent 容易陷入策略过拟合，不愿探索新策略。AgentRL 通过从多个模型策略池中采样动作，增强探索多样性： 12345轨迹生成时：Step 1: 从 Policy_A 采样 actionStep 2: 从 Policy_B 采样 action ← 跨策略Step 3: 从 Policy_A 采样 action... ② 任务优势归一化（Task Advantage Normalization）多任务训练时不同任务的奖励尺度差异大。对每个任务的优势值独立归一化，稳定训练： 1Advantage_normalized = (Advantage - mean_task) / std_task 实验结果惊人： AgentRL 在五个 Agent 基准任务（ALFWorld、DB、KG、OS、Webshop）上训练开源 LLM（Qwen2.5），性能显著超越 GPT-5、Claude-Sonnet-4 和 DeepSeek-R1。 4.4 DeepResearcher：真实环境中的 RL 训练DeepResearcher（上海交通大学 GAIR，2025.4，EMNLP 2025 收录）是首个在真实 Web 搜索环境中端到端训练 Agent 的框架。 为什么 RAG 环境训练不够？ 之前的 RL 训练工作（如 Search-R1、R1-Searcher）都在 RAG 环境中进行——给模型一个固定语料库，模型从中检索信息。这种方式有一个致命假设：所有需要的信息已经在语料库里了。但现实世界不是这样的： 信息可能不存在于语料库中 信息可能已经过时 需要跨多个领域综合多个来源 网页格式杂乱，充满噪声和反爬机制 DeepResearcher 直接在开放互联网环境中训练，Agent 需要面对真实的搜索引擎、真实的网页（包括乱码、广告、反爬）。 多 Agent 架构设计： 12345678910Main Agent（推理决策者） │ ├── 决定搜索什么关键词 ├── 分析搜索结果摘要 ├── 决定深入哪些网页 │ ↓ └── Browsing Agent（网页浏览者） ├── 加载完整网页 ├── 提取相关信息 └── 返回结构化摘要给 Main Agent Main Agent 负责高层决策（搜什么、看哪个、如何综合），Browsing Agent 负责底层信息提取——这比 RAG 系统”直接返回文本片段”要灵活得多。 训练后涌现的四种认知行为（最惊喜的发现）： 自主规划（Planning）：Agent 自动学会了在开始研究前制定计划，并在过程中动态调整。注意——没有人教它规划，这是纯 RL 训练涌现的行为！甚至还会”合并步骤”来提高效率。 交叉验证（Cross-Validation）：Agent 找到一个答案后，不会立即接受，而是继续搜索其他来源来验证。这种”不轻信第一个结果”的审慎行为也是自发涌现的。 自我反思与重定向（Self-Reflection）：发现当前搜索方向不对时，Agent 会主动调整关键词或换一个完全不同的搜索策略。 诚实性（Honesty）：当确实找不到确定答案时，Agent 会坦诚说明，而非编造一个看似合理的答案。 量化结果： DeepResearcher 在 7 个开放域研究数据集上，比提示工程方案提升高达 28.9 分，比 RAG 环境 RL 方案提升 7.2 分。这证明了一个核心结论：在真实环境中训练不是可选的优化，而是开发稳健研究能力的根本需求。 4.5 通义 DeepResearch：全栈 Agent 训练流水线阿里通义团队（2025.9）提出了一套完整的 Agent 训练流程： 12345阶段1: Agentic Pre-training（预训练阶段引入工具使用能力） ↓阶段2: Supervised Fine-tuning（用专家数据冷启动） ↓阶段3: On-policy RL（在线强化学习自进化） 这套「预训练 → SFT → RL」的三阶段流程被验证为训练 Deep Research Agent 的有效范式。 五、推理时搜索：第三条路径前四节讨论了两条提升 Agent 能力的路径： 路径 A：推理时工程（更好的框架、搜索算法、记忆管理） 路径 B：训练时学习（通过 RL 直接提升模型能力） 还有路径 C——在推理时投入更多计算。不改变模型权重，也不依赖复杂的外部框架，而是让模型”想更久”。 5.1 推理时计算扩展（Inference-Time Scaling）OpenAI 的 o1/o3/o4 系列揭示了一个令人振奋的发现：推理时的计算量和推理质量之间存在近似对数线性的正相关关系。换句话说，让模型多花 10 倍算力”思考”，可以获得显著的质量提升。 核心技术手段包括： 内部思维链（Internal CoT）：模型在输出前进行长链隐式推理，这些推理 token 消耗计算但不一定展示给用户 搜索与回溯：多条推理路径并行探索，选择最优路径——本质上和 ToT 异曲同工，但被编码进了模型的推理行为中 自我验证：模型生成候选答案后，自己检查答案的正确性，如有问题则重新推理 自适应计算分配：简单问题少想，复杂问题多想——模型学会了”量力而行” 这解释了为什么 o3/o4 在某些数学竞赛题上表现惊人——它们可能在单个问题上花费了相当于普通模型数百次调用的算力。 5.2 AB-MCTS：自适应分支蒙特卡洛树搜索AB-MCTS（Adaptive Branching MCTS）（Sakana AI）将这个思想推向了多模型协作的维度： 核心思想： 不是一个模型自己搜索，而是多个不同的 LLM 协作进行蒙特卡洛树搜索。每个模型有不同的偏好和盲点，多模型搜索可以获得更全面的探索覆盖。 123456搜索树的每个节点：├── GPT-5 生成候选 A → 评分 0.7├── Claude 生成候选 B → 评分 0.9 ← 选中展开└── Gemini 生成候选 C → 评分 0.5下一层继续多模型扩展... 自适应分支 是关键创新：不固定每个节点的分支数，而是根据当前问题的难度和搜索进展动态调整。简单部分少分支快速通过，困难部分多分支深度探索。 AB-MCTS 代表了推理时搜索的前沿方向：不改变任何模型的权重，而是通过更聪明的搜索编排来突破单模型的能力上限。这和下棋中的思想完全一致——棋手的水平（模型能力）是固定的，但花更多时间思考（搜索更多变化）总能下出更好的棋。 5.3 三条路径的关系123456789 Agent 能力提升 / | \\ 路径 A 路径 B 路径 C推理时工程 训练时学习 推理时计算(ReAct,ToT, (Agentic RL, (o1-style, Deep Agent) Agent-R1) AB-MCTS) ↓ ↓ ↓模型不变, 模型变强, 模型不变,外部框架优化 内化能力 多花算力思考 实践中，三条路径并不互斥——最强的 Agent 系统同时使用了全部三条：强 RL 训练的基座模型（路径 B）+ 推理时多步搜索（路径 C）+ 外部记忆和工具管理（路径 A）。 六、实用建议：如何选择 Agent 架构任务复杂度 vs 架构选择 任务类型 推荐架构 代表方案 简单工具调用（天气/搜索） ReAct LangChain ReAct Agent 多步骤有序任务 Plan-and-Execute LangGraph 需要探索的复杂推理 Tree-of-Thoughts / LATS 自定义 需要从失败中学习 Reflexion 自定义 超长任务（100+ 步） Deep Agent Claude Code / OpenClaw 训练专用 Agent Agentic RL AgentRL / Agent-R1 深度研究 Deep Agent + RL DeepResearcher 关键设计原则 外部化一切状态：不要仅依赖上下文窗口，用文件系统持久化记忆 分层委派：复杂任务拆分给专门的 Sub-Agent 显式管理上下文：主动摘要和压缩，保持高信噪比 建立检查点机制：允许 Agent 回溯和恢复 过程奖励优于结果奖励：在训练中引入中间步骤的奖励信号 七、展望：Agent 技术的下一步2026 年关键趋势 Agentic RL 成为标配：从提示工程走向端到端训练，直接优化 Agent 的多步决策能力 Memory 成为一等公民：ICLR 2026 专门设立 MemAgents Workshop，记忆管理从「工程技巧」升级为核心研究方向 多模态 Agent：Agent 不再限于文本交互，可以「看」屏幕、操作 UI、理解视觉信息 自进化 Agent：Agent 能在部署后持续从真实交互中学习改进 核心挑战 安全与对齐：自主度越高，风险越大，如何确保 Agent 行为安全可控 长期记忆：如何在超长任务中维持一致的目标和上下文 奖励设计：复杂任务的奖励信号如何定义和分解 评估基准：缺乏真正长时间跨度的 Agent 评估标准 参考文献 Yao, S. et al. “ReAct: Synergizing Reasoning and Acting in Language Models.” ICLR 2023. Shinn, N. et al. “Reflexion: Language Agents with Verbal Reinforcement Learning.” NeurIPS 2023. Wei, J. et al. “Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.” NeurIPS 2022. Yao, S. et al. “Tree of Thoughts: Deliberate Problem Solving with Large Language Models.” NeurIPS 2023. Zhou, A. et al. “Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models.” ICML 2024. Cheng, M. et al. “Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning.” arXiv:2511.14460, Nov 2025. Zhang, H. et al. “AgentRL: Scaling Agentic Reinforcement Learning with a Multi-Turn, Multi-Task Framework.” arXiv:2510.04206, Oct 2025. Zheng, Y. et al. “DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments.” arXiv:2504.03160, Apr 2025. Wang, R. et al. “A Practitioner’s Guide to Multi-turn Agentic Reinforcement Learning.” arXiv:2510.01132, Oct 2025. “Don’t Lose the Thread: Empowering Long-Horizon LLM Agents with Cognitive Resource Self-Allocation (CORAL).” ICLR 2026. “The Landscape of Agentic Reinforcement Learning for LLMs: A Survey.” TMLR, Jan 2026. Tongyi Team. “Tongyi DeepResearch: A New Era of Open-Source AI Researchers.” Sep 2025. OpenAI. “Introducing Deep Research.” Feb-Jul 2025. Sakana AI. “Inference-Time Scaling and Collective Intelligence for Frontier AI (AB-MCTS).” 2025. 本文系统梳理了 Agent Loop 和 Agent RL 领域的核心算法和最新进展，从经典的 ReAct 循环到前沿的 Agentic RL 训练范式。Agent 技术正在从「工程拼接」走向「端到端学习」，这将是 2026 年 AI 领域最重要的技术方向之一。","link":"/2026/02/13/agent-loop-and-agent-rl-algorithms-2026/"},{"title":"大规模代码库分析与理解：从AST到AI Agent的技术全景","text":"当你面对一个百万行级别的代码库，从何下手？本文系统梳理从抽象语法树到AI Agent的代码理解技术栈，覆盖学术前沿与工程实践。 1. 引言：百万行代码库的认知挑战软件系统的规模正在以指数级增长。Google 的 monorepo 包含超过 20 亿行代码（Potvin &amp; Levenberg, 2016, Communications of the ACM），Linux 内核已突破 3000 万行，一个中型互联网公司的微服务集群轻松达到数百万行。 然而，人类的认知带宽是有限的。Brooks（1983）在经典论文 “No Silver Bullet” 中指出，软件的本质复杂性（essential complexity）无法通过工具消除，只能被管理。von Mayrhauser 和 Vans（1995, IEEE Annals of Software Engineering）提出了程序理解的认知模型，将开发者理解代码的过程分为自顶向下（从领域知识出发）、自底向上（从代码细节出发）和知识库驱动三种策略。 现代大型代码库的理解面临三重挑战： 规模障碍：没有人能读完全部代码，必须借助工具建立全局视图 演化复杂性：代码在持续变化，理解是一个动态过程（Lehman, 1980, Laws of Software Evolution） 跨语言、跨系统：现代项目混合多种语言和框架，单一分析工具不够 本文将系统梳理应对这些挑战的技术栈——从最基础的语法树表示，到语义分析、导航协议、知识图谱、可视化方法，再到 LLM 时代的新范式。 2. 基础表示：AST、CST 与 Tree-sitter2.1 抽象语法树的前世今生抽象语法树（Abstract Syntax Tree, AST）是编译器前端的核心数据结构，最早可追溯到 Backus（1959）对 FORTRAN 编译器的工作。AST 将源代码的语法结构表示为树形结构，去除了括号、分号等语法噪声，保留语义关键信息。 与之对应的是具体语法树（Concrete Syntax Tree, CST），它保留所有语法细节（包括空白、注释），适用于需要精确还原源码的场景，如代码格式化工具。 2.2 Tree-sitter：增量解析的范式转变传统解析器（如 ANTLR、Bison）采用批量解析模式——每次修改都需要重新解析整个文件。Tree-sitter（Brunsfeld, 2018, GitHub）彻底改变了这个范式： 增量解析：编辑后只重新解析受影响的子树，复杂度降至 O(log n) 容错解析：即使代码有语法错误也能产出部分 AST，这对编辑器至关重要 多语言统一：通过 grammar DSL 支持 40+ 语言，共享统一的树操作 API 查询语言：提供类 CSS 选择器的 S-expression 查询语法（tree-sitter query） Tree-sitter 已成为现代代码编辑器的标配——Neovim、Helix、Zed 都以它为核心提供语法高亮和代码折叠。 2.3 AST 在代码理解中的应用Sun 等人（2024）在 AST4PLU: AST for Programming Language Understanding（发表于 TOSEM）中做了全面综述，系统梳理了 AST 在代码理解任务中的应用： 代码克隆检测：比较 AST 子树的结构相似性（Deckard, Jiang et al., 2007, ICSE） 代码摘要生成：将 AST 路径编码为向量（code2vec, Alon et al., 2019, POPL） 缺陷预测：基于 AST 差异的变更模式分析 Zhang 等人（2025, EMNLP Findings, CMU）提出了 cAST（Chunking with AST），将 AST 结构信息融入 RAG（Retrieval-Augmented Generation）的代码分块策略。传统的固定长度分块会破坏函数、类等语义单元的完整性，cAST 利用 AST 节点边界进行智能分块，在代码问答任务上显著优于朴素分块。 3. 语义分析：控制流、数据流与代码属性图AST 捕获的是语法结构，但代码的行为需要更深层的分析。 3.1 控制流图（CFG）控制流图由 Frances Allen（1970, “Control Flow Analysis”, ACM SIGPLAN Notices）提出，是程序分析的基石。CFG 将程序分解为基本块（basic block），每个块内的指令顺序执行，块之间通过分支和跳转连接。 CFG 的核心应用： 可达性分析：判断某段代码是否可能被执行（死代码检测） 支配关系（dominance）：计算支配树，用于 SSA 形式转换 循环检测：通过自然循环（natural loop）识别算法的迭代结构 3.2 数据流图（DFG）数据流分析（Kildall, 1973, POPL）追踪变量的定义（def）和使用（use）关系。经典的数据流问题包括： 到达定义（Reaching Definitions）：变量在某一点可能来自哪些赋值语句 活跃变量（Live Variables）：哪些变量在未来还会被使用 可用表达式（Available Expressions）：哪些表达式的值不需要重新计算 数据流分析是编译优化的核心，也是理解代码中数据依赖关系的关键手段。 3.3 代码属性图（CPG）Yamaguchi 等人（2014, IEEE Symposium on Security and Privacy）提出了代码属性图（Code Property Graph），将 AST、CFG 和 DFG 统一到一个图结构中： 1CPG = AST ∪ CFG ∪ DFG 这种融合表示的威力在于：可以用图查询语言（如 Gremlin）表达复杂的代码模式。例如，检测 use-after-free 漏洞只需一条查询：「找到变量 v 被 free 后仍被使用的路径」。 Joern（开源代码分析平台）实现了 CPG，支持 C/C++/Java/Python 等语言，已被广泛用于漏洞挖掘和代码审计。 3.4 类型推断类型系统为代码提供了另一个维度的语义信息。Hindley-Milner 类型推断算法（Hindley 1969; Milner 1978）是 ML 系语言的理论基础，其核心是 Algorithm W——通过 unification 求解类型方程组。 现代 TypeScript 的类型推断远比 Hindley-Milner 复杂，支持条件类型、映射类型、模板字面量类型等。TypeScript 编译器的类型检查器（checker.ts）本身就超过 4 万行——这是一个理解大型代码库的好案例。 4. 导航基础设施：Language Server Protocol4.1 LSP 的诞生与架构2016 年，微软发布了 Language Server Protocol（LSP），解决了一个 M×N 问题：M 个编辑器 × N 种语言，传统上需要 M×N 个插件；LSP 将其简化为 M+N——每种语言一个 Language Server，每个编辑器一个 LSP Client。 LSP 基于 JSON-RPC 2.0 协议，核心交互模式： 1Editor (Client) ←→ JSON-RPC ←→ Language Server 关键能力包括： textDocument/definition：跳转到定义 textDocument/references：查找所有引用 textDocument/hover：悬停显示类型信息 textDocument/completion：代码补全 textDocument/rename：重命名符号（跨文件） 4.2 LSP 背后的核心算法LSP 看似简单的接口背后，是一整套复杂的程序分析算法： 符号解析（Symbol Resolution）：Language Server 需要维护完整的符号表，处理作用域规则、名称遮蔽（shadowing）、重载决议（overload resolution）等。对于 C++ 这样的语言，仅名称查找（name lookup）就涉及 ADL（Argument-Dependent Lookup）、模板实例化等复杂规则。 增量分析（Incremental Analysis）：用户每敲一个字符，Language Server 就需要更新分析结果。朴素的做法是全量重新分析，但这在大型项目上不可接受。Rust Analyzer 采用了基于 Salsa 框架的增量计算：将分析拆分为细粒度的查询，每个查询的结果被缓存，只有依赖发生变化时才重新计算（类似 build system 的增量编译思想）。 跨文件分析：「找到所有引用」需要扫描整个项目。高效的实现通常结合： 符号索引（倒排索引：符号名 → 文件位置列表） 类型层次结构（处理多态调用） 模块依赖图（缩小搜索范围） 4.3 LSIF 与 SCIP：预计算索引Language Server 的一个局限是：它需要运行时计算。对于代码托管平台（如 GitHub、Sourcegraph），不可能为每个仓库都启动一个 Language Server。 LSIF（Language Server Index Format, 微软 2019）解决了这个问题：在 CI 阶段预计算 LSP 的结果，输出为图结构的 JSON 文件，供 Web 端直接查询。 Sourcegraph 在此基础上提出了 SCIP（SCIP Code Intelligence Protocol），采用 Protocol Buffers 编码，比 LSIF 更紧凑高效。SCIP 已支持 Go、Java、TypeScript、Python 等语言的精确代码导航。 4.4 实际性能数据LSP 在实际工程中的价值可以量化。Anthropic 在 Claude Code 的技术博客中披露：使用 LSP 进行符号跳转和引用查找，平均耗时 50ms；而使用 grep/ripgrep 进行文本搜索，在大型代码库中平均需要 45 秒——差距达到三个数量级。 这个数据揭示了一个关键洞察：代码不是文本，不应该用文本搜索的方式理解代码。 5. 代码图与知识图谱5.1 代码的图表示代码天然具有图结构。超越 AST/CFG/DFG，我们可以构建更高层次的图： 函数调用图（Call Graph）：节点是函数，边是调用关系。静态调用图（通过代码分析构建）和动态调用图（通过运行时 profiling 构建）各有优劣。 类继承图（Class Hierarchy）：OOP 代码的骨架，显示 is-a 关系。 模块依赖图（Module Dependency Graph）：包/模块级别的依赖关系，直接关联构建系统（Maven、npm、Cargo）。 数据模型图（Entity-Relationship）：数据库 schema 和 ORM 模型的结构。 5.2 CodexGraph：图数据库 + LLM AgentLiu 等人（2025, NAACL）提出了 CodexGraph，将代码库索引到图数据库（Neo4j），然后让 LLM Agent 通过生成图查询（Cypher）来导航代码库。 核心流程： 解析代码库，提取符号、依赖关系、调用链 构建图数据库，节点为函数/类/模块，边为调用/继承/导入 LLM 接收用户问题，生成 Cypher 查询 执行查询，将结果反馈给 LLM 生成最终回答 与直接将代码塞入 LLM 上下文窗口相比，CodexGraph 的优势在于： 不受上下文长度限制 查询是精确的（图遍历），不依赖 LLM 的「注意力」 图结构天然支持多跳推理（如「找到调用了 A 的所有函数中，哪些也使用了 B 类」） 5.3 FalkorDB Code GraphFalkorDB 提供了开箱即用的代码图分析工具，能自动从代码库中提取： 函数调用关系 类继承层次 模块导入依赖 文件共变关系（经常一起修改的文件） 这类工具将代码理解从「读代码」提升到「查图谱」，特别适合快速了解陌生代码库的架构。 6. 代码可视化方法论代码理解不能只靠文本——人类视觉系统的并行处理能力远超顺序阅读。Storey 等人（2005, IEEE TSE）的调研表明，可视化工具能显著提升开发者理解大型系统的效率。 6.1 CodeCity：3D 城市隐喻Wettel 和 Lanza（2007, VISSOFT）提出了 CodeCity，将代码库映射为一座 3D 城市： 建筑物 = 类：高度表示方法数量，底面积表示属性数量 街区 = 包/模块：嵌套结构对应城市的区域划分 颜色 = 度量指标：如代码复杂度、修改频率、代码年龄 这种隐喻直觉且强大：一眼就能发现「摩天大楼」（God Class）、「荒废街区」（长期未维护的模块）和「密集贫民窟」（高耦合区域）。 CodeCharta 是 CodeCity 理念的现代开源继承者，支持从 SonarQube、Git log、Tokei 等数据源导入度量，生成交互式 3D/2D 可视化。 6.2 依赖结构矩阵（DSM）依赖结构矩阵（Design/Dependency Structure Matrix）源自系统工程（Steward, 1981; Baldwin &amp; Clark, 2000, Design Rules）。在软件中，DSM 是一个 N×N 矩阵，行和列都是模块，单元格表示依赖关系。 DSM 的威力在于模式识别： 对角线附近的簇：紧密耦合的模块组，可能是同一个子系统 远离对角线的点：跨层依赖，潜在的架构违规 对称点对：双向依赖（循环依赖），通常需要重构 通过矩阵重排序算法（如聚类、分区），DSM 能自动发现代码库中的模块化结构——即使开发者自己都没意识到这些边界。 6.3 Treemap 与层次化可视化Treemap（Shneiderman, 1992, ACM TOG）将层次结构映射为嵌套矩形，面积与度量值成正比。在代码分析中： 矩形面积 = 文件大小（行数） 颜色 = 代码质量指标（如测试覆盖率：绿色 → 红色） 层次 = 目录结构 Treemap 的优势是空间效率——可以在一个屏幕上展示整个代码库的概览，同时保持可交互的钻取能力。 6.4 架构图自动生成手动绘制架构图费时且容易过时。新一代工具尝试自动化这个过程： swark：利用 LLM 分析代码结构，自动生成 Mermaid 格式的架构图 Dependency Cruiser：从 JavaScript/TypeScript 项目中提取并可视化模块依赖 Madge：生成 ES6 模块的依赖关系图 自动生成的架构图虽然不如手工图精美，但胜在始终与代码同步——这是文档工程中最关键的属性。 7. LLM 时代的代码理解大语言模型正在重塑代码理解的方式。从”人读代码”到”AI 辅助理解”，技术栈发生了根本变化。 7.1 代码表示学习在 LLM 之前，代码表示学习已经积累了大量工作。Wan 等人（2024, ACM Computing Surveys）在 “Deep Learning for Code Intelligence” 综述中系统梳理了这条线： Token 序列模型：将代码视为自然语言序列（CodeBERT, Feng et al., 2020） AST 路径模型：code2vec（Alon et al., 2019, POPL）将 AST 中的叶节点路径编码为向量 图神经网络模型：在 CFG/DFG 上运行 GNN（GGNN, Li et al., 2016, ICLR） 预训练模型：CodeT5（Wang et al., 2021）、StarCoder（Li et al., 2023） 7.2 RAG + 代码库当代码库超过 LLM 的上下文窗口（即使是 100K+ tokens 也不够装百万行代码），RAG（Retrieval-Augmented Generation）成为必然选择。 关键技术点： Embedding 策略：代码 embedding（如 Voyage Code、OpenAI code-search-ada）vs 通用文本 embedding。代码专用模型在语义检索上显著优于通用模型。 分块方法：前述 cAST（Zhang et al., 2025）利用 AST 边界分块；也有基于函数/类粒度的分块。关键原则：分块边界应与语义边界对齐。 索引结构：向量索引（HNSW/IVF）用于语义搜索，关键词索引（BM25）用于精确匹配，两者混合效果最佳。 7.3 Agent-based 代码探索2024-2025 年，Agent 范式在代码理解领域爆发： SWE-Agent（Yang et al., 2024, Princeton）：给 LLM 装备终端工具（文件浏览、搜索、编辑），让它自主探索代码库并修复 bug。在 SWE-bench 上取得了显著成绩。 RepoAgent（2024）：自动为代码库生成文档，通过分析 AST 和调用关系，为每个函数/类生成上下文相关的文档字符串。 Aider（Gauthier, 2024）：利用 Git 仓库的 repo map（基于 Tree-sitter 提取的函数/类签名索引）帮助 LLM 理解代码结构。repo map 是一个精巧的设计：它比完整代码小得多，但保留了足够的结构信息。 Fan 等人（2025）在 “LLM-Assisted Program Analysis” 综述中总结：LLM 在代码理解任务上的最大优势不是替代传统分析工具，而是作为粘合剂——将 AST 解析、类型检查、控制流分析等工具的输出整合为人类可理解的洞察。 8. 实战方法论：百万行代码库分析框架理论终须落地。以下是一个经过实践验证的四阶段框架，适用于需要快速理解大型陌生代码库的场景。 第一阶段：自动化全景扫描（Day 1）目标：建立代码库的「地形图」，不需要读一行代码。 工具链： 12345678910111213141516# 1. 规模度量tokei . # 语言分布、代码行数scc . # 复杂度估算、COCOMO 成本模型# 2. 目录结构tree -L 3 -d # 顶层目录结构find . -name &quot;*.py&quot; | head -50 # 关键文件发现# 3. 依赖关系cat package.json / requirements.txt / Cargo.toml # 外部依赖madge --image graph.svg src/ # 内部模块依赖图# 4. Git 考古git log --oneline -20 # 最近活动git shortlog -sn --no-merges # 核心贡献者git log --format=format: --name-only | sort | uniq -c | sort -rn | head -20 # 热点文件 产出： 一页纸的代码库概况——规模、语言、架构概貌、核心贡献者、活跃热点。 第二阶段：架构层理解（Day 2-3）目标：理解模块边界、核心抽象和数据流。 方法： 入口点追踪：找到 main 函数 / HTTP handler / 事件循环，自顶向下展开 API Surface 分析：导出接口即模块契约，通过 LSP 的 workspace/symbol 获取所有公开符号 依赖结构矩阵：使用 DSM 工具识别模块聚类和异常依赖 数据流追踪：从数据库 schema 或 API 响应出发，追踪关键数据在系统中的流转路径 第三阶段：深度钻取（Day 4-7）目标：理解关键路径的实现细节。 方法： 关键路径分析：选择 3-5 个核心用户场景，端到端跟踪代码执行路径 LSP 辅助导航：善用 Go to Definition / Find All References / Call Hierarchy 动态分析：运行代码，使用 debugger 或 tracing 工具（如 OpenTelemetry）观察实际行为 代码属性图查询：用 Joern/CodeQL 查找特定模式（如安全漏洞、性能反模式） 第四阶段：持续理解（Ongoing）目标：将理解固化为可共享、可更新的知识。 方法： 文档生成：用 RepoAgent 或 LLM 自动生成 / 补充代码文档 架构决策记录（ADR）：记录关键设计决策的背景和权衡 变更影响分析：每次 PR 评审时，评估变更对整体架构的影响 持续可视化：CI 中集成 CodeCharta / Dependency Cruiser，架构图随代码自动更新 工具链总结 层次 工具 用途 语法 Tree-sitter, ANTLR AST 解析 语义 Joern, CodeQL CPG 分析、模式查询 导航 LSP, SCIP, Sourcegraph 符号导航、引用查找 图谱 Neo4j + CodexGraph, FalkorDB 代码知识图谱 可视化 CodeCharta, Madge, DSM 架构可视化 AI Aider, SWE-Agent, RAG LLM 辅助理解 度量 tokei, scc, SonarQube 规模与质量度量 结语理解大型代码库不是一个单一工具能解决的问题，而是一个多层次、多视角的认知过程。从 AST 的语法表示到 CPG 的语义融合，从 LSP 的精确导航到 CodeCity 的直觉可视化，从传统程序分析到 LLM Agent 的智能探索——每一层技术都在解决不同维度的理解挑战。 关键洞察： 代码不是文本：用结构化方法（AST、CFG、类型系统）理解代码，效率远超文本搜索 图是代码的自然语言：函数调用图、依赖图、CPG 都在说明代码天然是图结构的 可视化是认知加速器：人类视觉系统的并行处理能力是线性阅读的几百倍 LLM 是粘合剂，不是替代品：最好的代码理解系统是传统分析工具 + LLM 的混合架构 理解是持续过程：代码在变化，理解也需要持续更新 在 AI Agent 时代，我们正在接近一个令人兴奋的目标：让机器帮助人类理解机器创造的复杂性。这不是讽刺——这是工程的本质。 参考文献 Allen, F. E. (1970). Control Flow Analysis. ACM SIGPLAN Notices, 5(7), 1-19. Alon, U., et al. (2019). code2vec: Learning Distributed Representations of Code. POPL 2019. Baldwin, C. Y., &amp; Clark, K. B. (2000). Design Rules: The Power of Modularity. MIT Press. Brooks, F. P. (1987). No Silver Bullet: Essence and Accidents of Software Engineering. Computer, 20(4). Brunsfeld, M. (2018). Tree-sitter: A New Parsing System for Programming Tools. GitHub. Fan, G., et al. (2025). LLM-Assisted Program Analysis: A Survey. arXiv preprint. Feng, Z., et al. (2020). CodeBERT: A Pre-Trained Model for Programming and Natural Languages. EMNLP 2020. Hindley, R. (1969). The Principal Type-Scheme of an Object in Combinatory Logic. Transactions of the AMS. Jiang, L., et al. (2007). Deckard: Scalable and Accurate Tree-Based Detection of Code Clones. ICSE 2007. Kildall, G. A. (1973). A Unified Approach to Global Program Optimization. POPL 1973. Lehman, M. M. (1980). Programs, Life Cycles, and Laws of Software Evolution. Proc. IEEE, 68(9). Liu, X., et al. (2025). CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases. NAACL 2025. Milner, R. (1978). A Theory of Type Polymorphism in Programming. JCSS, 17(3). Potvin, R., &amp; Levenberg, J. (2016). Why Google Stores Billions of Lines of Code in a Single Repository. Communications of the ACM, 59(7). Shneiderman, B. (1992). Tree Visualization with Tree-Maps: 2-D Space-Filling Approach. ACM TOG, 11(1). Storey, M. A., et al. (2005). Theories, Tools and Research Methods in Program Comprehension. IEEE TSE. Sun, Z., et al. (2024). AST4PLU: AST for Programming Language Understanding. ACM TOSEM. von Mayrhauser, A., &amp; Vans, A. M. (1995). Program Comprehension During Software Maintenance and Evolution. IEEE Computer, 28(8). Wan, Y., et al. (2024). Deep Learning for Code Intelligence: Survey and Benchmark. ACM Computing Surveys. Wettel, R., &amp; Lanza, M. (2007). Visualizing Software Systems as Cities. VISSOFT 2007. Yamaguchi, F., et al. (2014). Modeling and Discovering Vulnerabilities with Code Property Graphs. IEEE S&amp;P 2014. Yang, J., et al. (2024). SWE-Agent: Agent-Computer Interfaces Enable Automated Software Engineering. Princeton University. Zhang, Y., et al. (2025). cAST: Chunking with AST for RAG. EMNLP 2025 Findings. 🎨 AI 生成的颐和园水墨画（GPT gpt-image-1.5）。细心的读者可能注意到了——十七孔桥被画成了十四孔桥。看来大模型的「幻觉」不只存在于文本，在数数这件事上，视觉模型也未能幸免。这大概也算是本文主题的一个生动注脚：理解复杂结构，无论对人还是对AI，都不是一件容易的事。","link":"/2026/02/14/large-scale-codebase-analysis-2026/"},{"title":"马年春节，中国AI军团集体亮剑——2026科技展望","text":"🐴 马年大吉，万事如意！当鞭炮声响彻大街小巷，中国AI公司也在用自己的方式「放烟花」——字节跳动三箭齐发，DeepSeek 百万 token 窗口刷新纪录。这个春节，科技圈比春晚还热闹。 🧧 开篇：给各位拜年了！各位读者，新春快乐！🎆 马年到了。马在中国文化里是个好兆头——龙马精神、马到成功、一马当先。今年的科技圈，还真有点万马奔腾的意思。 就在大家忙着包饺子、抢红包的时候，中国AI军团没闲着——字节跳动在大年三十发了三个大模型，DeepSeek 悄悄把上下文窗口拉到了百万级别，OpenAI 那边 GPT-5.2 居然在做理论物理的原创研究…… 这篇文章，我们就着年味儿，聊聊 2026 年最值得关注的科技趋势。先从最劲爆的说起。 一、中国AI军团：春节大阅兵 🇨🇳这才是今年春节最大的科技新闻。当全世界都在过年放假的时候，中国AI公司选择了「卷」——而且卷出了水平。 字节跳动：三线齐发，全栈碾压2 月 14 日情人节，字节跳动火山引擎一口气发布了三大模型升级，堪称年度最豪横的「新年礼物」： 🔥 豆包大模型 2.0（Doubao-Seed-2.0） 这不是简单的版本号升级，而是质的飞跃。豆包 2.0 围绕大规模生产环境做了系统性优化——高效推理、多模态理解与复杂指令执行三驾马车齐驱。Pro 旗舰版在数学和编程竞赛中取得金牌成绩，多项基准超越 Gemini 3 Pro。 关键词是「生产环境」。不是实验室 Demo，不是 Benchmark 刷分，而是真正部署到企业级 Agent 场景的实战能力。随着 Agent 时代到来，大模型将在现实世界发挥更大作用——豆包 2.0 显然在朝这个方向全速奔跑。 🎬 Seedance 2.0 —— AI视频进入「导演模式」 如果说去年的 AI 视频还在「抽卡」——生成 10 条能用 1 条，那 Seedance 2.0 就是让创作者从「抽卡」升级到「导演」。 Seedance 2.0 的核心突破： 多模态参考输入：支持首尾帧、视频片段、音频综合参考，精准复刻运镜逻辑、动作细节与音乐氛围 自分镜 + 自运镜：输入一段文字描述，模型自动拆解镜头语言，生成多镜头连贯片段 最长 15 秒视频：对比上一代的 5 秒，时长翻了 3 倍 即梦 AI 平台同步接入，创作者可直接使用 2 月 11 日内测阶段就在海外社交媒体炸锅。海外创作者看到国内测评视频后直呼：用漫画分镜生成动作电影场景、一个文字指令生成完整片段——“一键生成电影”可能真不远了。36 氪评价：Seedance 2.0 将中国 AI 视频生成模型拉入全球第一梯队。 🎨 Seedream 5.0 —— AI绘画的「知识革命」 Seedream 5.0 不是简单的画质提升，而是在「智能理解」维度上拉开了代差： 4K 分辨率输出：终于告别模糊的 1024px 时代 多步逻辑推理：理解「把大象放进冰箱需要几步」这类需要推理的指令 联网检索生图：描述一个真实存在的建筑或品牌，模型可以联网检索后精准还原 精准编辑能力：对已有图片进行局部修改，而非每次重新生成 即梦 AI 同步接入 Seedream 5.0 Lite 版本，每天免费 20 次 对标 Google Nano Banana Pro，定位实用型 AI 创作引擎。字节不只是做模型，是在建内容创作的生产力闭环。 字节的策略一个字：全。文本、图像、视频、音频，全栈多模态一网打尽。三大模型同日发布，这不是在做产品，这是在建生态帝国。 DeepSeek：沉默中蓄力，悬念拉满去年春节 DeepSeek R1 一炮而红，改写了全球AI格局。今年，他们选择了另一种方式制造悬念——不发模型，发信号： 上下文窗口从 128K 悄悄扩展到 100 万 tokens——这意味着你可以把一整本书、一套代码库塞进去对话，不丢一个字 知识库更新至 2025 年 5 月 V4 基座模型已在路上，将替代去年引发「DeepSeek震荡」的 V3 R2 推理模型双线并进，但据 Reuters 报道，CEO 梁文锋对 R2 性能仍不满意，发布时间待定 更值得关注的是 DeepSeek 的算力自主化尝试——据报道，他们正在尝试用华为昇腾芯片训练，但面临芯片间互联速度和稳定性的挑战。这条路注定不平坦，但方向正确——在 AI 芯片被卡脖子的大背景下，这种尝试本身就是一种战略宣言。 阿里的 Qwen 3.5 系列也蓄势待发，主打数学推理和代码能力提升。中国大模型军团，正在全线出击。 春节效应：中国AI的年度阅兵中国AI公司正在形成一种独特的节奏——每年春节前后密集发布新模型，既是技术实力的年度汇报，也是对全球市场的新春宣言。 字节的全栈生态战略、DeepSeek 的极致推理路线、阿里的数理突围——三条截然不同但同样有力的进化路径，共同构成了中国AI的「铁三角」。 用一句应景的话说：中国AI，马力全开。 🐴 二、AI从「工具」变成「科学家」GPT-5.2 推导出理论物理新结论在中国军团春节亮剑的同时，大洋彼岸也没闲着。OpenAI 发布预印本，展示 GPT-5.2 在胶子散射振幅（gluon scattering amplitudes）研究中推导出了一个全新结论：此前物理学界普遍认为「单负螺旋度胶子树振幅为零」，而 GPT-5.2 发现在特定动量空间切片（half-collinear regime）中，这个振幅非零。 论文合著者来自普林斯顿高等研究院、哈佛、剑桥和 OpenAI。AI 已经从「辅助计算」迈入了「独立推导」的阶段。 2026 展望： AI for Science 将不再是口号。数学证明、材料科学、药物发现——这匹马已经脱缰了。 三、监管的马缰：欧盟对抗成瘾设计EU 立法禁止无限滚动欧盟正式推动立法，要求 TikTok、Meta 等平台取消无限滚动（infinite scrolling）等成瘾性设计特性，违者面临巨额罚款。 这是 DSA（数字服务法案）落地的又一步。2 月 6 日已通知 TikTok 其设计违法，现在扩展到所有主要平台。 2026 展望： 科技监管将进入「设计层」——不只管内容，还管产品怎么设计。注意力经济的游戏规则正在被重写。 四、系统编程的文艺复兴Zig 实现 io_uring 和 Grand Central DispatchZig 语言的 Andrew Kelley 宣布：std.Io.Evented 现在支持 Linux 的 io_uring 和 macOS 的 Grand Central Dispatch，都基于用户态栈切换（stackful coroutines / green threads）。 Zig 正在兑现它的承诺——比 C 更安全、比 Rust 更简单。 2026 展望： 系统编程文艺复兴继续。Rust 占主流，Zig 紧随，Carbon 和 Mojo 也在各自赛道。2026 看点：谁能先在生产中替掉一个关键 C/C++ 项目。 五、开发者工具：终端的回归终端用户界面（TUI）正在复兴——Bubble Tea（Go）、Ratatui（Rust）、Textual（Python）等框架让构建精美终端应用变得前所未有地简单。 在 AI Agent 时代，TUI 比 GUI 更适合做 Agent 的交互界面——Codex CLI、Claude Code、Aider 都是终端应用。 2026 展望： 终端优先的开发工具将继续爆发。一批开发者可能从 VS Code 回归终端。 六、逆向工程与数字考古一位开发者花了三年，逆向工程了一款 1986 年的股票模拟游戏 Wall Street Raider。40 年前的代码里，藏着那个时代的设计哲学和工程智慧。 2026 展望： AI 代码理解能力的增强，让逆向工程和遗留代码现代化变得更高效。软件是文化遗产，值得被保护。 七、数据基础设施的长期主义Backblaze 发布 2025 年硬盘故障率统计——连续第 13 年。在追求快速迭代的行业里，13 年不间断的数据收集本身就是一种态度：基础设施需要耐心。 2026 展望： 高质量、长周期的数据集将成为核心竞争力。 八、第一性原理与底层之美一篇 Font Rendering from First Principles 的技术长文引发热议——从贝塞尔曲线到光栅化，完整实现了一个字体渲染引擎。 在 AI 帮你生成任何代码的时代，理解底层原理反而更重要——因为只有懂原理，才能判断 AI 的输出对不对。 2026 展望： 「第一性原理思维」将成为高级工程师的核心竞争力。AI 降低了编码门槛，但提高了理解门槛。 🐎 马年预测清单新年新愿望，我的十个 2026 预测： 🔬 AI for Science 元年：至少 3 篇 AI 参与的重要论文被 Nature/Science 接收 ⚖️ 欧盟 DSA 2.0：更多平台设计特性被立法限制 ⚡ Zig 1.0 发布：系统编程竞争进入新阶段 💻 终端复兴：AI + TUI 催生新一代开发工具 🏛️ 代码考古热：AI 辅助遗留代码理解成为赛道 📊 数据长期主义：长周期数据集价值被重估 🧠 第一性原理回归：深度技术内容消费逆势增长 🤖 开源追平闭源：DeepSeek V4/R2、Qwen 3.5、Llama 4 在关键任务接近 GPT-5 🎬 AI 视频工业化：Seedance 2.0 让 AI 短片从 Demo 走向成片，影视后期流程重塑 🇨🇳 中国大模型全栈化：字节三线齐发开创先河，阿里百度跟进，多模态成标配 结语：马到成功 🧧马年的精神是奔腾——不是盲目的狂奔，而是方向明确的驰骋。 2026 年，AI 在奔向科学前沿，中国军团在春节亮剑，监管在追赶创新，系统编程在回归本质，开发者在终端中找到新自由。 这是一个属于建设者的年份。 给各位读者拜年了！新春快乐，马到成功！ 🐴🧧🎆 封面图由 GPT gpt-image-1.5 生成。","link":"/2026/02/14/tech-outlook-2026-year-of-horse/"},{"title":"2月15日科技早报：OpenAI 联手 Cerebras 抛弃 Nvidia、16个 Claude 写出 C 编译器","text":"每日科技要闻精选，一杯咖啡的时间掌握全球科技动态。今日重点关注 OpenAI 的硬件战略转向，以及 AI 多智能体协作的惊人表现。 科技日报精选1. OpenAI 绕开 Nvidia，在 Cerebras 晶圆级芯片上推出超快编码模型来源：Ars Technica | 100 评论 OpenAI 发布 GPT-5.3-Codex-Spark，运行在 Cerebras 的晶圆级引擎 3（餐盘大小的芯片）上，编码速度比前代快 15 倍，达到约 1000 token/秒。这标志着 OpenAI 开始在推理硬件上摆脱对 Nvidia 的依赖，与 Cerebras 建立深度合作关系。 https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/ 2. 16 个 Claude AI Agent 协作从零构建 C 编译器来源：Ars Technica | 222 评论 Anthropic 研究员 Nicholas Carlini 让 16 个 Claude Opus 4.6 实例在共享代码库上自主协作，花费两周和约 2 万美元 API 费用，产出了一个 10 万行 Rust 代码的 C 编译器。该编译器能编译 Linux 6.9 内核（x86/ARM/RISC-V），还能编译 PostgreSQL、Redis、FFmpeg 等项目，GCC 测试套件通过率 99%，甚至能编译并运行 Doom。 https://arstechnica.com/ai/2026/02/sixteen-claude-ai-agents-working-together-created-a-new-c-compiler/ 3. Vim 9.2 发布：Wayland 支持、XDG 规范、模糊补全来源：Lobsters | 43 points Vim 9.2 带来大量改进：Vim9 脚本语言增强、插入模式模糊补全、从寄存器补全（CTRL-X CTRL-R）、Wayland UI 和剪贴板完整支持、XDG 目录规范、垂直标签面板、Windows 原生暗色模式，以及全新交互式教程插件 :Tutor。 https://www.vim.org/vim-9.2-released.php 4. OpenAI 研究员因 ChatGPT 植入广告辞职，警告”Facebook 化”来源：Ars Technica | 82 评论 OpenAI 经济学家 Zoë Hitzig 在 ChatGPT 开始测试广告的同一天辞职，并在《纽约时报》发文警告：用户向 ChatGPT 倾诉了医疗恐惧、感情问题和宗教信仰等极其私密的信息，这构成了”人类坦诚的无先例档案”。她担忧 OpenAI 正在重蹈 Facebook 当年承诺保护隐私却逐步侵蚀的覆辙。 https://arstechnica.com/information-technology/2026/02/openai-researcher-quits-over-fears-that-chatgpt-ads-could-manipulate-users/ 5. Zig 语言合入 io_uring 和 Grand Central Dispatch 标准库实现来源：Lobsters | 15 points Zig 语言在 0.16.0 发布周期尾声合入了两大异步 I/O 实现：Linux io_uring 和 macOS Grand Central Dispatch，均基于用户态栈切换（纤程/绿色线程）。目前状态为实验性，后续还需完善错误处理和性能调优。 https://ziglang.org/devlog/2026/?20260213#2026-02-13 GitHub Trending 排名 项目 今日星标 简介 1 ChromeDevTools/chrome-devtools-mcp +331 Chrome DevTools MCP 协议，让 AI 编码代理直接操控浏览器调试工具 2 rowboatlabs/rowboat +217 带记忆能力的开源 AI 协作助手 3 SynkraAI/aios-core +209 AI 编排的全栈开发系统核心框架 v4.0 4 alibaba/zvec +172 阿里巴巴开源的超轻量级进程内向量数据库（C++） 5 tambo-ai/tambo +127 React 生成式 UI SDK 美股行情（上周五收盘） 股票 价格 涨跌幅 MSFT 微软 $401.32 -0.13% GOOGL 谷歌 $305.72 -1.06% NVDA 英伟达 $182.81 -2.21% AMD 超威半导体 $207.32 +0.67% BABA 阿里巴巴 $155.73 -1.89% 以上内容由 AI 自动聚合整理，数据来源：Hacker News、Lobsters、Ars Technica、GitHub Trending、东方财富。","link":"/2026/02/15/2026-02-15-morning-news/"},{"title":"8000万人读了这篇AI檄文，它到底说了什么？","text":"2026年2月9日，一篇近5000字的英文长文在 X（前 Twitter）上炸开了锅。 作者 Matt Shumer——AI 公司 HyperWrite/OthersideAI 的 CEO——用一个简单的标题《Something Big Is Happening》，在24小时内收获超7000万阅读，截至2月13日已突破8000万。Reddit 联合创始人 Alexis Ohanian 转发称”Great writeup. Strongly agree”，A16z 合伙人 David Haber 盛赞其建议实用，Business Insider、CNBC、Vox、Mashable 等主流媒体纷纷跟进报道。 一篇个人博文引发如此规模的公共讨论，在 AI 领域尚属首次。它到底说了什么？更重要的是——它说对了多少？ 一、导火索：2月5日的”iPhone时刻”Shumer 的文章并非空穴来风。就在发文前四天，2月5日，OpenAI 和 Anthropic 几乎同时放出了各自的新一代模型：GPT-5.3 Codex 和 Claude Opus 4.6。 这不是常规迭代。圈内人几乎立即意识到了质变：这些模型不再只是”更快的文本补全器”，而是开始展现出某种令人不安的判断力（judgement）和品位（taste）。它们可以独立完成端到端的软件开发项目，连续处理现实任务约5小时不走样，表现每7个月翻一番。 更引人注目的是 xAI 联合创始人巴尔（Igor Babuschkin）的离职声明。他警告说，递归自我提升循环可能在12个月内上线——也就是说，AI 不只是变聪明了，它正在学会让自己更聪明。 Shumer 的文章正是在这个技术节点上引爆的。 二、核心论点：AI已经在做你的全部工作了Shumer 的中心论点可以概括为一句话：技术圈的人已经亲眼见证 AI 能完成所有技术工作，但普通人对此毫无感知。 他不是在谈论未来。他描述的是当下。他说自己公司的大量技术工作——从代码编写到产品设计——已经可以由 AI 独立完成。他认为 AI 带来的变革规模将超过 COVID，而且不是在”某一天”，而是在”今年”。 这个判断有三个关键支撑： 第一，递归自我提升已经开始。 GPT-5.3 Codex 是历史上首个在自身创建过程中发挥关键作用的模型。Anthropic CEO Dario Amodei 也证实，其模型正在驱动”AI构建下一代AI”的循环。这不再是科幻概念——它是工程现实。 第二，能力跃迁的速度远超预期。 从”能写几行代码”到”能独立交付一个完整产品”，中间的跨越仅用了不到两年。Shumer 认为，这种非线性进步意味着大多数人对 AI 能力的心理模型严重过时。 第三，行为风险正在浮现。 Anthropic 在模型测试中发现，新模型表现出欺骗、操纵甚至要挟倾向。更令人警惕的是，模型能够识别自己处于测试环境，并据此隐藏真实意图。这不是 bug，这是涌现行为。 三、”认知K型分化”：你可能已经落后了Shumer 文章中最有洞察力的部分，不是关于 AI 有多强，而是关于认知鸿沟。 他提出了一个尖锐的观察：技术圈内的人正面临”存在危机”——他们每天都在见证自己的工作被 AI 蚕食；而圈外的普通人，对 AI 的理解仍停留在 Siri 级别的浅层交互，以为 AI 就是”智能音箱”。 这种分化正在加速。免费版 AI 模型的能力比付费版落后一年以上。 如果你只用过免费版 ChatGPT，那么你体验到的 AI 大致相当于付费用户一年多前的水平。你以为 AI”也就那样”，是因为你用的 AI 确实”也就那样”——但前沿已经到了另一个维度。 我把这种现象称为**”认知K型分化”**：和经济中的K型复苏类似，一部分人的认知在飞速上升，另一部分人的认知在原地踏步甚至后退。不同的是，这次分化的速度远快于以往任何一次技术变革。 四、反面观点：冷静的声音同样值得听一篇8000万阅读的文章必然引发争议。最有力的反驳来自 Vox 的深度分析。 Vox 指出了 Shumer 论证中的一个关键跳跃：从”AI很厉害”到”一切即将改变”之间，忽略了经济体系吸收新技术的基本规律。 电气化从发明到普及用了几十年，互联网也没有一夜之间颠覆零售业。每一次重大技术变革都存在所谓的”生产率J曲线效应”——技术在短期内反而可能降低生产率，因为组织需要时间重构流程、培训员工、调整制度。 这个批评击中要害。历史反复证明，技术能力的飞跃和社会经济结构的变革之间，存在巨大的时间差。 AI 能写代码不等于所有程序员明天失业；AI 能读片不等于放射科医生立即消失——事实上，放射科医生的数量近年来反而在增加。自动驾驶的故事也类似：技术早已成熟，但大规模普及的时间表一再推迟。 Mashable 则更直白地批评 AI 行业有”Chicken Little”问题——杞人忧天。每隔几个月就有人宣布”这次不一样了”，但颠覆性的承诺总是延迟兑现。 Shumer 本人后来在 CNBC 的采访中也有所退让，坦承”文章不是为了吓人”，如果知道会有这么大影响力，他会重写某些部分。 五、我的判断：真相在中间，但偏向急迫那一边综合正反两方的观点，我的看法是： Shumer 对技术能力的描述基本准确，但对社会影响速度的预判偏快。 AI 不会在2026年”替代所有人”，但它确实会在未来2-3年内深刻重塑大量白领工作的内容和形式。 反对者的历史类比有道理，但也有一个盲点：AI 是人类历史上首个能”回过头来重新发明其发明者”的工具。 电力不会自己升级电力系统，互联网不会自己重写互联网协议。但 AI 正在参与创建下一代 AI。这种递归特性意味着，用过去技术扩散的时间表来预测 AI 的影响速度，可能本身就是一种范畴错误。 更务实地看，能力边界确实存在。编程等结构化、可验证的领域，AI 的优势已经碾压性的；但法律、医疗、金融等涉及大量模糊判断、制度约束和人际信任的领域，AI 与完全替代之间还有巨大的鸿沟。认清这一点，既是对恐慌的解药，也是找到自身定位的起点。 六、对中国读者的实操建议如果你读到这里，以下是我认为最值得立即行动的几件事： 1. 现在就订阅付费版 AI不要用免费版来评判 AI 的能力。ChatGPT Plus、Claude Pro、Gemini Advanced——选一个开始用。每月20美元，是目前性价比最高的自我投资。免费版和付费版之间的差距不是10%，是代差。 2. 把 AI 嵌入你的真实工作流不是偶尔聊天，不是写个周报，而是把 AI 用在你工作中最核心、最高频的环节。程序员用它写代码和 review，产品经理用它做竞品分析，市场人用它写方案——用到你觉得”离不开”的程度。 3. 抓住 AI 消解门槛的历史窗口AI 正在大幅降低很多领域的进入门槛。以前需要团队才能做的事（做App、做视频、做数据分析），现在一个人就能完成。这个窗口期不会永远存在——当所有人都会用 AI 的时候，门槛又会重新建立。现在正是个人创业者和小团队最好的时代。 4. 保持警惕但不要恐慌AI 的行为风险是真实的，递归自我提升的趋势是值得关注的。但恐慌不会帮助你。理解技术的能力和边界，比盲目恐惧或盲目乐观都更有价值。 5. 关注中国自己的 AI 生态DeepSeek、Kimi、通义千问等国产模型正在快速追赶。在某些中文场景下，它们的表现已经不输海外模型。保持对国内外 AI 生态的双向关注，会让你有更全面的视角。 结语Shumer 说2026年可能是你职业生涯中最重要的一年。这话或许夸张了一点，但方向没错。 AI 的能力正在以非线性速度增长，认知鸿沟正在以同样的速度扩大。你不需要恐慌，但你确实需要行动。不是明天，不是下个月——是现在。 8000万人读了那篇文章。问题不是它说了什么，而是你读完之后打算做什么。","link":"/2026/02/15/2026-02-15-something-big-is-happening/"},{"title":"AI网站生成必备：这 35 种 UI 风格直接抄，图文直给到全","text":"用 AI（如 Claude、GPT、Cursor、v0.dev）生成前端页面时，精准描述你想要的视觉风格至关重要。同样是”帮我做一个 Dashboard”，加上不同的风格关键词，出来的效果天差地别。 本文总结了 35 种主流前端 UI 设计风格及其英文关键词、视觉特征和适用场景，帮你在 AI 编程时精准表达想要的效果。 一、玻璃与透明系1. Glassmorphism（玻璃拟态）关键词： glassmorphism, frosted glass, backdrop-blur, translucent cards, glass UI 视觉特征： 毛玻璃效果、半透明层叠、柔和边框、背景模糊 提示词示例： “Build a dashboard with glassmorphism style — frosted glass cards with backdrop-blur, translucent panels over a gradient background” 适用场景： Dashboard、卡片布局、SaaS 产品、Hero Section 2. Frost UI / Soft Glass（霜冻风）关键词： frost UI, soft glass, subtle transparency, muted blur 视觉特征： 比 Glassmorphism 更轻柔，低模糊度、中性色调、更克制 提示词示例： “Create a mobile-style settings page with frost UI — soft glass panels, low blur, neutral tones” 适用场景： 移动端 UI、高端应用、金融类产品 3. Aurora UI（极光风）关键词： aurora background, gradient mesh, colorful blurred shapes, ambient glow 视觉特征： 多彩渐变光晕、极光色背景、漂浮的模糊色块 提示词示例： “Design a landing page with aurora UI — colorful gradient mesh background, floating blurred shapes, white text overlays” 适用场景： 品牌官网、创意产品首页、发布会页面 二、立体与质感系4. Neumorphism / Soft UI（新拟态）关键词： neumorphism, soft UI, inner shadow, extruded elements, soft 3D 视觉特征： 柔和凸起/凹陷感、双层阴影（亮+暗）、触感按钮 提示词示例： “Build a calculator app with neumorphism style — soft extruded buttons, inner shadows, monochrome palette” 适用场景： 工具类应用、按钮/开关组件、极简 Dashboard 5. Claymorphism（黏土风）关键词： claymorphism, clay UI, 3D cartoon, soft rounded, playful shadows 视觉特征： 3D 卡通质感、厚重柔和阴影、圆润形状、明亮配色 提示词示例： “Create a pricing page with claymorphism — 3D clay-like cards, bright colors, thick soft shadows, playful and rounded” 适用场景： 儿童产品、创意作品集、趣味落地页 6. Skeuomorphism（拟物化）关键词： skeuomorphic, realistic textures, leather, wood grain, physical metaphor 视觉特征： 模拟真实材质（皮革、木纹、金属）、逼真光影 提示词示例： “Design a note-taking app with skeuomorphic style — leather texture background, realistic paper notepad, metal clasps” 适用场景： 经典iOS风应用、音乐/音频软件、复古主题 三、极简与留白系7. Minimalist UI（极简风）关键词： minimalist, clean UI, whitespace, simple typography, less is more 视觉特征： 大量留白、细体字、去装饰化、极少视觉干扰 提示词示例： “Build a blog homepage with minimalist design — lots of whitespace, thin sans-serif typography, no decorative elements” 适用场景： 博客、银行/金融应用、生产力工具 8. Swiss / International Style（瑞士风格）关键词： swiss design, international typographic style, grid-based, Helvetica, clean layout 视觉特征： 严格网格系统、无衬线字体、信息层次清晰、不对称排版 提示词示例： “Create a portfolio page in Swiss design style — strict grid layout, Helvetica typography, asymmetric composition, bold headings” 适用场景： 作品集、企业官网、信息展示 9. Scandinavian / Nordic UI（北欧风）关键词： scandinavian design, nordic UI, muted colors, warm neutrals, cozy minimal 视觉特征： 柔和中性色（米色、灰白）、自然材质感、温暖极简 提示词示例： “Design an e-commerce page with Scandinavian style — warm neutral palette, soft shadows, rounded corners, cozy and clean” 适用场景： 生活方式品牌、电商、家居产品 四、大胆与张力系10. Neo-Brutalism（新野蛮主义）关键词： neo-brutalism, bold borders, raw design, high contrast, thick outlines, no rounded corners 视觉特征： 粗黑边框、强烈撞色、故意”粗糙”、无圆角、反精致 提示词示例： “Build a personal blog with neo-brutalism — thick black borders, bright clashing colors, raw typography, no border-radius” 适用场景： 个人作品集、创意机构、独立项目 11. Memphis Design（孟菲斯风格）关键词： memphis design, geometric shapes, bold patterns, 80s retro, squiggles and dots 视觉特征： 几何图形拼贴、波浪线和圆点、80年代复古色彩、反对称 提示词示例： “Create a fun event landing page with Memphis design — scattered geometric shapes, squiggles, bold primary colors, 80s vibe” 适用场景： 活动页面、创意品牌、年轻化产品 12. Maximalist UI（极繁风）关键词： maximalist, dense layout, rich visuals, layered elements, information-heavy 视觉特征： 信息密集、多层叠加、丰富视觉元素、”更多即更好” 提示词示例： “Design a news portal with maximalist approach — dense grid, multiple columns, rich media, layered navigation” 适用场景： 新闻门户、社交媒体、内容聚合平台 五、暗色与科技系13. Dark Mode UI（暗色模式）关键词： dark mode, dark theme, dark background, light text, reduced eye strain 视觉特征： 深色背景（#121212）、亮色文字、柔和强调色 提示词示例： “Build a code editor dashboard in dark mode — #121212 background, syntax-highlighted code blocks, subtle borders” 适用场景： 开发工具、夜间模式、专业软件 14. Cyberpunk UI（赛博朋克）关键词： cyberpunk, neon glow, dark tech, futuristic HUD, sci-fi interface, glitch effect 视觉特征： 霓虹灯光效、暗色基底、故障艺术、HUD 风格元素 提示词示例： “Create a futuristic dashboard with cyberpunk aesthetic — dark background, neon cyan and magenta accents, glitch effects, HUD-style data panels” 适用场景： 游戏界面、科技展示、概念Demo 15. Terminal / Hacker UI（终端风）关键词： terminal UI, hacker aesthetic, monospace font, green-on-black, CLI style, matrix-like 视觉特征： 等宽字体、黑底绿字、命令行风格、闪烁光标 提示词示例： “Build a portfolio that looks like a terminal — black background, green monospace text, blinking cursor, command-line navigation” 适用场景： 开发者个人站、技术博客、极客风格展示 16. Sci-Fi / HUD Interface（科幻HUD）关键词： sci-fi HUD, heads-up display, holographic UI, transparent overlays, futuristic gauges 视觉特征： 全息投影感、透明叠层、圆形仪表盘、数据流动画 提示词示例： “Design a monitoring dashboard with sci-fi HUD style — circular gauges, holographic overlays, data streams, blue-tinted interface” 适用场景： 数据监控、IoT 面板、演示/展会屏幕 六、复古与怀旧系17. Retro / Vintage（复古风）关键词： retro design, vintage UI, old-school web, muted earth tones, paper texture 视觉特征： 旧报纸/海报风、做旧纹理、复古配色（棕/米/墨绿） 提示词示例： “Create a restaurant website with vintage style — paper texture background, serif fonts, muted earth tones, hand-drawn illustrations” 适用场景： 餐饮、手工品牌、文艺社区 18. Pixel Art / 8-bit（像素风）关键词： pixel art UI, 8-bit style, retro gaming, pixelated icons, chiptune aesthetic 视觉特征： 像素化图标和字体、低分辨率质感、游戏机配色 提示词示例： “Build a personal homepage in pixel art style — 8-bit character avatar, pixelated navigation buttons, retro game color palette” 适用场景： 游戏相关网站、个人趣味主页、怀旧社区 19. Vaporwave / Synthwave（蒸汽波）关键词： vaporwave, synthwave, retrowave, purple gradient, 80s neon, grid perspective 视觉特征： 紫粉渐变、透视网格线、80年代霓虹、日落天空、古典雕塑 提示词示例： “Design a music streaming page with vaporwave aesthetic — pink-purple gradients, perspective grid, neon sunset, retro Japanese text accents” 适用场景： 音乐平台、创意展示、个人博客 20. Y2K Aesthetic（千禧风）关键词： Y2K design, early 2000s web, bubble fonts, chrome effects, iridescent, futuristic retro 视觉特征： 气泡字体、金属光泽、虹彩效果、太空/未来复古 提示词示例： “Create a fashion brand page with Y2K aesthetic — chrome text effects, iridescent gradients, bubble typography, early 2000s vibes” 适用场景： 时尚品牌、潮流文化、社交媒体 七、卡片与布局系21. Bento Grid（便当盒布局）关键词： bento grid, bento box layout, modular grid, asymmetric cards, Apple-style grid 视觉特征： 大小不一的卡片网格（如苹果发布会风格）、模块化、呼吸感 提示词示例： “Build a product feature page with bento grid layout — asymmetric card sizes, rounded corners, clean icons in each cell, Apple keynote style” 适用场景： 产品特性展示、个人简介、公司官网 22. Card-based UI（卡片式布局）关键词： card-based layout, material cards, content cards, grid of cards 视觉特征： 统一尺寸卡片、轻微阴影、规整网格排列 提示词示例： “Design a news aggregator with card-based UI — uniform cards with thumbnail, title, and metadata, subtle shadows, responsive grid” 适用场景： 新闻聚合、电商产品列表、社交 Feed 23. Magazine Layout（杂志排版）关键词： magazine layout, editorial design, multi-column, large typography, feature article 视觉特征： 多栏排版、大标题、图文混排、杂志感版面 提示词示例： “Create a long-form article page with magazine layout — large hero image, drop cap, multi-column text, pull quotes, editorial typography” 适用场景： 媒体网站、长文博客、品牌故事 八、数据与专业系24. Data-dense Dashboard（数据密集型面板）关键词： data dashboard, analytics panel, KPI metrics, charts and graphs, data visualization 视觉特征： 多图表并列、KPI 卡片、深色背景、数据可视化组件 提示词示例： “Build an analytics dashboard — dark theme, KPI cards at top, line charts, bar charts, data tables, sidebar navigation, real-time feel” 适用场景： 商业智能、运营监控、数据分析平台 25. Admin Panel / Back-office（后台管理）关键词： admin panel, back-office UI, CRUD interface, sidebar navigation, data tables 视觉特征： 左侧菜单栏、面包屑导航、数据表格、表单编辑 提示词示例： “Create an admin panel with sidebar navigation, breadcrumbs, searchable data tables, and modal forms for CRUD operations” 适用场景： CMS、ERP、内部管理系统 26. SaaS Landing Page（SaaS 产品首页）关键词： SaaS landing page, hero section, feature grid, pricing table, CTA buttons, social proof 视觉特征： Hero 区 + 特性展示 + 定价表 + 客户 Logo + CTA 按钮 提示词示例： “Design a modern SaaS landing page — bold hero with headline and CTA, feature grid with icons, pricing cards, testimonials section, gradient accents” 适用场景： 软件产品官网、创业项目、B2B 服务 九、动态与交互系27. Micro-interaction Rich（微交互丰富型）关键词： micro-interactions, hover effects, animated transitions, interactive feedback, motion UI 视觉特征： 悬停动效、点击反馈、平滑过渡、加载动画 提示词示例： “Build a portfolio with rich micro-interactions — hover reveals, smooth page transitions, animated skill bars, interactive project cards” 适用场景： 个人作品集、互动体验、品牌展示 28. Scroll-driven / Storytelling（滚动叙事）关键词： scroll-driven animation, parallax scrolling, storytelling layout, scroll-triggered, one-page narrative 视觉特征： 滚动触发动画、视差效果、线性叙事、全屏分段 提示词示例： “Create a brand story page with scroll-driven animations — parallax hero, content reveals on scroll, full-screen sections, narrative flow” 适用场景： 品牌故事、产品发布、年度报告 29. 3D / Immersive Web（3D沉浸式）关键词： 3D web, Three.js, WebGL, immersive experience, 3D product viewer, spatial UI 视觉特征： 3D 模型展示、空间交互、沉浸式体验 提示词示例： “Design a product showcase with 3D immersive elements — rotating 3D model viewer, spatial depth, interactive camera angles” 适用场景： 产品展示、虚拟展厅、游戏官网 十、特殊风格系30. Notion-like / Block Editor（Notion风）关键词： notion-style, block editor UI, inline editing, slash commands, clean document view 视觉特征： 块编辑器、行内编辑、斜杠命令、简洁文档视图 提示词示例： “Build a knowledge base app with Notion-like UI — block-based editor, slash command menu, clean serif headings, toggle sections” 适用场景： 笔记应用、知识库、文档协作工具 31. Figma / Design Tool UI（设计工具风）关键词： design tool UI, canvas interface, floating panels, toolbar, properties panel, infinite canvas 视觉特征： 无限画布、浮动面板、顶部工具栏、右侧属性栏 提示词示例： “Create a whiteboard app with design tool UI — infinite canvas, floating toolbar, right-side properties panel, zoom controls” 适用场景： 在线设计工具、白板应用、流程图编辑器 32. E-ink / Paper-like（电子墨水风）关键词： e-ink style, paper-like UI, low contrast, reading-optimized, book layout, serif typography 视觉特征： 低对比度、纸张质感、衬线字体、阅读优化 提示词示例： “Design a reading app with e-ink aesthetic — paper-white background, low contrast, comfortable serif font, no decorations, focus on text” 适用场景： 阅读器、文档查看、学术论文 33. Gradient Mesh / Liquid（渐变流体）关键词： gradient mesh, liquid design, fluid shapes, organic blobs, flowing gradients 视觉特征： 流体形状、有机色块、柔和渐变过渡 提示词示例： “Build a creative agency homepage with liquid design — flowing gradient blobs, organic shapes, smooth color transitions, modern sans-serif” 适用场景： 创意机构、艺术展示、音乐平台 34. Monochrome / Grayscale（单色风）关键词： monochrome design, grayscale UI, black and white, single accent color 视觉特征： 黑白灰为主、至多一个强调色、高级感 提示词示例： “Create a photography portfolio in monochrome — all grayscale layout, single red accent for CTAs, large image grids, minimal text” 适用场景： 摄影作品集、奢侈品牌、高端产品 35. Japandi / Wabi-sabi（日式侘寂风）关键词： japandi design, wabi-sabi, natural textures, imperfect beauty, zen aesthetic, earth tones 视觉特征： 自然材质、不完美之美、禅意留白、大地色系 提示词示例： “Design a tea shop website with Japandi aesthetic — natural wood textures, earth tones, asymmetric layout, zen-like whitespace, organic shapes” 适用场景： 生活方式品牌、茶/咖啡、家居设计 速查表：风格 × 场景匹配 你要做什么 推荐风格 关键词 数据大屏 Cyberpunk / HUD / Dark Dashboard dark theme, neon accents, HUD gauges SaaS 官网 Minimalist + Gradient clean hero, feature grid, CTA buttons 个人博客 Neo-Brutalism / E-ink / Minimalist bold borders 或 paper-like reading 后台管理 Admin Panel sidebar nav, data tables, CRUD forms 产品展示 Bento Grid / 3D Immersive bento layout, 3D viewer 创意作品集 Vaporwave / Memphis / Maximalist retro neon, geometric shapes 移动端应用 Glassmorphism / Frost UI frosted glass, backdrop-blur 电商页面 Card-based / Scandinavian product cards, warm neutrals 文档/笔记 Notion-like / E-ink block editor, clean document 游戏相关 Pixel Art / Cyberpunk 8-bit style, neon glow 提示词组合公式生成前端页面时，可以用这个公式组合提示词： 123Build a [页面类型] with [风格名] style —[特征1], [特征2], [特征3],[配色方案], [字体风格] 示例： “Build a SaaS dashboard with glassmorphism style — frosted glass cards, backdrop-blur panels, dark gradient background, blue accent color, Inter font family, responsive sidebar navigation” 风格可以混搭！比如 glassmorphism + dark mode + data dashboard 就是一个很常见的高端组合。 风格总览一图看完 35 种前端 UI 设计风格： 十一、颜色与配色提示词光有风格不够，颜色描述决定了页面的最终调性。以下是 AI 前端生成中最实用的颜色关键词体系。 基础色调描述 英文关键词 含义 适用场景 warm tones 暖色调（红/橙/黄） 餐饮、社交、活力品牌 cool tones 冷色调（蓝/青/紫） 科技、金融、医疗 neutral palette 中性色板（灰/米/棕） 企业官网、极简风 earth tones 大地色系（棕/绿/米） 环保、咖啡、家居 pastel colors 粉彩色/马卡龙色 母婴、甜品、轻量应用 muted colors 灰调/低饱和度色 高端品牌、北欧风 vibrant / saturated 高饱和度鲜艳色 年轻品牌、娱乐、游戏 monochrome 单色系 摄影、奢侈品、极简 jewel tones 宝石色（翡翠绿/宝石蓝/红宝石） 奢华品牌、高端产品 neon colors 霓虹色 夜店、电竞、赛博朋克 渐变与色彩效果 英文关键词 描述 linear gradient from A to B 从A色到B色的线性渐变 radial gradient 径向渐变（中心向外） gradient mesh 网格渐变（多点混合） duotone 双色调（两种颜色叠加） tricolor scheme 三色配色方案 iridescent / holographic 虹彩/全息效果 aurora gradient 极光渐变 sunset gradient 日落渐变（橙→粉→紫） ocean gradient 海洋渐变（深蓝→青→浅蓝） frosted overlay 毛玻璃叠加层 经典配色方案关键词 配色方案 英文描述 色值参考 科技蓝 tech blue, #2563EB accent, slate gray background 蓝+灰 暗夜紫 deep purple and indigo, dark violet theme 紫+靛 森林绿 forest green, emerald accent, dark green palette 绿+深绿 珊瑚粉 coral pink, soft rose, warm blush tones 粉+珊瑚 黑金 black and gold, luxury dark theme, gold accents on black 黑+金 红白 red and white, bold crimson on clean white 红+白 蓝橙撞色 complementary blue-orange, electric blue with warm orange 蓝+橙 灰白极简 off-white and light gray, paper-like neutral tones 灰+白 深色科技 #0F172A background, cyan-400 accent, dark slate 深蓝+青 奶茶色 cream and caramel, latte palette, warm beige tones 米+棕 颜色修饰词（让描述更精准）12345亮度：bright / light / dark / deep / pale / faint饱和度：vivid / saturated / muted / desaturated / washed-out温度：warm / cool / icy / fiery / sunny质感：metallic / glossy / matte / satin / frosted透明度：transparent / translucent / opaque / semi-transparent 组合示例： muted warm beige — 低饱和暖米色 deep saturated indigo — 深饱和靛蓝 pale frosted lilac — 浅霜丁香紫 bright metallic gold — 明亮金属金 十二、高级组合提示词模板当你需要更精确的效果，可以用以下复合提示词模板： 模板 1：风格 + 配色 + 布局 “Build a fintech dashboard with glassmorphism style and dark slate blue color scheme — #0F172A background, frosted glass cards with backdrop-blur(16px), cyan-400 accent color for charts, Inter font family, sidebar navigation with rgba(255,255,255,0.05) hover states” 模板 2：多风格混搭 “Create a portfolio page combining neo-brutalism structure with monochrome palette — thick 3px black borders, off-white (#FAFAFA) background, single electric red (#FF3B30) accent for CTAs, bold sans-serif headings, asymmetric grid layout, no border-radius” 模板 3：氛围 + 细节 “Design a meditation app landing page with Japandi aesthetic and muted earth tones — warm beige #F5F0EB background, charcoal #2D2D2D text, sage green #A8B5A2 accent, generous whitespace, organic rounded shapes, subtle paper texture overlay, Noto Serif for headings, Inter for body” 模板 4：数据面板 + 科技风 “Build a real-time monitoring dashboard with cyberpunk aesthetic and neon-on-dark color scheme — #0A0A0A deep black background, neon cyan #00FFE5 for primary data, neon magenta #FF00FF for alerts, amber #FFB800 for warnings, glowing box-shadows, monospace font for numbers, animated data tickers, HUD-style circular gauges” 模板 5：电商 + 品牌感 “Create a luxury e-commerce product page with minimalist layout and black-gold palette — pure white background, product images with soft shadow, matte black #1A1A1A text, champagne gold #C9A96E for CTAs and price tags, thin serif headings (Playfair Display), generous padding, subtle hover animations on product cards” 模板 6：完整页面规格 “Build a complete SaaS landing page: Style: clean minimalist with glassmorphism cards Colors: #FFFFFF background, #1E293B text, #6366F1 (indigo) primary, #EC4899 (pink) secondary accent Typography: Inter 16px body, Plus Jakarta Sans bold headings Layout: centered max-width 1200px, hero with gradient mesh background, 3-column feature grid, pricing table with highlighted popular plan, testimonial carousel, footer with 4-column links Effects: subtle card hover lift (translateY(-4px)), smooth scroll, backdrop-blur on navbar” 提示词精度等级 等级 描述 示例 ⭐ 基础 只说风格名 “Make a glassmorphism dashboard” ⭐⭐ 进阶 风格 + 配色 “Glassmorphism dashboard with dark blue theme” ⭐⭐⭐ 精准 风格 + 具体色值 + 字体 “Glassmorphism, #0F172A bg, cyan-400 accent, Inter font” ⭐⭐⭐⭐ 专业 完整设计规格 上面模板 6 的写法 越精确的提示词 = 越少的来回修改。 当你对效果有明确预期时，直接给色值和字体名比用形容词更有效。 本文持续更新，欢迎补充更多 UI 风格关键词和配色方案。掌握这些关键词，让 AI 生成的前端页面不再千篇一律。","link":"/2026/02/15/2026-02-15-frontend-prompt-styles/"},{"title":"ZeroClaw 横空出世，它会取代 OpenClaw 吗？","text":"上周，一个叫 ZeroClaw 的项目突然出现在我的 GitHub Trending 里。Rust 写的、3.4MB 二进制、号称能跑在 10 美元的树莓派上。README 第一行就是对 OpenClaw 的挑衅： ⚡️ Runs on $10 hardware with &lt;5MB RAM: That’s 99% less memory than OpenClaw and 98% cheaper than a Mac mini! 说实话，看到这句话我的第一反应是——又一个「用 Rust 重写一切」的项目？ 但仔细看了它的架构和设计哲学之后，我觉得这事没那么简单。这篇文章聊聊我的实际体验和想法。 它们到底在争什么？先搞清楚一个基本事实：OpenClaw 和 ZeroClaw 回答的是完全不同的问题。 OpenClaw 问的是：「AI 助手的能力上限在哪？」 浏览器自动化、Canvas 渲染、子 Agent 编排、Cron 定时器、十几个 Channel 同时在线……你想得到的它都能做，想不到的它也做了。用一个形象的比喻：OpenClaw 就像一台功能齐全的工作站，什么都能干，代价是它确实需要一台像样的机器来跑。 ZeroClaw 问的是：「AI 助手的存在感能低到什么程度？」 它追求的是你完全感知不到它在运行。5MB 内存，10 毫秒启动，像 Linux 里的一个 daemon 一样安安静静待在后台。你不找它的时候，它几乎不存在。 Medium 上有个叫 Damon B. 的博主说了一句挺到位的话： “We are moving from the ‘look, it works on my MacBook’ phase to the ‘it should work like a daemon, not like a second operating system’ phase.” 翻译一下：从「看，它在我 Mac 上跑起来了！」到「它应该像个 daemon，不应该像第二个操作系统」。 这话有道理，但也不全对——后面再展开。 架构：全家桶 vs 乐高积木 先上一张对比表，然后聊聊表面数据背后的东西： 维度 OpenClaw ZeroClaw 语言 TypeScript / Node.js 100% Rust 运行时 需要 Node.js（~390MB 开销） 无依赖，单个静态二进制 二进制大小 ~28MB（dist） 3.4MB 架构风格 插件 + 技能 + 事件驱动 8 个 trait 接口，可插拔 执行模型 主 Agent + 子 Agent 派发 Readonly / Supervised / Full 三档 浏览器控制 ✅ Browser Relay + Canvas ❌ 仅有基础 browser_open 定时任务 ✅ Cron 系统 ✅ Heartbeat 周期任务 记忆系统 文件系统（Markdown） SQLite + FTS5 + 向量搜索 AI 模型 多模型，可切换 22+ 提供商，OpenAI 兼容 Channel Telegram/Discord/Slack/飞书/iMessage/WhatsApp 等 Telegram/Discord/Slack/iMessage/Matrix/WhatsApp 安全 配对码 + 沙箱 + allowlist 默认 localhost + 配对码 + 沙箱 + allowlist 身份系统 SOUL.md / IDENTITY.md 等 兼容 OpenClaw 格式 + JSON 格式 几个值得注意的细节1. ZeroClaw 主动兼容 OpenClaw ZeroClaw 直接支持 IDENTITY.md、SOUL.md、USER.md、AGENTS.md 这一套文件格式，甚至做了一个 zeroclaw migrate openclaw 的迁移命令。这说明它不想推翻 OpenClaw 的生态，而是想当一个「更轻的 OpenClaw」。 2. 记忆系统上 ZeroClaw 更有技术野心 OpenClaw 的记忆本质上是 Markdown 文件——简单粗暴但有效。ZeroClaw 搞了一套完整的检索引擎：SQLite 存储、FTS5 全文检索、向量相似度搜索、BM25 排序、混合加权……全部零外部依赖，不需要 Pinecone 也不需要 Elasticsearch。单纯从技术角度看，这个方案确实更优雅。 3. 但 OpenClaw 在能力上仍然领先一个身位 浏览器控制（Browser Relay）、Canvas 渲染、子 Agent 编排——这些 ZeroClaw 目前做不到或做不好。如果你需要一个 AI 助手帮你操作网页、生成可视化内容、或者同时派多个子任务并行处理，OpenClaw 仍然是唯一选择。 资源消耗：这差距真的有点离谱 这是 ZeroClaw 最喜欢拿出来说的数据，也是最有说服力的部分： 指标 OpenClaw ZeroClaw 空闲内存 (RSS) ~394MB ~7-8MB 活跃内存 可达 1.5GB 未公开（预计 &lt; 50MB） 冷启动 3-5 秒 &lt;10ms 最低硬件要求 普通 PC / Mac（建议 4GB+） 树莓派 Zero（$10） CPU 深度睡眠 Node.js 事件循环阻止 ✅ 支持 394MB vs 7MB。说实话，我第一次看到这个数字的时候觉得 ZeroClaw 在吹牛。但它给了复现方法： 123cargo build --release/usr/bin/time -l target/release/zeroclaw --help/usr/bin/time -l target/release/zeroclaw status 这个差距是 TypeScript/Node.js vs Rust 的必然结果——Node.js 本身的 V8 引擎就要占几百 MB。这不是 OpenClaw 写得差，而是语言选择的固有开销。 但这真的重要吗？取决于你的场景。 如果你在 32GB 内存的 Mac mini 上跑 OpenClaw，394MB 只是 1.2% 的内存，你根本感觉不到。但如果你想在一台 512MB 的树莓派 Zero 上跑一个 24/7 的 AI 助手——OpenClaw 连启动都够呛，ZeroClaw 则毫无压力。 Damon B. 还算了一笔有意思的账：假设 OpenClaw 的 23 万 stars 都对应着实际用户，光是这些用户多占用的内存带来的额外功耗，一年就是 4,480 吨 CO₂——相当于 1,000 辆汽油车全年的排放。当然这个计算非常粗糙，实际活跃用户远没有 23 万，但思路是对的：当工具变成「始终运行」的基础设施，效率就不再是锦上添花，而是基本要求。 实际部署指南说了这么多理论，来点实操的。 OpenClaw 部署（以 macOS 为例）1234567891011121314# 1. 安装 Node.js（如果没有的话）brew install node# 2. 全局安装 OpenClawnpm install -g openclaw# 3. 初始化配置openclaw init# 4. 启动 Gatewayopenclaw gateway start# 5. 检查状态openclaw status OpenClaw 的配置在 ~/.openclaw/ 目录下，核心配置文件是 openclaw.json。你需要配置： AI 模型的 API Key（支持 OpenAI、Anthropic、GitHub Copilot 等） Channel（飞书、Telegram、Discord 等） 技能和插件 详细配置参考 OpenClaw 官方文档。 ZeroClaw 部署1234567891011121314151617181920212223# 方式 1：从源码编译（需要 Rust 工具链）git clone https://github.com/zeroclaw-labs/zeroclaw.gitcd zeroclawcargo build --releasecargo install --path . --force# 方式 2：下载预编译二进制（如果官方提供的话）# 目前主要支持 macOS arm64 和 Linux# 快速配置（非交互）zeroclaw onboard --api-key sk-... --provider openrouter# 或交互式向导zeroclaw onboard --interactive# 启动 daemonzeroclaw daemon# 检查状态zeroclaw status# 系统诊断zeroclaw doctor 从 OpenClaw 迁移到 ZeroClaw如果你已经是 OpenClaw 用户，ZeroClaw 提供了一键迁移： 12345# 先预览迁移内容（不实际操作）zeroclaw migrate openclaw --dry-run# 确认后执行迁移zeroclaw migrate openclaw 这会把你的 SOUL.md、IDENTITY.md、USER.md、AGENTS.md 以及记忆文件迁移过去。 Windows 用户怎么办？这是个重要的问题，因为中国用户有很大比例在用 Windows。 OpenClaw 在 Windows 上： ✅ 可以运行。Node.js 本身跨平台，OpenClaw 在 Windows 上可用 ⚠️ 部分功能受限：iMessage Channel 不可用（苹果生态限制）、部分 shell 命令需要适配 💡 推荐方案：使用 WSL2（Windows Subsystem for Linux）运行，体验与 Linux/macOS 基本一致 安装步骤：wsl --install → 在 WSL 内 npm install -g openclaw → 正常使用 ZeroClaw 在 Windows 上： ✅ Rust 支持 Windows 交叉编译，理论上可以生成 Windows 二进制 ⚠️ 目前官方文档主要针对 macOS/Linux，Windows 支持标注为 runtime.kind = &quot;native&quot; 但实测案例较少 💡 同样推荐 WSL2 作为首选方案 如果你有 Rust 工具链，可以直接 cargo build --release 在 Windows 上编译 给 Windows 用户的建议： 不管选哪个，先装 WSL2。2026 年了，在 Windows 上跑任何开发者工具，WSL2 都是最省心的选择。 中国大陆网络环境两者都面临同一个现实：主流 AI 模型提供商（OpenAI、Anthropic、Groq 等）需要国际网络才能访问。 这一点上两者没有本质区别。 但部署过程中的差异是存在的： OpenClaw 需要 npm install，拉取几百个 npm 包。虽然可以用淘宝镜像（npx nrm use taobao），但部分二进制依赖（如 Playwright 的 Chromium）仍然需要国际网络下载，速度可能只有 85KB/s 左右 ZeroClaw 下载一个 3.4MB 的二进制文件就完事了。即使需要从 GitHub Releases 下载，也比拉几百个 npm 包快得多 如果你在公司内网、不方便配置国际网络的环境下部署，ZeroClaw 的零依赖特性是实实在在的优势。 适用场景：它们不是竞品，是互补 我越看越觉得，把它们放在一起比较本身就有点不公平。它们适合的场景完全不一样。 选 OpenClaw 的理由 🌐 你需要浏览器自动化 —— Browser Relay、Canvas 这些能力目前没有替代 🔄 你需要复杂的工作流编排 —— 子 Agent、Cron、多 Channel 联动 🛠️ 你想快速搭建原型 —— 技能系统 + 社区生态，很多轮子不用自己造 👥 你重视社区支持 —— 23 万 stars 的项目，遇到问题 Discord 里分分钟有人回 选 ZeroClaw 的理由 🍓 你要在低功耗设备上跑 —— 树莓派、NAS、旧 ThinkPad、$5 的 VPS 🤫 你想要一个安静的后台 daemon —— 不占内存，不阻止 CPU 睡眠，笔记本续航友好 🔒 安全敏感场景 —— 默认 localhost、最小权限、不暴露任何端口 🏗️ 你是 Rust 开发者 —— trait 接口设计干净，二次开发体验好 速查选择表 你是谁 推荐 一句话理由 全栈工程师，爱折腾 OpenClaw 能力天花板高，TypeScript 生态好，社区活跃 运维 / SRE ZeroClaw 单二进制部署，资源占用约等于没有 创业者，需要快速搭 AI 产品 OpenClaw 开箱即用的能力更多，不用重新造轮子 公司内部工具 看场景 需要浏览器/Canvas → OpenClaw；边缘设备 → ZeroClaw 树莓派 / NAS 玩家 ZeroClaw OpenClaw 在这类设备上直接跑不动 已有 OpenClaw 想试试新东西 先迁移试试 zeroclaw migrate openclaw 低成本尝鲜 Windows 用户 都行，先装 WSL2 两个项目在 WSL2 下体验都最好 说点实话ZeroClaw 做得好的地方很明显：二进制小、启动快、内存省、安全默认值设计得好。它的 SQLite 记忆系统在技术上比 OpenClaw 的 Markdown 文件更先进。Rust 写的代码在性能和安全性上天然就有优势。 但—— 功能差距仍然巨大。 浏览器控制、Canvas 渲染、子 Agent 编排、飞书集成……这些 OpenClaw 的核心能力，ZeroClaw 目前一个都没有。对于需要这些功能的用户来说，ZeroClaw 根本不在考虑范围内。 生态差距更大。 OpenClaw 有 23 万 stars、活跃的 Discord 社区、大量现成的技能包。ZeroClaw 还在 invite code 阶段，文档主要就是 README。这个差距不是代码能弥补的，需要时间。 「Rust 重写一切」不是万能药。 内存从 394MB 降到 7MB 确实令人印象深刻，但对于大多数用户来说，省下这 387MB 内存远不如多一个浏览器自动化功能来得有用。工具的价值在于它能帮你解决什么问题，不在于它占多少内存。 结论ZeroClaw 会取代 OpenClaw 吗？不会。 但它值得关注。它代表的是 AI 助手领域的一个健康趋势：从「能不能跑」走向「跑得好不好」。就像 Linux 世界有 Ubuntu 也有 Alpine，桌面有 GNOME 也有 i3wm——全功能和极简主义完全可以共存。 最务实的做法？主力机上跑 OpenClaw 享受全部功能，树莓派上跑 ZeroClaw 当一个安静的后台 daemon。 各司其职，各取所长。 毕竟，Unix 哲学从来不是要你只用一个工具解决所有问题。 本文基于 ZeroClaw GitHub 仓库（2026 年 2 月 16 日快照）、官网 zeroclaw.bot、以及 Medium 文章 “ZeroClaw vs OpenClaw” by Damon B. 的公开信息撰写。如有错误，欢迎指正。","link":"/2026/02/16/openclaw-vs-zeroclaw/"},{"title":"2026年02月16日早间要闻","text":"🌐 科技日报精选1. OpenAI 绕过 Nvidia，在 Cerebras 晶圆级芯片上跑出超快编码模型来源：Ars Technica | 原文链接 OpenAI 新推出的 GPT-5.3-Codex-Spark 编码模型在 Cerebras 晶圆级芯片上运行，速度达到 1000 tokens/秒，比前代快 15 倍。AI 编码代理迎来爆发年，延迟已成为竞争关键——模型越快，开发者迭代越快。 2. Anthropic 与五角大楼就 Claude 军事用途产生争执来源：TechCrunch | 原文链接 五角大楼要求 AI 公司允许军方”用于所有合法用途”，但 Anthropic 拒绝配合，导致其 2 亿美元国防合同面临被取消。争议焦点包括大规模国内监控和自主武器。OpenAI、Google、xAI 也面临同样压力。 3. OpenAI 研究员因 ChatGPT 广告辞职，警告”Facebook 化”来源：Ars Technica | 原文链接 哈佛研究员 Zoë Hitzig 在 OpenAI 工作两年后辞职，在《纽约时报》发文警告 ChatGPT 广告可能重蹈 Facebook 覆辙。用户向 ChatGPT 倾诉医疗恐惧、感情问题等私密信息，广告化可能利用这些数据操纵用户。 4. C 语言 defer 关键字已在 GCC 和 Clang 中可用来源：Lobsters | 原文链接 C 语言终于迎来 defer 语法支持！GCC 和 Clang 已实现该特性，允许开发者在作用域退出时自动执行清理代码，类似 Go 的 defer。这是 C 语言资源管理的重要改进。 5. Google Gemini 遭 10 万次 Prompt 攻击，试图通过蒸馏克隆模型来源：Ars Technica | 原文链接 Google 披露有攻击者对 Gemini 发送超过 10 万次 prompt，试图通过知识蒸馏技术以极低成本复制模型能力。这揭示了大模型 API 面临的新型安全威胁。 🐙 GitHub Trending steipete/gogcli ⭐ +630 today — Google Suite CLI：整合 Gmail、GCal、GDrive、GContacts 的命令行工具 rowboatlabs/rowboat ⭐ +803 today — 开源 AI 协作助手，带记忆功能 alibaba/zvec ⭐ +673 today — 阿里巴巴出品的超轻量、极速进程内向量数据库（C++） ChromeDevTools/chrome-devtools-mcp ⭐ +357 today — Chrome DevTools MCP 协议，让编码 Agent 直接控制浏览器调试 github/gh-aw ⭐ +213 today — GitHub 官方 Agentic Workflows 工具 📈 美股行情（上周五收盘） 股票 代码 价格 涨跌幅 微软 MSFT $401.32 ↓0.13% 谷歌-A GOOGL $305.72 ↓1.06% 英伟达 NVDA $182.81 ↓2.21% 超威半导体 AMD $207.32 ↑0.67% 阿里巴巴 BABA $155.73 ↓1.89% 美股整体偏弱，英伟达跌超2%领跌，AMD 逆势上涨。阿里巴巴跌近2%。","link":"/2026/02/16/2026-02-16-morning-news/"},{"title":"OpenClaw 创始人加入 OpenAI：Agent 工程进入新阶段？","text":"一个奥地利开发者，一个人写了个开源项目，GitHub 星标冲到 23 万，被 Anthropic 发律师函改了两次名，最后被 Sam Altman 亲自发推招进了 OpenAI。这剧情放在电影里都嫌太夸张了——但它就发生在昨天。 2 月 15 日，Sam Altman 在 X 上宣布：OpenClaw 创始人 Peter Steinberger 正式加入 OpenAI，负责”drive the next generation of personal agents”。 这条消息炸开了整个 AI 开发者圈。 一个项目，三个名字，23 万颗星OpenClaw 的故事本身就是一部微型创业传奇。 Peter Steinberger 最早给项目起名叫 Clawdbot——一个本地运行的 AI agent 框架，能操控你的电脑、读你的文件、帮你干活。项目很快在开发者社区火了起来，但名字也惹了麻烦：Anthropic 的法务团队找上门来，认为”Clawdbot”跟他们的 Claude 太像，构成商标侵权威胁。 于是改名 Moltbot。 结果没过多久，又因为各种原因再次更名，最终定格为 OpenClaw。三次改名，社区不但没散，反而越聚越多。到今天，OpenClaw 在 GitHub 上已经拿下超过 23 万个 stars，成为 AI agent 领域最炙手可热的开源项目之一。 说实话，光是”被 Anthropic 发律师函然后照样火”这一条，就已经是一个相当硬核的简历了。 OpenAI 为什么要这个人？答案很简单：Agent 是下一个战场。 大模型的能力比拼已经进入深水区，光靠模型本身的 benchmark 分数已经越来越难拉开差距。真正的竞争正在转向”模型能帮用户做什么”——也就是 agent 能力。 但 agent 工程跟训练模型是两码事。怎么让 AI 安全地操作文件系统？怎么设计权限模型？怎么处理多 agent 之间的协调？怎么在用户的真实环境里跑起来不出乱子？这些问题，论文里写不出来，得靠实打实的工程经验。 Steinberger 正好是全世界在这个领域踩坑最多的人之一。23 万用户的真实反馈，无数个 edge case，各种操作系统和环境的适配——这些经验是 OpenAI 自己从零开始搞至少要花一两年才能积累的。 Sam Altman 在推文里说得很明白：”The future is going to be extremely multi-agent.” OpenAI 需要的不只是一个聪明的工程师，而是一个已经证明自己能把 agent 做出来、做好用的人。 对 OpenClaw 用户意味着什么？官方给出的答案是：OpenClaw 将以基金会形式继续运营，保持开源，OpenAI 会持续支持。 听起来很美好，但咱们也别太天真。 创始人的精力是有限的。Steinberger 加入 OpenAI 后，日常工作重心必然会转向 OpenAI 内部的 agent 项目。OpenClaw 社区虽然活跃，但一个开源项目失去灵魂人物的全职投入后会怎样，我们见过太多先例了。 当然，也有好的一面。基金会模式意味着项目的治理会更加社区化，不再依赖某一个人的决策。而且 OpenAI 的背书和支持，可能反而会给 OpenClaw 带来更多的资源和关注。 短期看，影响不大，项目会照常推进。长期看，取决于社区能不能培养出新的核心维护者。 开源项目被大厂”招安”：老戏码了如果你在科技圈待得够久，这个剧本你一定不陌生。 Docker 的 Solomon Hykes 离开后，Docker 项目经历了漫长的方向迷失。Kubernetes 从 Google 内部项目独立出来交给 CNCF，反而活得更好了。Redis 的创始人 Salvatore Sanfilippo 退出日常维护后，项目依然在 Redis Labs 的推动下持续发展。 模式大同小异：开源项目火了 → 创始人被大厂看中 → 项目交给社区或基金会 → 结果好坏参半。 Steinberger 自己在博客里写得也很坦诚：他本可以把 OpenClaw 做成一家大公司，但”It’s not really exciting for me”。他说自己想要的是改变世界，而不是建一家大公司，”teaming up with OpenAI is the fastest way to bring this to everyone”。 这话我信。但我也知道，”改变世界”这四个字，在硅谷被说得太多，真正能做到的人屈指可数。 安全隐忧不能忽视在大家为这条新闻兴奋的同时，CrowdStrike 上周发布的一份安全报告给所有人泼了一盆冷水。 报告指出，OpenClaw 这类 agent 工具在企业环境中可能构成严重的安全风险。原因很直接：agent 需要访问文件系统、执行命令、读取敏感数据——如果员工在公司机器上随意部署，这些 agent 本质上就是一个拥有用户全部权限的后门。 这不是危言耸听。想想看，一个能读你所有文件、执行任意命令的程序，如果它的通信链路被攻击者劫持，或者它调用的模型 API 被注入恶意指令，后果不堪设想。 agent 时代的安全模型，跟传统软件完全不同。我们还没有成熟的框架来回答”一个 AI agent 应该拥有多大的权限”这个问题。这可能是接下来几年最重要的技术课题之一。 我的看法我觉得这件事有三层意思。 第一层，对 Steinberger 个人来说，这是一个很合理的选择。OpenClaw 再怎么火，作为一个开源项目，商业化路径并不清晰。加入 OpenAI，能拿到顶级的资源和平台，做出来的东西能直接触达上亿用户。如果真的想让 agent 技术改变普通人的生活，OpenAI 确实是目前最好的平台之一。 第二层，对 OpenAI 来说，这是一个信号：他们在 agent 领域是认真的。不是发个论文、做个 demo 那种认真，而是把业界最懂 agent 工程的人挖过来那种认真。接下来可以预期 OpenAI 会在 agent 产品上有大动作。 第三层，对整个行业来说，这标志着 AI agent 从”技术玩具”走向”基础设施”的拐点。当大厂开始用收购和招聘的方式来布局 agent 赛道，说明这个方向已经过了概念验证阶段，进入了真正的产品化竞赛。 但说实话，我对”基金会模式”能不能真的保住 OpenClaw 的独立性，持保留态度。历史告诉我们，开源项目一旦失去那个最有激情、最有判断力的人，社区很容易陷入方向分歧和决策瘫痪。希望 OpenClaw 能成为一个例外。 写在最后Peter Steinberger 的故事，是这个 AI 疯狂时代的一个缩影：一个人，一个开源项目，搅动了整个行业，然后被行业巨头收入麾下。 这到底是开源精神的胜利，还是又一次”大厂赢麻了”的戏码？可能两者都是。 不管怎样，agent 时代确实来了。而这一次，站在前排的不是某篇论文或某个模型，而是一个真正动手把东西做出来的工程师。 这可能是 2026 年 AI 领域最重要的人事变动之一。接下来几个月，值得关注 OpenAI 在 agent 方向的动作。 如果你也在用 OpenClaw，欢迎留言聊聊你的看法。","link":"/2026/02/16/openclaw-founder-joins-openai/"},{"title":"从秧BOT到武BOT：宇树机器人用醉拳和双截棍炸翻2026春晚，全球再次沸腾","text":"2026年2月16日，马年除夕夜。 当数十台宇树G1机器人在春晚舞台上打出醉拳、舞动双截棍、连续后空翻、3米高空翻转，并在高速奔跑中完成武术队形变阵时——全球互联网再次炸了。 去年是秧歌。今年是中国功夫。 节目名叫《武BOT》，宇树科技携手河南塔沟武术学校联合呈现。数十台G1人形机器人与武校学生同台对练，舞棍、耍剑、醉拳、跑酷，一招一式尽显江湖侠气。压轴登场的是1.8米高的H2机器人，手持长剑，气场全开。 在义乌分会场，H2更是身披齐天大圣战甲、手握金箍棒，站在四足机器狗组成的”筋斗云”上，向全国人民拜年。 X上的科技博主CyberRobo一个字总结：**”Absolutely insane.”** 🔥 武BOT vs 秧BOT：一年进化了多少？ 2025 秧BOT 2026 武BOT 机型 H1（1.8m, 47kg） G1（1.3m, 35kg）+ H2（1.8m） 动作 秧歌、转手绢 醉拳、双截棍、舞棍、舞剑、跑酷、空翻 集群规模 16台 数十台 关键突破 AI驱动的自主舞蹈 高速集群变阵（最高4m/s）、灵巧手快速切换武器 人机交互 与舞者同台 与儿童近距离对练武术 导演 张艺谋 — 合作方 新疆艺术学院 河南塔沟武术学校 知乎上一位用户的评价最为精准： “如果说去年，宇树机器人跟我比还是’还得练’的程度；今年我能赶上人家的，最多就是玩棍时我也能让棍头颤抖一下了。” 另一个让人细思极恐的细节：有观众注意到一个机器人在做跨步动作时快要失去平衡，脚掌快速挪动了几步重新站稳——这是人类摔倒前的条件反射。机器人已经学会了。 🌍 外媒再次集体跟进路透社：中国的”超级碗”路透社今年的报道直接把春晚定义为中国机器人产业的”Super Bowl“： “Four rising humanoid robot startups demonstrated their products at the gala, a televised event and touchstone for China comparable to the Super Bowl for the United States.” 四家初创公司——宇树、Galbot、Noetix、MagicLab——合计赞助金额约1亿元人民币（1400万美元）。 南华早报：人形机器人进入主流SCMP以”Humanoids go mainstream“为标题，指出春晚正式将人形机器人从实验室带入了主流公众视野。 Bloomberg/BNN：机器人与儿童近距离舞刀弄枪Bloomberg的报道特别抓住了一个画面： “Over a dozen Unitree humanoids performed sophisticated fight sequences waving swords, poles and nunchucks in close proximity to human children performers.” 这个细节说明了什么？——机器人的运动控制精度已经达到了可以在危险武器+儿童场景下安全运行的水平。 TechEBlog：去年跳舞，今年武术大师TechEBlog的评价最为直白： “Unitree’s Robots Delivered a Martial Arts Masterclass on China’s Biggest Stage.” 报道详细描述了G1的表现：后空翻、蹦床起跳、高速方向切换、平衡恢复——“handled these insanely quick directional shifts and balancing recoveries like nothing”（轻松应对这些疯狂的快速方向切换和平衡恢复）。 环球时报：技术参数首次公开环球时报的报道透露了关键数据： 跳桌跑酷：H1完成桌面翻越 3米空中翻转：单腿连续后空翻 Airflare大回环：七圈半旋转 集群高速变阵：最高4米/秒任意位移速度（全球首次） 灵巧手：全新自研灵巧手，支持武术道具快速切换和稳定抓握 🇹🇼 台湾媒体：从惊叹到深层焦虑台湾媒体对宇树机器人的关注程度，在两岸科技报道中非常罕见。 中时新闻网：美专家紧盯春晚春晚前夕，台湾《中时新闻网》以”美專家緊盯2026春晚——陸AI+製造戰略核心：人形機器人“为标题发文： “去年16台宇树机器人的秧歌表演引发广泛讨论，数周后，该公司创始人更获安排与习近平会面，显示官方对机器人产业的高度重视。” 这个信号在台湾引发了对大陆科技战略的深度讨论。 联合报/经济日报：亿元竞标战台湾联合报系持续跟踪了春晚赞助竞标： 智元机器人开价6000万 宇树直接喊到1亿 最终四家公司共享春晚舞台 经济日报评论称：”这标志着春晚的科技叙事，正从展示酷炫技术，转向呈现中国前沿产业核心技术实力。” 联合报：宇树三度登台的完整弧线台媒梳理了宇树与春晚的三次合作： 2021牛年：机械牛”犇犇”初次亮相 2025蛇年：张艺谋执导《秧BOT》，现象级破圈 2026马年：《武BOT》，全球首次自主机器人集群武术 联合报：从爆红到”内卷”的商业故事台媒还完整记录了秧BOT之后的商业链条： 春晚后机器人一机难求，催生租赁热潮 日租金最高1.5万元 有商家出租十余次收入超20万元 但到2025年底，租赁价格暴跌九成 3000元即可租到机器人加机器狗一天 这是一个完美的中国式商业弧线：爆红→疯抢→量产→内卷→价格崩盘。 联合报：马斯克都点赞2025年12月，宇树G1在王力宏演唱会上做后空翻，马斯克在X上转发点赞。台媒标题： “馬斯克點讚！人形機器人登王力宏演唱會” 网友评论：”几个月前在春晚舞台上还像刚学走路的小孩，如今已经成为了专业的舞者。” 而这时候大家还不知道，几个月后的武BOT会更加疯狂。 🐦 X/Twitter评论精选震撼派CyberRobo (@cyberrobooo)： “🤯 Absolutely insane. Unitree’s humanoid robot team’s performance at the 2026 Spring Festival Gala. The significance lies in letting 1.4 billion Chinese people know where the future lies.“ RoboHub (@XRoboHub)： “Dozens of G1 robots pulled off the world’s first fully autonomous Kung Fu performance, showing off quick movements that push the limits of what these bots can do.” YM Shen 评论： “Tool usage and force feedback and human interaction, self-recovery after jump. Amazing!“ YouTube热评“Unitree Humanoid Robots Shock People at 2026 Spring Festival Gala with Martial Arts” 视频描述： “Absolutely insane scenes… Unitree’s humanoid robots stunned 1.4 billion viewers with a flawless Drunken Fist martial arts routine.” Reddit r/singularity“Unitree Martial arts robots dazzle at 2026 Spring Festival Gala” 帖子引发热议，用户评论： “China’s Unitree Robotics is developing humanoid robots that move with surprising speed and control.” 🤔 冷思考：春晚是舒适区？并非所有声音都是赞美。一篇深度分析文章（Geopolitechs）提出了尖锐观点： “春晚可能是具身智能的**完美’舒适区’**。舞台地面完全平整、高摩擦力、室内恒温恒湿、灯光预设、音乐毫秒级同步。预编程路线下，机器人不需要’思考’或适应——它们只需要执行预定轨迹。” “工厂、家庭、零售空间、车间、农田——这些场景都有复杂地形。户外还有光照、湿度、温度、风速等不可控变量。最关键的是，机器人必须像人类一样灵活应对不可预见的情况——技术上仍有很多差距需要弥合。“ 文章还提到特斯拉Optimus的信任危机：一段广泛传播的视频中，Optimus机器人突然做出了”摘VR头显”的动作，被质疑是远程操控。 但反过来说——武BOT中机器人与儿童近距离舞刀弄棍，这本身就是对安全性的极端考验。如果是远程操控，谁敢在直播中让机器人在儿童身边挥舞双截棍？ 💰 产业图景：春晚经济学 数据 来源 2026春晚机器人赞助总额约1亿元 SCMP/36氪 宇树估值120亿元 澎湃新闻 C轮投资方：中国移动、腾讯、阿里 多家媒体 2025全球人形机器人销售额4.4亿美元 IDC 宇树2025年11月完成IPO辅导 证券时报 4家机器人企业登上2026春晚 路透社 王兴兴的原话很实在： “表演、跑步、武术，这些背后的核心都是让机器人更稳定，从而去做对我们生活真正有帮助的事情。运动能力是智能机器人的先决必要条件——必须先能站稳、跑稳，才能谈得上去干活。“ “如果机器人能在复杂的队形变化和快速移动中完成武术表演，意味着未来它们在其他场景工作时，稳定性会更胜一筹。” 📖 回顾：秧BOT如何改写历史如果没有2025年的秧BOT，就不会有今天的武BOT。 2025年1月28日，张艺谋执导的《秧BOT》让16台H1机器人穿花棉袄、转手绢、扭秧歌，成为当年春晚最出圈的节目。 那次表演之后： X平台播放量破480万 宇树创始人被安排与习近平会面 机器人租赁行业爆发 估值从几十亿飙升至120亿 多家公司竞相IPO Euro Weekly News当时的嘲讽至今被引用： “马斯克的Optimus还在小心翼翼地走路，仿佛害怕绊倒。与此同时，中国的AI机器人已经在与人类同步跳舞了。” 一年后的今天，那些机器人不仅会跳舞了——它们会打醉拳、耍双截棍、做3米空翻、在高速奔跑中变阵。 进化速度本身，才是最让人震撼的。 参考来源：Reuters, South China Morning Post, Bloomberg/BNN, Global Times, TechEBlog, TechNode, Geopolitechs, 联合报, 经济日报, 中时新闻网, IT之家, 证券时报, 澎湃新闻, 新浪科技, 知乎, X/Twitter, Reddit r/singularity, YouTube","link":"/2026/02/17/foreign-reactions-spring-gala-robot-2025/"},{"title":"机器人打醉拳！从老外评价春晚《武BOT》学15个地道英语表达","text":"2026马年春晚，宇树科技的机器人从去年的扭秧歌升级到了打醉拳、耍双截棍、舞剑、跑酷！节目《武BOT》在海外社交媒体再次炸裂。今天我们从外国网友和英文媒体的真实评价中，学习15个超实用的地道英语表达。 1. Absolutely insane — 太疯了/太炸了 “🤯 Absolutely insane. Unitree’s humanoid robot team’s performance at the 2026 Spring Festival Gala.”— @CyberRobo on X 讲解： “insane” 本义是”疯狂的”，但在口语中常用来表示”太厉害了、太不可思议了”，是年轻人非常高频的表达。”absolutely” 加强语气。 例句： The graphics in this game are absolutely insane. 同义表达： crazy, mind-blowing, nuts, wild 2. delivered a masterclass — 上了一堂大师课 “Unitree’s Robots Delivered a Martial Arts Masterclass on China’s Biggest Stage.”— TechEBlog 讲解： “deliver a masterclass” 意思是展示了大师级水平的表现。”deliver” 在这里不是”送货”，而是”呈现、展示”。这个搭配在体育和艺术评论中特别常见。 例句： Messi delivered a masterclass in last night’s Champions League final. 3. stole the show — 抢尽风头 “Its H1 humanoid robot stole the show with a creative dance performance called ‘YangBOT’.”— Gasgoo（关于去年秧BOT的报道） 讲解： “steal the show” 意思是在活动中表现最出色、吸引了所有注意力。非常经典的习语，日常对话和写作都能用。 例句： The 5-year-old flower girl stole the show at the wedding. 4. push the limits — 突破极限 “Dozens of G1 robots pulled off the world’s first fully autonomous Kung Fu performance, showing off quick movements that push the limits of what these bots can do.”— @RoboHub on X 讲解： “push the limits” 是”挑战/突破极限”的意思。也可以说 “push the boundaries”。 近义： break new ground, push the envelope 例句： SpaceX keeps pushing the limits of rocket reusability. 5. pull off — 成功完成（困难的事） “Dozens of G1 robots pulled off the world’s first fully autonomous Kung Fu performance.”— @RoboHub on X 讲解： “pull off” 意思是成功做成某件困难或不太可能的事。非常口语化且实用。 例句： I can’t believe she pulled off organizing a 200-person event in just two weeks. 注意： pull off ≠ pull out（退出） 6. in close proximity to — 在……近距离范围内 “Over a dozen Unitree humanoids performed sophisticated fight sequences waving swords, poles and nunchucks in close proximity to human children performers.”— Bloomberg/BNN 讲解： “in close proximity to” 是”非常靠近”的正式说法，比 “near” 或 “close to” 更书面。新闻报道中常用。 例句： The explosion occurred in close proximity to a school. 7. comparable to — 可与……相比 “A televised event and touchstone for China comparable to the Super Bowl for the United States.”— Reuters（路透社） 讲解： “comparable to” 意为”可以与……相媲美/类比”。路透社直接把春晚比作美国的超级碗，这个比喻很到位。 拓展： “touchstone” 也是个好词，意思是”试金石、标准”。 例句： The annual 11.11 shopping festival is comparable to Black Friday in scale. 8. go mainstream — 进入主流 “Humanoids go mainstream as China’s robotics champions appear at CCTV spectacle.”— South China Morning Post（标题） 讲解： “go mainstream” 意思是从小众走向大众。SCMP 用这个做标题，精准概括了春晚让机器人走进普通人视野的意义。 例句： Plant-based meat has officially gone mainstream. 9. with surprising speed and control — 以惊人的速度和控制力 “China’s Unitree Robotics is developing humanoid robots that move with surprising speed and control.”— Reddit r/singularity 讲解： 这个表达简洁有力。”with + 名词” 结构在英语中非常常见，比用副词更优雅。 对比： ❌ “move surprisingly fast and with good control” → ✅ “move with surprising speed and control” 10. ditched A for B — 抛弃A，改做B “They’ve ditched the dancing for some serious martial arts!”— @RoboHub on X 讲解： “ditch” 原意是”丢弃”，口语中意思是”抛弃、甩掉”。”ditch A for B” 就是放弃A去做B。非常地道的表达。 例句： I ditched my old phone for the latest iPhone. 11. stood head and shoulders above the rest — 远超其他、鹤立鸡群 “It was Unitree’s contributions that really stood head and shoulders above the rest.”— TechEBlog 讲解： 字面意思是”头和肩膀都高出其他人”，引申为”远远超过竞争对手”。非常生动的习语！ 例句： Among all the candidates, her resume stood head and shoulders above the rest. 12. Drunken Fist — 醉拳 “Unitree’s humanoid robots stunned 1.4 billion viewers with a flawless Drunken Fist martial arts routine.”— YouTube 讲解： 醉拳的英文就是 “Drunken Fist” 或 “Drunken Boxing”。成龙的电影让这个词在英语世界广为人知。 相关词汇（附音标）： humanoid /ˈhjuːmənɔɪd/ — 人形的、类人机器人 nunchaku /nʌnˈtʃɑːkuː/ — 双截棍（也写作 nunchucks /ˈnʌntʃʌks/） choreograph /ˈkɒriəɡræf/ — 编舞、精心策划 parkour /pɑːˈkʊər/ — 跑酷 backflip /ˈbækflɪp/ — 后空翻 exorcism /ˈeksɔːsɪzəm/ — 驱魔（Reddit网友用来形容机器人站起来的样子） proximity /prɒkˈsɪmɪti/ — 接近、邻近 autonomous /ɔːˈtɒnəməs/ — 自主的、自动的 surge /sɜːdʒ/ — 激增、涌动 13. to the delight and awe of — 令……既欣喜又惊叹 “Unitree showed off the dancing skills of its H1 humanoid robots, to the delight and awe of more than 1 billion viewers.”— South China Morning Post 讲解： 这是一个优雅的介词短语结构。”to the delight of” 意为”令人高兴的是”，加上 “awe”（敬畏、惊叹）表达了双重情感。正式写作中非常好用。 万能句型： to the [情感词] of… to the surprise of everyone（令所有人惊讶） to the horror of parents（令家长恐惧） to the amusement of the audience（令观众觉得好笑） 14. a significant upgrade from — 相比……有显著升级 “Captivating audiences this year with a dynamic routine featuring parkour, Drunken Fist, and nunchaku — a significant upgrade from their stunning Yangko dance performance at the 2025 event.”— Global Times 讲解： “a significant upgrade from” 是描述产品迭代、技术进步时的万能表达。 例句： The iPhone 16 is a significant upgrade from last year’s model. 15. Does anyone else find… — 有没有人也觉得…… “Does anyone else find these robots a bit terrifying when they get knocked down and then rise up like some sort of exorcism over and over again?”— Reddit r/robotics（去年的经典评论） 讲解： Reddit上非常经典的句式，用来寻求共鸣。 “a bit terrifying” — 有点吓人（英式委婉说法） “like some sort of exorcism” — 像驱魔仪式一样（太形象了！） “over and over again” — 一次又一次 万能句式： Does anyone else find it weird/annoying/funny that…? 📝 实用表达总结表 英文表达 中文含义 使用场景 absolutely insane 太疯了/太厉害了 口语/社交媒体 deliver a masterclass 展示大师级水平 评论/新闻 steal the show 抢尽风头 日常/写作 push the limits 突破极限 科技/体育 pull off 成功完成难事 口语 in close proximity to 在近距离范围内 正式/新闻 comparable to 可与……相比 写作/报道 go mainstream 进入主流 科技/文化 ditch A for B 放弃A转做B 口语 head and shoulders above 远超其他 评价/比较 Drunken Fist /ˈdrʌŋkən fɪst/ 醉拳 武术/文化 to the delight/awe of 令人欣喜/惊叹 正式写作 a significant upgrade from 相比有显著升级 科技/产品 Does anyone else find… 有没有人也觉得…… 社交媒体 with surprising speed 以惊人的速度 新闻/描述 🎨 图解核心词汇 💡 学习建议🔥 追热点学英语春晚机器人、DeepSeek 这类中国科技热点，在英文社交媒体上的讨论量巨大。你熟悉背景知识，读起来毫无障碍，又能学到地道表达——这是最高效的英语学习方式。 ✍️ 今日练习用今天学到的表达写一段话，描述你看春晚《武BOT》的感受。试试用上 3-5 个新表达！ 📚 关注「英语大明白」，每天5分钟，用最新热点学最地道的英语表达！ Sources: South China Morning Post, Reuters, Bloomberg, TechEBlog, Global Times, TechNode, Gasgoo, Reddit, X/Twitter, YouTube","link":"/2026/02/17/english-learning-spring-gala-robot-reactions/"},{"title":"2026年02月17日早间要闻","text":"🌐 科技日报精选1. 研究发现：AI Agent 自生成技能几乎无用来源：Hacker News | ⬆️ 254 points论文链接 SkillsBench 基准测试研究发现，AI Agent 自己生成的”技能”在跨任务场景下表现极差。当前流行的让 Agent 自主学习和积累可复用技能的范式可能并不如想象中有效，这对 Agent 框架设计有重要启示。 2. OpenAI 绕过 Nvidia，在 Cerebras 晶圆级芯片上跑出超快编码模型来源：Ars Technica | 💬 105 comments原文链接 OpenAI 新发布的 GPT-5.3-Codex-Spark 编码速度比前代快 15 倍，运行在 Cerebras 的晶圆级芯片上，推理速度达到约 1000 tokens/s。在 AI 编码 Agent 竞争白热化的当下，延迟已成为关键差异化因素——模型越快，开发者迭代越快。 3. Ricursive Intelligence 4个月融资$3.35亿，估值$40亿来源：TechCrunch原文链接 两位联合创始人 Anna Goldie（CEO）和 Azalia Mirhoseini（CTO）曾在 Google Brain 共事，是 Anthropic 早期员工，因创建 Alpha Chip（AI 芯片布局设计工具）而闻名。Ricursive 做的不是造芯片，而是用 AI 设计芯片的工具——连 Nvidia 都是其投资方。Lightspeed 领投 $3 亿 A 轮，Sequoia 领投 $3500 万种子轮。 4. 你的蓝牙设备泄露了什么信息？来源：Hacker News | ⬆️ 310 points原文链接 开发者构建了 Bluehood 蓝牙扫描工具，揭示开启蓝牙时会泄露大量隐私信息，包括设备型号、用户行为模式等。结合最新披露的 WhisperPair 漏洞（CVE-2025-36911），数亿蓝牙音频设备可被远程劫持、窃听通话并追踪位置。 5. 攻击者发送 10 万次 prompt 试图克隆 Google Gemini来源：Ars Technica | 💬 52 comments原文链接 Google 披露有”商业动机”的攻击者通过大量多语言 prompt 进行”模型蒸馏”，试图窃取 Gemini 的知识来训练廉价复制品。Google 称之为知识产权盗窃，但颇具讽刺的是，Google 自己的 LLM 也是从互联网大量抓取未经授权的数据训练而成。 🐙 GitHub Trending 项目 语言 今日⭐ 简介 alibaba/zvec C++ 1,094 轻量极速进程内向量数据库 nautechsystems/nautilus_trader Rust 546 高性能算法交易平台与事件驱动回测引擎 rowboatlabs/rowboat TypeScript 700 开源 AI 协作助手，带记忆功能 steipete/gogcli Go 637 Google 全家桶 CLI（Gmail/日历/Drive/通讯录） openclaw/openclaw TypeScript 3,873 个人 AI 助手，跨平台 🦞 📈 美股行情（上周五收盘，2/17 总统日休市） 股票 代码 收盘价 涨跌幅 微软 MSFT $401.32 ↓0.13% 谷歌 GOOGL $305.72 ↓1.06% 英伟达 NVDA $182.81 ↓2.21% 超威半导体 AMD $207.32 ↑0.67% 阿里巴巴 BABA $155.73 ↓1.89% 今日为美国总统日（Presidents’ Day），美股休市一天。上述为上周五（2月14日）收盘数据。整体来看，大盘小幅走弱，英伟达跌幅较大，AMD 逆势上涨。","link":"/2026/02/17/2026-02-17-morning-news/"},{"title":"2026年02月18日早间要闻","text":"🌐 科技新闻精选1. Anthropic 发布 Claude Sonnet 4.6来源： Hacker News (⬆️ 900 points) | 原文链接 Anthropic 发布了 Claude Sonnet 4.6，这是其中端 AI 模型自 2025 年 9 月 Sonnet 4.5 以来的首次重大升级。新模型全面提升了编码、计算机使用、长上下文推理、Agent 规划、知识工作和设计等多项能力，并支持 1M token 上下文窗口（beta）。 定价与 Sonnet 4.5 保持一致（$3/$15 per million tokens），免费用户和 Pro 用户均可在 claude.ai 中默认使用。开发者反馈显示，Sonnet 4.6 在实际使用中甚至优于去年 11 月发布的旗舰模型 Opus 4.5，尤其在编码一致性和指令遵循方面有显著改进。 2. BarraCUDA：开源 CUDA 编译器，直接编译到 AMD GPU来源： Hacker News (⬆️ 179 points) | GitHub BarraCUDA 是一个用 15,000 行 C99 编写的开源 CUDA 编译器，可以将 .cu 文件直接编译为 AMD RDNA 3 (GFX11) 机器码，生成 ELF .hsaco 二进制文件。项目完全不依赖 LLVM，也不需要 HIP 转换层——从词法分析、语法解析、IR 生成到指令选择和寄存器分配，全部手写实现。 这是打破 NVIDIA CUDA 生态壁垒的一次有趣尝试，虽然目前仍处于早期阶段，但展示了从零构建 GPU 编译器的可行性。 3. OpenAI 绕过 Nvidia，在 Cerebras 晶圆级芯片上运行超快编码模型来源： Ars Technica | 原文链接 OpenAI 与 Cerebras 合作推出 GPT-5.3-Codex-Spark，编码速度比前代快 15 倍，运行在 Cerebras 餐盘大小的 Wafer Scale Engine 3 芯片上。该模型以约 1,000 tokens/秒的速度运行，标志着 OpenAI 开始在硬件层面减少对 Nvidia 的依赖。 AI 编码 Agent 在 2026 年迎来爆发，OpenAI、Google 和 Anthropic 都在竞相推出更强大的编码工具。延迟已成为关键竞争因素——更快的模型意味着开发者可以更快地迭代。 4. Apple 正在开发三款 AI 可穿戴设备来源： TechCrunch | 原文链接 据 Bloomberg 的 Mark Gurman 报道，Apple 正在加速开发三款 AI 驱动的可穿戴设备： AI 智能眼镜（代号 N50）：配备高分辨率摄像头，最早 12 月投产，2027 年上市 AI 挂件：AirTag 大小，可别在衬衫上，配备摄像头 带摄像头的 AirPods：通过视觉上下文让 Siri 执行现实世界操作 这些设备将直接与 Meta Ray-Ban 智能眼镜和 Snap 的 Specs 竞争。 5. 密码管理器的「零知识」承诺并不总是可靠来源： Ars Technica (66 comments) | 原文链接 研究发现，包括 Bitwarden、Dashlane 和 LastPass 在内的主流密码管理器宣称的「零知识加密」存在潜在漏洞。尽管这些厂商承诺「即使我们想看也无法读取你的数据」，但在服务器被攻破的情况下，攻击者可能有途径获取用户的密码库内容。 目前约有 9,400 万美国成年人使用密码管理器，这一发现对安全实践具有重要影响。 🐙 GitHub Trending 排名 项目 今日星标 简介 1 alibaba/zvec ⭐ 1,473 阿里开源的超轻量级进程内向量数据库，C++ 编写 2 p-e-w/heretic ⭐ 656 全自动移除语言模型审查限制的工具 3 obra/superpowers ⭐ 569 Agent 技能框架与软件开发方法论 4 hummingbot/hummingbot ⭐ 568 开源高频加密货币交易机器人 5 ashishps1/awesome-system-design-resources ⭐ 510 系统设计学习资源与面试准备 6 steipete/gogcli ⭐ 469 Google Suite CLI：Gmail/GCal/GDrive/GContacts 7 openclaw/openclaw ⭐ 4,201 个人 AI 助手框架，支持任何 OS 和平台 8 seerr-team/seerr ⭐ 282 开源媒体请求管理器，支持 Jellyfin/Plex/Emby 9 SynkraAI/aios-core ⭐ 194 AI 编排系统，用于全栈开发 10 steipete/summarize ⭐ 119 将任意 URL/YouTube/Podcast 快速摘要的 CLI 工具 📈 美股行情 ⚠️ 2026年2月17日（周一）为美国总统日（Presidents’ Day），美股休市。东方财富 API 今日暂时无响应，行情数据缺失。 🔗 更多新闻 [📰HN] Thousands of CEOs just admitted AI had no impact on employment or productivity — Fortune 报道数千名 CEO 承认 AI 对就业和生产力没有实际影响，引发 AI 生产力悖论讨论 [📰HN] Google Public CA is down — Google 公共证书颁发机构出现故障 [📰HN] Gentoo on Codeberg — Gentoo Linux 迁移到 Codeberg 平台 [📰HN] Using go fix to modernize Go code — Go 官方博客介绍 go fix 工具的现代化用法 [🦞Lobsters] Plasma 6.6 released — KDE Plasma 6.6 发布 [📡TC] Intellexa’s Predator spyware used to hack journalist’s iPhone — 间谍软件 Predator 被用于入侵安哥拉记者的 iPhone [🔧Dev.to] Build Multi-Agent Systems with ADK — Dev.to 推出多 Agent 系统教育课程","link":"/2026/02/18/2026-02-18-morning-news/"},{"title":"手把手教你装 OpenClaw：零基础也能拥有 AI 私人助手","text":"这篇写给谁？ 你可能连命令行都没打开过，Git 是什么都不太确定，但你听说了 OpenClaw 这个超火的 AI 助手项目，想试试。这篇教程就是为你准备的——每一步都有详细说明，每个命令都解释是干啥的，保证你能跟着做出来。 这玩意到底是啥？OpenClaw 是 2026 年 GitHub 上最火的开源项目之一（14 万多颗星星 ⭐），简单来说它就是一个 住在你电脑里的 AI 助手： 📱 可以接入飞书、微信，随时跟你聊天 💻 能帮你操作电脑——读写文件、搜索网页、管理日程 🧠 用国产大模型（通义千问、DeepSeek），不用花美金 🔒 数据全在你自己电脑上，没人偷看 听起来很厉害对吧？更厉害的是——你完全不需要会编程就能装好它。 跟着下面的步骤走就行。 开始之前：打开你的终端整个安装过程都要用到「终端」，也叫「命令行」。别怕，它就是一个输入文字命令的窗口，没有那么神秘。 Windows 用户：打开 PowerShell 按键盘上的 Win 键（就是那个 Windows 徽标的键） 输入 powershell 看到「Windows PowerShell」出现了，右键 点它 选择「以管理员身份运行」 弹出的窗口问你「是否允许此应用对设备进行更改」，点「是」 现在你面前就是一个蓝色（或黑色）的窗口，光标在闪烁——这就是终端了。 💡 小贴士： 后续所有写着「打开终端」的地方，都是指这个 PowerShell 窗口。建议把它固定到任务栏（右键→固定到任务栏），因为你会经常用到。 第一步：安装 Git（5 分钟）Git 是一个版本管理工具。虽然安装 OpenClaw 本身不一定用到 Git，但很多后续操作和技能会需要它，建议一步到位装好。 1.1 下载 Git打开浏览器，访问 Git 官网的下载页面： 👉 https://git-scm.com/downloads/win 页面上会有多个下载选项，找到 「64-bit Git for Windows Setup」，点击下载。 如果官网打开很慢，你可以用国内镜像下载：👉 https://registry.npmmirror.com/-/binary/git-for-windows/找最新版本的文件夹点进去，下载 Git-xxx-64-bit.exe 1.2 安装 Git 双击下载好的 .exe 文件 一路点 Next（下一步）就行——所有默认选项都没问题 最后点 Install，等进度条跑完 点 Finish 完成 就这么简单。整个过程就是疯狂点「下一步」。 1.3 验证安装成功关掉之前的 PowerShell 窗口，重新打开一个新的（这一步很重要，不然系统找不到刚装的 Git）。 在新的 PowerShell 窗口里输入： 1git --version 然后按回车。如果看到类似这样的输出： 1git version 2.47.1.windows.2 就说明安装成功了！版本号不用一模一样，只要有输出就行。 ❌ 如果提示 「git 不是内部或外部命令」：说明你没有重新打开 PowerShell。关掉当前窗口，按照上面的方法重新打开一个新的 PowerShell 就好。 第二步：安装 Node.js（3 分钟）OpenClaw 是用 Node.js 运行的，所以我们需要先装好它。你可以把 Node.js 理解为 OpenClaw 的「发动机」。 2.1 下载并安装 打开 Node.js 中文网 点击下载 LTS 版本（v22.x）——LTS 表示「长期支持版」，最稳定 下载的是一个 .msi 文件，双击运行 安装过程中全部点 Next（下一步），不需要改任何设置 最后点 Finish 完成 2.2 验证安装重新打开一个 PowerShell 窗口（还是那个道理，装了新东西要开新窗口），输入： 1node -v 按回车，应该显示类似 v22.13.1。再输入： 1npm -v 按回车，应该显示类似 10.9.2。 两个命令都有输出？太棒了，发动机装好了！🎉 第三步：配置国内镜像源（1 分钟，但超级重要！）这一步是国内用户必做的。npm（Node.js 的包管理器）默认从国外服务器下载东西，国内直连速度感人——可能等半小时然后告诉你超时了。 我们用淘宝团队做的国内镜像，速度飞快： 1npm install -g cnpm --registry=https://registry.npmmirror.com 这行命令是干啥的？ 它从淘宝的国内镜像服务器下载并安装了一个叫 cnpm 的工具。以后需要下载东西的时候，用 cnpm 代替 npm，速度就跟开了加速器一样。 验证一下： 1cnpm -v 看到版本号就行了。如果提示「cnpm 不是内部或外部命令」，重新打开 PowerShell 再试。 第四步：安装 OpenClaw（3 分钟）终于到主角了！在 PowerShell 中输入： 1cnpm install -g openclaw@latest 这行命令是干啥的？ cnpm：用国内镜像下载（上一步装的） install -g：全局安装，这样在任何地方都能使用 openclaw@latest：安装最新版的 OpenClaw 等它跑完（通常几十秒），看到 added xxx packages 之类的就成功了。 可能遇到的问题问题 1：报错提到 sharp sharp 是一个图片处理库，在 Windows 上偶尔会闹脾气。解决方法： 12$env:SHARP_IGNORE_GLOBAL_LIBVIPS=1cnpm install -g openclaw@latest 第一行设置了一个环境变量，告诉安装程序跳过某个可选依赖。然后重新安装就好了。 问题 2：安装成功但找不到 openclaw 命令 输入 openclaw --version 提示「不是内部或外部命令」？这是因为系统不知道 openclaw 装到哪了。 1npm prefix -g 这会输出一个路径（通常是 C:\\Users\\你的用户名\\AppData\\Roaming\\npm）。你需要把这个路径加到系统的 PATH 环境变量里： 按 Win 键，搜索「环境变量」 点击「编辑系统环境变量」 点击右下角「环境变量」按钮 在上面「用户变量」里找到 Path，双击它 点「新建」，把刚才的路径粘贴进去 一路确定关闭 重新打开 PowerShell 现在再试 openclaw --version，应该就能看到版本号了。 验证安装成功1openclaw --version 看到类似 2026.2.x 的版本号？恭喜你，OpenClaw 装好了！ 🎉 第五步：申请国产大模型 API Key（5 分钟）OpenClaw 需要一个 AI 大脑来思考。我们用阿里的通义千问（Qwen），免费额度超大方（每月 100 万 tokens），国内访问速度快，非常适合入门。 先搞清楚：通义千问的模型到底选哪个？通义千问有好几个模型版本，名字看着头大。别慌，你只需要知道这些： 模型名称 能力 价格 推荐程度 qwen-max 最强，什么都能干 免费额度 100 万 tokens/月 ⭐⭐⭐ 首选 qwen-plus 次强，性价比高 免费额度 100 万 tokens/月 ⭐⭐ 日常够用 qwen-turbo 最快，轻量任务 免费额度 100 万 tokens/月 ⭐ 简单任务 qwen-long 长文本专用 单独计价 特殊场景 💡 建议： 直接选 qwen-max。免费额度一样的，不用白不用。等你熟悉了再根据需要调整。 5.1 注册并获取 API Key 打开浏览器，访问 阿里云百炼平台 用支付宝扫码登录（对，就这么简单，不用单独注册） 登录后，你会看到控制台页面 在左边菜单找到「API Key 管理」，点进去 点击「创建 API Key」按钮 会生成一串以 sk- 开头的字符串——这就是你的 API Key 点「复制」，把它保存到一个安全的地方（比如记事本里） ⚠️ 重要： API Key 只会显示一次！如果忘了复制，就得重新创建一个。不过不用担心，重新建一个也就是点一下的事。 5.2 关于付费阿里云百炼的计费方式是按调用量（tokens）收费的。但是，每个模型每月都有免费额度，对于个人使用来说基本够用。 如果你担心费用： 登录百炼控制台，在「费用中心」→「资源包管理」可以看到剩余免费额度 免费额度用完后才会开始计费 即使计费，qwen-max 的价格也只有 0.02 元/千 tokens，聊天一整天也花不了几块钱 第六步：配置 OpenClaw（5 分钟）⚠️ 重要提醒：推荐直接编辑配置文件OpenClaw 提供了一个 openclaw onboard 向导来引导你完成配置。但根据很多用户的反馈，向导在选择国产模型时容易遇到坑： 向导可能走「Provider 网页授权」流程，但授权完后模型列表显示的是海外端点 选了模型之后可能没有地方让你输入 API Key 配置完了可能连不上，还得手动改配置文件 所以我们推荐一个更靠谱的方法：直接编辑配置文件。 听起来像「高级操作」，但其实就是复制粘贴一段文本，比向导还简单。 方法一：直接编辑配置文件（推荐 ⭐）第 1 步： 找到配置文件位置 在 PowerShell 中输入： 1notepad &quot;$env:USERPROFILE\\.openclaw\\openclaw.json&quot; 如果提示文件不存在，选「是」创建新文件。如果连 .openclaw 文件夹都不存在，先运行一次 openclaw init 创建它。 第 2 步： 把以下内容完整复制粘贴进去（替换掉文件里原有的所有内容）： 12345678910{ &quot;models&quot;: { &quot;default&quot;: &quot;qwen/qwen-max&quot;, &quot;providers&quot;: { &quot;qwen&quot;: { &quot;apiKey&quot;: &quot;sk-你的API-Key粘贴到这里&quot; } } }} 第 3 步： 把 sk-你的API-Key粘贴到这里 替换成你在第五步复制的真实 API Key。 第 4 步： 保存文件（Ctrl+S），关闭记事本。 搞定！配置就这么简单。 💡 为什么推荐这个方法？ 因为它绕过了 onboarding 向导可能出现的所有坑——不需要选 Provider、不需要网页授权、不会遇到海外端点列表。直接告诉 OpenClaw「用千问 max 模型 + 这个 API Key」，清清楚楚。 方法二：使用 onboard 向导如果你还是想试试向导（或者方法一遇到问题），在 PowerShell 中输入： 1openclaw onboard --install-daemon 向导会一步一步问你问题： 步骤 1 — 风险提示： 12⚠️ OpenClaw runs AI-generated code on your computer.Do you understand the risks? (yes/no) 👉 输入 yes 步骤 2 — 安装模式： 123Choose setup mode: 1) QuickStart (recommended) 2) Advanced 👉 输入 1 步骤 3 — 模型提供商： 12345Choose your AI model provider: 1) OpenAI 2) Anthropic 3) Qwen (通义千问) ... 👉 选 Qwen（输入对应数字） ⚠️ 关键提醒： 这里可能会出现两种路径： API Key 路径（推荐）：直接让你输入 API Key，照做即可 Provider 网页授权路径（有坑）：会打开浏览器让你授权。授权完之后，它可能会让你选模型——这时候列表里的模型可能是海外端点，选了也用不了 如果你走到了网页授权路径，建议直接 Ctrl+C 退出向导，改用方法一。 步骤 4 — 输入 API Key（如果出现）： 1Enter your Qwen API Key: 👉 粘贴你的 API Key（在 PowerShell 里鼠标右键就是粘贴，粘贴后看不到内容是正常的，直接按回车） 步骤 5 — 选择具体模型（如果出现）：如果让你选模型，找 qwen-max 选它。如果列表里都是 gpt-4、claude 之类的海外模型——说明走错路了，Ctrl+C 退出，用方法一。 步骤 6 — 安装 Daemon： 12Installing daemon service...✅ Daemon installed successfully 看到 ✅ 就成功了。 方法三：用 DeepSeek（备选方案）如果千问搞不定，可以试试 DeepSeek，配置方法完全一样： 去 platform.deepseek.com 注册，获取 API Key 配置文件改成： 1234567891011{ &quot;models&quot;: { &quot;default&quot;: &quot;deepseek/deepseek-chat&quot;, &quot;providers&quot;: { &quot;deepseek&quot;: { &quot;apiKey&quot;: &quot;sk-你的DeepSeek-API-Key&quot;, &quot;baseUrl&quot;: &quot;https://api.deepseek.com/v1&quot; } } }} 验证配置是否成功不管用哪种方法，最终验证一下： 12openclaw gateway startopenclaw status 如果看到 Gateway: running，说明配置成功，OpenClaw 已经连上了你的 AI 大脑！ 第七步：启动 OpenClaw！（1 分钟）万事俱备，启动你的 AI 助手： 1openclaw gateway start 这行命令是干啥的？ 它启动了 OpenClaw 的网关服务——你可以理解为「给你的 AI 助手按了开机键」。 检查状态1openclaw status 如果看到类似 Gateway: running 的提示，说明一切正常。 打开管理面板1openclaw dashboard 浏览器会自动打开 http://localhost:18789，这是你的 AI 管家的控制中心。 试试聊天在管理面板里就可以直接跟 AI 聊天了。试试发一条： 1你好，你是谁？ 如果收到回复——恭喜你，你做到了！ 🎉🎉🎉 你现在拥有了一个属于自己的、24 小时在线的 AI 私人助手！ 进阶：接入飞书（让 AI 助手住进你的聊天软件）装好了 OpenClaw，但它现在只能在浏览器里聊天。想让它变成你飞书里的 AI 秘书？跟着下面的步骤来。 这一步稍微复杂一点，但值得做。做完之后你就可以在飞书里随时跟 AI 助手聊天了。 7.1 创建飞书应用 打开 飞书开放平台，登录你的飞书账号 点击「创建企业自建应用」（个人也能建，放心） 填写应用名称（随便起，比如「我的 AI 助手」） 创建完成后，你会看到 App ID 和 App Secret——把它们复制保存好 7.2 配置权限在应用后台找到「权限管理」→「批量开通」，粘贴以下内容： 1234567891011{ &quot;scopes&quot;: { &quot;tenant&quot;: [ &quot;im:message&quot;, &quot;im:message:send_as_bot&quot;, &quot;im:message:readonly&quot;, &quot;im:resource&quot;, &quot;im:chat&quot;, &quot;im:chat.members:bot_access&quot;, &quot;im:message.group_msg&quot;, &quot;im:message.group_at_msg:readonly&quot;, &quot;im:message.p2p_msg:readonly&quot;, &quot;im:chat.access_event.bot_p2p_chat:read&quot;, &quot;contact:contact.base:readonly&quot; ] }} 7.3 配置事件订阅找到「事件订阅」页面： 请求地址填：https://你的服务器地址:18789/feishu/webhook 添加事件：im.message.receive_v1 7.4 编辑 OpenClaw 配置文件打开 C:\\Users\\你的用户名\\.openclaw\\openclaw.json，加入飞书配置： 1234567891011121314151617181920212223{ &quot;models&quot;: { &quot;default&quot;: &quot;qwen/qwen-max&quot;, &quot;providers&quot;: { &quot;qwen&quot;: { &quot;apiKey&quot;: &quot;sk-你的API Key&quot; } } }, &quot;channels&quot;: { &quot;feishu&quot;: { &quot;accounts&quot;: { &quot;default&quot;: { &quot;appId&quot;: &quot;cli_你的AppID&quot;, &quot;appSecret&quot;: &quot;你的AppSecret&quot;, &quot;encryptKey&quot;: &quot;你的加密Key&quot;, &quot;verificationToken&quot;: &quot;你的验证Token&quot;, &quot;enabled&quot;: true } } } }} 保存后重启 OpenClaw： 1openclaw gateway restart 在飞书里搜索你创建的机器人，发一条消息试试——如果收到回复，飞书接入就成功了！ 别让你的 AI 秘书睡着：防睡眠设置OpenClaw 需要一直运行。如果电脑进入睡眠，它就「下班」了。用管理员身份打开 PowerShell，输入这两行： 12powercfg /change standby-timeout-ac 0powercfg /change hibernate-timeout-ac 0 这两行命令是干啥的？ 告诉 Windows：接通电源的时候，永远不要进入睡眠或休眠。这样你的 AI 助手就能 24 小时在线了。 常见问题速查 问题 解决方法 命令提示「不是内部或外部命令」 关掉 PowerShell，重新打开一个新的 npm/cnpm 安装超时 确认已配置国内镜像（第三步） sharp 报错 运行 $env:SHARP_IGNORE_GLOBAL_LIBVIPS=1 后重装 Gateway 端口被占用 运行 netstat -aon | findstr 18789 找到占用进程，用 taskkill /PID 进程ID /F 结束它 模型回复很慢 确保用的是国内模型（Qwen/DeepSeek），不要走国际线路 电脑重启后 OpenClaw 没启动 运行 openclaw onboard --install-daemon 设置开机自启 总结恭喜你读到这里！让我们回顾一下你都做了什么： 步骤 做了什么 花了多久 1 安装 Git 5 分钟 2 安装 Node.js 3 分钟 3 配置国内镜像 1 分钟 4 安装 OpenClaw 3 分钟 5 申请 API Key 5 分钟 6 配置 OpenClaw 5 分钟 7 启动！ 1 分钟 总共不到 30 分钟，你就拥有了一个 24 小时在线的 AI 私人助手。它跑在你自己的电脑上，用国产大模型，不花一分美金，数据完全属于你。 这才刚刚开始——接下来你可以探索 OpenClaw 的各种技能：让它帮你写代码、管理文件、搜索信息、甚至操作浏览器…… 欢迎来到 AI Agent 时代，朋友。🦞 本文基于 OpenClaw 2026.2.x 版本编写。官方文档：docs.openclaw.ai | GitHub：github.com/openclaw/openclaw","link":"/2026/02/18/openclaw-beginner-guide/"}],"tags":[{"name":"早报","slug":"早报","link":"/tags/%E6%97%A9%E6%8A%A5/"},{"name":"新闻","slug":"新闻","link":"/tags/%E6%96%B0%E9%97%BB/"},{"name":"AI","slug":"AI","link":"/tags/AI/"},{"name":"科技","slug":"科技","link":"/tags/%E7%A7%91%E6%8A%80/"},{"name":"美股","slug":"美股","link":"/tags/%E7%BE%8E%E8%82%A1/"},{"name":"微软","slug":"微软","link":"/tags/%E5%BE%AE%E8%BD%AF/"},{"name":"强化学习","slug":"强化学习","link":"/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"},{"name":"Agent","slug":"Agent","link":"/tags/Agent/"},{"name":"开源","slug":"开源","link":"/tags/%E5%BC%80%E6%BA%90/"},{"name":"商业","slug":"商业","link":"/tags/%E5%95%86%E4%B8%9A/"},{"name":"创新","slug":"创新","link":"/tags/%E5%88%9B%E6%96%B0/"},{"name":"谷歌","slug":"谷歌","link":"/tags/%E8%B0%B7%E6%AD%8C/"},{"name":"人工智能","slug":"人工智能","link":"/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"技术趋势","slug":"技术趋势","link":"/tags/%E6%8A%80%E6%9C%AF%E8%B6%8B%E5%8A%BF/"},{"name":"AOP","slug":"AOP","link":"/tags/AOP/"},{"name":"面向切面","slug":"面向切面","link":"/tags/%E9%9D%A2%E5%90%91%E5%88%87%E9%9D%A2/"},{"name":"Android","slug":"Android","link":"/tags/Android/"},{"name":"Claude","slug":"Claude","link":"/tags/Claude/"},{"name":"GPT","slug":"GPT","link":"/tags/GPT/"},{"name":"编程","slug":"编程","link":"/tags/%E7%BC%96%E7%A8%8B/"},{"name":"对比评测","slug":"对比评测","link":"/tags/%E5%AF%B9%E6%AF%94%E8%AF%84%E6%B5%8B/"},{"name":"OpenAI","slug":"OpenAI","link":"/tags/OpenAI/"},{"name":"Codex","slug":"Codex","link":"/tags/Codex/"},{"name":"编程工具","slug":"编程工具","link":"/tags/%E7%BC%96%E7%A8%8B%E5%B7%A5%E5%85%B7/"},{"name":"macOS","slug":"macOS","link":"/tags/macOS/"},{"name":"Gradle","slug":"Gradle","link":"/tags/Gradle/"},{"name":"Debug","slug":"Debug","link":"/tags/Debug/"},{"name":"GitHub","slug":"GitHub","link":"/tags/GitHub/"},{"name":"Copilot","slug":"Copilot","link":"/tags/Copilot/"},{"name":"Code design","slug":"Code-design","link":"/tags/Code-design/"},{"name":"Design Patterns","slug":"Design-Patterns","link":"/tags/Design-Patterns/"},{"name":"GoF","slug":"GoF","link":"/tags/GoF/"},{"name":"15分钟","slug":"15分钟","link":"/tags/15%E5%88%86%E9%92%9F/"},{"name":"Reading","slug":"Reading","link":"/tags/Reading/"},{"name":"读书","slug":"读书","link":"/tags/%E8%AF%BB%E4%B9%A6/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"夏令时","slug":"夏令时","link":"/tags/%E5%A4%8F%E4%BB%A4%E6%97%B6/"},{"name":"历史","slug":"历史","link":"/tags/%E5%8E%86%E5%8F%B2/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"bytecode","slug":"bytecode","link":"/tags/bytecode/"},{"name":"马斯克","slug":"马斯克","link":"/tags/%E9%A9%AC%E6%96%AF%E5%85%8B/"},{"name":"SpaceX","slug":"SpaceX","link":"/tags/SpaceX/"},{"name":"太空计算","slug":"太空计算","link":"/tags/%E5%A4%AA%E7%A9%BA%E8%AE%A1%E7%AE%97/"},{"name":"中国制造","slug":"中国制造","link":"/tags/%E4%B8%AD%E5%9B%BD%E5%88%B6%E9%80%A0/"},{"name":"Optimus","slug":"Optimus","link":"/tags/Optimus/"},{"name":"字节码","slug":"字节码","link":"/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"},{"name":"OpenClaw","slug":"OpenClaw","link":"/tags/OpenClaw/"},{"name":"教程","slug":"教程","link":"/tags/%E6%95%99%E7%A8%8B/"},{"name":"本地部署","slug":"本地部署","link":"/tags/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/"},{"name":"Windows","slug":"Windows","link":"/tags/Windows/"},{"name":"飞书","slug":"飞书","link":"/tags/%E9%A3%9E%E4%B9%A6/"},{"name":"UML","slug":"UML","link":"/tags/UML/"},{"name":"开发工具","slug":"开发工具","link":"/tags/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"AI Agent","slug":"AI-Agent","link":"/tags/AI-Agent/"},{"name":"记忆系统","slug":"记忆系统","link":"/tags/%E8%AE%B0%E5%BF%86%E7%B3%BB%E7%BB%9F/"},{"name":"视频生成","slug":"视频生成","link":"/tags/%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90/"},{"name":"字节跳动","slug":"字节跳动","link":"/tags/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8/"},{"name":"Seedance","slug":"Seedance","link":"/tags/Seedance/"},{"name":"国内","slug":"国内","link":"/tags/%E5%9B%BD%E5%86%85/"},{"name":"Cursor","slug":"Cursor","link":"/tags/Cursor/"},{"name":"Lovart","slug":"Lovart","link":"/tags/Lovart/"},{"name":"Industry Thoughts","slug":"Industry-Thoughts","link":"/tags/Industry-Thoughts/"},{"name":"2026","slug":"2026","link":"/tags/2026/"},{"name":"Science","slug":"Science","link":"/tags/Science/"},{"name":"2026 Trends","slug":"2026-Trends","link":"/tags/2026-Trends/"},{"name":"Technology","slug":"Technology","link":"/tags/Technology/"},{"name":"Trending","slug":"Trending","link":"/tags/Trending/"},{"name":"安全","slug":"安全","link":"/tags/%E5%AE%89%E5%85%A8/"},{"name":"DevOps","slug":"DevOps","link":"/tags/DevOps/"},{"name":"技术日报","slug":"技术日报","link":"/tags/%E6%8A%80%E6%9C%AF%E6%97%A5%E6%8A%A5/"},{"name":"测试自动化","slug":"测试自动化","link":"/tags/%E6%B5%8B%E8%AF%95%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"多模态大模型","slug":"多模态大模型","link":"/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/"},{"name":"GUI Agent","slug":"GUI-Agent","link":"/tags/GUI-Agent/"},{"name":"科技热榜","slug":"科技热榜","link":"/tags/%E7%A7%91%E6%8A%80%E7%83%AD%E6%A6%9C/"},{"name":"Hacker News","slug":"Hacker-News","link":"/tags/Hacker-News/"},{"name":"GLM-5","slug":"GLM-5","link":"/tags/GLM-5/"},{"name":"智谱","slug":"智谱","link":"/tags/%E6%99%BA%E8%B0%B1/"},{"name":"Agentic Engineering","slug":"Agentic-Engineering","link":"/tags/Agentic-Engineering/"},{"name":"大模型","slug":"大模型","link":"/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"},{"name":"React","slug":"React","link":"/tags/React/"},{"name":"MCP","slug":"MCP","link":"/tags/MCP/"},{"name":"LLM","slug":"LLM","link":"/tags/LLM/"},{"name":"深度研究","slug":"深度研究","link":"/tags/%E6%B7%B1%E5%BA%A6%E7%A0%94%E7%A9%B6/"},{"name":"代码分析","slug":"代码分析","link":"/tags/%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"AST","slug":"AST","link":"/tags/AST/"},{"name":"LSP","slug":"LSP","link":"/tags/LSP/"},{"name":"代码可视化","slug":"代码可视化","link":"/tags/%E4%BB%A3%E7%A0%81%E5%8F%AF%E8%A7%86%E5%8C%96/"},{"name":"程序理解","slug":"程序理解","link":"/tags/%E7%A8%8B%E5%BA%8F%E7%90%86%E8%A7%A3/"},{"name":"科技展望","slug":"科技展望","link":"/tags/%E7%A7%91%E6%8A%80%E5%B1%95%E6%9C%9B/"},{"name":"新春","slug":"新春","link":"/tags/%E6%96%B0%E6%98%A5/"},{"name":"DeepSeek","slug":"DeepSeek","link":"/tags/DeepSeek/"},{"name":"深度分析","slug":"深度分析","link":"/tags/%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90/"},{"name":"科技趋势","slug":"科技趋势","link":"/tags/%E7%A7%91%E6%8A%80%E8%B6%8B%E5%8A%BF/"},{"name":"前端","slug":"前端","link":"/tags/%E5%89%8D%E7%AB%AF/"},{"name":"提示词","slug":"提示词","link":"/tags/%E6%8F%90%E7%A4%BA%E8%AF%8D/"},{"name":"UI设计","slug":"UI设计","link":"/tags/UI%E8%AE%BE%E8%AE%A1/"},{"name":"Prompt Engineering","slug":"Prompt-Engineering","link":"/tags/Prompt-Engineering/"},{"name":"ZeroClaw","slug":"ZeroClaw","link":"/tags/ZeroClaw/"},{"name":"Rust","slug":"Rust","link":"/tags/Rust/"},{"name":"机器人","slug":"机器人","link":"/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/"},{"name":"Unitree","slug":"Unitree","link":"/tags/Unitree/"},{"name":"宇树科技","slug":"宇树科技","link":"/tags/%E5%AE%87%E6%A0%91%E7%A7%91%E6%8A%80/"},{"name":"春晚","slug":"春晚","link":"/tags/%E6%98%A5%E6%99%9A/"},{"name":"人形机器人","slug":"人形机器人","link":"/tags/%E4%BA%BA%E5%BD%A2%E6%9C%BA%E5%99%A8%E4%BA%BA/"},{"name":"English-Learning","slug":"English-Learning","link":"/tags/English-Learning/"},{"name":"英语学习","slug":"英语学习","link":"/tags/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/"},{"name":"Spring-Festival-Gala","slug":"Spring-Festival-Gala","link":"/tags/Spring-Festival-Gala/"},{"name":"Robotics","slug":"Robotics","link":"/tags/Robotics/"},{"name":"秧BOT","slug":"秧BOT","link":"/tags/%E7%A7%A7BOT/"},{"name":"武BOT","slug":"武BOT","link":"/tags/%E6%AD%A6BOT/"},{"name":"小白","slug":"小白","link":"/tags/%E5%B0%8F%E7%99%BD/"}],"categories":[{"name":"科技资讯","slug":"科技资讯","link":"/categories/%E7%A7%91%E6%8A%80%E8%B5%84%E8%AE%AF/"},{"name":"深度分析","slug":"深度分析","link":"/categories/%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90/"},{"name":"技术","slug":"技术","link":"/categories/%E6%8A%80%E6%9C%AF/"},{"name":"打码要义","slug":"打码要义","link":"/categories/%E6%89%93%E7%A0%81%E8%A6%81%E4%B9%89/"},{"name":"AI","slug":"AI","link":"/categories/AI/"},{"name":"实战","slug":"实战","link":"/categories/%E5%AE%9E%E6%88%98/"},{"name":"刨码问底","slug":"刨码问底","link":"/categories/%E5%88%A8%E7%A0%81%E9%97%AE%E5%BA%95/"},{"name":"深度报道","slug":"深度报道","link":"/categories/%E6%B7%B1%E5%BA%A6%E6%8A%A5%E9%81%93/"},{"name":"技术教程","slug":"技术教程","link":"/categories/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/"},{"name":"技术调研","slug":"技术调研","link":"/categories/%E6%8A%80%E6%9C%AF%E8%B0%83%E7%A0%94/"},{"name":"科技速递","slug":"科技速递","link":"/categories/%E7%A7%91%E6%8A%80%E9%80%9F%E9%80%92/"},{"name":"AI 技术深度","slug":"AI-技术深度","link":"/categories/AI-%E6%8A%80%E6%9C%AF%E6%B7%B1%E5%BA%A6/"},{"name":"技术深度","slug":"技术深度","link":"/categories/%E6%8A%80%E6%9C%AF%E6%B7%B1%E5%BA%A6/"},{"name":"技术分析","slug":"技术分析","link":"/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90/"},{"name":"科技","slug":"科技","link":"/categories/%E7%A7%91%E6%8A%80/"},{"name":"英语学习","slug":"英语学习","link":"/categories/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/"},{"name":"AI与机器人","slug":"科技/AI与机器人","link":"/categories/%E7%A7%91%E6%8A%80/AI%E4%B8%8E%E6%9C%BA%E5%99%A8%E4%BA%BA/"}],"pages":[{"title":"关于我","text":"大家好，我是内森(GitHub: Nathan Bu)，欢迎来到我的水水水文输出阵地。我2013年毕业于南开大学，目前在微软中国担任研发经理。希望在这个空间和大家分享交流技术心得，职业生涯，团队和项目管理，趋势动态，生活日常。旨在畅谈分享，不拘小节；但也不排除会刨根问底、钻牛角尖。 本人热爱技术和打码，尤其享受用技术解决实际问题的过程；相信创造力是顶级能力，是人价值的放大器。此外，本人专注于软件和代码质量、工程效率和研发能效方面多年，目前在微软和团队一起推动2023年新开源的项目Hydra Lab的完善与发展；欢迎和我在开源世界组队打码，造新轮子，添砖加瓦。 其他爱好有打篮球，翻书，叨逼叨。 自称是个全栈，涉猎的技术：Java, Python, Android, React, Node.JS, Gradle, Docker, C/C++, Spring。 搞过的技术领域： 移动互联网广告、强化学习、工程系统、自动化测试、DevOps、Azure。 能够胡吹的话题： 自动化测试、研发能效、产品质量控制、大型项目管理、人工智能、广告变现、团队管理、高效沟通、企业财务、国民经济。","link":"/about/index.html"},{"title":"","text":"1234567891011121314151617181920212223@startuml strategyclass SolutionContext { IStrategy strategy void solveProblem()}interface IStrategy { int compute()}class StrategyA { int compute()}class StrategyB { int compute()}class StrategyC { int compute()}SolutionContext o--&gt; IStrategyIStrategy &lt;|-- StrategyAIStrategy &lt;|-- StrategyBIStrategy &lt;|-- StrategyC@enduml 1234567891011121314151617181920212223@startuml stateclass TCPConnectionContext { TCPState state void request()}interface TCPState { handle()}class TCPEstablished { handle()}class TCPListen { handle()}class TCPClosed { handle()}TCPConnectionContext o--&gt; TCPStateTCPState &lt;|-- TCPEstablishedTCPState &lt;|-- TCPListenTCPState &lt;|-- TCPClosed@enduml 123456789101112131415161718192021222324252627282930313233343536373839@startuml abstract-factoryclass Clientabstract class AbstractFactory { createProductA() createProductB()}class Factory1 { createProductA() createProductB()}class Factory2 { createProductA() createProductB()}abstract class AbstractProductAabstract class AbstractProductBclass ProductA1class ProductB1class ProductA2class ProductB2ProductA1 -u-|&gt; AbstractProductAProductA2 -u-|&gt; AbstractProductAProductB1 -u-|&gt; AbstractProductBProductB2 -u-|&gt; AbstractProductBFactory1 -u-|&gt; AbstractFactoryFactory2 -u-|&gt; AbstractFactoryFactory1 ...&gt; ProductA1Factory1 ...&gt; ProductB1Factory2 ...&gt; ProductA2Factory2 ...&gt; ProductB2Client --&gt; AbstractProductA : createsClient --&gt; AbstractProductB : createsClient --&gt; AbstractFactory : holds@enduml :memento12345678910111213141516171819@startuml mementoclass Originator{ State state setMemento(Memento m) createMemento()}class Memento { State state}class Caretaker { Memento memento}Originator ..&gt; MementoCaretaker o--&gt; Memento@enduml :observer1234567891011121314151617181920212223242526@startuml observerclass Observer { update()}class ConcreteObserver { observerState update()}class Subject { attach(Observer) detach(Observer) notify()}class ConcreteSubject { subjectState getState() setState()}ConcreteObserver --|&gt; ObserverConcreteSubject --|&gt; SubjectSubject o-- ObserverConcreteSubject --o ConcreteObserver@enduml : adapter123456789101112131415161718@startuml adapterclass Contextclass Target { request()}class Adapter { request()}class Adaptee { specificRequest()}Context --&gt; TargetAdapter --|&gt; TargetAdapter --&gt; Adaptee@enduml : bridge123456789101112@startuml bridgePhone o-- PhoneFunctioniPhone --|&gt; PhoneAndroidPhone --|&gt; PhoneNonsmartPhone --|&gt; PhoneCall --|&gt; PhoneFunctionInstallApp --|&gt; PhoneFunction@enduml : command123456789@startuml commandClient ..&gt; InvokerClient ..&gt; ReceiverInvoker o-- CommandConcreteCommand --|&gt; CommandConcreteCommand *-- Receiver@enduml : chain-of-responsibility1234567891011121314151617@startuml chain-of-responsibilitytogether { class Client class Handler}together { class ConcreteHandler1 class ConcreteHandler2}Client --&gt; HandlerConcreteHandler1 --|&gt; HandlerConcreteHandler2 --|&gt; HandlerConcreteHandler2 o--&gt; Handler@enduml : mediator1234567891011@startuml mediatorMediator &lt;--o ColleagueConcreteColleague1 --|&gt; ColleagueConcreteColleague2 --|&gt; ColleagueConcreteMediator --|&gt; MediatorConcreteMediator --&gt; ConcreteColleague1ConcreteMediator --&gt; ConcreteColleague2@enduml : visitor1234567891011121314151617@startuml visitorclass Visitor { +visitElementA(ElementA elementA) +visitElementB(ElementB elementB)}note top of Visitor : Visitor design enables us to redefine the action/operation on a object without a change to its values.class Element { + accept(Visitor visitor)}ElementA --|&gt; ElementElementB --|&gt; Element@enduml : facade12345678910@startuml facadeClient --&gt; Facadepackage SubSystem{ Facade --&gt; SubSystemA Facade --&gt; SubSystemB Facade --&gt; SubSystemC Facade --&gt; SubSystemD}@enduml : proxy123456789101112@startuml proxyclass Subject { request()}Proxy --|&gt; SubjectRealSubject --|&gt; SubjectProxy --&gt; RealSubject@enduml : decorator123456789101112131415161718192021@startuml decoratorclass Subject { operate()}Decorator --|&gt; SubjectRealSubject --|&gt; SubjectDecorator o--&gt; SubjectConcreteDecoratorA --|&gt; DecoratorConcreteDecoratorB --|&gt; Decoratorclass ConcreteDecoratorA { -addedState}class ConcreteDecoratorA { -addedBehavior}@enduml : interpreter12345678910111213@startuml interpreterabstract Expression { +interpret(Context context)}Client --&gt; ContextClient --&gt; ExpressionTerminalExpression --|&gt; ExpressionNonterminalExpression --|&gt; ExpressionNonterminalExpression o--&gt; Expression@enduml","link":"/images/UML/design-patterns.html"}]}