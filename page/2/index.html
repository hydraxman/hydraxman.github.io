<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>内森淼文</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="内森淼文"><meta name="msapplication-TileImage" content="/images/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="内森淼文"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="内森的个人水水水文输出阵地，涵盖技术、日常思考"><meta property="og:type" content="blog"><meta property="og:title" content="内森淼文"><meta property="og:url" content="https://hydraxman.github.io/"><meta property="og:site_name" content="内森淼文"><meta property="og:description" content="内森的个人水水水文输出阵地，涵盖技术、日常思考"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://hydraxman.github.io/img/og_image.png"><meta property="article:author" content="Nathan"><meta property="article:tag" content="计算机技术, 生活中的胡思乱想"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://hydraxman.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hydraxman.github.io"},"headline":"内森淼文","image":["https://hydraxman.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Nathan"},"publisher":{"@type":"Organization","name":"内森淼文","logo":{"@type":"ImageObject","url":"https://hydraxman.github.io/images/logo.svg"}},"description":"内森的个人水水水文输出阵地，涵盖技术、日常思考"}</script><link rel="icon" href="/images/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/logo.svg" alt="内森淼文" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="My GitHub Index" href="https://github.com/hydraxman"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2026-02-14T11:00:00.000Z" title="2/14/2026, 7:00:00 PM">2026-02-14</time>发表</span><span class="level-item"><time dateTime="2026-02-14T18:22:51.680Z" title="2/15/2026, 2:22:51 AM">2026-02-15</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E7%A7%91%E6%8A%80%E9%80%9F%E9%80%92/">科技速递</a></span><span class="level-item">20 分钟读完 (大约3010个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/02/14/tech-outlook-2026-year-of-horse/">马年春节，中国AI军团集体亮剑——2026科技展望</a></h1><div class="content"><p><img src="/images/horse_newyear_cover_wide.png" alt="马年新春大吉 — Tech Home 2026"></p>
<blockquote>
<p>🐴 马年大吉，万事如意！当鞭炮声响彻大街小巷，中国AI公司也在用自己的方式「放烟花」——字节跳动三箭齐发，DeepSeek 百万 token 窗口刷新纪录。这个春节，科技圈比春晚还热闹。</p>
</blockquote></div><a class="article-more button is-small is-size-7" href="/2026/02/14/tech-outlook-2026-year-of-horse/#more">阅读更多</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2026-02-14T10:30:00.000Z" title="2/14/2026, 6:30:00 PM">2026-02-14</time>发表</span><span class="level-item"><time dateTime="2026-02-14T10:46:21.758Z" title="2/14/2026, 6:46:21 PM">2026-02-14</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%8A%80%E6%9C%AF%E6%B7%B1%E5%BA%A6/">技术深度</a></span><span class="level-item">39 分钟读完 (大约5923个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/02/14/large-scale-codebase-analysis-2026/">大规模代码库分析与理解：从AST到AI Agent的技术全景</a></h1><div class="content"><blockquote>
<p>当你面对一个百万行级别的代码库，从何下手？本文系统梳理从抽象语法树到AI Agent的代码理解技术栈，覆盖学术前沿与工程实践。</p>
</blockquote></div><a class="article-more button is-small is-size-7" href="/2026/02/14/large-scale-codebase-analysis-2026/#more">阅读更多</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2026-02-13T13:30:00.000Z" title="2/13/2026, 9:30:00 PM">2026-02-13</time>发表</span><span class="level-item"><time dateTime="2026-02-14T00:22:28.769Z" title="2/14/2026, 8:22:28 AM">2026-02-14</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/AI-%E6%8A%80%E6%9C%AF%E6%B7%B1%E5%BA%A6/">AI 技术深度</a></span><span class="level-item">1 小时读完 (大约9144个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/02/13/agent-loop-and-agent-rl-algorithms-2026/">Agent Loop 与 Agent RL：驱动 AI Agent 完成长任务的算法全景</a></h1><div class="content"><h2 id="引言：从聊天机器人到自主智能体"><a href="#引言：从聊天机器人到自主智能体" class="headerlink" title="引言：从聊天机器人到自主智能体"></a>引言：从聊天机器人到自主智能体</h2><p>2025-2026 年，AI Agent 迎来了从「对话助手」到「自主执行者」的质变。过去，构建一个 AI Agent 的方法极其简单——拿一个大语言模型（LLM），套一个 while 循环，给它接上工具 API，就能完成简单任务。但当任务变得复杂（比如深度研究、代码重构、多步决策），这种朴素架构就会崩溃。</p>
<p>Agent 领域正在经历一场深刻的范式转移：<strong>从基于提示工程的静态 Agent，走向基于强化学习的自适应 Agent</strong>。本文将系统梳理驱动 Agent 完成长任务的各类算法与架构，从经典的 Agent Loop 到前沿的 Agentic RL。</p>
<hr>
<h2 id="一、Agent-Loop：基础循环架构"><a href="#一、Agent-Loop：基础循环架构" class="headerlink" title="一、Agent Loop：基础循环架构"></a>一、Agent Loop：基础循环架构</h2><h3 id="1-1-最简-Agent-循环"><a href="#1-1-最简-Agent-循环" class="headerlink" title="1.1 最简 Agent 循环"></a>1.1 最简 Agent 循环</h3><p>最基础的 Agent 架构可以抽象为一个循环：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">while not done:</span><br><span class="line">    thought = LLM.think(context)</span><br><span class="line">    action = LLM.decide(thought)</span><br><span class="line">    observation = environment.execute(action)</span><br><span class="line">    context.append(observation)</span><br></pre></td></tr></table></figure>

<p>这就是所谓的 <strong>Agent 1.0 架构</strong>。LLM 充当「大脑」，在循环中反复执行「思考→行动→观察」直到任务完成或达到终止条件。</p>
<h3 id="1-2-ReAct：推理与行动的交错"><a href="#1-2-ReAct：推理与行动的交错" class="headerlink" title="1.2 ReAct：推理与行动的交错"></a>1.2 ReAct：推理与行动的交错</h3><p><strong>ReAct（Reasoning and Acting）</strong> 是最经典的 Agent Loop 框架，由 Yao 等人于 2022 年提出。其核心思想是让 LLM 交替生成推理步骤和执行动作：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">循环流程：</span><br><span class="line">Thought → Action → Observation → Thought → Action → Observation → ... → Final Answer</span><br></pre></td></tr></table></figure>

<p><strong>关键设计：</strong></p>
<ul>
<li><strong>Thought（思考）</strong>：LLM 内部推理，分析当前状态，制定下一步计划</li>
<li><strong>Action（行动）</strong>：调用外部工具（搜索、计算、API 等）</li>
<li><strong>Observation（观察）</strong>：接收工具返回结果，更新上下文</li>
</ul>
<p>ReAct 的优势在于推理过程透明可追踪，但在长任务中会遇到严重问题：上下文窗口被大量历史信息污染，导致模型「迷失方向」。</p>
<p><img src="/images/agent-loop-react.png" alt="Agent Loop ReAct 架构"><br><em>图：ReAct 的核心循环——Thought（推理）→ Action（行动）→ Observation（观察）交替执行，直到任务完成。</em></p>
<h3 id="1-3-Plan-and-Execute：先规划后执行"><a href="#1-3-Plan-and-Execute：先规划后执行" class="headerlink" title="1.3 Plan-and-Execute：先规划后执行"></a>1.3 Plan-and-Execute：先规划后执行</h3><p>为解决 ReAct 在长任务中的漂移问题，<strong>Plan-and-Execute</strong> 架构将任务分为两个阶段：</p>
<ol>
<li><strong>规划阶段（Planner）</strong>：LLM 分析任务，生成分步计划</li>
<li><strong>执行阶段（Executor）</strong>：按计划逐步执行，每步可调用工具</li>
<li><strong>重规划（Re-Planner）</strong>：根据执行结果动态调整剩余计划</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Plan: [Step1, Step2, Step3, Step4]</span><br><span class="line">Execute Step1 → Result1</span><br><span class="line">Re-Plan: [Step2&#x27;, Step3, Step4]  // 根据 Result1 调整</span><br><span class="line">Execute Step2&#x27; → Result2</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>这种架构的优势是目标感更强，不容易在长链推理中丧失方向。</p>
<h3 id="1-4-ReWOO：推理与观察解耦"><a href="#1-4-ReWOO：推理与观察解耦" class="headerlink" title="1.4 ReWOO：推理与观察解耦"></a>1.4 ReWOO：推理与观察解耦</h3><p><strong>ReWOO（Reasoning Without Observation）</strong> 进一步优化了 Plan-and-Execute 模式：</p>
<ul>
<li>先一次性生成完整的推理计划和所有工具调用</li>
<li>并行执行所有工具调用</li>
<li>最后综合所有结果生成答案</li>
</ul>
<p>优势是减少 LLM 调用次数，提升效率；但牺牲了动态调整能力。</p>
<hr>
<h2 id="二、高级推理框架：从线性到树状再到自我进化"><a href="#二、高级推理框架：从线性到树状再到自我进化" class="headerlink" title="二、高级推理框架：从线性到树状再到自我进化"></a>二、高级推理框架：从线性到树状再到自我进化</h2><p>上一节的 Agent Loop 架构解决了”如何让 LLM 与外部世界交互”的问题，但它们都面临一个共同瓶颈：<strong>推理质量</strong>。ReAct 按顺序执行每一步，一旦某步方向错误，整个链条就会偏离正确路径。Plan-and-Execute 有规划能力，但规划本身也可能出错，且无法在推理层面进行深度探索。</p>
<p>这就引出了一个核心问题：<strong>如何让 LLM 在推理过程中更智能地搜索和探索？</strong></p>
<p>答案隐藏在三个递进的范式中：CoT（线性思考）→ ToT（树状探索）→ Reflexion&#x2F;LATS（自我进化的搜索）。</p>
<h3 id="2-1-Chain-of-Thought（CoT）：思维链推理"><a href="#2-1-Chain-of-Thought（CoT）：思维链推理" class="headerlink" title="2.1 Chain-of-Thought（CoT）：思维链推理"></a>2.1 Chain-of-Thought（CoT）：思维链推理</h3><p>CoT 是 Agent 推理的基石。2022 年 Wei 等人在 Google Brain 的工作揭示了一个关键发现：只需在提示中加入”Let’s think step by step”，就能让 LLM 将复杂问题拆解为一系列中间推理步骤，显著提升数学、逻辑和常识推理的准确率。</p>
<p><strong>CoT 的核心机制：</strong></p>
<ul>
<li>LLM 不再直接输出最终答案，而是生成一条<strong>线性推理链</strong></li>
<li>每个中间步骤为后续步骤提供额外的”证据”或约束条件</li>
<li>从概率角度看，这相当于对模型输出分布的贝叶斯更新——每一步都缩小了解空间</li>
</ul>
<p><strong>一个典型例子：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">问题：停车场有3排车，每排8辆，又开走了4辆，还剩多少辆？</span><br><span class="line"></span><br><span class="line">CoT 推理链：</span><br><span class="line">Step 1: 总共有 3 × 8 = 24 辆车</span><br><span class="line">Step 2: 开走了 4 辆</span><br><span class="line">Step 3: 剩下 24 - 4 = 20 辆</span><br><span class="line">答案：20 辆</span><br></pre></td></tr></table></figure>

<p>然而，CoT 作为一条<strong>单一的线性链条</strong>，存在三个根本性局限：</p>
<p><strong>① 不可回溯（No Backtracking）</strong><br>一旦某一步推理出错，错误会沿着链条一路传播，无法返回修正。就像在迷宫中只能一直往前走，走错了也不能回头。</p>
<p><strong>② 无法探索多条路径（No Branching）</strong><br>面对有多种可能解法的问题，CoT 只能选择一条路走到底。比如解数学题时，可能有代数法和几何法两条路径，CoT 只会选择一条。</p>
<p><strong>③ 缺乏自我评估（No Self-Evaluation）</strong><br>链条上的每一步都没有被评估是否合理，模型无法判断当前方向是否正确，只能盲目前进。</p>
<p>CoT-SC（Self-Consistency）通过<strong>并行采样多条独立链条</strong>然后投票选择最佳答案，部分缓解了上述问题——但每条链条之间仍然是完全独立的，无法共享中间发现，也无法在关键决策点分叉探索。</p>
<h3 id="2-2-从-CoT-到-ToT：为什么需要进化？"><a href="#2-2-从-CoT-到-ToT：为什么需要进化？" class="headerlink" title="2.2 从 CoT 到 ToT：为什么需要进化？"></a>2.2 从 CoT 到 ToT：为什么需要进化？</h3><p>正是 CoT 的上述三个局限催生了 Tree-of-Thoughts（ToT）。让我们通过一个经典问题来理解这个进化的必要性：</p>
<p><strong>Game of 24 问题</strong>：用 4、5、6、10 四个数字和加减乘除，组合出结果为 24。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">CoT 的困境：</span><br><span class="line">Step 1: 尝试 4 × 6 = 24... 但还剩 5 和 10 没用</span><br><span class="line">Step 2: 好像不行，但已经无法回头了</span><br><span class="line">→ 失败，只能从头再来一次（但新的一次完全独立，不会记住上次的教训）</span><br><span class="line"></span><br><span class="line">ToT 的优势：</span><br><span class="line">          4, 5, 6, 10</span><br><span class="line">        /      |       \</span><br><span class="line">   4+5=9    4×6=24    10-6=4</span><br><span class="line">   /    \     ✗(剩余无法凑)  /   \</span><br><span class="line"> 9×(10-6)  6×(10-5)   4×5=20  ...</span><br><span class="line"> =9×4=36✗  =6×5=30✗   20+4=24? ✗(4已用)</span><br><span class="line">                        ↑ 回溯，换路</span><br></pre></td></tr></table></figure>

<p>ToT 在每一步都可以<strong>分叉探索多个方向</strong>，在发现死路时<strong>回溯</strong>到之前的节点尝试其他路径。</p>
<h3 id="2-3-Tree-of-Thoughts（ToT）：树状搜索推理"><a href="#2-3-Tree-of-Thoughts（ToT）：树状搜索推理" class="headerlink" title="2.3 Tree-of-Thoughts（ToT）：树状搜索推理"></a>2.3 Tree-of-Thoughts（ToT）：树状搜索推理</h3><p>ToT（由 Yao 等人于 2023 年在普林斯顿提出）将推理从线性链扩展为<strong>树状结构</strong>，本质上是将经典搜索算法引入 LLM 推理过程。</p>
<p><strong>ToT 的四大核心组件：</strong></p>
<p><strong>① 思维分解（Thought Decomposition）</strong><br>将问题拆解为适当粒度的”思维单元”。粒度选择至关重要——太细则搜索空间爆炸，太粗则失去探索灵活性。比如写一篇文章，一个思维单元可以是”段落大纲”而非”单个句子”。</p>
<p><strong>② 思维生成（Thought Generation）</strong><br>在每个节点生成 k 个候选思维，有两种策略：</p>
<ul>
<li><strong>采样（Sample）</strong>：独立生成多个候选（适合创意性任务，解空间大）</li>
<li><strong>提议（Propose）</strong>：基于前文依次生成（适合逻辑性任务，避免重复）</li>
</ul>
<p><strong>③ 状态评估（State Evaluation）</strong><br>这是 ToT 最关键的创新——<strong>用 LLM 自己来评估每个中间状态的质量</strong>：</p>
<ul>
<li><strong>打分法</strong>：对每个状态评分（如 1-10 分，或”确定&#x2F;可能&#x2F;不可能”）</li>
<li><strong>投票法</strong>：让 LLM 比较多个候选，选出最有前途的</li>
</ul>
<p>评估函数充当了”导航仪”的角色，告诉搜索算法哪些方向值得继续探索、哪些应该剪枝放弃。</p>
<p><strong>④ 搜索算法（Search Algorithm）</strong><br>ToT 支持两种经典搜索策略：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">BFS（广度优先）：                    DFS（深度优先）：</span><br><span class="line">层层扩展，不遗漏                     一条路走到底，走不通再回头</span><br><span class="line"></span><br><span class="line">Level 0:    [A]                     探索顺序：A → B → D → (回溯) → E → (回溯)</span><br><span class="line">Level 1:  [B] [C]                              → C → F → ✓ 找到解</span><br><span class="line">Level 2: [D][E][F][G]</span><br><span class="line"></span><br><span class="line">适合：解空间较小，需要最优解           适合：解空间大，需要尽快找到一个可行解</span><br></pre></td></tr></table></figure>

<p><strong>ToT 解决了 CoT 的三大痛点：</strong></p>
<table>
<thead>
<tr>
<th>CoT 的局限</th>
<th>ToT 的解决方案</th>
</tr>
</thead>
<tbody><tr>
<td>不可回溯</td>
<td>DFS 自然支持回溯，发现死路可返回上一节点</td>
</tr>
<tr>
<td>无法分叉探索</td>
<td>每个节点可生成 k 个候选分支</td>
</tr>
<tr>
<td>缺乏自我评估</td>
<td>状态评估函数在每步进行质量判断</td>
</tr>
</tbody></table>
<p><strong>代价是什么？</strong> ToT 需要更多的 LLM 调用（生成 + 评估），计算成本显著高于 CoT。这是”搜索质量”与”计算成本”之间的经典权衡——和 AlphaGo 的蒙特卡洛树搜索是同一种思想。</p>
<p><img src="/images/cot-vs-tot-comparison.png" alt="CoT vs ToT 推理结构对比"><br><em>图：CoT 线性链 vs ToT 树状搜索的结构差异。CoT 只能沿单一路径前进，ToT 在每步分叉并评估，支持回溯探索。</em></p>
<h3 id="2-4-Reflexion：自我反思学习"><a href="#2-4-Reflexion：自我反思学习" class="headerlink" title="2.4 Reflexion：自我反思学习"></a>2.4 Reflexion：自我反思学习</h3><p>ToT 解决了”单次推理中的探索问题”，但还有一个更深层的问题没有解决：<strong>跨任务的经验积累</strong>。人类在失败后会反思总结教训，下次遇到类似问题时表现更好。CoT 和 ToT 都没有这种”从失败中学习”的能力——每次推理都从零开始。</p>
<p><strong>Reflexion</strong> 引入了一个关键的「反思」闭环，让 Agent 能在多次尝试之间积累经验：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Trial 1: Actor 执行 → 得到结果 → Evaluator 评判 → 失败 ❌</span><br><span class="line">         ↓</span><br><span class="line">    Self-Reflection: &quot;我在第3步选错了API，应该用search而不是lookup&quot;</span><br><span class="line">         ↓  反思摘要存入长期记忆</span><br><span class="line">Trial 2: Actor 带着反思记忆重新执行 → 改进但仍有问题 ❌</span><br><span class="line">         ↓</span><br><span class="line">    Self-Reflection: &quot;API调对了，但参数格式不对，应该用JSON而非字符串&quot;</span><br><span class="line">         ↓  追加到长期记忆</span><br><span class="line">Trial 3: Actor 综合两次教训执行 → 成功 ✅</span><br></pre></td></tr></table></figure>

<p>Reflexion 包含三个核心组件的协作循环：</p>
<ul>
<li><strong>Actor（执行器）</strong>：基于 ReAct 或 CoT 的执行引擎，负责实际操作</li>
<li><strong>Evaluator（评估器）</strong>：判断执行结果的成功&#x2F;失败，提供二元或标量反馈信号</li>
<li><strong>Self-Reflection（反思器）</strong>：最核心的创新——将失败经验转化为自然语言反思摘要，存入一个持久的<strong>语言记忆（verbal memory）</strong></li>
</ul>
<p><strong>为什么用语言记忆而不是梯度更新？</strong> 这是 Reflexion 最巧妙的设计——传统 RL 通过更新模型权重来学习，成本极高且需要大量样本。Reflexion 用自然语言存储教训（如”不要用 deprecated API v1，改用 v2”），轻量、可解释，而且在推理时通过上下文注入即可使用。</p>
<p><strong>Reflexion 在编程任务上的惊人效果：</strong></p>
<ul>
<li>HumanEval 上从 80.1%（CoT 基线）提升到 91.0%（+11%）</li>
<li>其中约 40% 的错误在第二次尝试时就被修正</li>
<li>这证明了”反思+重试”机制的强大——很多错误不需要更强的模型，只需要从失败中学到教训</li>
</ul>
<p><img src="/images/reflexion-learning-loop.png" alt="Reflexion 自我反思学习循环"><br><em>图：Reflexion 的三组件反思循环——Actor 执行、Evaluator 评判、Self-Reflection 生成语言化教训存入记忆，驱动下一次尝试改进。</em></p>
<h3 id="2-5-从-ToT-到-LATS：统一搜索、行动与反思"><a href="#2-5-从-ToT-到-LATS：统一搜索、行动与反思" class="headerlink" title="2.5 从 ToT 到 LATS：统一搜索、行动与反思"></a>2.5 从 ToT 到 LATS：统一搜索、行动与反思</h3><p>到这里，我们已经有了三种关键能力：</p>
<ul>
<li><strong>CoT&#x2F;ToT</strong>：推理时的搜索与探索</li>
<li><strong>ReAct</strong>：与外部环境的交互（工具调用）</li>
<li><strong>Reflexion</strong>：从失败中学习</li>
</ul>
<p>但这三种能力是<strong>各自独立</strong>的。ToT 只做推理搜索，不调用工具；ReAct 调用工具但不做搜索；Reflexion 做反思但搜索策略很原始。有没有一个框架能把这三者统一起来？</p>
<p><strong>LATS（Language Agent Tree Search）</strong> 正是这个统一框架。它将蒙特卡洛树搜索（MCTS）——AlphaGo 的核心算法——引入 LLM Agent 决策，将搜索、行动和反思融合为一个整体：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">                   ┌──────────────────────┐</span><br><span class="line">                   │    MCTS 搜索循环      │</span><br><span class="line">                   └──────────────────────┘</span><br><span class="line">                             │</span><br><span class="line">   ┌─────────────┬──────────┼──────────┬──────────────┐</span><br><span class="line">   ▼             ▼          ▼          ▼              ▼</span><br><span class="line">Selection    Expansion  Simulation  Evaluation   Backpropagation</span><br><span class="line">(选择节点)   (生成动作)  (执行动作)  (LLM评分)    (反向传播)</span><br><span class="line">   │             │          │          │              │</span><br><span class="line"> UCB1算法    LLM生成     调用工具    价值评估      更新节点</span><br><span class="line"> 平衡探索     候选动作    获取反馈    + 反思        质量分数</span><br><span class="line"> 与利用                              </span><br></pre></td></tr></table></figure>

<p><strong>MCTS 五步循环详解：</strong></p>
<p><strong>① Selection（选择）</strong>：用 UCB1 公式选择最值得探索的节点，自动平衡”深入已知好路径”和”尝试未探索方向”——这解决了 ToT 简单 BFS&#x2F;DFS 策略的效率问题。</p>
<p><strong>② Expansion（扩展）</strong>：在选中节点用 LLM 生成 n 个候选动作，每个动作可以是推理步骤或工具调用——这融合了 ToT 的分支能力和 ReAct 的工具交互。</p>
<p><strong>③ Simulation（模拟）</strong>：执行动作并观察环境反馈——ReAct 的核心循环。</p>
<p><strong>④ Evaluation（评估）</strong>：LLM 对当前状态进行价值评估，给出分数。<strong>关键创新：如果检测到失败，触发 Reflexion 式的自我反思，生成反思摘要指导后续搜索。</strong></p>
<p><strong>⑤ Backpropagation（反向传播）</strong>：将评估分数沿树路径回传，更新每个祖先节点的质量估计——这让 LATS 能从全局视角优化搜索方向。</p>
<p><strong>LATS &#x3D; ToT（搜索框架）+ ReAct（环境交互）+ Reflexion（失败学习）</strong></p>
<p>这种统一带来的效果是显著的：在 HotPotQA 多跳推理任务上，LATS 比单独的 ReAct 提升 16%，比 Reflexion 提升 8%，比 ToT 提升 12%。代价是更高的计算成本——但这正是”用推理时计算换取更好决策”的核心思想。</p>
<p><img src="/images/lats-mcts-agent.png" alt="LATS 蒙特卡洛树搜索 Agent 决策"><br><em>图：LATS 将 MCTS 的五步循环应用于 Agent 决策，统一了搜索（ToT）、行动（ReAct）和反思（Reflexion）三大能力。</em></p>
<hr>
<h2 id="三、Deep-Agent-架构：当任务跨越百步"><a href="#三、Deep-Agent-架构：当任务跨越百步" class="headerlink" title="三、Deep Agent 架构：当任务跨越百步"></a>三、Deep Agent 架构：当任务跨越百步</h2><p>LATS 统一了搜索、行动和反思，但它仍然在<strong>单个上下文窗口</strong>内运作。当任务复杂度从”几步完成”升级到”数十甚至上百步”——比如写一份完整的研究报告、重构一个大型代码库、或执行一个跨越数小时的深度研究——上下文窗口就成了不可逾越的瓶颈：推理历史、工具返回、中间结果……全部挤在有限的 token 窗口中，信噪比急剧下降。</p>
<p><strong>Deep Agent（深度智能体）</strong> 架构是 2025 年下半年兴起的新范式，代表产品包括 Claude Code、OpenAI Deep Research、Manus AI 等。它的核心思想是：**将 Agent 的认知从”上下文内”扩展到”上下文外”**——用外部持久化系统弥补上下文窗口的局限。</p>
<p><img src="/images/agent-architecture-evolution.png" alt="Agent 架构演进全景图"><br><em>图：从 ReAct 到 Deep Agent 的架构演进。每一步进化都在解决前一代的核心瓶颈：ReAct 解决了工具交互、CoT&#x2F;ToT 解决了推理搜索、Reflexion 解决了经验学习、Deep Agent 解决了长任务上下文管理。</em></p>
<h3 id="3-1-四大支柱"><a href="#3-1-四大支柱" class="headerlink" title="3.1 四大支柱"></a>3.1 四大支柱</h3><p>Deep Agent 架构建立在四个基础之上：</p>
<p><strong>① 显式规划（Explicit Planning）</strong><br>不依赖 LLM 隐式推理，而是维护一个<strong>外部的、可持久化的任务计划</strong>。计划可以被检查、修改和恢复。这意味着即使上下文窗口被清空，Agent 仍然知道自己在做什么、做到了哪一步。</p>
<p>以 Claude Code 为例：当它重构一个大型代码库时，会在文件系统中写入一份 <code>plan.md</code>，记录每个模块的改造状态。即使中间因为上下文溢出导致会话重置，Agent 读取 plan.md 后就能无缝继续。</p>
<p><strong>② 层级委派（Hierarchical Delegation）</strong><br>单个 Agent 的能力总有上限。Deep Agent 将复杂任务拆分给<strong>专门化的子 Agent</strong>，每个子 Agent 有独立的上下文窗口和专属工具集：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Orchestrator Agent（指挥官）</span><br><span class="line">├── Research Sub-Agent（负责信息检索）→ 有搜索工具</span><br><span class="line">├── Code Sub-Agent（负责代码编写）→ 有文件读写和终端</span><br><span class="line">├── Review Sub-Agent（负责质量审查）→ 有测试工具</span><br><span class="line">└── Memory Sub-Agent（负责信息管理）→ 有知识库</span><br></pre></td></tr></table></figure>

<p>这种设计的关键优势是<strong>上下文隔离</strong>：Research Agent 的搜索结果不会污染 Code Agent 的编码上下文。每个子 Agent 只接收与自己任务相关的信息，信噪比大幅提升。</p>
<p><strong>③ 持久化记忆（Persistent Memory）</strong><br>使用文件系统作为外部记忆，而非仅依赖上下文窗口。Agent 可以：</p>
<ul>
<li>写入结构化笔记和发现摘要</li>
<li>读取之前的研究结果</li>
<li>维护状态文件跟踪进度</li>
<li>建立知识索引便于快速检索</li>
</ul>
<p>这本质上是将人类研究员的”做笔记”习惯编码为 Agent 的核心行为——上下文窗口是”工作记忆”（短期），文件系统是”笔记本”（长期）。</p>
<p><strong>④ 极致的上下文工程（Extreme Context Engineering）</strong><br>精心管理什么信息进入上下文窗口。具体技术包括：</p>
<ul>
<li><strong>渐进式摘要</strong>：每隔 N 步将历史压缩为摘要</li>
<li><strong>选择性加载</strong>：只加载与当前子任务相关的信息</li>
<li><strong>上下文分层</strong>：系统提示 &gt; 当前任务 &gt; 相关历史 &gt; 可选参考</li>
<li><strong>智能截断</strong>：工具返回过长时自动截取关键部分</li>
</ul>
<p>以 OpenClaw 为例——它在每次 heartbeat 时读取 HEARTBEAT.md（而非全部历史），在每个 session 开始时读取 SOUL.md 和 USER.md（身份信息），只有在主 session 中才加载 MEMORY.md（长期记忆），这就是上下文工程的实际应用。</p>
<h3 id="3-2-CORAL：认知资源自分配"><a href="#3-2-CORAL：认知资源自分配" class="headerlink" title="3.2 CORAL：认知资源自分配"></a>3.2 CORAL：认知资源自分配</h3><p><strong>CORAL（Cognitive Resource Self-Allocation）</strong> 是 ICLR 2026 收录的工作，专门解决长任务中 Agent 的「注意力漂移」问题——当上下文中积累了太多无关信息，LLM 的注意力被分散，推理质量急剧下降。</p>
<p><strong>核心洞察：</strong> 人类处理长任务时，会主动”清空短期记忆”——比如写论文写了3小时后，会先休息，回来后重新读一遍大纲，而不是试图记住之前的每一个细节。CORAL 给 Agent 提供了类似的能力。</p>
<p><strong>工作记忆管理工具集：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Agent 工具箱中新增三种&quot;元工具&quot;：</span><br><span class="line">1. set_checkpoint(label)  → 在关键节点保存状态快照</span><br><span class="line">2. clear_memory()         → 清除工作记忆中的杂乱信息  </span><br><span class="line">3. restore(label)         → 从指定检查点恢复推理上下文</span><br></pre></td></tr></table></figure>

<p>当 Agent 探索了多条路径、积累了大量搜索结果，发现自己”迷失方向”时，可以主动调用 <code>clear_memory()</code> + <code>restore(&quot;initial_plan&quot;)</code> 来重新开始——但不是完全从零开始，而是保留了检查点中的关键发现。</p>
<p><strong>训练方式：</strong> CORAL 使用<strong>多轮 Agentic 强化策略优化（Multi-episode Agentic Reinforced Policy Optimization）</strong> 算法，让 Agent 通过 RL 学会三个关键判断：</p>
<ul>
<li><strong>何时设置检查点</strong>（在做出重要发现或关键决策后）</li>
<li><strong>何时清理记忆</strong>（当上下文信噪比过低时）</li>
<li><strong>恢复到哪个检查点</strong>（选择最有价值的历史状态）</li>
</ul>
<p>CORAL 在 SWE-bench 等长任务基准上显著优于没有记忆管理的 Agent，验证了”主动管理认知资源”的价值——这也为 Deep Agent 架构的”极致上下文工程”提供了理论支撑。</p>
<hr>
<h2 id="四、Agentic-RL：从工程拼接到端到端学习"><a href="#四、Agentic-RL：从工程拼接到端到端学习" class="headerlink" title="四、Agentic RL：从工程拼接到端到端学习"></a>四、Agentic RL：从工程拼接到端到端学习</h2><p>前三节的所有架构——从 ReAct 到 LATS 到 Deep Agent——都属于「推理时（inference-time）」的工程技巧。它们通过精巧的提示设计、搜索算法和记忆管理来提升 Agent 表现，但<strong>模型本身并没有因此变得更强</strong>。模型权重是冻结的，所有的”聪明”都来自外部框架。</p>
<p>这就像给一个普通人配备了最好的工具箱、最详细的操作手册——他确实能完成更复杂的任务，但他自身的能力并没有提升。如果工具箱被拿走或手册不适用，他就回到了原点。</p>
<p><strong>Agentic RL</strong> 代表了一个根本性的范式转移：<strong>直接通过强化学习训练 LLM 的 Agent 行为能力</strong>，让模型在多步交互中学会规划、工具使用、错误修正——这些能力被编码进模型权重，而非依赖外部框架。</p>
<h3 id="4-1-从-RLHF-到-Agentic-RL"><a href="#4-1-从-RLHF-到-Agentic-RL" class="headerlink" title="4.1 从 RLHF 到 Agentic RL"></a>4.1 从 RLHF 到 Agentic RL</h3><table>
<thead>
<tr>
<th>维度</th>
<th>RLHF</th>
<th>Agentic RL</th>
</tr>
</thead>
<tbody><tr>
<td>目标</td>
<td>让 LLM 输出更符合人类偏好</td>
<td>让 LLM 学会多步决策与工具使用</td>
</tr>
<tr>
<td>交互</td>
<td>单轮：prompt → response</td>
<td>多轮：action → env feedback → action</td>
</tr>
<tr>
<td>奖励</td>
<td>人类偏好评分</td>
<td>任务完成度 + 过程奖励</td>
</tr>
<tr>
<td>训练格式</td>
<td>单条序列</td>
<td>多轮轨迹（trajectory）</td>
</tr>
<tr>
<td>环境</td>
<td>无</td>
<td>真实或模拟环境</td>
</tr>
</tbody></table>
<p>Agentic RL 的核心突破在于：<strong>将 LLM 从被动的序列生成器重新定义为主动的、嵌入复杂动态世界的决策智能体。</strong></p>
<p><img src="/images/agentic-rl-paradigm.png" alt="Agentic RL 范式转移"><br><em>图：从推理时工程（左）到 Agentic RL 端到端训练（右）的范式转移——外部脚手架 vs 内化能力。</em></p>
<h3 id="4-2-Agent-R1：端到端-Agent-强化学习"><a href="#4-2-Agent-R1：端到端-Agent-强化学习" class="headerlink" title="4.2 Agent-R1：端到端 Agent 强化学习"></a>4.2 Agent-R1：端到端 Agent 强化学习</h3><p><strong>Agent-R1</strong>（中国科学技术大学，2025.11）是将 DeepSeek-R1 的 RL 训练范式扩展到 Agent 场景的里程碑工作。</p>
<p><strong>核心问题：为什么不能直接把 RLHF&#x2F;GRPO 套到 Agent 上？</strong></p>
<p>传统 RL 训练 LLM 时，轨迹（trajectory）是一个单轮序列：prompt → response。但 Agent 的轨迹是多轮交互序列，包含两种本质不同的 token：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">轨迹结构：</span><br><span class="line">[System Prompt] → Agent生成思考 → Agent调用工具 → 环境返回结果 → Agent继续思考 → ...</span><br><span class="line">                  ↑ Agent token（可训练）      ↑ 环境 token（不可训练！）</span><br></pre></td></tr></table></figure>

<p>关键区分：<strong>Agent 生成的 token 需要参与梯度计算，但环境返回的 token 不应该</strong>——因为你不能通过训练模型来改变环境的行为。Agent-R1 在 MDP 框架中明确建模了这个区分。</p>
<p><strong>MDP 扩展详解：</strong></p>
<table>
<thead>
<tr>
<th>组件</th>
<th>静态 LLM</th>
<th>Agent-R1</th>
</tr>
</thead>
<tbody><tr>
<td><strong>状态空间</strong></td>
<td>prompt + 已生成 token</td>
<td>完整对话历史 + 每轮环境反馈</td>
</tr>
<tr>
<td><strong>动作空间</strong></td>
<td>词表中选下一个 token</td>
<td>同上，但 token 序列可触发工具调用</td>
</tr>
<tr>
<td><strong>转移函数</strong></td>
<td>确定性（拼接 token）</td>
<td><strong>随机性</strong>（环境返回不确定）</td>
</tr>
<tr>
<td><strong>奖励函数</strong></td>
<td>单次终端奖励</td>
<td>终端奖励 + 中间过程奖励</td>
</tr>
</tbody></table>
<p><strong>过程奖励（Process Rewards）</strong> 是 Agent-R1 的重要创新——不只在任务完成时给奖励，在中间步骤也给信号。比如：正确调用了 search API 但查询词不够精确，可以给一个小的正奖励（鼓励工具使用）但不是满分（查询还需优化）。这解决了长任务中”奖励稀疏”的经典难题。</p>
<p>Agent-R1 开源了完整的训练框架（基于 veRL），支持快速接入不同环境，已在 Multi-hop QA 上验证了效果。</p>
<h3 id="4-3-AgentRL：多任务多轮-Agent-训练框架"><a href="#4-3-AgentRL：多任务多轮-Agent-训练框架" class="headerlink" title="4.3 AgentRL：多任务多轮 Agent 训练框架"></a>4.3 AgentRL：多任务多轮 Agent 训练框架</h3><p><strong>AgentRL</strong>（清华大学 THUDM，2025.10）是目前最系统的 Agentic RL 训练框架，其训练成果已应用于智谱的 AutoGLM。</p>
<p><strong>两大技术创新：</strong></p>
<p><strong>① 跨策略采样（Cross-Policy Sampling）</strong><br>在多轮设定中，Agent 容易陷入策略过拟合，不愿探索新策略。AgentRL 通过从多个模型策略池中采样动作，增强探索多样性：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">轨迹生成时：</span><br><span class="line">Step 1: 从 Policy_A 采样 action</span><br><span class="line">Step 2: 从 Policy_B 采样 action  ← 跨策略</span><br><span class="line">Step 3: 从 Policy_A 采样 action</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p><strong>② 任务优势归一化（Task Advantage Normalization）</strong><br>多任务训练时不同任务的奖励尺度差异大。对每个任务的优势值独立归一化，稳定训练：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Advantage_normalized = (Advantage - mean_task) / std_task</span><br></pre></td></tr></table></figure>

<p><strong>实验结果惊人：</strong> AgentRL 在五个 Agent 基准任务（ALFWorld、DB、KG、OS、Webshop）上训练开源 LLM（Qwen2.5），性能显著超越 GPT-5、Claude-Sonnet-4 和 DeepSeek-R1。</p>
<h3 id="4-4-DeepResearcher：真实环境中的-RL-训练"><a href="#4-4-DeepResearcher：真实环境中的-RL-训练" class="headerlink" title="4.4 DeepResearcher：真实环境中的 RL 训练"></a>4.4 DeepResearcher：真实环境中的 RL 训练</h3><p><strong>DeepResearcher</strong>（上海交通大学 GAIR，2025.4，EMNLP 2025 收录）是首个在真实 Web 搜索环境中端到端训练 Agent 的框架。</p>
<p><strong>为什么 RAG 环境训练不够？</strong></p>
<p>之前的 RL 训练工作（如 Search-R1、R1-Searcher）都在 RAG 环境中进行——给模型一个固定语料库，模型从中检索信息。这种方式有一个致命假设：<strong>所有需要的信息已经在语料库里了</strong>。但现实世界不是这样的：</p>
<ul>
<li>信息可能不存在于语料库中</li>
<li>信息可能已经过时</li>
<li>需要跨多个领域综合多个来源</li>
<li>网页格式杂乱，充满噪声和反爬机制</li>
</ul>
<p>DeepResearcher 直接在开放互联网环境中训练，Agent 需要面对真实的搜索引擎、真实的网页（包括乱码、广告、反爬）。</p>
<p><strong>多 Agent 架构设计：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Main Agent（推理决策者）</span><br><span class="line">    │</span><br><span class="line">    ├── 决定搜索什么关键词</span><br><span class="line">    ├── 分析搜索结果摘要</span><br><span class="line">    ├── 决定深入哪些网页</span><br><span class="line">    │       ↓</span><br><span class="line">    └── Browsing Agent（网页浏览者）</span><br><span class="line">            ├── 加载完整网页</span><br><span class="line">            ├── 提取相关信息</span><br><span class="line">            └── 返回结构化摘要给 Main Agent</span><br></pre></td></tr></table></figure>

<p>Main Agent 负责高层决策（搜什么、看哪个、如何综合），Browsing Agent 负责底层信息提取——这比 RAG 系统”直接返回文本片段”要灵活得多。</p>
<p><strong>训练后涌现的四种认知行为（最惊喜的发现）：</strong></p>
<ol>
<li><p><strong>自主规划（Planning）</strong>：Agent 自动学会了在开始研究前制定计划，并在过程中动态调整。注意——<strong>没有人教它规划</strong>，这是纯 RL 训练涌现的行为！甚至还会”合并步骤”来提高效率。</p>
</li>
<li><p><strong>交叉验证（Cross-Validation）</strong>：Agent 找到一个答案后，不会立即接受，而是继续搜索其他来源来验证。这种”不轻信第一个结果”的审慎行为也是自发涌现的。</p>
</li>
<li><p><strong>自我反思与重定向（Self-Reflection）</strong>：发现当前搜索方向不对时，Agent 会主动调整关键词或换一个完全不同的搜索策略。</p>
</li>
<li><p><strong>诚实性（Honesty）</strong>：当确实找不到确定答案时，Agent 会坦诚说明，而非编造一个看似合理的答案。</p>
</li>
</ol>
<p><strong>量化结果：</strong> DeepResearcher 在 7 个开放域研究数据集上，比提示工程方案提升高达 <strong>28.9 分</strong>，比 RAG 环境 RL 方案提升 <strong>7.2 分</strong>。这证明了一个核心结论：<strong>在真实环境中训练不是可选的优化，而是开发稳健研究能力的根本需求。</strong></p>
<h3 id="4-5-通义-DeepResearch：全栈-Agent-训练流水线"><a href="#4-5-通义-DeepResearch：全栈-Agent-训练流水线" class="headerlink" title="4.5 通义 DeepResearch：全栈 Agent 训练流水线"></a>4.5 通义 DeepResearch：全栈 Agent 训练流水线</h3><p>阿里通义团队（2025.9）提出了一套完整的 Agent 训练流程：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">阶段1: Agentic Pre-training（预训练阶段引入工具使用能力）</span><br><span class="line">    ↓</span><br><span class="line">阶段2: Supervised Fine-tuning（用专家数据冷启动）</span><br><span class="line">    ↓</span><br><span class="line">阶段3: On-policy RL（在线强化学习自进化）</span><br></pre></td></tr></table></figure>

<p>这套「预训练 → SFT → RL」的三阶段流程被验证为训练 Deep Research Agent 的有效范式。</p>
<hr>
<h2 id="五、推理时搜索：第三条路径"><a href="#五、推理时搜索：第三条路径" class="headerlink" title="五、推理时搜索：第三条路径"></a>五、推理时搜索：第三条路径</h2><p>前四节讨论了两条提升 Agent 能力的路径：</p>
<ul>
<li><strong>路径 A：推理时工程</strong>（更好的框架、搜索算法、记忆管理）</li>
<li><strong>路径 B：训练时学习</strong>（通过 RL 直接提升模型能力）</li>
</ul>
<p>还有<strong>路径 C</strong>——<strong>在推理时投入更多计算</strong>。不改变模型权重，也不依赖复杂的外部框架，而是让模型”想更久”。</p>
<h3 id="5-1-推理时计算扩展（Inference-Time-Scaling）"><a href="#5-1-推理时计算扩展（Inference-Time-Scaling）" class="headerlink" title="5.1 推理时计算扩展（Inference-Time Scaling）"></a>5.1 推理时计算扩展（Inference-Time Scaling）</h3><p>OpenAI 的 o1&#x2F;o3&#x2F;o4 系列揭示了一个令人振奋的发现：<strong>推理时的计算量和推理质量之间存在近似对数线性的正相关关系</strong>。换句话说，让模型多花 10 倍算力”思考”，可以获得显著的质量提升。</p>
<p>核心技术手段包括：</p>
<ul>
<li><strong>内部思维链（Internal CoT）</strong>：模型在输出前进行长链隐式推理，这些推理 token 消耗计算但不一定展示给用户</li>
<li><strong>搜索与回溯</strong>：多条推理路径并行探索，选择最优路径——本质上和 ToT 异曲同工，但被编码进了模型的推理行为中</li>
<li><strong>自我验证</strong>：模型生成候选答案后，自己检查答案的正确性，如有问题则重新推理</li>
<li><strong>自适应计算分配</strong>：简单问题少想，复杂问题多想——模型学会了”量力而行”</li>
</ul>
<p>这解释了为什么 o3&#x2F;o4 在某些数学竞赛题上表现惊人——它们可能在单个问题上花费了相当于普通模型数百次调用的算力。</p>
<h3 id="5-2-AB-MCTS：自适应分支蒙特卡洛树搜索"><a href="#5-2-AB-MCTS：自适应分支蒙特卡洛树搜索" class="headerlink" title="5.2 AB-MCTS：自适应分支蒙特卡洛树搜索"></a>5.2 AB-MCTS：自适应分支蒙特卡洛树搜索</h3><p><strong>AB-MCTS（Adaptive Branching MCTS）</strong>（Sakana AI）将这个思想推向了多模型协作的维度：</p>
<p><strong>核心思想：</strong> 不是一个模型自己搜索，而是<strong>多个不同的 LLM 协作进行蒙特卡洛树搜索</strong>。每个模型有不同的偏好和盲点，多模型搜索可以获得更全面的探索覆盖。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">搜索树的每个节点：</span><br><span class="line">├── GPT-5 生成候选 A → 评分 0.7</span><br><span class="line">├── Claude 生成候选 B → 评分 0.9  ← 选中展开</span><br><span class="line">└── Gemini 生成候选 C → 评分 0.5</span><br><span class="line"></span><br><span class="line">下一层继续多模型扩展...</span><br></pre></td></tr></table></figure>

<p><strong>自适应分支</strong> 是关键创新：不固定每个节点的分支数，而是根据当前问题的难度和搜索进展动态调整。简单部分少分支快速通过，困难部分多分支深度探索。</p>
<p>AB-MCTS 代表了推理时搜索的前沿方向：不改变任何模型的权重，而是通过更聪明的搜索编排来突破单模型的能力上限。这和下棋中的思想完全一致——棋手的水平（模型能力）是固定的，但花更多时间思考（搜索更多变化）总能下出更好的棋。</p>
<h3 id="5-3-三条路径的关系"><a href="#5-3-三条路径的关系" class="headerlink" title="5.3 三条路径的关系"></a>5.3 三条路径的关系</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">         Agent 能力提升</span><br><span class="line">        /       |       \</span><br><span class="line">  路径 A        路径 B        路径 C</span><br><span class="line">推理时工程    训练时学习    推理时计算</span><br><span class="line">(ReAct,ToT,   (Agentic RL,  (o1-style,</span><br><span class="line"> Deep Agent)   Agent-R1)     AB-MCTS)</span><br><span class="line">     ↓            ↓            ↓</span><br><span class="line">模型不变,       模型变强,     模型不变,</span><br><span class="line">外部框架优化    内化能力      多花算力思考</span><br></pre></td></tr></table></figure>

<p>实践中，三条路径并不互斥——最强的 Agent 系统同时使用了全部三条：强 RL 训练的基座模型（路径 B）+ 推理时多步搜索（路径 C）+ 外部记忆和工具管理（路径 A）。</p>
<hr>
<h2 id="六、实用建议：如何选择-Agent-架构"><a href="#六、实用建议：如何选择-Agent-架构" class="headerlink" title="六、实用建议：如何选择 Agent 架构"></a>六、实用建议：如何选择 Agent 架构</h2><h3 id="任务复杂度-vs-架构选择"><a href="#任务复杂度-vs-架构选择" class="headerlink" title="任务复杂度 vs 架构选择"></a>任务复杂度 vs 架构选择</h3><table>
<thead>
<tr>
<th>任务类型</th>
<th>推荐架构</th>
<th>代表方案</th>
</tr>
</thead>
<tbody><tr>
<td>简单工具调用（天气&#x2F;搜索）</td>
<td>ReAct</td>
<td>LangChain ReAct Agent</td>
</tr>
<tr>
<td>多步骤有序任务</td>
<td>Plan-and-Execute</td>
<td>LangGraph</td>
</tr>
<tr>
<td>需要探索的复杂推理</td>
<td>Tree-of-Thoughts &#x2F; LATS</td>
<td>自定义</td>
</tr>
<tr>
<td>需要从失败中学习</td>
<td>Reflexion</td>
<td>自定义</td>
</tr>
<tr>
<td>超长任务（100+ 步）</td>
<td>Deep Agent</td>
<td>Claude Code &#x2F; OpenClaw</td>
</tr>
<tr>
<td>训练专用 Agent</td>
<td>Agentic RL</td>
<td>AgentRL &#x2F; Agent-R1</td>
</tr>
<tr>
<td>深度研究</td>
<td>Deep Agent + RL</td>
<td>DeepResearcher</td>
</tr>
</tbody></table>
<h3 id="关键设计原则"><a href="#关键设计原则" class="headerlink" title="关键设计原则"></a>关键设计原则</h3><ol>
<li><strong>外部化一切状态</strong>：不要仅依赖上下文窗口，用文件系统持久化记忆</li>
<li><strong>分层委派</strong>：复杂任务拆分给专门的 Sub-Agent</li>
<li><strong>显式管理上下文</strong>：主动摘要和压缩，保持高信噪比</li>
<li><strong>建立检查点机制</strong>：允许 Agent 回溯和恢复</li>
<li><strong>过程奖励优于结果奖励</strong>：在训练中引入中间步骤的奖励信号</li>
</ol>
<hr>
<h2 id="七、展望：Agent-技术的下一步"><a href="#七、展望：Agent-技术的下一步" class="headerlink" title="七、展望：Agent 技术的下一步"></a>七、展望：Agent 技术的下一步</h2><h3 id="2026-年关键趋势"><a href="#2026-年关键趋势" class="headerlink" title="2026 年关键趋势"></a>2026 年关键趋势</h3><ol>
<li><strong>Agentic RL 成为标配</strong>：从提示工程走向端到端训练，直接优化 Agent 的多步决策能力</li>
<li><strong>Memory 成为一等公民</strong>：ICLR 2026 专门设立 MemAgents Workshop，记忆管理从「工程技巧」升级为核心研究方向</li>
<li><strong>多模态 Agent</strong>：Agent 不再限于文本交互，可以「看」屏幕、操作 UI、理解视觉信息</li>
<li><strong>自进化 Agent</strong>：Agent 能在部署后持续从真实交互中学习改进</li>
</ol>
<h3 id="核心挑战"><a href="#核心挑战" class="headerlink" title="核心挑战"></a>核心挑战</h3><ul>
<li><strong>安全与对齐</strong>：自主度越高，风险越大，如何确保 Agent 行为安全可控</li>
<li><strong>长期记忆</strong>：如何在超长任务中维持一致的目标和上下文</li>
<li><strong>奖励设计</strong>：复杂任务的奖励信号如何定义和分解</li>
<li><strong>评估基准</strong>：缺乏真正长时间跨度的 Agent 评估标准</li>
</ul>
<hr>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol>
<li>Yao, S. et al. “ReAct: Synergizing Reasoning and Acting in Language Models.” ICLR 2023.</li>
<li>Shinn, N. et al. “Reflexion: Language Agents with Verbal Reinforcement Learning.” NeurIPS 2023.</li>
<li>Wei, J. et al. “Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.” NeurIPS 2022.</li>
<li>Yao, S. et al. “Tree of Thoughts: Deliberate Problem Solving with Large Language Models.” NeurIPS 2023.</li>
<li>Zhou, A. et al. “Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models.” ICML 2024.</li>
<li>Cheng, M. et al. “Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning.” arXiv:2511.14460, Nov 2025.</li>
<li>Zhang, H. et al. “AgentRL: Scaling Agentic Reinforcement Learning with a Multi-Turn, Multi-Task Framework.” arXiv:2510.04206, Oct 2025.</li>
<li>Zheng, Y. et al. “DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments.” arXiv:2504.03160, Apr 2025.</li>
<li>Wang, R. et al. “A Practitioner’s Guide to Multi-turn Agentic Reinforcement Learning.” arXiv:2510.01132, Oct 2025.</li>
<li>“Don’t Lose the Thread: Empowering Long-Horizon LLM Agents with Cognitive Resource Self-Allocation (CORAL).” ICLR 2026.</li>
<li>“The Landscape of Agentic Reinforcement Learning for LLMs: A Survey.” TMLR, Jan 2026.</li>
<li>Tongyi Team. “Tongyi DeepResearch: A New Era of Open-Source AI Researchers.” Sep 2025.</li>
<li>OpenAI. “Introducing Deep Research.” Feb-Jul 2025.</li>
<li>Sakana AI. “Inference-Time Scaling and Collective Intelligence for Frontier AI (AB-MCTS).” 2025.</li>
</ol>
<hr>
<blockquote>
<p>本文系统梳理了 Agent Loop 和 Agent RL 领域的核心算法和最新进展，从经典的 ReAct 循环到前沿的 Agentic RL 训练范式。Agent 技术正在从「工程拼接」走向「端到端学习」，这将是 2026 年 AI 领域最重要的技术方向之一。</p>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2026-02-13T00:00:00.000Z" title="2/13/2026, 8:00:00 AM">2026-02-13</time>发表</span><span class="level-item"><time dateTime="2026-02-13T00:11:14.706Z" title="2/13/2026, 8:11:14 AM">2026-02-13</time>更新</span><span class="level-item">15 分钟读完 (大约2305个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/02/13/github-trending/2026-02-13/">GitHub Trending 热榜 | 2026-02-13：Generative UI、个人 AI 基础设施、Chrome DevTools MCP</a></h1><div class="content"><blockquote>
<p>今天的 GitHub Trending 榜单有一个鲜明的主题：<strong>AI 正在从「模型」走向「基础设施」</strong>。无论是让 React 组件被 AI 动态生成的 Tambo，还是把整个个人生活用 AI Agent 武装起来的 PAI，抑或是让编程 Agent 直接操控 Chrome DevTools 的 MCP 工具——开发者们不再满足于调 API，而是在构建让 AI 真正融入工作流的基础设施。</p>
</blockquote>
<hr>
<h2 id="1-Tambo-—-让-AI-Agent-说你的-UI-语言"><a href="#1-Tambo-—-让-AI-Agent-说你的-UI-语言" class="headerlink" title="1. Tambo — 让 AI Agent 说你的 UI 语言"></a>1. Tambo — 让 AI Agent 说你的 UI 语言</h2><blockquote>
<p>⭐ 8,997 Stars | 📈 +300 today | 🟦 TypeScript | 📜 MIT</p>
</blockquote>
<h3 id="项目简介"><a href="#项目简介" class="headerlink" title="项目简介"></a>项目简介</h3><p>Tambo 是一个面向 React 的 <strong>Generative UI（生成式 UI）</strong> 开源工具包。核心理念很简单：你注册你的 React 组件并描述它们的 schema，AI Agent 在对话中自动选择合适的组件、流式生成 props、渲染出交互式 UI。</p>
<p>用户说「展示各地区销售额」，Agent 不是返回一段文字，而是直接渲染你的 <code>&lt;Chart&gt;</code> 组件。用户说「添加一个任务」，Agent 更新你的 <code>&lt;TaskBoard&gt;</code>。</p>
<h3 id="为什么火？"><a href="#为什么火？" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>Generative UI 是 2026 年前端领域最热的方向之一。传统的 AI 聊天界面只能返回文本或 Markdown，但真实的应用需要按钮、表格、图表、表单等丰富的交互组件。</p>
<p>Tambo 解决了这个问题的工程化难题：</p>
<ul>
<li><strong>流式 Props</strong>：LLM 生成的 props 实时流式传输到组件，不用等全部生成完</li>
<li><strong>状态管理内置</strong>：对话状态、组件状态、错误恢复全部封装好</li>
<li><strong>MCP 集成</strong>：支持 Model Context Protocol，可以和各种 Agent 框架无缝对接</li>
<li><strong>Cloud 或自托管</strong>：提供托管后端，也支持 Docker 自部署</li>
</ul>
<h3 id="技术亮点"><a href="#技术亮点" class="headerlink" title="技术亮点"></a>技术亮点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm create tambo-app my-tambo-app</span><br><span class="line"><span class="built_in">cd</span> my-tambo-app</span><br><span class="line">npm run dev</span><br></pre></td></tr></table></figure>

<p>5 分钟就能跑起来。支持 OpenAI、Anthropic、Gemini、Mistral 等多种模型。配套了一个预构建组件库（ui.tambo.co），包含对话气泡、工具卡片、数据可视化等 Agent UI 基础组件。</p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><ul>
<li>需要在 AI 聊天中展示复杂交互界面的 SaaS 产品</li>
<li>企业内部的 AI 助手面板</li>
<li>任何想让 AI 不止返回文字的 React 应用</li>
</ul>
<hr>
<h2 id="2-PAI（Personal-AI-Infrastructure）—-个人-AI-基础设施"><a href="#2-PAI（Personal-AI-Infrastructure）—-个人-AI-基础设施" class="headerlink" title="2. PAI（Personal AI Infrastructure）— 个人 AI 基础设施"></a>2. PAI（Personal AI Infrastructure）— 个人 AI 基础设施</h2><blockquote>
<p>⭐ 7,488 Stars | 📈 +351 today | 🟦 TypeScript | 📜 MIT</p>
</blockquote>
<h3 id="项目简介-1"><a href="#项目简介-1" class="headerlink" title="项目简介"></a>项目简介</h3><p>来自安全领域知名人物 Daniel Miessler（Fabric 框架创始人）的新项目。PAI 的目标宏大：<strong>为每个人构建一套完整的 AI Agent 基础设施</strong>，用 AI 放大个人能力。</p>
<p>PAI 不是一个 Agent，而是一个 <strong>Agent 操作系统</strong>——它定义了一套 Primitives（原语）和 Packs（功能包），让你可以像搭积木一样组装自己的 AI 系统。</p>
<h3 id="为什么火？-1"><a href="#为什么火？-1" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>因为它抓住了一个核心矛盾：<strong>AI 工具太多了，但缺少一个把它们统一起来的架构。</strong></p>
<p>你可能用了 ChatGPT、Claude、各种 MCP 工具、本地 LLM……但它们各自为战。PAI 提供了一个统一框架：</p>
<ul>
<li><strong>Packs</strong>：23 个功能包，覆盖写作、分析、安全、编程等场景</li>
<li><strong>Bundles</strong>：预配置的功能包组合，一键部署</li>
<li><strong>Two-Pass Capability Selection</strong>：双通道能力选择，自动匹配最合适的工具</li>
<li><strong>Thinking Tools</strong>：带推理过程的工具调用，支持 Justify-Exclusion（解释为什么不选某个工具）</li>
<li><strong>并行执行</strong>：默认并行处理多个 Agent 任务</li>
</ul>
<h3 id="技术亮点-1"><a href="#技术亮点-1" class="headerlink" title="技术亮点"></a>技术亮点</h3><p>v2.5.0 刚发布，三大升级：</p>
<ol>
<li><strong>双通道能力选择</strong>：先粗筛再精选，提高工具匹配准确率</li>
<li><strong>Thinking Tools + Justify-Exclusion</strong>：Agent 不仅解释为什么选这个工具，还解释为什么不选其他工具——更透明的决策过程</li>
<li><strong>并行执行默认开启</strong>：多任务不再串行等待</li>
</ol>
<h3 id="适用场景-1"><a href="#适用场景-1" class="headerlink" title="适用场景"></a>适用场景</h3><ul>
<li>想构建个人 AI 工作流的技术爱好者</li>
<li>对 AI Agent 架构设计感兴趣的开发者</li>
<li>Fabric 框架的老用户——PAI 是 Fabric 理念的大幅进化</li>
</ul>
<hr>
<h2 id="3-Google-LangExtract-—-用-LLM-从混沌文本中提取结构化数据"><a href="#3-Google-LangExtract-—-用-LLM-从混沌文本中提取结构化数据" class="headerlink" title="3. Google LangExtract — 用 LLM 从混沌文本中提取结构化数据"></a>3. Google LangExtract — 用 LLM 从混沌文本中提取结构化数据</h2><blockquote>
<p>⭐ 31,355 Stars | 📈 +1,122 today | 🐍 Python | 📜 Apache-2.0</p>
</blockquote>
<h3 id="项目简介-2"><a href="#项目简介-2" class="headerlink" title="项目简介"></a>项目简介</h3><p>Google 开源的 Python 库，专门用 LLM 从非结构化文本（临床笔记、研报、法律文件等）中提取结构化信息。这不是简单的 NER（命名实体识别），而是带<strong>精准溯源</strong>的信息提取——每个结果都能映射回源文本的精确位置。</p>
<h3 id="为什么火？-2"><a href="#为什么火？-2" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>今日 +1,122 Stars，连续多日霸榜，已经冲到 31K Stars。</p>
<p>核心原因：它解决了 LLM 落地的信任难题。大模型擅长理解文本，但企业场景要的不只是「理解」，还要「证据」。LangExtract 的溯源机制让每条提取结果都有据可查，配合交互式可视化工具，让用户可以验证 AI 的每一个判断。</p>
<ul>
<li><strong>Source Grounding</strong>：每个提取字段都标注了源文本位置</li>
<li><strong>交互式可视化</strong>：一键查看提取结果与原文的对应关系</li>
<li><strong>多模型支持</strong>：原生 Gemini，同时支持 OpenAI 和 Ollama 本地模型</li>
<li><strong>Pydantic Schema</strong>：用标准的 Python 数据类定义提取目标</li>
</ul>
<h3 id="适用场景-2"><a href="#适用场景-2" class="headerlink" title="适用场景"></a>适用场景</h3><ul>
<li>医疗记录结构化（从临床笔记提取诊断、用药、检查结果）</li>
<li>金融研报数据提取</li>
<li>法律文件关键条款提取</li>
<li>任何需要「可溯源 AI 提取」的场景</li>
</ul>
<hr>
<h2 id="4-Chrome-DevTools-MCP-—-让编程-Agent-拥有浏览器超能力"><a href="#4-Chrome-DevTools-MCP-—-让编程-Agent-拥有浏览器超能力" class="headerlink" title="4. Chrome DevTools MCP — 让编程 Agent 拥有浏览器超能力"></a>4. Chrome DevTools MCP — 让编程 Agent 拥有浏览器超能力</h2><blockquote>
<p>⭐ 24,380 Stars | 📈 +436 today | 🟦 TypeScript | 📜 Apache-2.0</p>
</blockquote>
<h3 id="项目简介-3"><a href="#项目简介-3" class="headerlink" title="项目简介"></a>项目简介</h3><p>Chrome 官方出品。这个 MCP Server 让你的编程 Agent（Gemini、Claude、Cursor、Copilot 等）可以<strong>直接控制和检查实时 Chrome 浏览器</strong>——完整的 DevTools 能力，包括性能分析、网络请求检查、控制台日志、截图等。</p>
<h3 id="为什么火？-3"><a href="#为什么火？-3" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>因为它补上了 AI 编程助手最大的盲区之一：<strong>前端调试</strong>。</p>
<p>以前 Agent 写完前端代码，你需要自己打开浏览器、检查渲染效果、查看 Console 错误、分析网络请求。现在 Agent 自己就能做这些事：</p>
<ul>
<li><strong>性能分析</strong>：录制 Chrome Trace，提取可操作的性能优化建议</li>
<li><strong>网络调试</strong>：检查 HTTP 请求&#x2F;响应、分析加载瀑布图</li>
<li><strong>控制台监控</strong>：获取浏览器控制台消息，包含 source-mapped 堆栈追踪</li>
<li><strong>可靠自动化</strong>：基于 Puppeteer，自动等待操作结果</li>
</ul>
<h3 id="技术亮点-2"><a href="#技术亮点-2" class="headerlink" title="技术亮点"></a>技术亮点</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;mcpServers&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;chrome-devtools&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;npx&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;-y&quot;</span><span class="punctuation">,</span> <span class="string">&quot;chrome-devtools-mcp@latest&quot;</span><span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>一行配置接入。支持 Field Data（CrUX 真实用户数据）对比 Lab Data，给出更全面的性能评估。</p>
<h3 id="适用场景-3"><a href="#适用场景-3" class="headerlink" title="适用场景"></a>适用场景</h3><ul>
<li>AI 辅助前端开发和调试</li>
<li>自动化性能分析和优化</li>
<li>Web 应用端到端测试</li>
<li>任何需要 Agent 理解「浏览器里发生了什么」的场景</li>
</ul>
<hr>
<h2 id="5-Microsoft-PowerToys-—-老牌效率神器持续进化"><a href="#5-Microsoft-PowerToys-—-老牌效率神器持续进化" class="headerlink" title="5. Microsoft PowerToys — 老牌效率神器持续进化"></a>5. Microsoft PowerToys — 老牌效率神器持续进化</h2><blockquote>
<p>⭐ 129,637 Stars | 📈 +316 today | 🟣 C# | 📜 MIT</p>
</blockquote>
<h3 id="项目简介-4"><a href="#项目简介-4" class="headerlink" title="项目简介"></a>项目简介</h3><p>微软的 Windows 效率工具集，不需要多介绍了——FancyZones、PowerToys Run、Color Picker、File Locksmith……每一个都是 Windows 用户的效率神器。</p>
<h3 id="为什么又上热榜？"><a href="#为什么又上热榜？" class="headerlink" title="为什么又上热榜？"></a>为什么又上热榜？</h3><p>PowerToys 持续更新，最近的版本带来了新的 AI 增强功能和更多实用工具。12.9 万 Stars 的项目还能每天 +316，说明它的用户群极其活跃。</p>
<p>作为微软少数几个「真正好用」的开源项目，PowerToys 证明了大公司也能做出开发者真心喜欢的工具——前提是给团队足够的自由度。</p>
<hr>
<h2 id="今日趋势总结"><a href="#今日趋势总结" class="headerlink" title="今日趋势总结"></a>今日趋势总结</h2><h3 id="🔥-AI-Agent-基础设施爆发"><a href="#🔥-AI-Agent-基础设施爆发" class="headerlink" title="🔥 AI Agent 基础设施爆发"></a>🔥 AI Agent 基础设施爆发</h3><p>今天前 4 名里有 3 个直接和 AI Agent 相关。但关键词不再是「大模型」而是「基础设施」：</p>
<ul>
<li><strong>Tambo</strong>：Agent 的 UI 层</li>
<li><strong>PAI</strong>：Agent 的操作系统层</li>
<li><strong>Chrome DevTools MCP</strong>：Agent 的感知层</li>
</ul>
<p>这三个项目加在一起，描绘了一个完整的 Agent 工作流：AI 通过 MCP 感知浏览器环境 → 通过 PAI 规划和调度任务 → 通过 Tambo 渲染交互界面给用户。</p>
<h3 id="📊-MCP-生态持续膨胀"><a href="#📊-MCP-生态持续膨胀" class="headerlink" title="📊 MCP 生态持续膨胀"></a>📊 MCP 生态持续膨胀</h3><p>Chrome DevTools MCP 拿到 24K Stars，说明 Anthropic 提出的 MCP 协议已经成为 AI Agent 工具调用的事实标准。Google、Microsoft 等大厂纷纷拥抱，第三方工具更是遍地开花。</p>
<h3 id="🏗️-从「用-AI」到「建-AI-的家」"><a href="#🏗️-从「用-AI」到「建-AI-的家」" class="headerlink" title="🏗️ 从「用 AI」到「建 AI 的家」"></a>🏗️ 从「用 AI」到「建 AI 的家」</h3><p>今天的热榜反映了一个更大的趋势：开发者不再满足于简单地「用 AI」，而是在为 AI 构建更好的栖息环境。当基础设施足够成熟，AI Agent 才能从 Demo 走向生产。</p>
<hr>
<p><em>数据来源：GitHub Trending（2026-02-13 daily）</em></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2026-02-12T16:00:00.000Z" title="2/13/2026, 12:00:00 AM">2026-02-13</time>发表</span><span class="level-item"><time dateTime="2026-02-13T00:07:47.707Z" title="2/13/2026, 8:07:47 AM">2026-02-13</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E6%8A%A5%E9%81%93/">深度报道</a></span><span class="level-item">19 分钟读完 (大约2900个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/02/13/glm-5-agentic-engineering/">智谱 GLM-5 深度解析：744B 参数开源巨兽，从 Vibe Coding 迈向 Agentic Engineering</a></h1><div class="content"><blockquote>
<p>2026 年 2 月 11 日，智谱 AI 发布了新一代旗舰模型 GLM-5——一个 744B 参数的 MoE 开源模型，在编码和 Agent 能力上全面对齐 Claude Opus 4.5，并在多项关键指标上超越 GPT-5.2。这不只是又一个大模型的发布，而是一个信号：<strong>开源模型和闭源前沿之间的差距，正在以不可思议的速度消失。</strong></p>
</blockquote>
<p><img src="/images/glm-5-cover.png" alt="GLM-5 封面"></p>
<h2 id="一句话：GLM-5-是什么？"><a href="#一句话：GLM-5-是什么？" class="headerlink" title="一句话：GLM-5 是什么？"></a>一句话：GLM-5 是什么？</h2><p>GLM-5 是智谱 AI（Z.AI）最新发布的旗舰基座大模型。和大多数追求「聊天体验」的模型不同，GLM-5 明确瞄准了一个更大的赛道：<strong>复杂系统工程和长程 Agent 任务</strong>。</p>
<p>智谱自己给它起了个口号：**”From Vibe Coding to Agentic Engineering”**（从感觉式编程到工程化 Agent）。</p>
<p>什么意思？市面上大多数 AI 编程助手做的是「Vibe Coding」——你描述一下想要什么，模型帮你写个函数、补个代码片段。而 Agentic Engineering 是另一个级别的事情：模型需要理解整个系统架构，自主规划多步骤任务，在数百个连续操作中保持目标一致，处理依赖关系和异常情况，最终交付生产级代码。</p>
<p><strong>简单说：GLM-5 不是来帮你写代码的，它是来帮你做工程的。</strong></p>
<p><img src="/images/glm-5-vibe-vs-agentic.png" alt="从 Vibe Coding 到 Agentic Engineering"></p>
<hr>
<h2 id="架构：一个扎扎实实的规模飞跃"><a href="#架构：一个扎扎实实的规模飞跃" class="headerlink" title="架构：一个扎扎实实的规模飞跃"></a>架构：一个扎扎实实的规模飞跃</h2><table>
<thead>
<tr>
<th>指标</th>
<th>GLM-4.5&#x2F;4.7</th>
<th>GLM-5</th>
</tr>
</thead>
<tbody><tr>
<td>总参数量</td>
<td>355B</td>
<td><strong>744B</strong></td>
</tr>
<tr>
<td>活跃参数量</td>
<td>32B</td>
<td><strong>40B</strong></td>
</tr>
<tr>
<td>架构</td>
<td>MoE</td>
<td>MoE</td>
</tr>
<tr>
<td>预训练数据</td>
<td>23T tokens</td>
<td><strong>28.5T tokens</strong></td>
</tr>
<tr>
<td>注意力机制</td>
<td>标准</td>
<td><strong>DeepSeek Sparse Attention</strong></td>
</tr>
<tr>
<td>许可证</td>
<td>MIT</td>
<td><strong>MIT</strong></td>
</tr>
</tbody></table>
<p>GLM-5 的参数量翻了一倍多，预训练数据从 23T 增加到 28.5T tokens。但更值得关注的是两个技术创新：</p>
<h3 id="DeepSeek-Sparse-Attention（DSA）"><a href="#DeepSeek-Sparse-Attention（DSA）" class="headerlink" title="DeepSeek Sparse Attention（DSA）"></a>DeepSeek Sparse Attention（DSA）</h3><p>GLM-5 首次集成了 DeepSeek 发明的稀疏注意力机制。传统 Transformer 的注意力复杂度是平方级——上下文长度翻倍，计算量翻四倍。DSA 打破了这个瓶颈，让 GLM-5 在保持 200K 上下文窗口的同时，大幅降低了部署成本。</p>
<p>这也是中国 AI 社区协作的一个缩影：智谱用了 DeepSeek 的技术，而不是重新造轮子。</p>
<h3 id="Slime：异步强化学习框架"><a href="#Slime：异步强化学习框架" class="headerlink" title="Slime：异步强化学习框架"></a>Slime：异步强化学习框架</h3><p>GLM-5 训练中最关键的创新是 <strong>Slime</strong>——一个全新的异步强化学习框架（已开源在 GitHub）。</p>
<p>传统 RL 训练大模型的效率很低。Slime 通过解耦数据生成和策略更新，实现了比传统同步 RL 高 3 倍的训练吞吐量。更重要的是，它针对长程 Agent 行为做了专门的奖励建模——不是优化表面的 benchmark 数字，而是奖励任务完成的一致性。</p>
<p>这解释了为什么 GLM-5 在需要长时间持续执行的任务上表现突出。</p>
<hr>
<h2 id="Benchmark：全面对齐-Claude-Opus-4-5，多项超越-GPT-5-2"><a href="#Benchmark：全面对齐-Claude-Opus-4-5，多项超越-GPT-5-2" class="headerlink" title="Benchmark：全面对齐 Claude Opus 4.5，多项超越 GPT-5.2"></a>Benchmark：全面对齐 Claude Opus 4.5，多项超越 GPT-5.2</h2><p><img src="/images/glm-5-benchmarks.png" alt="GLM-5 Benchmark 对比"></p>
<h3 id="编码能力"><a href="#编码能力" class="headerlink" title="编码能力"></a>编码能力</h3><table>
<thead>
<tr>
<th>Benchmark</th>
<th>GLM-5</th>
<th>Claude Opus 4.5</th>
<th>GPT-5.2</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>SWE-bench Verified</td>
<td><strong>77.8</strong></td>
<td>80.9</td>
<td>80.0</td>
<td>真实 GitHub Issue 修复</td>
</tr>
<tr>
<td>SWE-bench Multilingual</td>
<td><strong>73.3</strong></td>
<td>77.5</td>
<td>-</td>
<td>多语言代码理解</td>
</tr>
<tr>
<td>Terminal-Bench 2.0</td>
<td><strong>56.2</strong></td>
<td>59.3</td>
<td>54.0</td>
<td>终端操作与系统管理</td>
</tr>
<tr>
<td>CyberGym</td>
<td><strong>43.2</strong></td>
<td>50.6</td>
<td>-</td>
<td>安全攻防任务</td>
</tr>
</tbody></table>
<p>GLM-5 在 SWE-bench（真实 GitHub 项目 bug 修复）上拿到 77.8，与 Claude Opus 4.5 的 80.9 差距仅 3.1 个百分点。对于一个开源模型来说，这是前所未有的接近。</p>
<p>在 Terminal-Bench（终端命令行操作）上，GLM-5 的 56.2 已经超过了 GPT-5.2 的 54.0。</p>
<h3 id="Agent-能力：真正的亮点"><a href="#Agent-能力：真正的亮点" class="headerlink" title="Agent 能力：真正的亮点"></a>Agent 能力：真正的亮点</h3><table>
<thead>
<tr>
<th>Benchmark</th>
<th>GLM-5</th>
<th>Claude Opus 4.5</th>
<th>GPT-5.2</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>BrowseComp</td>
<td><strong>62.0</strong></td>
<td>37.0</td>
<td>-</td>
<td>联网搜索与信息综合</td>
</tr>
<tr>
<td>BrowseComp + 上下文管理</td>
<td><strong>75.9</strong></td>
<td>-</td>
<td>65.8</td>
<td>带记忆的复杂网页任务</td>
</tr>
<tr>
<td>τ²-Bench</td>
<td><strong>89.7</strong></td>
<td>91.6</td>
<td>-</td>
<td>多工具复杂场景</td>
</tr>
<tr>
<td>Vending Bench 2</td>
<td><strong>$4,432</strong></td>
<td>$4,967</td>
<td>$3,591</td>
<td>模拟一年商业经营</td>
</tr>
<tr>
<td>MCP-Atlas</td>
<td><strong>67.8</strong></td>
<td>65.2</td>
<td>-</td>
<td>工具调用与多步骤执行</td>
</tr>
</tbody></table>
<p><strong>BrowseComp 是最炸裂的数据。</strong> GLM-5 拿到 62.0，几乎是 Claude Opus 4.5（37.0）的两倍。带上下文管理后达到 75.9，超过 GPT-5.2 的 65.8。这意味着在联网搜索、信息检索和多步网页任务上，GLM-5 是目前所有模型中最强的。</p>
<p><strong>Vending Bench 2</strong> 是最能体现「长程 Agent 能力」的测试——让 AI 经营一年的自动售货机生意，做采购决策、库存管理、定价优化。GLM-5 最终账户余额 $4,432，仅次于 Claude Opus 4.5 的 $4,967，而 GPT-5.2 只有 $3,591。</p>
<p><strong>MCP-Atlas</strong>（工具调用与多步骤执行）上，GLM-5 的 67.8 甚至反超了 Claude Opus 4.5 的 65.2。</p>
<h3 id="推理能力"><a href="#推理能力" class="headerlink" title="推理能力"></a>推理能力</h3><table>
<thead>
<tr>
<th>Benchmark</th>
<th>GLM-5</th>
<th>Claude Opus 4.5</th>
<th>GPT-5.2</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Humanity’s Last Exam（带工具）</td>
<td><strong>50.4</strong></td>
<td>43.4</td>
<td>45.5</td>
<td>人类最难测试</td>
</tr>
<tr>
<td>AIME 2026 I</td>
<td><strong>92.7</strong></td>
<td>93.3</td>
<td>-</td>
<td>数学竞赛</td>
</tr>
<tr>
<td>HMMT 2025</td>
<td><strong>96.9</strong></td>
<td>-</td>
<td>97.1</td>
<td>哈佛&#x2F;MIT 数学竞赛</td>
</tr>
<tr>
<td>GPQA-Diamond</td>
<td><strong>86.0</strong></td>
<td>87.0</td>
<td>92.4</td>
<td>博士级科学推理</td>
</tr>
</tbody></table>
<p>在 Humanity’s Last Exam（带工具）上，GLM-5 的 50.4 超过了 Claude（43.4）和 GPT-5.2（45.5）。数学竞赛 AIME 上 92.7 几乎追平 Claude 的 93.3。</p>
<hr>
<h2 id="对软件工程的意义：为什么-Agentic-Engineering-是下一个范式"><a href="#对软件工程的意义：为什么-Agentic-Engineering-是下一个范式" class="headerlink" title="对软件工程的意义：为什么 Agentic Engineering 是下一个范式"></a>对软件工程的意义：为什么 Agentic Engineering 是下一个范式</h2><p>GLM-5 的发布不只是一个模型的事。它代表了 AI 辅助软件工程正在发生的范式转移。</p>
<h3 id="从「写代码」到「做工程」"><a href="#从「写代码」到「做工程」" class="headerlink" title="从「写代码」到「做工程」"></a>从「写代码」到「做工程」</h3><p>传统 AI 编程助手（Copilot、Cursor 等）本质上是<strong>代码补全</strong>——你写一半，它帮你补另一半。即使是 Claude Code 和 Codex，也主要是在<strong>单文件或单功能</strong>层面工作。</p>
<p>GLM-5 瞄准的是另一个维度：</p>
<ul>
<li><strong>理解整个代码库的架构</strong>，而不只是当前文件</li>
<li><strong>自主规划多步骤修改方案</strong>，涉及多个文件和模块</li>
<li><strong>在数百步操作中保持目标一致</strong>，不会做到一半忘了自己在干什么</li>
<li><strong>处理依赖关系和副作用</strong>，像一个真正的工程师一样思考</li>
</ul>
<p>这正是 Vending Bench 2 测试的价值——经营一年的生意需要的不是聪明，而是<strong>持续的、可靠的决策能力</strong>。</p>
<h3 id="CC-Bench-V2：真实工程场景评测"><a href="#CC-Bench-V2：真实工程场景评测" class="headerlink" title="CC-Bench-V2：真实工程场景评测"></a>CC-Bench-V2：真实工程场景评测</h3><p>智谱自己开发的 CC-Bench-V2 专门评测「复杂软件工程」——不是算法题，而是涉及多文件、多依赖、需要架构决策的真实工程任务。GLM-5 在前端、后端和长程任务上都大幅超越前代 GLM-4.7，逼近 Claude Opus 4.5 的水准。</p>
<h3 id="工程化-Agent-的三大支柱"><a href="#工程化-Agent-的三大支柱" class="headerlink" title="工程化 Agent 的三大支柱"></a>工程化 Agent 的三大支柱</h3><p>智谱官方总结了 Agentic Engineering 的三个核心能力：</p>
<ol>
<li><strong>长程目标一致性</strong>：在几百步的连续操作中不偏离目标</li>
<li><strong>资源管理与规划</strong>：合理分配计算资源、管理上下文窗口</li>
<li><strong>多步骤依赖处理</strong>：理解任务之间的依赖关系，按正确顺序执行</li>
</ol>
<p>这三个能力恰好是目前 AI 编程助手最薄弱的环节——它们擅长写函数，但不擅长做项目。GLM-5 正在填补这个空白。</p>
<hr>
<h2 id="神秘的-Pony-Alpha：一个有趣的插曲"><a href="#神秘的-Pony-Alpha：一个有趣的插曲" class="headerlink" title="神秘的 Pony Alpha：一个有趣的插曲"></a>神秘的 Pony Alpha：一个有趣的插曲</h2><p>在 GLM-5 正式发布前，OpenRouter 上悄然出现了一个叫 <strong>“Pony Alpha”</strong> 的匿名模型，凭借出色的编码能力引发了大量关注和猜测——有人说是 DeepSeek V4，有人说是 GLM-5。</p>
<p>现在谜底揭晓：<strong>Pony Alpha 就是 GLM-5。</strong> 智谱用了一招「匿名发布，实力说话」，在模型揭面之前就已经在开发者社区积累了口碑。</p>
<hr>
<h2 id="开源-MIT-许可：最大的诚意"><a href="#开源-MIT-许可：最大的诚意" class="headerlink" title="开源 MIT 许可：最大的诚意"></a>开源 MIT 许可：最大的诚意</h2><p>GLM-5 采用 <strong>MIT 许可证</strong>——这是开源世界中最宽松的许可证：</p>
<ul>
<li>✅ 完全商用，无任何限制</li>
<li>✅ 可修改、微调、蒸馏</li>
<li>✅ 无需开源你自己的代码（没有 copyleft 义务）</li>
<li>✅ 法律风险极低</li>
</ul>
<p>对比 Meta Llama 的受限许可和其他「半开源」模型，GLM-5 给出了真正的自由。对于企业来说，这意味着可以放心地在 GLM-5 基础上构建产品，不用担心后续的许可证问题。</p>
<p>模型权重已在 HuggingFace 和 ModelScope 开放下载。</p>
<hr>
<h2 id="价格：比-Claude-便宜-7-倍"><a href="#价格：比-Claude-便宜-7-倍" class="headerlink" title="价格：比 Claude 便宜 7 倍"></a>价格：比 Claude 便宜 7 倍</h2><table>
<thead>
<tr>
<th>模型</th>
<th>输入价格&#x2F;M tokens</th>
<th>输出价格&#x2F;M tokens</th>
</tr>
</thead>
<tbody><tr>
<td>GLM-5</td>
<td><strong>~$0.80</strong></td>
<td><strong>~$3.20</strong></td>
</tr>
<tr>
<td>Claude Opus 4.5</td>
<td>$5.00</td>
<td>$25.00</td>
</tr>
<tr>
<td>GPT-5.2</td>
<td>$1.25</td>
<td>$5.00</td>
</tr>
</tbody></table>
<p>GLM-5 的 API 定价大约是 Claude Opus 4.5 的 <strong>七分之一</strong>。在性能逼近的前提下，这个价格差距对于企业级 Agent 应用来说是巨大的优势——Agent 任务通常涉及大量的多轮对话和工具调用，token 消耗量远超普通聊天。</p>
<hr>
<h2 id="不只是聊天：GLM-5-的办公生产力"><a href="#不只是聊天：GLM-5-的办公生产力" class="headerlink" title="不只是聊天：GLM-5 的办公生产力"></a>不只是聊天：GLM-5 的办公生产力</h2><p>GLM-5 不满足于做一个聊天模型。通过 Z.ai 的 Agent 模式，它可以直接生成：</p>
<ul>
<li>📄 <strong>Word 文档</strong>（.docx）：PRD、报告、教案、会议纪要</li>
<li>📊 <strong>Excel 表格</strong>（.xlsx）：财务报表、数据分析、透视表</li>
<li>📋 <strong>PDF 文件</strong>：格式化的专业文档</li>
</ul>
<p>这不是「生成文字然后你自己粘贴到 Word」，而是<strong>端到端的、带格式的、可以直接用的文档</strong>。支持多轮迭代优化，像一个真正的文档工程师。</p>
<hr>
<h2 id="生态兼容：无缝接入现有工具链"><a href="#生态兼容：无缝接入现有工具链" class="headerlink" title="生态兼容：无缝接入现有工具链"></a>生态兼容：无缝接入现有工具链</h2><p>GLM-5 已经支持主流的 Agent 编程工具：</p>
<ul>
<li><strong>Claude Code</strong>：直接替换模型为 <code>glm-5</code></li>
<li><strong>OpenCode &#x2F; Cline &#x2F; Roo Code</strong>：通过 GLM Coding Plan 接入</li>
<li><strong>OpenRouter</strong>：已上线，可立即调用</li>
<li><strong>vLLM &#x2F; SGLang</strong>：支持本地部署</li>
<li><strong>国产芯片</strong>：支持华为昇腾、摩尔线程、寒武纪、昆仑芯、燧原等</li>
</ul>
<p>这意味着你不需要改变现有的工作流，就可以把 GLM-5 接入你的 Agent 系统。</p>
<hr>
<h2 id="全球视角：开源-AI-的分水岭"><a href="#全球视角：开源-AI-的分水岭" class="headerlink" title="全球视角：开源 AI 的分水岭"></a>全球视角：开源 AI 的分水岭</h2><p>让我们把视角拉远一点。</p>
<p><strong>一年前</strong>，开源模型和闭源前沿之间的差距是巨大的。最好的开源模型在 SWE-bench 上可能只有 50% 多的成绩，而 Claude 和 GPT 已经接近 80%。</p>
<p><strong>现在</strong>，GLM-5 在 SWE-bench 上拿到 77.8%，在 BrowseComp 上甚至碾压闭源模型，在 Vending Bench 的长程 Agent 任务上逼近 Claude。</p>
<p>这个趋势的意义远超技术本身：</p>
<ol>
<li><p><strong>企业 build vs buy 的天平正在倾斜</strong>。当开源模型性能够用且可以完全控制时，为什么要给 Anthropic 或 OpenAI 交高额 API 费用？</p>
</li>
<li><p><strong>Agent 能力成为新赛场</strong>。GLM-5 不是在聊天能力上竞争，而是在「做工作」的能力上竞争。这是 AI 从工具变成同事的关键一步。</p>
</li>
<li><p><strong>中国 AI 的技术实力不容忽视</strong>。智谱在香港 IPO 募资 43.5 亿港元后，把资金投入了实实在在的技术——GLM-5 的 MIT 开源不是姿态，而是对自身技术实力的自信。</p>
</li>
</ol>
<hr>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>GLM-5 证明了一件事：<strong>在 2026 年，最好的开源模型已经不再是闭源模型的「平替」，而是真正的竞争者。</strong></p>
<p>对于软件工程师来说，一个能在长程任务中保持可靠、在真实工程场景中逼近 Claude Opus 4.5 表现、价格便宜 7 倍、还完全开源的模型——很难不认真对待。</p>
<p>Agentic Engineering 不再是 PPT 上的概念。GLM-5 把它变成了可以跑的代码。</p>
<hr>
<p><em>数据来源：智谱 AI 官方博客、BuildFastWithAI、Reuters、Bloomberg、SCMP | 2026 年 2 月 13 日</em></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2026-02-12T02:00:00.000Z" title="2/12/2026, 10:00:00 AM">2026-02-12</time>发表</span><span class="level-item"><time dateTime="2026-02-12T02:03:04.280Z" title="2/12/2026, 10:03:04 AM">2026-02-12</time>更新</span><span class="level-item">9 分钟读完 (大约1350个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/02/12/2026-02-12-morning-news/">2026年02月12日早间要闻</a></h1><div class="content"><h2 id="📰-今日要闻"><a href="#📰-今日要闻" class="headerlink" title="📰 今日要闻"></a>📰 今日要闻</h2><h3 id="1-字节跳动-Seedance-2-0-引爆-A-股传媒板块"><a href="#1-字节跳动-Seedance-2-0-引爆-A-股传媒板块" class="headerlink" title="1. 字节跳动 Seedance 2.0 引爆 A 股传媒板块"></a>1. 字节跳动 Seedance 2.0 引爆 A 股传媒板块</h3><p>字节跳动发布 Seedance 2.0 视频生成模型，支持从文本或图像直接生成电影级品质的视频内容。该消息直接引爆 A 股传媒板块，中文在线、光线传媒、掌阅科技等个股单日涨幅超 10% 甚至触及 20% 涨停板。市场将其类比为”2025年的 DeepSeek 时刻”，认为这标志着 AI 视频生成技术进入新阶段。不过需要注意的是，多数被炒作的公司缺乏实际业绩支撑，主要靠题材轮动推动。</p>
<h3 id="2-央行重申适度宽松货币政策"><a href="#2-央行重申适度宽松货币政策" class="headerlink" title="2. 央行重申适度宽松货币政策"></a>2. 央行重申适度宽松货币政策</h3><p>中国人民银行发布《2025年第四季度货币政策执行报告》，明确将继续实施适度宽松货币政策，灵活运用降准降息等工具，保持流动性充裕和融资条件宽松。报告显示金融总量增长、融资成本下行、重点领域支持有力。这一表态对 A 股和宏观经济预期构成正面支撑。</p>
<h3 id="3-美国-1-月就业数据超预期"><a href="#3-美国-1-月就业数据超预期" class="headerlink" title="3. 美国 1 月就业数据超预期"></a>3. 美国 1 月就业数据超预期</h3><p>美国劳工部公布 1 月非农就业数据，新增就业 13 万人，大幅超出经济学家预期的 7.5 万人，失业率意外降至 4.3%。强劲的就业数据缓解了经济放缓担忧，但同时也强化了美联储”higher for longer”的利率预期。市场目前预计 2026 年全年利率将维持在 3.5% 以上。</p>
<h3 id="4-AI-供应链瓶颈：电子布价格跳涨"><a href="#4-AI-供应链瓶颈：电子布价格跳涨" class="headerlink" title="4. AI 供应链瓶颈：电子布价格跳涨"></a>4. AI 供应链瓶颈：电子布价格跳涨</h3><p>AI 基础设施需求持续拉动上游材料紧缺。7628 电子布（电子级玻璃纤维布）价格从 2025 年 9 月底的 4.15 元&#x2F;米涨至目前的 4.75 元&#x2F;米，2025Q4 至今已累计上涨约 15%。A 股电子布概念集体爆发，宏和科技、国际复材、中材科技等多股涨停创历史新高。电子布是覆铜板制造的关键材料，直接影响 PCB 和芯片封装成本。</p>
<h3 id="5-美国禁止中国随锐科技收购美企"><a href="#5-美国禁止中国随锐科技收购美企" class="headerlink" title="5. 美国禁止中国随锐科技收购美企"></a>5. 美国禁止中国随锐科技收购美企</h3><p>美国司法部依据 1950 年《国防生产法》提起诉讼，要求中国随锐科技集团从加州丘比特系统公司（Jupiter Systems）撤资，理由是保护国家安全。这是中美科技脱钩趋势的又一案例，显示美国在科技并购审查方面持续收紧。</p>
<hr>
<h2 id="📈-美股重点关注（2月11日收盘）"><a href="#📈-美股重点关注（2月11日收盘）" class="headerlink" title="📈 美股重点关注（2月11日收盘）"></a>📈 美股重点关注（2月11日收盘）</h2><h3 id="微软-MSFT-—-404-37（-2-15-）"><a href="#微软-MSFT-—-404-37（-2-15-）" class="headerlink" title="微软 MSFT — $404.37（-2.15%）"></a>微软 MSFT — $404.37（-2.15%）</h3><ul>
<li>Azure 收入增长 38% 符合预期，但市场持续忧虑 AI 资本开支的投资回报率</li>
<li>股价从 2025 年高点 $555.45 回撤超过 20%，估值回归合理区间（PE 25.8，EPS $15.65）</li>
<li>下一催化剂：Q1 2026 财报（4月29日），核心看 Copilot 渗透率和 Azure 增长加速</li>
<li>分析师平均目标价 $591.95，当前价位存在较大上行空间</li>
</ul>
<h3 id="谷歌-GOOGL-—-322-86（-2-53-）"><a href="#谷歌-GOOGL-—-322-86（-2-53-）" class="headerlink" title="谷歌 GOOGL — $322.86（-2.53%）"></a>谷歌 GOOGL — $322.86（-2.53%）</h3><ul>
<li>2026 年资本开支指引高达 $1750-1850 亿美元（同比翻倍），市场震惊</li>
<li>“资本焚烧”担忧持续拖累股价，从历史高点 $349 回落约 7.5%</li>
<li>核心看点：广告业务韧性 + Gemini 模型商业化进展 + 反垄断案进展</li>
<li>PE 29.8，估值不算离谱，关键是证明 AI 投资能转化为收入增长</li>
</ul>
<h3 id="英伟达-NVDA-—-190-01（-0-75-）"><a href="#英伟达-NVDA-—-190-01（-0-75-）" class="headerlink" title="英伟达 NVDA — $190.01（+0.75%）"></a>英伟达 NVDA — $190.01（+0.75%）</h3><ul>
<li>逆市上涨，盘中一度冲高至 $193.26，Blackwell 芯片周期需求持续强劲</li>
<li>合作伙伴 Vertiv 发布亮眼财报（股价+15%），间接提振 NVDA 信心</li>
<li><strong>2月25日财报是近期最大催化剂</strong>，市场期待极高</li>
<li>风险点：25% AI 硬件关税（”Trump Cut”）由超级云厂商自行消化，可能抑制采购量</li>
<li>当前市值 4.63 万亿美元，PE 46.7，1年目标价 $253.79</li>
</ul>
<h3 id="AMD-—-213-58（持平）"><a href="#AMD-—-213-58（持平）" class="headerlink" title="AMD — $213.58（持平）"></a>AMD — $213.58（持平）</h3><ul>
<li>Q4 财报后股价已回调约 11%，盘中波动剧烈（$209-$219 区间）</li>
<li>MI300 系列数据中心 GPU 出货在增长，但与 NVDA 的差距仍然明显</li>
<li>PE 81.8 偏高，需要持续证明在 AI GPU 市场的份额扩张</li>
<li>从 52 周高点 $267 回落约 20%，处于估值消化期</li>
</ul>
<h3 id="阿里巴巴-BABA-—-168-39（-0-69-）"><a href="#阿里巴巴-BABA-—-168-39（-0-69-）" class="headerlink" title="阿里巴巴 BABA — $168.39（-0.69%）"></a>阿里巴巴 BABA — $168.39（-0.69%）</h3><ul>
<li>重金押注 AI：投入 30 亿元（约 $4.31 亿）推广通义千问 Qwen AI 应用</li>
<li>20 亿美元投资 Zelos Technology 加强物流基础设施能力</li>
<li><strong>2月19日 Q3 财报在即</strong>，云智能增长和 AI 布局是关键看点</li>
<li>PE 22.5 估值合理，52 周高点 $192.67，当前距高点约 13%</li>
</ul>
<hr>
<h2 id="📊-市场大势"><a href="#📊-市场大势" class="headerlink" title="📊 市场大势"></a>📊 市场大势</h2><ul>
<li><strong>纳斯达克综合指数</strong>：23,102.47（-0.6%），连续两日收跌</li>
<li><strong>道琼斯工业指数</strong>：50,188.14（+0.1%），连续三日创历史新高</li>
<li><strong>标普500</strong>：6,941.81（-0.3%）</li>
</ul>
<p>市场呈现明显分化格局——传统工业、金融板块走强（道指创新高），而科技成长股承压（纳指回调）。核心矛盾在于：AI 资本开支螺旋式上升 vs 高利率环境下投资回报周期拉长。</p>
<p><strong>关键日期：</strong></p>
<ul>
<li>2&#x2F;13（周五）：1月 CPI 数据发布，将决定短期市场方向</li>
<li>2&#x2F;19：阿里巴巴 Q3 财报</li>
<li>2&#x2F;25：英伟达 Q4 财报</li>
</ul>
<blockquote>
<p>免责声明：以上内容仅为信息分享，不构成投资建议。</p>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2026-02-11T16:00:00.000Z" title="2/12/2026, 12:00:00 AM">2026-02-12</time>发表</span><span class="level-item"><time dateTime="2026-02-12T05:02:24.085Z" title="2/12/2026, 1:02:24 PM">2026-02-12</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%8A%80%E6%9C%AF%E8%B0%83%E7%A0%94/">技术调研</a></span><span class="level-item">20 分钟读完 (大约3059个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/02/12/ai-ui-testing-automation-2026/">2026年AI驱动UI测试自动化全景：当大模型学会「看屏幕操作电脑」</a></h1><div class="content"><blockquote>
<p>GPT-5.3 在 OSWorld 上拿到 64.7%，Claude Opus 4.6 达到 72.7% 超越人类水平（72.36%），UI-TARS-2 在 12 个 Poki 游戏上通关率 100%——2026 年 2 月，AI 操控电脑的能力正在以不可思议的速度进化。本文全面梳理基于最新一线大模型的 Agentic UI 测试框架，聚焦 Windows + Android 双平台。</p>
</blockquote>
<h2 id="核心变化：从「定位元素」到「看屏幕操作」"><a href="#核心变化：从「定位元素」到「看屏幕操作」" class="headerlink" title="核心变化：从「定位元素」到「看屏幕操作」"></a>核心变化：从「定位元素」到「看屏幕操作」</h2><p>传统 UI 自动化测试依赖 XPath、CSS Selector、Accessibility ID 等定位器。UI 一改，测试就崩。</p>
<p>2026 年的新范式彻底不同：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">截图 → 多模态大模型理解界面 → 规划操作步骤 → 模拟鼠标键盘执行 → 截图验证结果</span><br></pre></td></tr></table></figure>

<p><strong>不再需要任何定位器、不依赖 DOM 结构、不怕 UI 改版。</strong> 只要人类能看懂屏幕，AI 就能操作。</p>
<p>这背后的核心驱动力是<strong>多模态大模型的能力飞跃</strong>。让我们先看看 2026 年 2 月的最新战况。</p>
<hr>
<h2 id="一、模型层：谁在驱动-Computer-Use？"><a href="#一、模型层：谁在驱动-Computer-Use？" class="headerlink" title="一、模型层：谁在驱动 Computer Use？"></a>一、模型层：谁在驱动 Computer Use？</h2><h3 id="OSWorld-Benchmark：AI-操控桌面的黄金标准"><a href="#OSWorld-Benchmark：AI-操控桌面的黄金标准" class="headerlink" title="OSWorld Benchmark：AI 操控桌面的黄金标准"></a>OSWorld Benchmark：AI 操控桌面的黄金标准</h3><p>OSWorld 是评估 AI 操控真实桌面环境（Windows&#x2F;Linux&#x2F;Mac）能力的权威 benchmark，包含文件管理、办公软件操作、浏览器任务等数百项真实任务。</p>
<p><strong>2026 年 2 月最新排名：</strong></p>
<table>
<thead>
<tr>
<th>模型&#x2F;方案</th>
<th>OSWorld 得分</th>
<th>发布时间</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Anthropic BJudge (Claude Opus 4.6)</strong></td>
<td><strong>72.7%</strong></td>
<td>2026.02</td>
<td>🏆 超越人类水平（72.36%）</td>
</tr>
<tr>
<td>UiPath Screen Agent + Claude Opus 4.5</td>
<td>OSWorld-Verified #1</td>
<td>2026.01</td>
<td>企业级方案</td>
</tr>
<tr>
<td><strong>GPT-5.3 Codex</strong></td>
<td><strong>64.7%</strong></td>
<td>2026.02</td>
<td>历史最高单模型得分</td>
</tr>
<tr>
<td>UI-TARS-1.5</td>
<td>42.5%</td>
<td>2025.04</td>
<td>开源最强</td>
</tr>
<tr>
<td>OpenAI CUA (GPT-5 架构)</td>
<td>36.4%</td>
<td>2025</td>
<td>Operator 产品底层</td>
</tr>
<tr>
<td>Claude 3.7 Sonnet</td>
<td>28%</td>
<td>2024</td>
<td>Computer Use 首发版</td>
</tr>
</tbody></table>
<p><strong>关键信号</strong>：仅仅一年时间，从 28% 到 72.7%，<strong>AI 在桌面操控任务上已经超越了普通人类水平</strong>。</p>
<h3 id="最新一线模型的-Computer-Use-能力对比"><a href="#最新一线模型的-Computer-Use-能力对比" class="headerlink" title="最新一线模型的 Computer Use 能力对比"></a>最新一线模型的 Computer Use 能力对比</h3><table>
<thead>
<tr>
<th>能力维度</th>
<th>Claude Opus 4.6</th>
<th>GPT-5.3 Codex</th>
<th>Gemini 3 Pro</th>
<th>UI-TARS-2</th>
</tr>
</thead>
<tbody><tr>
<td>OSWorld（桌面操控）</td>
<td>72.7% 🏆</td>
<td>64.7%</td>
<td>-</td>
<td>42.5%*</td>
</tr>
<tr>
<td>上下文窗口</td>
<td>1M tokens</td>
<td>400K tokens</td>
<td>1M+</td>
<td>本地部署</td>
</tr>
<tr>
<td>Agent Teams（多 Agent 协作）</td>
<td>✅</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
</tr>
<tr>
<td>Computer Use API</td>
<td>原生支持</td>
<td>原生支持</td>
<td>-</td>
<td>pyautogui</td>
</tr>
<tr>
<td>BrowseComp（浏览器搜索）</td>
<td>84.0%</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>视频理解</td>
<td>图片+文本</td>
<td>原生视频+音频</td>
<td>原生多模态</td>
<td>图片</td>
</tr>
<tr>
<td>成本（输入&#x2F;1M tokens）</td>
<td>$5</td>
<td>$1.25</td>
<td>-</td>
<td>免费（本地）</td>
</tr>
<tr>
<td>Android 支持</td>
<td>需搭配框架</td>
<td>需搭配框架</td>
<td>需搭配框架</td>
<td>原生</td>
</tr>
<tr>
<td>Windows 支持</td>
<td>原生 Computer Use</td>
<td>原生 Computer Use</td>
<td>-</td>
<td>原生</td>
</tr>
</tbody></table>
<blockquote>
<p>*UI-TARS-2 的 OSWorld 得分基于 2025.09 版本，最新版可能更高。其 benchmark 优势在 ScreenSpot（UI 定位精度）上更明显，达到 94.2%。</p>
</blockquote>
<hr>
<h2 id="二、框架层：把大模型能力变成可用的测试工具"><a href="#二、框架层：把大模型能力变成可用的测试工具" class="headerlink" title="二、框架层：把大模型能力变成可用的测试工具"></a>二、框架层：把大模型能力变成可用的测试工具</h2><p>光有模型不够，还需要框架来编排 Agent 工作流。以下是 2026 年最值得关注的 Agentic 测试框架。</p>
<h3 id="1-Cua-—-开源-Computer-Use-Agent-平台（⭐12-4K）"><a href="#1-Cua-—-开源-Computer-Use-Agent-平台（⭐12-4K）" class="headerlink" title="1. Cua — 开源 Computer Use Agent 平台（⭐12.4K）"></a>1. Cua — 开源 Computer Use Agent 平台（⭐12.4K）</h3><p><strong>GitHub</strong>：<a target="_blank" rel="noopener" href="https://github.com/trycua/cua">trycua&#x2F;cua</a> | MIT 许可</p>
<p><strong>这是 2026 年最值得关注的新项目。</strong> Cua 是一个专门为「AI 操控真实电脑」设计的开源平台，三层架构：</p>
<p><strong>Layer 1 — 沙盒环境：</strong></p>
<table>
<thead>
<tr>
<th>环境类型</th>
<th>平台</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Cloud Sandbox</td>
<td>Linux&#x2F;Windows&#x2F;macOS</td>
<td>托管云环境，开箱即用</td>
</tr>
<tr>
<td>Docker 容器</td>
<td>Linux</td>
<td>轻量级桌面环境</td>
</tr>
<tr>
<td>QEMU 虚拟机</td>
<td>Linux&#x2F;Windows 11&#x2F;<strong>Android 11</strong></td>
<td>Docker 内运行完整 OS</td>
</tr>
<tr>
<td>Lume</td>
<td>macOS&#x2F;Linux</td>
<td>Apple Silicon 原生虚拟化</td>
</tr>
<tr>
<td>Windows Sandbox</td>
<td>Windows</td>
<td>原生 Windows 沙盒</td>
</tr>
</tbody></table>
<p><strong>Layer 2 — Computer SDK：</strong><br>统一的 Python&#x2F;TypeScript API，截图、鼠标点击、键盘输入、Shell 命令，一套代码跑所有沙盒。</p>
<p><strong>Layer 3 — Agent 框架：</strong></p>
<ul>
<li>100+ 模型支持（Claude &#x2F; GPT &#x2F; Gemini &#x2F; 开源模型）</li>
<li>预构建的 Agent Loop，专为 Computer Use 优化</li>
<li><strong>内置 Android 支持</strong>（QEMU 虚拟化 + CuaBot）</li>
</ul>
<p><strong>为什么 Cua 对 UI 测试很重要？</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> cua <span class="keyword">import</span> Agent, Sandbox</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建隔离的 Windows 沙盒</span></span><br><span class="line">sandbox = Sandbox.create(<span class="string">&quot;windows-11&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用 Claude Opus 4.6 驱动 Agent</span></span><br><span class="line">agent = Agent(model=<span class="string">&quot;claude-opus-4.6&quot;</span>, sandbox=sandbox)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自然语言描述测试任务</span></span><br><span class="line">agent.run(<span class="string">&quot;打开计算器，计算 123 × 456，验证结果是否为 56088&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>不需要写任何定位器，不需要了解应用内部结构。Agent 会自己截屏、理解界面、操作、验证结果。</p>
<h3 id="2-UiPath-Screen-Agent-—-企业级-AI-自动化（OSWorld-Verified-1）"><a href="#2-UiPath-Screen-Agent-—-企业级-AI-自动化（OSWorld-Verified-1）" class="headerlink" title="2. UiPath Screen Agent — 企业级 AI 自动化（OSWorld-Verified #1）"></a>2. UiPath Screen Agent — 企业级 AI 自动化（OSWorld-Verified #1）</h3><p>UiPath 是全球最大的 RPA 公司。2025-2026 年，他们推出了 <strong>Screen Agent</strong>：</p>
<ul>
<li>2025.09：基于 <strong>GPT-5</strong> 拿到 OSWorld #1</li>
<li>2026.01：切换到 <strong>Claude Opus 4.5</strong> 后拿到 OSWorld-Verified #1（369 项真实桌面任务）</li>
</ul>
<p>Screen Agent 代表了传统 RPA 与最新大模型的融合：用 UiPath 的企业级基础设施（机器人编排、权限管理、审计日志）+ 顶级大模型的视觉理解能力。</p>
<p><strong>适合</strong>：已有 UiPath 基础设施的企业团队。</p>
<h3 id="3-微软-UFO³-OmniParser-V2（⭐8K-⭐24-4K）"><a href="#3-微软-UFO³-OmniParser-V2（⭐8K-⭐24-4K）" class="headerlink" title="3. 微软 UFO³ + OmniParser V2（⭐8K + ⭐24.4K）"></a>3. 微软 UFO³ + OmniParser V2（⭐8K + ⭐24.4K）</h3><p><strong>GitHub</strong>：<a target="_blank" rel="noopener" href="https://github.com/microsoft/UFO">microsoft&#x2F;UFO</a> | <a target="_blank" rel="noopener" href="https://github.com/microsoft/OmniParser">microsoft&#x2F;OmniParser</a></p>
<p>微软自家出品，<strong>Windows 原生 Agent 操作系统</strong>。</p>
<p><strong>OmniParser V2</strong> 是目前最强的屏幕解析引擎：把任意截图转成结构化 UI 元素列表。支持开箱接入 GPT-5.x &#x2F; Claude &#x2F; DeepSeek R1 &#x2F; Qwen 2.5VL 等模型。配套 <strong>OmniTool</strong> 提供 Docker 化 Windows 11 VM。</p>
<p><strong>UFO³</strong> 的核心优势是 <strong>Windows 深度集成</strong>：</p>
<ul>
<li><strong>双通道感知</strong>：Windows UIA API（控件树）+ 视觉模型（OmniParser），精确性和灵活性兼得</li>
<li><strong>智能执行选择</strong>：自动判断用 API 直接调用还是模拟 GUI 操作</li>
<li><strong>多设备编排</strong>（Galaxy 模式）：DAG 任务分解 + 异步并行 + 跨设备协作</li>
</ul>
<p><strong>演进路线</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">UFO (2024.02) → UFO² (2025.04) → UFO³ Galaxy (2025.11)</span><br><span class="line">单设备 Agent  → Desktop AgentOS → 多设备编排</span><br></pre></td></tr></table></figure>

<p><strong>适合</strong>：Windows 桌面应用为核心的测试场景，尤其是需要操作 Office、Visual Studio 等微软生态软件。</p>
<h3 id="4-字节跳动-UI-TARS-Midscene-js（⭐9-5K-⭐27-8K-⭐11-7K）"><a href="#4-字节跳动-UI-TARS-Midscene-js（⭐9-5K-⭐27-8K-⭐11-7K）" class="headerlink" title="4. 字节跳动 UI-TARS + Midscene.js（⭐9.5K + ⭐27.8K + ⭐11.7K）"></a>4. 字节跳动 UI-TARS + Midscene.js（⭐9.5K + ⭐27.8K + ⭐11.7K）</h3><p><strong>GitHub</strong>：<a target="_blank" rel="noopener" href="https://github.com/bytedance/UI-TARS">bytedance&#x2F;UI-TARS</a> | <a target="_blank" rel="noopener" href="https://github.com/bytedance/UI-TARS-desktop">bytedance&#x2F;UI-TARS-desktop</a> | <a target="_blank" rel="noopener" href="https://github.com/web-infra-dev/midscene">web-infra-dev&#x2F;midscene</a></p>
<p><strong>UI-TARS</strong> 是字节开源的多模态 GUI Agent 模型，基于 Qwen2.5-VL。它和商业模型走的是不同路线——<strong>可本地部署、零 API 成本</strong>。</p>
<p>UI-TARS 的独特优势：</p>
<ul>
<li><strong>UI 定位精度最高</strong>：ScreenSpot-V2 达 94.2%（超 GPT 87.9%、Claude 87.6%）</li>
<li><strong>Windows + Android 双平台原生支持</strong>：提供 COMPUTER_USE 和 MOBILE_USE 两套 Prompt 模板</li>
<li><strong>UI-TARS-2</strong>（2025.09）：All-In-One Agent 模型，加入 Game、Code、Tool Use</li>
<li><strong>7B 模型可本地部署</strong>：一张消费级 GPU 即可运行</li>
</ul>
<p><strong>Midscene.js</strong> 是配套的测试框架（v1.0 已发布），用自然语言写测试：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 自然语言描述操作</span></span><br><span class="line"><span class="keyword">await</span> agent.<span class="title function_">aiAction</span>(<span class="string">&#x27;点击搜索框，输入 &quot;AI testing&quot;，按回车&#x27;</span>);</span><br><span class="line"><span class="keyword">await</span> agent.<span class="title function_">aiAssert</span>(<span class="string">&#x27;搜索结果中包含相关内容&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> data = <span class="keyword">await</span> agent.<span class="title function_">aiExtract</span>(<span class="string">&#x27;提取前3个搜索结果的标题&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>全平台支持：Web（Puppeteer&#x2F;Playwright）+ Android（adb）+ iOS（WebDriverAgent）</p>
<p><strong>适合</strong>：追求零成本本地部署、同时覆盖桌面和移动端的团队。</p>
<h3 id="5-AskUI-Vision-Agent-—-企业级跨平台（⭐501）"><a href="#5-AskUI-Vision-Agent-—-企业级跨平台（⭐501）" class="headerlink" title="5. AskUI Vision Agent — 企业级跨平台（⭐501）"></a>5. AskUI Vision Agent — 企业级跨平台（⭐501）</h3><p><strong>GitHub</strong>：<a target="_blank" rel="noopener" href="https://github.com/askui/vision-agent">askui&#x2F;vision-agent</a></p>
<p>Python SDK，支持 Windows &#x2F; Mac &#x2F; Linux &#x2F; Android &#x2F; iOS &#x2F; Citrix。独特优势：</p>
<ul>
<li><strong>Windows 后台自动化</strong>：Agent 创建独立会话，不占用前台鼠标键盘</li>
<li>支持热插拔模型 + 本地部署</li>
<li>Agent OS 底层设备控制器</li>
</ul>
<p><strong>适合</strong>：企业环境，对安全性和稳定性有要求。</p>
<h3 id="6-Arbigent-—-Android-x2F-iOS-场景分解测试（⭐505）"><a href="#6-Arbigent-—-Android-x2F-iOS-场景分解测试（⭐505）" class="headerlink" title="6. Arbigent — Android&#x2F;iOS 场景分解测试（⭐505）"></a>6. Arbigent — Android&#x2F;iOS 场景分解测试（⭐505）</h3><p><strong>GitHub</strong>：<a target="_blank" rel="noopener" href="https://github.com/takahirom/arbigent">takahirom&#x2F;arbigent</a></p>
<p>核心创新：<strong>场景分解（Scenario Breakdown）</strong>。把复杂的端到端测试拆成多个有依赖关系的子场景，每个子场景独立运行和验证，大幅提高 AI 测试的可预测性。</p>
<p>GUI 操作界面，非开发人员也能上手。支持 OpenAI &#x2F; Gemini &#x2F; Claude 等多种模型。</p>
<p><strong>适合</strong>：移动端 QA 团队。</p>
<hr>
<h2 id="三、学术前沿：正在孵化的下一代技术"><a href="#三、学术前沿：正在孵化的下一代技术" class="headerlink" title="三、学术前沿：正在孵化的下一代技术"></a>三、学术前沿：正在孵化的下一代技术</h2><table>
<thead>
<tr>
<th>项目</th>
<th>出处</th>
<th>核心贡献</th>
<th>平台</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Scaling Agents for CU</strong></td>
<td>Anthropic (2026.02)</td>
<td>BJudge + 多轮执行，OSWorld 72.6% 超越人类</td>
<td>桌面</td>
</tr>
<tr>
<td><strong>AUITestAgent</strong></td>
<td>北大</td>
<td>从自然语言需求自动生成 GUI 功能测试</td>
<td>Android</td>
</tr>
<tr>
<td><strong>VisionDroid</strong></td>
<td>学术界</td>
<td>MLLM 功能感知探索 + 非崩溃 bug 检测</td>
<td>Android</td>
</tr>
<tr>
<td><strong>DroidAgent</strong></td>
<td>KAIST</td>
<td>意图驱动自主探索，自动生成 UIAutomator2 脚本</td>
<td>Android</td>
</tr>
<tr>
<td><strong>CogAgent</strong></td>
<td>清华&#x2F;智谱</td>
<td>双分辨率视觉编码器，专为 GUI Agent 设计</td>
<td>双平台</td>
</tr>
<tr>
<td><strong>AppAgent</strong></td>
<td>腾讯</td>
<td>多模态 Agent 像用户操作手机，含自主学习阶段</td>
<td>Android</td>
</tr>
</tbody></table>
<p>论文合集：<a target="_blank" rel="noopener" href="https://github.com/showlab/Awesome-GUI-Agent">Awesome-GUI-Agent</a>（⭐1.1K），持续更新。</p>
<hr>
<h2 id="四、横向对比：该选哪个？"><a href="#四、横向对比：该选哪个？" class="headerlink" title="四、横向对比：该选哪个？"></a>四、横向对比：该选哪个？</h2><table>
<thead>
<tr>
<th>方案</th>
<th>Windows</th>
<th>Android</th>
<th>最新模型支持</th>
<th>开源</th>
<th>成熟度</th>
<th>成本</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Cua</strong></td>
<td>✅ 沙盒</td>
<td>✅ QEMU</td>
<td>Claude&#x2F;GPT&#x2F;Gemini&#x2F;开源</td>
<td>✅ MIT</td>
<td>活跃开发</td>
<td>免费+API</td>
</tr>
<tr>
<td><strong>UiPath Screen Agent</strong></td>
<td>✅ 原生</td>
<td>❌</td>
<td>Claude Opus 4.5&#x2F;GPT-5</td>
<td>❌ 商业</td>
<td>生产级</td>
<td>企业许可</td>
</tr>
<tr>
<td><strong>UFO³ + OmniParser</strong></td>
<td>✅✅ 最深</td>
<td>❌</td>
<td>GPT-5.x&#x2F;Claude&#x2F;DeepSeek&#x2F;Qwen</td>
<td>✅</td>
<td>生产级</td>
<td>免费+API</td>
</tr>
<tr>
<td><strong>UI-TARS + Midscene</strong></td>
<td>✅</td>
<td>✅ 原生</td>
<td>UI-TARS-2（本地）</td>
<td>✅</td>
<td>v1.0</td>
<td>完全免费</td>
</tr>
<tr>
<td><strong>AskUI</strong></td>
<td>✅</td>
<td>✅</td>
<td>多模型</td>
<td>部分</td>
<td>商业可用</td>
<td>SaaS</td>
</tr>
<tr>
<td><strong>Arbigent</strong></td>
<td>❌</td>
<td>✅✅</td>
<td>多模型</td>
<td>✅</td>
<td>早期</td>
<td>免费+API</td>
</tr>
</tbody></table>
<hr>
<h2 id="五、实战推荐方案"><a href="#五、实战推荐方案" class="headerlink" title="五、实战推荐方案"></a>五、实战推荐方案</h2><h3 id="方案-A：最强桌面能力（Claude-Opus-4-6-Cua-x2F-UFO³）"><a href="#方案-A：最强桌面能力（Claude-Opus-4-6-Cua-x2F-UFO³）" class="headerlink" title="方案 A：最强桌面能力（Claude Opus 4.6 + Cua&#x2F;UFO³）"></a>方案 A：最强桌面能力（Claude Opus 4.6 + Cua&#x2F;UFO³）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Claude Opus 4.6 (72.7% OSWorld) + Cua 沙盒 或 UFO³ 框架</span><br></pre></td></tr></table></figure>

<ul>
<li>当前桌面操控 SOTA，超越人类水平</li>
<li>Cua 提供隔离沙盒环境，安全可控</li>
<li>UFO³ 提供 Windows 原生深度集成</li>
<li><strong>成本</strong>：$5&#x2F;1M input tokens，适合高价值测试场景</li>
</ul>
<h3 id="方案-B：性价比之选（GPT-5-3-Codex-Cua）"><a href="#方案-B：性价比之选（GPT-5-3-Codex-Cua）" class="headerlink" title="方案 B：性价比之选（GPT-5.3 Codex + Cua）"></a>方案 B：性价比之选（GPT-5.3 Codex + Cua）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GPT-5.3 Codex (64.7% OSWorld) + Cua 沙盒</span><br></pre></td></tr></table></figure>

<ul>
<li>单模型历史最高 OSWorld 得分</li>
<li>成本仅 Claude 的 1&#x2F;4（$1.25&#x2F;1M input tokens）</li>
<li>原生视频+音频理解能力</li>
<li><strong>适合</strong>：大规模回归测试，对成本敏感</li>
</ul>
<h3 id="方案-C：零成本本地部署（UI-TARS-Midscene-js）"><a href="#方案-C：零成本本地部署（UI-TARS-Midscene-js）" class="headerlink" title="方案 C：零成本本地部署（UI-TARS + Midscene.js）"></a>方案 C：零成本本地部署（UI-TARS + Midscene.js）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UI-TARS-1.5-7B（本地 GPU）+ Midscene.js 框架</span><br></pre></td></tr></table></figure>

<ul>
<li>Windows + Android 双平台原生覆盖</li>
<li>零 API 费用，一张 GPU 搞定</li>
<li>Midscene.js 自然语言写测试，开发者友好</li>
<li><strong>适合</strong>：有 GPU 资源、追求长期低成本运营</li>
</ul>
<h3 id="方案-D：企业级落地（UiPath-Claude-Opus-4-5）"><a href="#方案-D：企业级落地（UiPath-Claude-Opus-4-5）" class="headerlink" title="方案 D：企业级落地（UiPath + Claude Opus 4.5）"></a>方案 D：企业级落地（UiPath + Claude Opus 4.5）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UiPath Screen Agent + Claude Opus 4.5</span><br></pre></td></tr></table></figure>

<ul>
<li>OSWorld-Verified 认证第一</li>
<li>企业级基础设施（编排、权限、审计）</li>
<li><strong>适合</strong>：已有 RPA 基础设施的大型企业</li>
</ul>
<hr>
<h2 id="六、趋势判断"><a href="#六、趋势判断" class="headerlink" title="六、趋势判断"></a>六、趋势判断</h2><p><strong>1. Computer Use 已超越人类水平</strong><br>Claude Opus 4.6 在 OSWorld 上达到 72.7%，超越人类的 72.36%。这是一个里程碑——意味着在标准化桌面任务上，AI Agent 已经比普通人更准确。</p>
<p><strong>2. 商业模型和开源模型走向不同赛道</strong></p>
<ul>
<li>商业模型（Claude&#x2F;GPT）追求极致准确率，适合高价值场景</li>
<li>开源模型（UI-TARS）追求零成本部署和定位精度，适合大规模应用</li>
</ul>
<p><strong>3. 沙盒化是 CI&#x2F;CD 集成的关键</strong><br>Cua、OmniTool 等都提供 Docker 化的隔离环境。这意味着 AI GUI 测试可以像单元测试一样跑在 CI pipeline 里。</p>
<p><strong>4. 速度和成本仍是主要瓶颈</strong><br>每步截图 + LLM 推理需要 2-5 秒，传统自动化是毫秒级。高频回归测试仍需混合策略：核心路径用传统方法，复杂场景用 AI Agent。</p>
<p><strong>5. 2026 是落地元年</strong><br>从 benchmark 到生产：UiPath Screen Agent 已在企业中部署，Midscene.js 已发布 v1.0，Cua 已有 12.4K star。这不再是论文里的概念。</p>
<hr>
<h2 id="资源汇总"><a href="#资源汇总" class="headerlink" title="资源汇总"></a>资源汇总</h2><table>
<thead>
<tr>
<th>资源</th>
<th>链接</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Awesome-GUI-Agent</td>
<td><a target="_blank" rel="noopener" href="https://github.com/showlab/Awesome-GUI-Agent">GitHub</a></td>
<td>最全论文列表（⭐1.1K）</td>
</tr>
<tr>
<td>OSWorld Benchmark</td>
<td><a target="_blank" rel="noopener" href="https://os-world.github.io/">官网</a></td>
<td>桌面操控标准评测</td>
</tr>
<tr>
<td>Cua</td>
<td><a target="_blank" rel="noopener" href="https://github.com/trycua/cua">GitHub</a></td>
<td>开源 Computer Use Agent 平台</td>
</tr>
<tr>
<td>UI-TARS</td>
<td><a target="_blank" rel="noopener" href="https://github.com/bytedance/UI-TARS">GitHub</a></td>
<td>字节开源 GUI Agent 模型</td>
</tr>
<tr>
<td>Midscene.js</td>
<td><a target="_blank" rel="noopener" href="https://midscenejs.com/">官网</a></td>
<td>自然语言 UI 测试框架</td>
</tr>
<tr>
<td>UFO³</td>
<td><a target="_blank" rel="noopener" href="https://github.com/microsoft/UFO">GitHub</a></td>
<td>微软 Windows Agent OS</td>
</tr>
<tr>
<td>OmniParser V2</td>
<td><a target="_blank" rel="noopener" href="https://github.com/microsoft/OmniParser">GitHub</a></td>
<td>微软屏幕解析引擎</td>
</tr>
<tr>
<td>LLM-Powered GUI Agents Survey</td>
<td><a target="_blank" rel="noopener" href="https://github.com/PhoneLLM/Awesome-LLM-Powered-Phone-GUI-Agents">GitHub</a></td>
<td>手机 GUI Agent 综述</td>
</tr>
</tbody></table>
<hr>
<p><em>本文基于 2026 年 2 月 12 日的调研。这个领域每周都在刷新纪录——一个月前 Claude Opus 4.5 还是 SOTA，现在 Opus 4.6 已经超越人类。建议持续关注 <a target="_blank" rel="noopener" href="https://os-world.github.io/">OSWorld Leaderboard</a> 获取最新排名。</em></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2026-02-11T16:00:00.000Z" title="2/12/2026, 12:00:00 AM">2026-02-12</time>发表</span><span class="level-item"><time dateTime="2026-02-13T00:13:53.120Z" title="2/13/2026, 8:13:53 AM">2026-02-13</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E7%A7%91%E6%8A%80%E9%80%9F%E9%80%92/">科技速递</a></span><span class="level-item">28 分钟读完 (大约4165个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/02/12/tech-hot-news-2026-02-12/">科技热榜速递 | 2026-02-13：Seedance 2.0 正式发布、Claude Code 变蠢争议、xAI 星际野心</a></h1><div class="content"><blockquote>
<p>每日精选国外科技社区热门内容，覆盖 Hacker News、Lobsters、TechCrunch、Dev.to、Ars Technica、Slashdot 六大平台。原文链接 + 详情摘要，一文速览全球科技圈在聊什么。</p>
</blockquote>
<hr>
<h2 id="🔥-今日头条：Seedance-2-0-正式发布——字节跳动视频生成模型迈入工业级"><a href="#🔥-今日头条：Seedance-2-0-正式发布——字节跳动视频生成模型迈入工业级" class="headerlink" title="🔥 今日头条：Seedance 2.0 正式发布——字节跳动视频生成模型迈入工业级"></a>🔥 今日头条：Seedance 2.0 正式发布——字节跳动视频生成模型迈入工业级</h2><p>2 月 12 日，字节跳动 Seed 团队正式发布新一代视频创作模型 <strong>Seedance 2.0</strong>，已全量上线豆包 App、即梦 AI 等平台。</p>
<p>这次升级的核心不是「更好看」，而是<strong>「更能用」</strong>：</p>
<ul>
<li><strong>统一多模态架构</strong>：文字、图片、音频、视频四种模态输入，最多同时引入 9 张图片 + 多段视听素材作为参考</li>
<li><strong>物理还原能力飞跃</strong>：双人花滑、多人竞技等高难度动作场景的连贯性大幅提升，模型真正开始「懂物理」</li>
<li><strong>15 秒多镜头 + 双声道立体声</strong>：音画同步，一次生成即可获得沉浸式视听体验</li>
<li><strong>导演级操控</strong>：支持精准指定构图、运镜、文字分镜脚本</li>
<li><strong>视频编辑与延展</strong>：可对特定片段进行定向修改，支持「接着拍」——极大降低影视、广告、电商制作门槛</li>
</ul>
<p>美国导演试用后评价「可能颠覆好莱坞的工作方式」。36 氪将其定性为视频生成领域的「奇点时刻」。</p>
<p>体验入口：即梦网页端 → 视频生成 → 选择 Seedance 2.0 | 豆包 App → 对话框 → Seedance 2.0 | 火山方舟体验中心</p>
<hr>
<h2 id="📰-Hacker-News-热门-Top-10"><a href="#📰-Hacker-News-热门-Top-10" class="headerlink" title="📰 Hacker News 热门 Top 10"></a>📰 Hacker News 热门 Top 10</h2><h3 id="1-Claude-Code-是不是在变蠢？（735分-x2F-505评论）"><a href="#1-Claude-Code-是不是在变蠢？（735分-x2F-505评论）" class="headerlink" title="1. Claude Code 是不是在变蠢？（735分 &#x2F; 505评论）"></a>1. Claude Code 是不是在变蠢？（735分 &#x2F; 505评论）</h3><p>Claude Code v2.1.20 发布了一个引发众怒的改动：<strong>所有文件读取和搜索操作的输出被替换成了一行无用的摘要</strong>。比如原来会显示具体读了哪些文件、搜了什么模式，现在只有「Read 3 files」「Searched for 1 pattern」——完全没有实际信息。</p>
<p>用户在 GitHub Issues 上集体抗议，要求恢复显示文件路径，或至少提供一个开关。Anthropic 的回应是「对大多数用户来说这是一个减少噪音的好改动」，并建议使用 verbose 模式——但 verbose 模式会倾泻大量调试信息、子 Agent 完整输出等内容，根本不是用户想要的。</p>
<p>这场争论反映了一个更深层的问题：<strong>当 AI 工具越来越强大时，用户对透明度和可控性的需求反而在增加，而不是减少。</strong> 你花了 $200&#x2F;月买一个工具，它却开始对你隐藏自己在做什么。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://symmetrybreak.ing/blog/claude-code-is-being-dumbed-down/">原文</a> | <a target="_blank" rel="noopener" href="https://news.ycombinator.com/item?id=46974853">HN 讨论</a></p>
<hr>
<h3 id="2-亚马逊-Ring「寻狗广告」引发隐私监控担忧（415分-x2F-232评论）"><a href="#2-亚马逊-Ring「寻狗广告」引发隐私监控担忧（415分-x2F-232评论）" class="headerlink" title="2. 亚马逊 Ring「寻狗广告」引发隐私监控担忧（415分 &#x2F; 232评论）"></a>2. 亚马逊 Ring「寻狗广告」引发隐私监控担忧（415分 &#x2F; 232评论）</h3><p>亚马逊在超级碗期间投放了 Ring 摄像头的「Search Party」广告，展示邻居们用 Ring 摄像头网络帮助寻找走失的狗。广告本意是温馨可爱，但却在网上引发了大规模反弹——批评者指出，这实质上展示了一个由私人摄像头组成的<strong>大规模监控网络</strong>。</p>
<p>公众担忧的核心：当数百万个家庭摄像头可以被串联搜索时，找狗和追踪人之间只有一步之遥。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://www.theverge.com/tech/876866/ring-search-party-super-bowl-ad-online-backlash">The Verge 报道</a></p>
<hr>
<h3 id="3-Fluorite-—-完全集成-Flutter-的主机级游戏引擎（393分-x2F-230评论）"><a href="#3-Fluorite-—-完全集成-Flutter-的主机级游戏引擎（393分-x2F-230评论）" class="headerlink" title="3. Fluorite — 完全集成 Flutter 的主机级游戏引擎（393分 &#x2F; 230评论）"></a>3. Fluorite — 完全集成 Flutter 的主机级游戏引擎（393分 &#x2F; 230评论）</h3><p>Fluorite 是一个全新的游戏引擎，核心卖点是<strong>完全集成 Flutter 生态</strong>。底层用 C++ 编写的高性能 ECS（Entity-Component-System）架构，上层用 Dart 编写游戏逻辑，可以直接使用 Flutter 的开发工具链和 UI 组件系统。</p>
<p>亮点功能：</p>
<ul>
<li><strong>FluoriteView Widget</strong>：在 Flutter 应用中嵌入多个 3D 场景视图</li>
<li><strong>模型定义触摸区域</strong>：3D 美术在 Blender 中直接定义可点击区域，开发者监听事件即可</li>
<li><strong>游戏代码和 UI 代码共享状态</strong>：完全用 Flutter 的方式</li>
</ul>
<p>这对移动游戏开发者来说是个有趣的选择：不用学 Unity&#x2F;Unreal，用已有的 Dart&#x2F;Flutter 技能就能做游戏。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://fluorite.game/">官网</a></p>
<hr>
<h3 id="4-无人机入侵导致美国厄尔巴索机场关闭（327分-x2F-513评论）"><a href="#4-无人机入侵导致美国厄尔巴索机场关闭（327分-x2F-513评论）" class="headerlink" title="4. 无人机入侵导致美国厄尔巴索机场关闭（327分 &#x2F; 513评论）"></a>4. 无人机入侵导致美国厄尔巴索机场关闭（327分 &#x2F; 513评论）</h3><p>FAA 因无人机入侵事件对德克萨斯州厄尔巴索机场实施了飞行限制。513 条评论讨论了无人机管控政策、机场安全以及越来越频繁的无人机干扰航空事件。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://www.nytimes.com/2026/02/11/us/faa-el-paso-flight-restrictions.html">NYT 报道</a></p>
<hr>
<h3 id="5-WiFi-可能成为隐形的大规模监控系统（297分-x2F-146评论）"><a href="#5-WiFi-可能成为隐形的大规模监控系统（297分-x2F-146评论）" class="headerlink" title="5. WiFi 可能成为隐形的大规模监控系统（297分 &#x2F; 146评论）"></a>5. WiFi 可能成为隐形的大规模监控系统（297分 &#x2F; 146评论）</h3><p>研究人员发出警告：WiFi 信号可以被用来追踪人体移动。WiFi 信号在室内传播时会被人体反射和吸收，通过分析这些信号变化，可以在不需要任何摄像头的情况下检测、定位甚至识别室内的人。</p>
<p>这种技术不需要目标携带任何设备，而且可以穿墙工作。研究人员警告这可能成为一种”隐形的大规模监控系统”。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://scitechdaily.com/researchers-warn-wifi-could-become-an-invisible-mass-surveillance-system/">SciTechDaily</a></p>
<hr>
<h3 id="6-Discord-x2F-Twitch-x2F-Snapchat-年龄验证绕过漏洞（285分-x2F-149评论）"><a href="#6-Discord-x2F-Twitch-x2F-Snapchat-年龄验证绕过漏洞（285分-x2F-149评论）" class="headerlink" title="6. Discord&#x2F;Twitch&#x2F;Snapchat 年龄验证绕过漏洞（285分 &#x2F; 149评论）"></a>6. Discord&#x2F;Twitch&#x2F;Snapchat 年龄验证绕过漏洞（285分 &#x2F; 149评论）</h3><p>安全研究人员发现，Discord 使用的年龄验证提供商 k-id 存在根本性的设计缺陷。k-id 声称不会将用户面部照片发送到服务器（出于隐私考虑），而是发送面部元数据。但这意味着<strong>可以构造看似合法的元数据来绕过验证</strong>，服务器无法区分真假。</p>
<p>之前的绕过方法被修补后，随着 Discord 将年龄验证扩展到全球，研究人员又找到了新的绕过方式。这暴露了一个根本矛盾：<strong>隐私保护（不发送真实人脸）和验证可靠性（需要真实人脸）之间的不可调和冲突。</strong></p>
<p>🔗 <a target="_blank" rel="noopener" href="https://age-verifier.kibty.town/">漏洞详情</a></p>
<hr>
<h3 id="7-GLM-5：面向复杂系统工程和长期-Agent-任务的模型（244分-x2F-397评论）"><a href="#7-GLM-5：面向复杂系统工程和长期-Agent-任务的模型（244分-x2F-397评论）" class="headerlink" title="7. GLM-5：面向复杂系统工程和长期 Agent 任务的模型（244分 &#x2F; 397评论）"></a>7. GLM-5：面向复杂系统工程和长期 Agent 任务的模型（244分 &#x2F; 397评论）</h3><p>智谱 AI（Z.AI）发布了 GLM-5，专门瞄准复杂系统工程和长时间运行的 Agent 任务场景。在 Hacker News 上获得 244 分和近 400 条评论，说明国际社区对中国 AI 的关注度在持续上升。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://z.ai/blog/glm-5">GLM-5 博客</a></p>
<hr>
<h3 id="8-GLM-OCR：复杂文档理解的多模态-OCR-模型（217分-x2F-67评论）"><a href="#8-GLM-OCR：复杂文档理解的多模态-OCR-模型（217分-x2F-67评论）" class="headerlink" title="8. GLM-OCR：复杂文档理解的多模态 OCR 模型（217分 &#x2F; 67评论）"></a>8. GLM-OCR：复杂文档理解的多模态 OCR 模型（217分 &#x2F; 67评论）</h3><p>智谱同时发布了 GLM-OCR，一个基于 GLM-V 编码器-解码器架构的多模态 OCR 模型。核心创新包括多 Token 预测（MTP）损失函数和全任务强化学习。</p>
<p>技术亮点：</p>
<ul>
<li><strong>OmniDocBench V1.5 得分 94.62</strong>，所有文档理解任务排名第一</li>
<li>使用 CogViT 视觉编码器 + GLM-0.5B 语言解码器</li>
<li>两阶段处理流水线：版面分析 + 并行识别</li>
<li>覆盖公式识别、表格识别、信息提取等场景</li>
</ul>
<p>🔗 <a target="_blank" rel="noopener" href="https://github.com/zai-org/GLM-OCR">GitHub</a></p>
<hr>
<h3 id="9-NetNewsWire-23-周年（202分-x2F-47评论）"><a href="#9-NetNewsWire-23-周年（202分-x2F-47评论）" class="headerlink" title="9. NetNewsWire 23 周年（202分 &#x2F; 47评论）"></a>9. NetNewsWire 23 周年（202分 &#x2F; 47评论）</h3><p>老牌 RSS 阅读器 NetNewsWire 迎来 23 岁生日。刚刚发布了 Mac 和 iOS 的 7.0 版本，正在开发 7.0.1 修复版。创始人 Brent 去年退休后，开发速度反而加快了。</p>
<p>在算法推荐统治信息流的时代，一个 23 年的 RSS 阅读器还能在 HN 上获得 200+ 分，说明<strong>开放 Web 和用户主权</strong>在技术社区仍然有强大的号召力。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://netnewswire.blog/2026/02/11/netnewswire-turns.html">博客</a></p>
<hr>
<h3 id="10-GPT-5-法律推理实验：100-vs-联邦法官-52-（112分-x2F-87评论）"><a href="#10-GPT-5-法律推理实验：100-vs-联邦法官-52-（112分-x2F-87评论）" class="headerlink" title="10. GPT-5 法律推理实验：100% vs 联邦法官 52%（112分 &#x2F; 87评论）"></a>10. GPT-5 法律推理实验：100% vs 联邦法官 52%（112分 &#x2F; 87评论）</h3><p>一项学术研究让 GPT-5 和联邦法官在相同法律推理任务上对比。结果：**GPT-5 达到 100% 准确率，而联邦法官只有 52%**。这是 AI 在专业领域能力的又一个里程碑式数据点，引发了关于 AI 在法律系统中角色的深入讨论。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=6155012">论文</a></p>
<hr>
<h2 id="🦞-Lobsters-热门-Top-5"><a href="#🦞-Lobsters-热门-Top-5" class="headerlink" title="🦞 Lobsters 热门 Top 5"></a>🦞 Lobsters 热门 Top 5</h2><h3 id="1-如何将-Google-搜索依赖减半（116分-x2F-50评论）"><a href="#1-如何将-Google-搜索依赖减半（116分-x2F-50评论）" class="headerlink" title="1. 如何将 Google 搜索依赖减半（116分 &#x2F; 50评论）"></a>1. 如何将 Google 搜索依赖减半（116分 &#x2F; 50评论）</h3><p>开发者构建了 <a target="_blank" rel="noopener" href="https://github.com/asciimoo/hister">Hister</a>，一个自托管的网页浏览历史搜索工具。它会在本地索引你访问过的所有网页，当你想找回之前看过的内容时，直接搜索本地索引而不是去 Google。</p>
<p>作者在 1.5 个月内成功将对 Google 搜索的依赖降低了 50%。核心观点：Google 搜索已经被广告和 SEO 操纵严重侵蚀，而你要找的信息很多时候就在你之前看过的页面里。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://hister.org/posts/how-i-cut-my-google-search-dependence-in-half/">原文</a></p>
<h3 id="2-缺失的-GitHub-状态页面（125分-x2F-19评论）"><a href="#2-缺失的-GitHub-状态页面（125分-x2F-19评论）" class="headerlink" title="2. 缺失的 GitHub 状态页面（125分 &#x2F; 19评论）"></a>2. 缺失的 GitHub 状态页面（125分 &#x2F; 19评论）</h3><p>一个展示 GitHub 各服务真实可用性状态的第三方页面，比 GitHub 官方状态页更准确和详细。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://mrshu.github.io/github-statuses/">GitHub Statuses</a></p>
<h3 id="3-Windows-记事本远程代码执行漏洞-CVE-2026-20841（47分-x2F-16评论）"><a href="#3-Windows-记事本远程代码执行漏洞-CVE-2026-20841（47分-x2F-16评论）" class="headerlink" title="3. Windows 记事本远程代码执行漏洞 CVE-2026-20841（47分 &#x2F; 16评论）"></a>3. Windows 记事本远程代码执行漏洞 CVE-2026-20841（47分 &#x2F; 16评论）</h3><p>Windows 记事本（Notepad）被发现存在远程代码执行漏洞。作为 Windows 上最简单、最基础的文本编辑器，记事本出现 RCE 漏洞着实令人意外。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://www.cve.org/CVERecord?id=CVE-2026-20841">CVE 详情</a></p>
<h3 id="4-Majutsu-—-jujutsu-版本控制的-Magit-接口（30分-x2F-4评论）"><a href="#4-Majutsu-—-jujutsu-版本控制的-Magit-接口（30分-x2F-4评论）" class="headerlink" title="4. Majutsu — jujutsu 版本控制的 Magit 接口（30分 &#x2F; 4评论）"></a>4. Majutsu — jujutsu 版本控制的 Magit 接口（30分 &#x2F; 4评论）</h3><p>为 jujutsu（新一代版本控制系统）开发的 Emacs Magit 风格接口。小众但精准地击中了 Emacs + 新型 VCS 用户群。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://github.com/0WD0/majutsu">GitHub</a></p>
<h3 id="5-前向求值构建系统（24分-x2F-6评论）"><a href="#5-前向求值构建系统（24分-x2F-6评论）" class="headerlink" title="5. 前向求值构建系统（24分 &#x2F; 6评论）"></a>5. 前向求值构建系统（24分 &#x2F; 6评论）</h3><p>Garnix 团队介绍 garn2，一种使用前向求值（forward evaluation）的构建系统设计理念。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://garnix.io/blog/garn2/">博客</a></p>
<hr>
<h2 id="📡-TechCrunch-头条-Top-5"><a href="#📡-TechCrunch-头条-Top-5" class="headerlink" title="📡 TechCrunch 头条 Top 5"></a>📡 TechCrunch 头条 Top 5</h2><h3 id="1-xAI-在公开全员会议上描述星际野心"><a href="#1-xAI-在公开全员会议上描述星际野心" class="headerlink" title="1. xAI 在公开全员会议上描述星际野心"></a>1. xAI 在公开全员会议上描述星际野心</h3><p>xAI 罕见地将一场 45 分钟的全员会议视频公开发布在 X 平台上。会议揭示了重大信息：</p>
<ul>
<li><strong>大规模裁员</strong>：Musk 描述为「组织结构变革」，导致大量创始团队成员离开</li>
<li><strong>四大团队重组</strong>：Grok 聊天机器人、编码系统、Imagine 视频生成器、<strong>Macrohard 项目</strong></li>
<li><strong>Macrohard</strong>：从简单的 Computer Use 到模拟整个企业运营，目标是「AI 全自动设计火箭引擎」</li>
<li>Toby Pohlen 将领导 Macrohard：「它能做电脑上任何事情」</li>
</ul>
<p>🔗 <a target="_blank" rel="noopener" href="https://techcrunch.com/2026/02/11/xai-lays-out-interplanetary-ambitions-in-public-all-hands/">TechCrunch</a></p>
<h3 id="2-AI-推理创业公司-Modal-Labs-融资估值-25-亿美元"><a href="#2-AI-推理创业公司-Modal-Labs-融资估值-25-亿美元" class="headerlink" title="2. AI 推理创业公司 Modal Labs 融资估值 25 亿美元"></a>2. AI 推理创业公司 Modal Labs 融资估值 25 亿美元</h3><p>Modal Labs 专注 AI 推理（inference）基础设施优化，正在与 General Catalyst 谈判以 $25 亿估值融资。这比 5 个月前 B 轮的 $11 亿估值翻了一倍多。年化收入约 $5000 万。</p>
<p>推理优化正在成为 AI 基础设施的下一个热门赛道——降低运行成本、减少响应延迟。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://techcrunch.com/2026/02/11/ai-inference-startup-modal-labs-in-talks-to-raise-at-2-5b-valuation-sources-say/">TechCrunch</a></p>
<h3 id="3-OpenAI-解散「使命对齐」团队"><a href="#3-OpenAI-解散「使命对齐」团队" class="headerlink" title="3. OpenAI 解散「使命对齐」团队"></a>3. OpenAI 解散「使命对齐」团队</h3><p>OpenAI 解散了负责向公众和内部员工传达公司使命的团队（约 6-7 人）。团队前负责人 Josh Achiam 被任命为新职位「首席未来学家」（Chief Futurist）。</p>
<p>团队成立于 2024 年 9 月，使命是确保「通用人工智能造福全人类」。解散后成员被分配到其他部门。继去年超级对齐团队解散后，OpenAI 安全相关团队的又一次变动。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://techcrunch.com/2026/02/11/openai-disbands-mission-alignment-team-which-focused-on-safe-and-trustworthy-ai-development/">TechCrunch</a></p>
<h3 id="4-Apple-Siri-改版再次延期"><a href="#4-Apple-Siri-改版再次延期" class="headerlink" title="4. Apple Siri 改版再次延期"></a>4. Apple Siri 改版再次延期</h3><p>Apple 自 2024 年宣布 Apple Intelligence 以来一直承诺升级 Siri，但发布日期持续推迟。最新消息：原定 iOS 26.4（3 月）上线的新 Siri 部分功能将推迟到 iOS 27（9 月）。</p>
<p>据 Bloomberg 报道，内部测试遇到了问题。新 Siri 将更像 LLM 聊天机器人，底层传闻使用 Google Gemini。但从 2024 到 2026，已经跳票两年了。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://techcrunch.com/2026/02/11/apples-siri-revamp-reportedly-delayed-again/">TechCrunch</a></p>
<h3 id="5-Uber-Eats-推出-AI-购物车助手"><a href="#5-Uber-Eats-推出-AI-购物车助手" class="headerlink" title="5. Uber Eats 推出 AI 购物车助手"></a>5. Uber Eats 推出 AI 购物车助手</h3><p>Uber Eats 推出 AI 购物助手，可以根据文字或图片描述自动添加商品到购物车。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://techcrunch.com/2026/02/11/uber-eats-launches-ai-assistant-to-help-with-grocery-cart-creation/">TechCrunch</a></p>
<hr>
<h2 id="🔧-Dev-to-热门"><a href="#🔧-Dev-to-热门" class="headerlink" title="🔧 Dev.to 热门"></a>🔧 Dev.to 热门</h2><h3 id="1-受够了-Trello：自己做生产力工具（17反应）"><a href="#1-受够了-Trello：自己做生产力工具（17反应）" class="headerlink" title="1. 受够了 Trello：自己做生产力工具（17反应）"></a>1. 受够了 Trello：自己做生产力工具（17反应）</h3><p>开发者 Karsten 吐槽 Trello 被 Atlassian 收购后变得臃肿不堪：更多工作流、更多仪表盘、更多定价层级、更少的清晰度。这些工具「为汇报而生，而非为工作而生」。于是他自己动手做了一个极简生产力工具。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://dev.to/karsten_biedermann/get-done-i-hate-what-trello-has-become-5a05">Dev.to</a></p>
<h3 id="2-用-CSS-重现-Pantone-色卡（15反应）"><a href="#2-用-CSS-重现-Pantone-色卡（15反应）" class="headerlink" title="2. 用 CSS 重现 Pantone 色卡（15反应）"></a>2. 用 CSS 重现 Pantone 色卡（15反应）</h3><p>纯 CSS 实现 Pantone 色卡的视觉效果，技术和设计的巧妙结合。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://dev.to/madsstoumann/re-creating-a-pantone-color-deck-in-css-3108">Dev.to</a></p>
<hr>
<h2 id="🔬-Ars-Technica-安全头条"><a href="#🔬-Ars-Technica-安全头条" class="headerlink" title="🔬 Ars Technica 安全头条"></a>🔬 Ars Technica 安全头条</h2><h3 id="Lumma-窃密恶意软件卷土重来"><a href="#Lumma-窃密恶意软件卷土重来" class="headerlink" title="Lumma 窃密恶意软件卷土重来"></a>Lumma 窃密恶意软件卷土重来</h3><p>去年 5 月，全球执法机构联合打击了 Lumma Stealer 的基础设施——这个信息窃取工具在短短两个月内感染了近 40 万台 Windows 电脑。但现在它又回来了，而且更难检测。</p>
<p>Lumma 的特点：</p>
<ul>
<li>2022 年首次出现在俄语网络犯罪论坛</li>
<li>云端恶意软件即服务（MaaS）模式，高级版售价 $2500</li>
<li>被 Scattered Spider 等多个著名犯罪组织使用</li>
<li>新版使用 <strong>ClickFix 诱饵 + Castleloader</strong> 进行大规模传播</li>
<li>微软称其为多个犯罪集团的「首选工具」</li>
</ul>
<p>教训：<strong>执法打击只能暂时压制，不能根除。</strong> 基础设施可以重建，恶意软件可以升级。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://arstechnica.com/security/2026/02/once-hobbled-lumma-stealer-is-back-with-lures-that-are-hard-to-resist/">Ars Technica</a></p>
<hr>
<h2 id="💬-Slashdot-极客新闻"><a href="#💬-Slashdot-极客新闻" class="headerlink" title="💬 Slashdot 极客新闻"></a>💬 Slashdot 极客新闻</h2><h3 id="1-Linux-Mint-考虑延长发布周期"><a href="#1-Linux-Mint-考虑延长发布周期" class="headerlink" title="1. Linux Mint 考虑延长发布周期"></a>1. Linux Mint 考虑延长发布周期</h3><p>Linux Mint 团队表示半年一版的发布节奏太累了，正在考虑延长发布周期。这反映了小型开源团队在维护大型发行版时的资源压力。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://linux.slashdot.org/story/26/02/11/1821222/">Slashdot</a></p>
<h3 id="2-科学家警告「温室地球」临界点比预想更近"><a href="#2-科学家警告「温室地球」临界点比预想更近" class="headerlink" title="2. 科学家警告「温室地球」临界点比预想更近"></a>2. 科学家警告「温室地球」临界点比预想更近</h3><p>最新研究表明，全球气候系统的多个临界点可能比此前模型预测的更接近。一旦跨过这些临界点，变化将不可逆转。</p>
<p>🔗 <a target="_blank" rel="noopener" href="https://news.slashdot.org/story/26/02/11/1814253/">Slashdot</a></p>
<hr>
<h2 id="🔥-今日洞察"><a href="#🔥-今日洞察" class="headerlink" title="🔥 今日洞察"></a>🔥 今日洞察</h2><h3 id="AI-安全与信任危机"><a href="#AI-安全与信任危机" class="headerlink" title="AI 安全与信任危机"></a>AI 安全与信任危机</h3><p>今天最突出的主题是 <strong>AI 公司与用户之间的信任问题</strong>：Claude Code 隐藏操作细节、OpenAI 解散使命对齐团队、GPT-5 在法律推理上 100% 准确但谁来监督它？当 AI 越来越强大，透明度和可控性不是可选项，而是必选项。</p>
<h3 id="中国-AI-的国际影响力"><a href="#中国-AI-的国际影响力" class="headerlink" title="中国 AI 的国际影响力"></a>中国 AI 的国际影响力</h3><p>智谱 GLM-5 和 GLM-OCR 同时登上 Hacker News 热门，GLM-5 更是获得了 244 分 &#x2F; 397 评论的高关注度。GLM-OCR 在文档理解 benchmark 上排名第一。中国 AI 正在技术社区获得越来越多的实质性认可。</p>
<h3 id="监控无处不在"><a href="#监控无处不在" class="headerlink" title="监控无处不在"></a>监控无处不在</h3><p>Ring 摄像头广告、WiFi 信号追踪、年龄验证绕过——三条不相关的新闻指向同一个主题：<strong>隐私正在以各种意想不到的方式被侵蚀</strong>。更值得警惕的是，很多时候这些工具被包装成「安全」和「便利」。</p>
<h3 id="xAI-的-Macrohard：Computer-Use-的企业级野心"><a href="#xAI-的-Macrohard：Computer-Use-的企业级野心" class="headerlink" title="xAI 的 Macrohard：Computer Use 的企业级野心"></a>xAI 的 Macrohard：Computer Use 的企业级野心</h3><p>xAI 全员会议透露的 Macrohard 项目值得关注：从 Computer Use 扩展到「模拟整个企业运营」。这和 Anthropic 的 Computer Use、OpenAI 的 Operator 本质上在抢同一个赛道，但 Musk 的野心显然更大——他想让 AI 设计火箭引擎。</p>
<hr>
<p><em>数据来源：Hacker News、Lobsters、TechCrunch、Dev.to、Ars Technica、Slashdot | 爬取时间：2026-02-12</em></p>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2026/02/11/github-trending/2026-02-11/"><img class="fill" src="/images/github-trending-cover.png" alt="GitHub Trending 日报：今日最火的 5 个开源项目深度解析"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2026-02-11T01:30:00.000Z" title="2/11/2026, 9:30:00 AM">2026-02-11</time>发表</span><span class="level-item"><time dateTime="2026-02-11T08:16:03.394Z" title="2/11/2026, 4:16:03 PM">2026-02-11</time>更新</span><span class="level-item">18 分钟读完 (大约2666个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/02/11/github-trending/2026-02-11/">GitHub Trending 日报：今日最火的 5 个开源项目深度解析</a></h1><div class="content"><p>AI Agent 工具链正在迎来爆发期——今天的 GitHub Trending 榜单几乎被 AI 相关项目垄断。从 Google 的结构化信息提取、到 GitHub 官方的 Agent 工作流、再到全自动 AI 渗透测试，每一个项目都在重新定义各自领域的工作方式。</p>
<p>让我们逐一拆解今日最火的 5 个开源项目。</p>
<hr>
<h2 id="1-Google-LangExtract-—-用-LLM-从非结构化文本中精准提取结构化数据"><a href="#1-Google-LangExtract-—-用-LLM-从非结构化文本中精准提取结构化数据" class="headerlink" title="1. Google LangExtract — 用 LLM 从非结构化文本中精准提取结构化数据"></a>1. Google LangExtract — 用 LLM 从非结构化文本中精准提取结构化数据</h2><blockquote>
<p>⭐ 28,463 Stars | 📈 +1,654 today | 🐍 Python | 📜 Apache-2.0</p>
</blockquote>
<p><strong>仓库地址：</strong> <a target="_blank" rel="noopener" href="https://github.com/google/langextract">google&#x2F;langextract</a></p>
<h3 id="项目简介"><a href="#项目简介" class="headerlink" title="项目简介"></a>项目简介</h3><p>LangExtract 是 Google 开源的 Python 库，专门用 LLM 从非结构化文本（临床笔记、研报、法律文件等）中提取结构化信息。与传统 NER 工具不同，它强调 <strong>精准溯源</strong>——每个提取结果都能映射回源文本的精确位置。</p>
<h3 id="为什么火？"><a href="#为什么火？" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>这个项目直击了 LLM 应用落地的一个核心痛点：<strong>可信度</strong>。大模型很擅长理解文本，但企业场景要求的不只是”理解”，还需要”证据”。LangExtract 的溯源（source grounding）机制让每条提取结果都有据可查，极大降低了幻觉风险。</p>
<p>加上 Google 亲自下场开源，自带 Gemini 系列模型的深度集成，又同时支持 OpenAI 和 Ollama 本地模型，适用面非常广。</p>
<h3 id="技术亮点"><a href="#技术亮点" class="headerlink" title="技术亮点"></a>技术亮点</h3><ul>
<li><strong>精准溯源</strong>：每个提取实体都映射到源文本的精确位置，支持可视化高亮</li>
<li><strong>长文档优化</strong>：分块+并行处理+多轮扫描策略，解决了”大海捞针”问题</li>
<li><strong>可控输出</strong>：基于 few-shot example 定义 schema，支持 Gemini 的 controlled generation 保证输出格式一致</li>
<li><strong>交互式可视化</strong>：一键生成独立 HTML 文件，可视化审查提取结果</li>
<li><strong>灵活的 LLM 后端</strong>：Gemini（推荐）&#x2F; OpenAI &#x2F; Ollama 本地模型</li>
</ul>
<h3 id="技术栈"><a href="#技术栈" class="headerlink" title="技术栈"></a>技术栈</h3><p>Python + Pydantic + Gemini API + 可选 OpenAI&#x2F;Ollama 后端。项目结构清晰：核心逻辑在 <code>langextract/</code>，示例在 <code>examples/</code>，基准测试在 <code>benchmarks/</code>。</p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><ul>
<li>医疗：从临床报告中提取药物、诊断、检查结果</li>
<li>法律：合同关键条款提取</li>
<li>金融：研报中的关键指标结构化</li>
<li>任何需要”从一堆文字里挑出关键信息”的场景</li>
</ul>
<hr>
<h2 id="2-AionUi-—-AI-CLI-工具的统一图形化工作台"><a href="#2-AionUi-—-AI-CLI-工具的统一图形化工作台" class="headerlink" title="2. AionUi — AI CLI 工具的统一图形化工作台"></a>2. AionUi — AI CLI 工具的统一图形化工作台</h2><blockquote>
<p>⭐ 14,445 Stars | 📈 +629 today | 💻 TypeScript | 📜 Apache-2.0</p>
</blockquote>
<p><strong>仓库地址：</strong> <a target="_blank" rel="noopener" href="https://github.com/iOfficeAI/AionUi">iOfficeAI&#x2F;AionUi</a></p>
<h3 id="项目简介-1"><a href="#项目简介-1" class="headerlink" title="项目简介"></a>项目简介</h3><p>AionUi 是一个给命令行 AI 工具（Gemini CLI、Claude Code、Codex、OpenClaw 等）套上图形界面的桌面应用。你可以把它理解为”AI 编程助手的统一工作台”——一个界面管理所有 CLI AI 工具。</p>
<h3 id="为什么火？-1"><a href="#为什么火？-1" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>2026 年初是 AI 编程工具井喷的时期，Claude Code、Gemini CLI、Codex、OpenClaw 等各有所长，但都是命令行工具。对于很多开发者来说，在多个终端窗口之间切换是真实的痛点。AionUi 把这些工具统一到一个可视化界面里，自动检测本地安装的 CLI 工具、支持多会话并行、对话历史本地存储。</p>
<h3 id="技术亮点-1"><a href="#技术亮点-1" class="headerlink" title="技术亮点"></a>技术亮点</h3><ul>
<li><strong>Multi-Agent 模式</strong>：一个界面同时接入 Gemini CLI、Claude Code、Codex、OpenClaw 等多种工具</li>
<li><strong>自动检测</strong>：自动识别本地安装的 CLI AI 工具并集成</li>
<li><strong>远程访问</strong>：支持通过内网穿透从手机&#x2F;平板访问桌面端的 AI 工具</li>
<li><strong>本地优先</strong>：所有对话数据本地存储，不上传到云端</li>
<li><strong>跨平台</strong>：macOS、Windows、Linux 全平台支持</li>
</ul>
<h3 id="技术栈-1"><a href="#技术栈-1" class="headerlink" title="技术栈"></a>技术栈</h3><p>TypeScript + Electron&#x2F;Tauri（桌面端框架）+ Node.js。内置 Gemini CLI，支持 API Key 直连各大模型。</p>
<h3 id="适用场景-1"><a href="#适用场景-1" class="headerlink" title="适用场景"></a>适用场景</h3><p>如果你同时使用多个 AI 编程助手，又不想在 N 个终端窗口之间切换，AionUi 是目前最成熟的统一方案。特别适合日常在 Claude Code 和 Gemini CLI 之间来回切换的开发者。</p>
<hr>
<h2 id="3-Shannon-—-全自动-AI-渗透测试工具（XBOW-基准-96-15-成功率）"><a href="#3-Shannon-—-全自动-AI-渗透测试工具（XBOW-基准-96-15-成功率）" class="headerlink" title="3. Shannon — 全自动 AI 渗透测试工具（XBOW 基准 96.15% 成功率）"></a>3. Shannon — 全自动 AI 渗透测试工具（XBOW 基准 96.15% 成功率）</h2><blockquote>
<p>⭐ 19,760 Stars | 📈 +3,619 today | 💻 TypeScript | 📜 AGPL-3.0</p>
</blockquote>
<p><strong>仓库地址：</strong> <a target="_blank" rel="noopener" href="https://github.com/KeygraphHQ/shannon">KeygraphHQ&#x2F;shannon</a></p>
<h3 id="项目简介-2"><a href="#项目简介-2" class="headerlink" title="项目简介"></a>项目简介</h3><p>Shannon 是一个全自动的 AI 渗透测试工具。你给它指向一个 Web 应用，它会自主完成从信息收集到漏洞利用的全流程，最终输出包含可复现 PoC 的安全报告。在 XBOW 基准测试中达到了 <strong>96.15% 的成功率</strong>。</p>
<h3 id="为什么火？-2"><a href="#为什么火？-2" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>今天的 star 增量高达 +3,619，是榜单上涨最猛的项目。原因很直接：<strong>Vibe Coding 时代的安全焦虑</strong>。</p>
<p>AI 编程工具让代码产出效率暴涨，但安全审计跟不上。传统渗透测试一年才做一次，中间 364 天的安全空窗期怎么办？Shannon 的定位就是”你的 AI Red Team”——每次部署前自动跑一遍渗透测试，把安全从”年度事件”变成”持续流程”。</p>
<h3 id="技术亮点-2"><a href="#技术亮点-2" class="headerlink" title="技术亮点"></a>技术亮点</h3><ul>
<li><strong>全自动化</strong>：一条命令启动，AI 自主完成侦察→分析→利用→报告全流程</li>
<li><strong>真实利用</strong>：不是简单的扫描器，而是真正在浏览器中执行攻击（XSS、注入、认证绕过等）</li>
<li><strong>代码感知</strong>：白盒测试模式，分析源代码指导攻击策略</li>
<li><strong>内置安全工具链</strong>：集成 Nmap、Subfinder、WhatWeb、Schemathesis 等专业工具</li>
<li><strong>并行处理</strong>：多类型漏洞并发检测，加速报告生成</li>
<li><strong>渗透级报告</strong>：输出包含可复制粘贴的 PoC，消灭误报</li>
</ul>
<h3 id="技术栈-2"><a href="#技术栈-2" class="headerlink" title="技术栈"></a>技术栈</h3><p>TypeScript + Playwright（浏览器自动化）+ Claude&#x2F;LLM 作为推理引擎 + Nmap&#x2F;Subfinder 等安全工具。分 Lite（AGPL 开源）和 Pro（商业版）两个版本。</p>
<h3 id="适用场景-2"><a href="#适用场景-2" class="headerlink" title="适用场景"></a>适用场景</h3><ul>
<li>开发团队：CI&#x2F;CD 管线中集成自动化安全测试</li>
<li>安全工程师：快速对目标应用做渗透评估</li>
<li>创业公司：没有专职安全团队时的自动化安全兜底</li>
</ul>
<h3 id="⚠️-注意事项"><a href="#⚠️-注意事项" class="headerlink" title="⚠️ 注意事项"></a>⚠️ 注意事项</h3><p>仅限白盒测试（需要源代码访问权限），AGPL-3.0 许可证对商业使用有要求。切勿对未授权的目标使用。</p>
<hr>
<h2 id="4-GitHub-gh-aw-—-用自然语言写-GitHub-Actions-Agent-工作流"><a href="#4-GitHub-gh-aw-—-用自然语言写-GitHub-Actions-Agent-工作流" class="headerlink" title="4. GitHub gh-aw — 用自然语言写 GitHub Actions Agent 工作流"></a>4. GitHub gh-aw — 用自然语言写 GitHub Actions Agent 工作流</h2><blockquote>
<p>⭐ 1,342 Stars | 📈 +496 today | 🐹 Go | 📜 MIT</p>
</blockquote>
<p><strong>仓库地址：</strong> <a target="_blank" rel="noopener" href="https://github.com/github/gh-aw">github&#x2F;gh-aw</a></p>
<h3 id="项目简介-3"><a href="#项目简介-3" class="headerlink" title="项目简介"></a>项目简介</h3><p>GitHub 官方出品的 <code>gh</code> CLI 扩展——<strong>Agentic Workflows</strong>。核心理念：用自然语言 Markdown 定义工作流，在 GitHub Actions 中运行 AI Agent。把”Actions + Agent + Safety”融为一体。</p>
<h3 id="为什么火？-3"><a href="#为什么火？-3" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>这是 GitHub 对”Agent-native CI&#x2F;CD”的官方回答。以前写 GitHub Actions 需要 YAML，现在可以用 Markdown 自然语言描述工作流，AI Agent 自动执行。这不是第三方工具，是 GitHub 自己的产品，信号意义巨大——CI&#x2F;CD 的下一个形态就是 Agent 驱动的。</p>
<h3 id="技术亮点-3"><a href="#技术亮点-3" class="headerlink" title="技术亮点"></a>技术亮点</h3><ul>
<li><strong>自然语言工作流</strong>：用 Markdown 写工作流定义，告别 YAML 噩梦</li>
<li><strong>安全优先架构</strong>：默认只读权限，写操作必须通过 <code>safe-outputs</code> 白名单</li>
<li><strong>多层安全防护</strong>：沙箱执行、输入消毒、网络隔离、依赖 SHA 锁定、工具白名单</li>
<li><strong>人工审批门</strong>：关键操作需人类确认</li>
<li><strong>配套安全组件</strong>：Agent Workflow Firewall（网络出口控制）+ MCP Gateway（MCP 协议网关）</li>
</ul>
<h3 id="技术栈-3"><a href="#技术栈-3" class="headerlink" title="技术栈"></a>技术栈</h3><p>Go（CLI 扩展）+ GitHub Actions 运行时 + AI Agent 推理层。支持 Claude Code、Codex、Copilot 等多种 Agent 后端。</p>
<h3 id="适用场景-3"><a href="#适用场景-3" class="headerlink" title="适用场景"></a>适用场景</h3><ul>
<li>自动化代码审查、Issue 分类、PR 处理</li>
<li>用自然语言定义复杂的 CI&#x2F;CD 流程</li>
<li>需要 AI Agent 参与但又要严格安全控制的 DevOps 场景</li>
</ul>
<hr>
<h2 id="5-Compound-Engineering-Plugin-—-Claude-Code-的复合工程插件"><a href="#5-Compound-Engineering-Plugin-—-Claude-Code-的复合工程插件" class="headerlink" title="5. Compound Engineering Plugin — Claude Code 的复合工程插件"></a>5. Compound Engineering Plugin — Claude Code 的复合工程插件</h2><blockquote>
<p>⭐ 8,174 Stars | 📈 +406 today | 💻 TypeScript | 📜 MIT</p>
</blockquote>
<p><strong>仓库地址：</strong> <a target="_blank" rel="noopener" href="https://github.com/EveryInc/compound-engineering-plugin">EveryInc&#x2F;compound-engineering-plugin</a></p>
<h3 id="项目简介-4"><a href="#项目简介-4" class="headerlink" title="项目简介"></a>项目简介</h3><p>由 Every 团队开源的 Claude Code 插件，核心理念是”<strong>复合工程</strong>“——让每一次工程工作都为下一次积累经验，而不是增加技术债务。提供 Plan → Work → Review → Compound 的完整工作循环。</p>
<h3 id="为什么火？-4"><a href="#为什么火？-4" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>这个项目代表了一种新的 AI 辅助编程哲学：<strong>不是让 AI 写更多代码，而是让 AI 帮你建立更好的工程习惯</strong>。80% 的时间花在规划和审查，20% 花在执行。每次代码变更都会被 AI 总结成可复用的知识，形成正向飞轮。</p>
<p>加上插件市场的设计——一条命令就能安装，还支持转换成 OpenCode 和 Codex 格式——降低了使用门槛。</p>
<h3 id="技术亮点-4"><a href="#技术亮点-4" class="headerlink" title="技术亮点"></a>技术亮点</h3><ul>
<li><strong>四步循环</strong>：<code>/workflows:plan</code>（规划）→ <code>/workflows:work</code>（执行）→ <code>/workflows:review</code>（多 Agent 代码审查）→ <code>/workflows:compound</code>（知识沉淀）</li>
<li><strong>插件市场</strong>：<code>/plugin marketplace add</code> 一键安装</li>
<li><strong>跨平台转换</strong>：支持将 Claude Code 插件转换成 OpenCode 和 Codex 格式</li>
<li><strong>知识复合</strong>：每次工作成果自动沉淀为 skills 和 patterns，供未来复用</li>
<li><strong>个人配置同步</strong>：<code>sync</code> 命令可将个人 Claude 配置同步到 OpenCode&#x2F;Codex</li>
</ul>
<h3 id="技术栈-4"><a href="#技术栈-4" class="headerlink" title="技术栈"></a>技术栈</h3><p>TypeScript + Bun 运行时 + Claude Code Plugin API。通过 npm 包 <code>@every-env/compound-plugin</code> 分发。</p>
<h3 id="适用场景-4"><a href="#适用场景-4" class="headerlink" title="适用场景"></a>适用场景</h3><ul>
<li>使用 Claude Code 做日常开发的团队</li>
<li>想建立系统化 AI 编程工作流的个人开发者</li>
<li>跨多个 AI 编程工具（Claude Code + OpenCode + Codex）工作的用户</li>
</ul>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>今天的 Trending 榜单呈现出一个清晰的趋势：**AI Agent 正在从”单点工具”走向”工程体系”**。</p>
<ul>
<li><strong>LangExtract</strong> 解决信息提取的可信度问题</li>
<li><strong>AionUi</strong> 统一 AI 工具的操作界面</li>
<li><strong>Shannon</strong> 把安全测试 Agent 化</li>
<li><strong>gh-aw</strong> 让 CI&#x2F;CD 进入 Agent-native 时代</li>
<li><strong>Compound Engineering</strong> 用 AI 建立知识复利的工程文化</li>
</ul>
<p>这五个项目放在一起看，AI 不仅在写代码，还在测试代码、审查代码、部署代码、从代码中学习。2026 年的软件工程，正在被 Agent 重新定义。</p>
<hr>
<p><em>如果觉得这篇分析有帮助，欢迎点赞、在看、转发三连 🚀</em></p>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2026/02/10/seedance-2-guide/"><img class="fill" src="/images/seedance-2/cover.png" alt="Seedance 2.0 深度解析：字节跳动&quot;杀死比赛&quot;的 AI 视频模型，附免费试用全攻略"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2026-02-10T08:00:00.000Z" title="2/10/2026, 4:00:00 PM">2026-02-10</time>发表</span><span class="level-item"><time dateTime="2026-02-11T08:50:48.705Z" title="2/11/2026, 4:50:48 PM">2026-02-11</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></span><span class="level-item">20 分钟读完 (大约2951个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/02/10/seedance-2-guide/">Seedance 2.0 深度解析：字节跳动&quot;杀死比赛&quot;的 AI 视频模型，附免费试用全攻略</a></h1><div class="content"><blockquote>
<p>Kill the Game — 字节跳动内部文档标题</p>
</blockquote>
<p>2月6日，字节跳动悄然在即梦 AI 平台上线了新一代视频生成模型 <strong>Seedance 2.0</strong>。没有发布会，没有官宣，只有一份飞书文档——标题赫然写着 <strong>“Kill the Game”（杀死比赛）</strong>。</p>
<p>这份文档同时在线人数一度超过 300 人，凌晨四点还有 90 多人在读。一份产品说明书被几百人围观十几个小时，这大概是前所未有的。</p>
<p><img src="/images/seedance-2/cover.png" alt="Seedance 2.0 封面"></p>
<p>AI 视频圈的评价近乎疯狂：</p>
<blockquote>
<p>“Seedance 2.0 是我 26 年来最大的震撼” —— AI 视频博主海辛<br>“碾压 Sora 2” —— 多位从业者评价<br>“AI 视频第一阶段的比赛，结束了” —— 极客公园</p>
</blockquote>
<p>那么，这个模型到底做到了什么？普通人怎么用？本文带你一次搞清楚。</p></div><a class="article-more button is-small is-size-7" href="/2026/02/10/seedance-2-guide/#more">阅读更多</a></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/">上一页</a></div><div class="pagination-next"><a href="/page/3/">下一页</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link is-current" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li><li><a class="pagination-link" href="/page/4/">4</a></li><li><a class="pagination-link" href="/page/5/">5</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/images/headshot.jpeg" alt="内森 Nathan"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">内森 Nathan</p><p class="is-size-6 is-block">Senior Software Engineer Manager @ Microsoft</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">46</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">17</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">110</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hydraxman" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hydraxman"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI/"><span class="level-start"><span class="level-item">AI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/AI-%E6%8A%80%E6%9C%AF%E6%B7%B1%E5%BA%A6/"><span class="level-start"><span class="level-item">AI 技术深度</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%88%A8%E7%A0%81%E9%97%AE%E5%BA%95/"><span class="level-start"><span class="level-item">刨码问底</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%AE%9E%E6%88%98/"><span class="level-start"><span class="level-item">实战</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%89%93%E7%A0%81%E8%A6%81%E4%B9%89/"><span class="level-start"><span class="level-item">打码要义</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%8A%80%E6%9C%AF/"><span class="level-start"><span class="level-item">技术</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90/"><span class="level-start"><span class="level-item">技术分析</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/"><span class="level-start"><span class="level-item">技术教程</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%8A%80%E6%9C%AF%E6%B7%B1%E5%BA%A6/"><span class="level-start"><span class="level-item">技术深度</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%8A%80%E6%9C%AF%E8%B0%83%E7%A0%94/"><span class="level-start"><span class="level-item">技术调研</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90/"><span class="level-start"><span class="level-item">深度分析</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E6%8A%A5%E9%81%93/"><span class="level-start"><span class="level-item">深度报道</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%A7%91%E6%8A%80/"><span class="level-start"><span class="level-item">科技</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E7%A7%91%E6%8A%80/AI%E4%B8%8E%E6%9C%BA%E5%99%A8%E4%BA%BA/"><span class="level-start"><span class="level-item">AI与机器人</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E7%A7%91%E6%8A%80%E8%B5%84%E8%AE%AF/"><span class="level-start"><span class="level-item">科技资讯</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%A7%91%E6%8A%80%E9%80%9F%E9%80%92/"><span class="level-start"><span class="level-item">科技速递</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">英语学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2026-02-18T02:00:00.000Z">2026-02-18</time></p><p class="title"><a href="/2026/02/18/2026-02-18-morning-news/">2026年02月18日早间要闻</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2026-02-17T02:00:00.000Z">2026-02-17</time></p><p class="title"><a href="/2026/02/17/2026-02-17-morning-news/">2026年02月17日早间要闻</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2026-02-16T16:00:00.000Z">2026-02-17</time></p><p class="title"><a href="/2026/02/17/foreign-reactions-spring-gala-robot-2025/">从秧BOT到武BOT：宇树机器人用醉拳和双截棍炸翻2026春晚，全球再次沸腾</a></p><p class="categories"><a href="/categories/%E7%A7%91%E6%8A%80/">科技</a> / <a href="/categories/%E7%A7%91%E6%8A%80/AI%E4%B8%8E%E6%9C%BA%E5%99%A8%E4%BA%BA/">AI与机器人</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2026-02-16T16:00:00.000Z">2026-02-17</time></p><p class="title"><a href="/2026/02/17/english-learning-spring-gala-robot-reactions/">机器人打醉拳！从老外评价春晚《武BOT》学15个地道英语表达</a></p><p class="categories"><a href="/categories/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/">英语学习</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2026-02-16T02:00:00.000Z">2026-02-16</time></p><p class="title"><a href="/2026/02/16/2026-02-16-morning-news/">2026年02月16日早间要闻</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2026/02/"><span class="level-start"><span class="level-item">二月 2026</span></span><span class="level-end"><span class="level-item tag">34</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">十一月 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">十月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/12/"><span class="level-start"><span class="level-item">十二月 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/07/"><span class="level-start"><span class="level-item">七月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/03/"><span class="level-start"><span class="level-item">三月 2017</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/02/"><span class="level-start"><span class="level-item">二月 2017</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/15%E5%88%86%E9%92%9F/"><span class="tag">15分钟</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/2026/"><span class="tag">2026</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/2026-Trends/"><span class="tag">2026 Trends</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">30</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI-Agent/"><span class="tag">AI Agent</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AOP/"><span class="tag">AOP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AST/"><span class="tag">AST</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Agent/"><span class="tag">Agent</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Agentic-Engineering/"><span class="tag">Agentic Engineering</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Android/"><span class="tag">Android</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Claude/"><span class="tag">Claude</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Code-design/"><span class="tag">Code design</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Codex/"><span class="tag">Codex</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Copilot/"><span class="tag">Copilot</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cursor/"><span class="tag">Cursor</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Debug/"><span class="tag">Debug</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DeepSeek/"><span class="tag">DeepSeek</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Design-Patterns/"><span class="tag">Design Patterns</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DevOps/"><span class="tag">DevOps</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/English-Learning/"><span class="tag">English-Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GLM-5/"><span class="tag">GLM-5</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT/"><span class="tag">GPT</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GUI-Agent/"><span class="tag">GUI Agent</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GitHub/"><span class="tag">GitHub</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GoF/"><span class="tag">GoF</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gradle/"><span class="tag">Gradle</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hacker-News/"><span class="tag">Hacker News</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Industry-Thoughts/"><span class="tag">Industry Thoughts</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JVM/"><span class="tag">JVM</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java/"><span class="tag">Java</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LSP/"><span class="tag">LSP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lovart/"><span class="tag">Lovart</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MCP/"><span class="tag">MCP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenAI/"><span class="tag">OpenAI</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenClaw/"><span class="tag">OpenClaw</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Optimus/"><span class="tag">Optimus</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Prompt-Engineering/"><span class="tag">Prompt Engineering</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/React/"><span class="tag">React</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reading/"><span class="tag">Reading</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Robotics/"><span class="tag">Robotics</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Rust/"><span class="tag">Rust</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Science/"><span class="tag">Science</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Seedance/"><span class="tag">Seedance</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SpaceX/"><span class="tag">SpaceX</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spring-Festival-Gala/"><span class="tag">Spring-Festival-Gala</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Technology/"><span class="tag">Technology</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Trending/"><span class="tag">Trending</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/UI%E8%AE%BE%E8%AE%A1/"><span class="tag">UI设计</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/UML/"><span class="tag">UML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unitree/"><span class="tag">Unitree</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Windows/"><span class="tag">Windows</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ZeroClaw/"><span class="tag">ZeroClaw</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/bytecode/"><span class="tag">bytecode</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/macOS/"><span class="tag">macOS</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B8%AD%E5%9B%BD%E5%88%B6%E9%80%A0/"><span class="tag">中国制造</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"><span class="tag">人工智能</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%BA%E5%BD%A2%E6%9C%BA%E5%99%A8%E4%BA%BA/"><span class="tag">人形机器人</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/"><span class="tag">代码分析</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BB%A3%E7%A0%81%E5%8F%AF%E8%A7%86%E5%8C%96/"><span class="tag">代码可视化</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%9B%E6%96%B0/"><span class="tag">创新</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%89%8D%E7%AB%AF/"><span class="tag">前端</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8E%86%E5%8F%B2/"><span class="tag">历史</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%95%86%E4%B8%9A/"><span class="tag">商业</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BD%E5%86%85/"><span class="tag">国内</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%8F%E4%BB%A4%E6%97%B6/"><span class="tag">夏令时</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="tag">多模态大模型</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="tag">大模型</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%AA%E7%A9%BA%E8%AE%A1%E7%AE%97/"><span class="tag">太空计算</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"><span class="tag">字节码</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8/"><span class="tag">字节跳动</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%87%E6%A0%91%E7%A7%91%E6%8A%80/"><span class="tag">宇树科技</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%89%E5%85%A8/"><span class="tag">安全</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AF%B9%E6%AF%94%E8%AF%84%E6%B5%8B/"><span class="tag">对比评测</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"><span class="tag">开发工具</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BC%80%E6%BA%90/"><span class="tag">开源</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"><span class="tag">强化学习</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BE%AE%E8%BD%AF/"><span class="tag">微软</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8A%80%E6%9C%AF%E6%97%A5%E6%8A%A5/"><span class="tag">技术日报</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8A%80%E6%9C%AF%E8%B6%8B%E5%8A%BF/"><span class="tag">技术趋势</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8F%90%E7%A4%BA%E8%AF%8D/"><span class="tag">提示词</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%99%E7%A8%8B/"><span class="tag">教程</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%B0%E6%98%A5/"><span class="tag">新春</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%B0%E9%97%BB/"><span class="tag">新闻</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%97%A9%E6%8A%A5/"><span class="tag">早报</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%98%A5%E6%99%9A/"><span class="tag">春晚</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%99%BA%E8%B0%B1/"><span class="tag">智谱</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/"><span class="tag">本地部署</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/"><span class="tag">机器人</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%AD%A6BOT/"><span class="tag">武BOT</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B5%8B%E8%AF%95%E8%87%AA%E5%8A%A8%E5%8C%96/"><span class="tag">测试自动化</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90/"><span class="tag">深度分析</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B7%B1%E5%BA%A6%E7%A0%94%E7%A9%B6/"><span class="tag">深度研究</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A7%91%E6%8A%80/"><span class="tag">科技</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A7%91%E6%8A%80%E5%B1%95%E6%9C%9B/"><span class="tag">科技展望</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A7%91%E6%8A%80%E7%83%AD%E6%A6%9C/"><span class="tag">科技热榜</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A7%91%E6%8A%80%E8%B6%8B%E5%8A%BF/"><span class="tag">科技趋势</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A7%A7BOT/"><span class="tag">秧BOT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A8%8B%E5%BA%8F%E7%90%86%E8%A7%A3/"><span class="tag">程序理解</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BC%96%E7%A8%8B/"><span class="tag">编程</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BC%96%E7%A8%8B%E5%B7%A5%E5%85%B7/"><span class="tag">编程工具</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BE%8E%E8%82%A1/"><span class="tag">美股</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/"><span class="tag">英语学习</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90/"><span class="tag">视频生成</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%B0%E5%BF%86%E7%B3%BB%E7%BB%9F/"><span class="tag">记忆系统</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%BB%E4%B9%A6/"><span class="tag">读书</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B0%B7%E6%AD%8C/"><span class="tag">谷歌</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9D%A2%E5%90%91%E5%88%87%E9%9D%A2/"><span class="tag">面向切面</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%A3%9E%E4%B9%A6/"><span class="tag">飞书</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%A9%AC%E6%96%AF%E5%85%8B/"><span class="tag">马斯克</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li></ul></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/logo.svg" alt="内森淼文" height="28"></a><p class="is-size-7"><span>&copy; 2026 Nathan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="My GitHub Index" href="https://github.com/hydraxman"><i class="fab fa-github"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>