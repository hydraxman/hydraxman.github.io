<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>ATM被黑客当提款机、Minecraft换引擎…本周科技圈炸了</title>
    <link href="/2026/02/20/tech-news-2026-02-20/"/>
    <url>/2026/02/20/tech-news-2026-02-20/</url>
    
    <content type="html"><![CDATA[<p>又到了每周科技新闻精选时间！本周有 FBI 的安全警告、Minecraft 的技术大迁移、还有 GitHub 上的宝藏项目。泡杯咖啡，花五分钟速览本周科技圈大事。</p><h2 id="🔐-安全与隐私"><a href="#🔐-安全与隐私" class="headerlink" title="🔐 安全与隐私"></a>🔐 安全与隐私</h2><p><img src="/images/img3_news.png" alt="Tech News Highlights"></p><h3 id="FBI-警告：ATM-Jackpotting-攻击激增"><a href="#FBI-警告：ATM-Jackpotting-攻击激增" class="headerlink" title="FBI 警告：ATM Jackpotting 攻击激增"></a>FBI 警告：ATM Jackpotting 攻击激增</h3><p>FBI 近日发布安全公告，警告 ATM “Jackpotting” 攻击正在显著增加。</p><p>什么是 Jackpotting？简单说，黑客通过物理接触或远程入侵 ATM 的操作系统，让机器像老虎机一样疯狂吐钞票。</p><p><strong>攻击方式主要有两种：</strong></p><ul><li><strong>物理攻击：</strong> 黑客打开 ATM 外壳，直接连接笔记本电脑或特制设备到 ATM 主板，植入恶意软件控制出钞机构</li><li><strong>远程攻击：</strong> 通过银行内部网络渗透到 ATM 管理系统，远程下发指令</li></ul><p>FBI 表示，近期案例中攻击者使用了更新的恶意软件变种，能绕过多数现有安全防护。受影响的主要是使用较旧操作系统（如 Windows XP&#x2F;7）的 ATM 设备。</p><blockquote><p>💡 <strong>对普通用户的影响：</strong> 直接影响不大，但建议优先使用银行网点内的 ATM，避免独立放置在便利店等处的设备。</p></blockquote><h3 id="密码管理器的”零知识”承诺值得信任吗？"><a href="#密码管理器的”零知识”承诺值得信任吗？" class="headerlink" title="密码管理器的”零知识”承诺值得信任吗？"></a>密码管理器的”零知识”承诺值得信任吗？</h3><p>一项新的安全研究指出，多款主流密码管理器宣称的”零知识”架构并非铁板一块。</p><p>所谓”零知识”，是指服务商声称他们<strong>完全无法看到你的密码</strong>——所有加解密都在本地完成，传到云端的只有加密后的密文。</p><p>但研究发现了几个问题：</p><ul><li><strong>元数据泄露：</strong> 虽然密码本身加密了，但网站 URL、用户名、时间戳等元数据可能未加密</li><li><strong>浏览器扩展风险：</strong> 部分密码管理器的浏览器扩展会在内存中短暂存储明文密码</li><li><strong>恢复流程漏洞：</strong> 某些”忘记主密码”的恢复机制可能破坏零知识承诺</li></ul><p><strong>建议：</strong> 密码管理器仍然比重复使用简单密码好得多。但不要盲目迷信”零知识”标签，关注具体的安全审计报告更靠谱。</p><h3 id="OpenAI-Persona-身份监控系统曝光"><a href="#OpenAI-Persona-身份监控系统曝光" class="headerlink" title="OpenAI + Persona 身份监控系统曝光"></a>OpenAI + Persona 身份监控系统曝光</h3><p>有开发者发现 OpenAI 正在与身份验证公司 Persona 合作，构建一套用户身份监控系统。</p><p>根据泄露的 API 文档和代码片段，这套系统可能用于：</p><ul><li>检测和阻止 API 滥用</li><li>识别违反使用政策的用户</li><li>跨设备&#x2F;账号关联同一用户</li></ul><p>这引发了隐私倡导者的担忧。虽然打击滥用是合理的，但”身份监控”这个词本身就够让人不安了。OpenAI 尚未对此做出官方回应。</p><h2 id="🎮-游戏与技术"><a href="#🎮-游戏与技术" class="headerlink" title="🎮 游戏与技术"></a>🎮 游戏与技术</h2><h3 id="Minecraft-Java-版：从-OpenGL-到-Vulkan-的大迁移"><a href="#Minecraft-Java-版：从-OpenGL-到-Vulkan-的大迁移" class="headerlink" title="Minecraft Java 版：从 OpenGL 到 Vulkan 的大迁移"></a>Minecraft Java 版：从 OpenGL 到 Vulkan 的大迁移</h3><p>Mojang 宣布 Minecraft Java 版将从 OpenGL 渲染引擎切换到 <strong>Vulkan</strong>。</p><p>这是一个意义重大的技术决策：</p><p><strong>为什么要换？</strong></p><ul><li>OpenGL 已经”上了年纪”，在现代 GPU 上的表现不如 Vulkan</li><li>Vulkan 提供更底层的硬件控制，减少驱动层的性能开销</li><li>更好的多线程渲染支持</li></ul><p><strong>玩家能感受到什么？</strong></p><ul><li><strong>帧率提升：</strong> 尤其是在复杂场景（红石机器、大量实体）中</li><li><strong>更稳定的帧时间：</strong> 减少卡顿和微掉帧</li><li><strong>更好的光影支持：</strong> 为未来的图形升级铺路</li></ul><p><strong>可能的问题：</strong></p><ul><li>老旧显卡可能不支持 Vulkan</li><li>Mod 社区需要适配（Fabric&#x2F;Forge 的渲染相关 mod 可能需要重写）</li><li>过渡期可能出现兼容性问题</li></ul><p>Mojang 表示将提供较长的过渡期，OpenGL 版本会继续维护一段时间。光影 mod 开发者社区对此普遍表示欢迎。</p><h2 id="🔥-GitHub-Trending-本周热榜-Top-5"><a href="#🔥-GitHub-Trending-本周热榜-Top-5" class="headerlink" title="🔥 GitHub Trending 本周热榜 Top 5"></a>🔥 GitHub Trending 本周热榜 Top 5</h2><p>每周必看的 GitHub 趋势项目，本周有几个特别有意思。</p><h3 id="1-obra-x2F-superpowers-⭐-55-4k"><a href="#1-obra-x2F-superpowers-⭐-55-4k" class="headerlink" title="1. obra&#x2F;superpowers ⭐ 55.4k"></a>1. obra&#x2F;superpowers ⭐ 55.4k</h3><p><strong>Agentic 技能框架</strong></p><p>Superpowers 可能是今年 GitHub 上增长最快的项目之一。它提供了一个框架，让你为 AI Agent 构建可组合的”超能力”模块。</p><p><strong>核心理念：</strong> 把复杂的 Agent 能力拆分成独立的、可复用的技能模块。每个技能有明确的输入&#x2F;输出定义，可以像乐高一样组合。</p><p><strong>为什么火：</strong> 随着 Agent 概念普及，大家发现最大的痛点不是模型能力，而是<strong>工程化</strong>。Superpowers 提供了一套工程化方案。</p><h3 id="2-RichardAtCT-x2F-claude-code-telegram-⭐-977"><a href="#2-RichardAtCT-x2F-claude-code-telegram-⭐-977" class="headerlink" title="2. RichardAtCT&#x2F;claude-code-telegram ⭐ 977"></a>2. RichardAtCT&#x2F;claude-code-telegram ⭐ 977</h3><p><strong>通过 Telegram 远程操控 Claude Code</strong></p><p>一个精巧的桥接工具，让你在手机上通过 Telegram 向远程服务器上的 Claude Code 发送指令。</p><p><strong>使用场景：</strong> 你在外面喝咖啡，突然想到一个 bug 的修复方案——掏出手机，在 Telegram 里告诉 Claude Code 去改，看它实时操作。不需要打开笔记本。</p><p>虽然 star 数不多，但这种”移动优先”的开发体验代表了一个有趣的方向。</p><h3 id="3-harvard-edge-x2F-cs249r-book-⭐-20-2k"><a href="#3-harvard-edge-x2F-cs249r-book-⭐-20-2k" class="headerlink" title="3. harvard-edge&#x2F;cs249r_book ⭐ 20.2k"></a>3. harvard-edge&#x2F;cs249r_book ⭐ 20.2k</h3><p><strong>哈佛 CS249r：ML Systems 教材</strong></p><p>哈佛大学 CS249r 课程的配套教材，开源在 GitHub 上。内容覆盖机器学习系统的方方面面：</p><ul><li>模型训练基础设施</li><li>推理优化</li><li>边缘部署</li><li>MLOps</li><li>硬件加速器</li></ul><p><strong>推荐人群：</strong> 想系统学习 ML 工程（而不只是 ML 算法）的同学。教材质量极高，配有大量实际案例和代码。</p><h3 id="4-p-e-w-x2F-heretic-⭐-8-5k"><a href="#4-p-e-w-x2F-heretic-⭐-8-5k" class="headerlink" title="4. p-e-w&#x2F;heretic ⭐ 8.5k"></a>4. p-e-w&#x2F;heretic ⭐ 8.5k</h3><p><strong>自动移除 LLM 审查限制</strong></p><p>这个项目一上线就引发了巨大争议。Heretic 声称可以自动检测和移除大语言模型中的安全限制（所谓的”alignment tax”）。</p><p><strong>技术原理：</strong> 通过分析模型的 activation patterns，定位负责”拒绝回答”的神经元簇，然后有选择地削弱它们。</p><p><strong>争议点：</strong> 支持者认为这是”AI 自由”的体现；反对者担心这会被用于生成有害内容。目前多个平台已经开始讨论是否应该限制此类工具的传播。</p><blockquote><p>⚠️ <strong>编辑注：</strong> 我们报道此项目是基于其技术影响力，不代表鼓励移除安全限制。负责任地使用 AI 是每个开发者的责任。</p></blockquote><h3 id="5-HailToDodongo-x2F-pyrite64-⭐-1-8k"><a href="#5-HailToDodongo-x2F-pyrite64-⭐-1-8k" class="headerlink" title="5. HailToDodongo&#x2F;pyrite64 ⭐ 1.8k"></a>5. HailToDodongo&#x2F;pyrite64 ⭐ 1.8k</h3><p><strong>N64 游戏引擎</strong></p><p>一个全新的 Nintendo 64 游戏引擎，目标是在原版 N64 硬件上运行。</p><p><strong>亮点：</strong></p><ul><li>现代 C 语言编写，不依赖官方 SDK</li><li>支持原生 N64 硬件和模拟器</li><li>内置关卡编辑器</li><li>完善的文档和教程</li></ul><p><strong>为什么值得关注：</strong> N64 homebrew 社区一直很活跃，但缺少一个现代化的游戏引擎。Pyrite64 填补了这个空白。如果你对复古游戏开发感兴趣，这是一个很好的起点。</p><h2 id="📊-一周数据"><a href="#📊-一周数据" class="headerlink" title="📊 一周数据"></a>📊 一周数据</h2><table><thead><tr><th>指标</th><th>数据</th></tr></thead><tbody><tr><td>GitHub 新增仓库（本周）</td><td>~120 万</td></tr><tr><td>npm 包发布量</td><td>~35 万</td></tr><tr><td>HN 头条热度最高话题</td><td>LLM 审查移除工具争议</td></tr><tr><td>本周最活跃语言</td><td>Python、TypeScript、Rust</td></tr></tbody></table><h2 id="下周预告"><a href="#下周预告" class="headerlink" title="下周预告"></a>下周预告</h2><ul><li>NVIDIA GTC 2026 即将开幕，预计发布新一代推理芯片</li><li>Apple 春季发布会传闻：可能更新 MacBook Air</li><li>Rust 2024 edition 正式进入稳定通道</li></ul><hr><p><em>本文由 TechHome 编辑部整理发布，信息截至 2026 年 2 月 20 日。转载请注明出处。</em></p>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GitHub</tag>
      
      <tag>安全</tag>
      
      <tag>科技新闻</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Claude、GPT、Gemini 二月大乱斗：到底谁才是真正的王者？</title>
    <link href="/2026/02/20/ai-models-feb-2026/"/>
    <url>/2026/02/20/ai-models-feb-2026/</url>
    
    <content type="html"><![CDATA[<p>2026 年 2 月，AI 圈再次热闹非凡。短短两周内，Anthropic、OpenAI、Google 三巨头接连放出重磅模型，让整个行业为之震动。</p><p>本文将深度对比本月发布的四大模型，帮你理清这场混战的格局。</p><p><img src="/images/img2_battle.png" alt="AI Models Battle"></p><h2 id="选手一览"><a href="#选手一览" class="headerlink" title="选手一览"></a>选手一览</h2><p>先来看全景对比：</p><p><strong>🟣 Claude Opus 4.6</strong> — Anthropic · 2月5日</p><ul><li>定位：全能旗舰</li><li>上下文：1M tokens (beta)</li><li>定价：$5&#x2F;$25 per M tokens</li><li>亮点：Agent Teams 多智能体协作</li></ul><p><strong>🟢 GPT-5.3-Codex</strong> — OpenAI · 2月5日</p><ul><li>定位：Agentic 编码</li><li>速度：比 5.2 快 25%</li><li>亮点：首个”自我创建”模型</li></ul><p><strong>⚡ GPT-5.3-Codex-Spark</strong> — OpenAI + Cerebras · 2月12日</p><ul><li>定位：实时编码</li><li>上下文：128k（纯文本）</li><li>亮点：1000+ tokens&#x2F;秒</li></ul><p><strong>🔵 Gemini 3.1 Pro</strong> — Google · 2月19日</p><ul><li>定位：推理升级</li><li>定价：预览阶段免费</li><li>亮点：ARC-AGI-2 达 77.1%</li></ul><p>接下来逐个拆解。</p><h2 id="🟣-Claude-Opus-4-6：全能选手再进化"><a href="#🟣-Claude-Opus-4-6：全能选手再进化" class="headerlink" title="🟣 Claude Opus 4.6：全能选手再进化"></a>🟣 Claude Opus 4.6：全能选手再进化</h2><p><strong>发布日期：2月5日</strong></p><p>Anthropic 这次带来的 Opus 4.6 堪称”六边形战士”。</p><p><strong>编码能力大幅提升</strong></p><p>Opus 4.6 在代码审查和调试方面有显著改进。在 Terminal-Bench 2.0 基准测试（使用 Anthropic 自己的 harness）中拿下高分，在 GDPval-AA（衡量金融、法律等知识工作能力的评测）上超过 GPT-5.2 约 <strong>144 Elo</strong>。在 Arena 排行榜上，Opus 4.6 在文本和代码方面均位居前列。</p><p><strong>Agent Teams：多智能体协作</strong></p><p>这可能是 Opus 4.6 最具前瞻性的特性。Agent Teams 允许多个 Claude 实例协作，自动拆分大任务，各自完成子任务后汇总结果。想象一下：一个 Agent 负责前端、一个负责后端、一个负责测试，同时开工。</p><p><strong>1M Token 上下文窗口</strong></p><p>百万级上下文窗口进入 beta。这意味着你可以把一整个代码仓库扔进去，让 Claude 通盘理解。配合新的 <strong>Compaction</strong> 特性（自动压缩上下文），即使是超长任务也能保持流畅。</p><p><strong>Adaptive Thinking：聪明地思考</strong></p><p>新的自适应思考机制让 Claude 动态决定思考深度。简单问题快速回答，复杂问题深入推理。你也可以通过 Effort 控制（high&#x2F;medium&#x2F;low）手动调节，在速度和质量之间找到平衡。</p><p><strong>更多亮点：</strong></p><ul><li>Cowork 自主多任务模式</li><li>Claude in Excel 升级</li><li>Claude in PowerPoint 研究预览</li></ul><p><strong>点评：</strong> Opus 4.6 是目前最全面的模型之一，Agent Teams 和 Compaction 让它在长任务和复杂项目中优势巨大。定价 $5&#x2F;$25 虽不便宜，但对得起这个能力。不过值得注意的是，在某些推理基准（如 ARC-AGI-2、Humanity’s Last Exam）上，Gemini 3.1 Pro 已经超过了它。</p><h2 id="🟢-GPT-5-3-Codex：编码之王"><a href="#🟢-GPT-5-3-Codex：编码之王" class="headerlink" title="🟢 GPT-5.3-Codex：编码之王"></a>🟢 GPT-5.3-Codex：编码之王</h2><p><strong>发布日期：2月5日</strong></p><p>和 Opus 4.6 同一天发布——OpenAI 显然不想让 Anthropic 独占风头。</p><p><strong>最强 Agentic 编码模型</strong></p><p>GPT-5.3-Codex 合并了 GPT-5.2-Codex 的编码能力和 GPT-5.2 的推理能力，同时速度提升了 **25%**。在 SWE-Bench Pro 和 Terminal-Bench 上拿到了行业最高分。</p><p><strong>“自我创建”的模型</strong></p><p>这是 GPT-5.3-Codex 最令人震撼的标签——它是首个用自身早期版本来调试训练过程的模型。换句话说，这个模型参与了自己的”出生”过程。虽然这更多是工程创新而非理论突破，但它暗示了 AI 开发流程的一个重要转折点。</p><p><strong>超长任务支持</strong></p><p>GPT-5.3-Codex 支持运行时间从数小时到数天甚至数周的任务。更重要的是，你可以在任务运行过程中<strong>实时交互和引导</strong>，而不是设定后坐等结果。这对大型软件项目的开发至关重要。</p><p><strong>点评：</strong> 如果你的核心需求是编程，GPT-5.3-Codex 目前可能是最佳选择。超长任务支持 + 实时交互的组合，让它更像一个真正的编程搭档，而不只是一个代码生成器。</p><h2 id="⚡-GPT-5-3-Codex-Spark：速度即正义"><a href="#⚡-GPT-5-3-Codex-Spark：速度即正义" class="headerlink" title="⚡ GPT-5.3-Codex-Spark：速度即正义"></a>⚡ GPT-5.3-Codex-Spark：速度即正义</h2><p><strong>发布日期：2月12日</strong></p><p>一周后，OpenAI 联手芯片公司 Cerebras 放出了 Spark。</p><p><strong>超过 1000 tokens&#x2F;秒</strong></p><p>这个速度意味着什么？普通模型大约 50-100 tok&#x2F;s，快的能到 200-300。Spark 直接飙到四位数，靠的是 Cerebras 的晶圆级芯片（Wafer-Scale Engine）。</p><p><strong>为实时编码而生</strong></p><p>Spark 是 GPT-5.3-Codex 的小型化版本，专注于实时交互场景。它的设计理念很明确：</p><ul><li>128k 上下文，纯文本（去掉了多模态以换取速度）</li><li>WebSocket 持久连接，减少连接开销</li><li>端到端延迟全面优化</li></ul><p><strong>性能数据：</strong></p><table><thead><tr><th>指标</th><th>优化幅度</th></tr></thead><tbody><tr><td>Roundtrip 开销</td><td>减少 80%</td></tr><tr><td>每 token 开销</td><td>减少 30%</td></tr><tr><td>首 token 延迟 (TTFT)</td><td>减少 50%</td></tr></tbody></table><p><strong>点评：</strong> Spark 瞄准的是”AI 原生 IDE”场景——你打字的同时，AI 就在实时补全和重构，延迟几乎为零。目前还在 ChatGPT Pro 用户研究预览阶段，但它代表了一个重要方向：不是所有场景都需要最聪明的模型，有时候够快就是最大的优势。</p><h2 id="🔵-Gemini-3-1-Pro：推理新标杆"><a href="#🔵-Gemini-3-1-Pro：推理新标杆" class="headerlink" title="🔵 Gemini 3.1 Pro：推理新标杆"></a>🔵 Gemini 3.1 Pro：推理新标杆</h2><p><strong>发布日期：2月19日</strong></p><p>Google 在月底压轴登场。</p><p><strong>ARC-AGI-2 突破性成绩</strong></p><p>Gemini 3.1 Pro 在 ARC-AGI-2 基准测试上达到了 <strong>77.1%</strong> 的成绩，是 Gemini 3 Pro（31.1%）的两倍以上。ARC-AGI 测试的是抽象推理能力——理解从未见过的模式和规则——这一直被认为是 AI 的薄弱环节。作为对比，Opus 4.6 为 68.8%，GPT-5.2 为 52.9%。</p><p><strong>Humanity’s Last Exam 同样领先</strong></p><p>在这项测试高级学术推理的基准上，3.1 Pro 拿到了 **44.4%**（无工具），超过 Opus 4.6 的 40.0% 和 GPT-5.2 的 34.5%。这说明它在纯推理深度上确实上了一个台阶。</p><p><strong>但也不是全面碾压</strong></p><p>在 Arena 排行榜（用户投票）上，Opus 4.6 在文本（1504 分）和代码两个维度仍然领先 Gemini 3.1 Pro 几个点。Terminal-Bench 2.0 上，GPT-5.3-Codex 自报成绩 77.3% 最高，Gemini 3.1 Pro 68.5%，Opus 4.6 65.4%。所以不同评测维度下各有胜负。</p><p><strong>幻觉率大幅下降</strong></p><p>Google 在 AA-Omniscience 幻觉评测上公布了一个亮眼数据：幻觉率从 3 Pro 的 88% 降至 3.1 Pro 的 **50%**。虽然50%仍然不低，但降幅接近一半，说明模型在”不知道就说不知道”这件事上有了明显进步。</p><p><strong>实测体验：推理能力确实强</strong></p><p>来自 Analytics Vidhya 的实测显示，3.1 Pro 在多步逻辑推理、代码生成与重构、长上下文分析这三类任务中表现突出。特别是在有多个约束条件的逻辑推理题中，3.1 Pro 能正确枚举所有有效组合，不会像很多模型那样在约束冲突时”编造”答案。测试者评价：”constraint-heavy logic without collapsing into contradictions”（处理密集约束的逻辑时不会自相矛盾）。</p><p>另一个值得注意的新特性是 <strong>Thinking 粒度控制</strong>：3.1 Pro 支持 Minimal &#x2F; Low &#x2F; Medium &#x2F; High 四个思考级别，开发者可以根据任务复杂度灵活调节，在延迟和推理质量之间取得平衡。</p><p><strong>创意编码的王者</strong></p><p>3.1 Pro 在几个特定方向上展现了惊人的能力：</p><ul><li><strong>SVG 动画生成</strong> — 从文字描述直接生成复杂动画</li><li><strong>复杂系统合成</strong> — 理解和设计多组件交互系统</li><li><strong>3D 交互设计</strong> — 生成可交互的 3D 场景</li><li><strong>创意编码</strong> — 将艺术创意转化为代码</li></ul><p><strong>广泛可用</strong></p><p>Gemini 3.1 Pro 可在以下平台使用：Gemini API、Vertex AI、Gemini App、NotebookLM、Android Studio、Google Antigravity。</p><p><strong>点评：</strong> Google 走了一条差异化路线。3.1 Pro 不仅在推理基准上领先（ARC-AGI-2、HLE 双料冠军），还在幻觉控制和思考粒度方面有实质性进步。目前还是预览阶段，定价和 Gemini 3 Pro 相同（等于免费升级），性价比极高。</p><h2 id="横向对比：谁适合谁？"><a href="#横向对比：谁适合谁？" class="headerlink" title="横向对比：谁适合谁？"></a>横向对比：谁适合谁？</h2><p><img src="/images/img2_comparison.png" alt="Which AI Model to Choose"></p><p><strong>日常编程</strong> → GPT-5.3-Codex<br>编码最强，支持超长自主任务</p><p><strong>实时编码 &#x2F; IDE 集成</strong> → Codex-Spark<br>极致速度，即时反馈</p><p><strong>复杂项目管理</strong> → Claude Opus 4.6<br>Agent Teams 多智能体协作</p><p><strong>代码审查 &#x2F; 调试</strong> → Claude Opus 4.6<br>Terminal-Bench 最高分</p><p><strong>创意 &#x2F; 设计</strong> → Gemini 3.1 Pro<br>SVG &#x2F; 3D &#x2F; 创意编码突出</p><p><strong>抽象推理</strong> → Gemini 3.1 Pro<br>ARC-AGI-2 断层领先</p><p><strong>超长文档处理</strong> → Claude Opus 4.6<br>1M 上下文 + Compaction</p><p><strong>预算敏感</strong> → Gemini 3.1 Pro<br>预览阶段免费</p><h2 id="趋势观察"><a href="#趋势观察" class="headerlink" title="趋势观察"></a>趋势观察</h2><h3 id="1-Agentic-AI-全面爆发"><a href="#1-Agentic-AI-全面爆发" class="headerlink" title="1. Agentic AI 全面爆发"></a>1. Agentic AI 全面爆发</h3><p>三家厂商不约而同地强化了 Agent 能力。Claude 有 Agent Teams，GPT-5.3-Codex 支持超长自主任务，Gemini 在系统合成上发力。2026 年的主题词已经很明确：<strong>从对话到行动</strong>。</p><h3 id="2-速度成为新战场"><a href="#2-速度成为新战场" class="headerlink" title="2. 速度成为新战场"></a>2. 速度成为新战场</h3><p>Cerebras 的入局让 OpenAI 找到了新的差异化维度。当模型能力趋于同质化，速度可能成为下一个决胜因素。可以预见，更多硬件厂商会加入这场竞争。</p><h3 id="3-专业化分工加速"><a href="#3-专业化分工加速" class="headerlink" title="3. 专业化分工加速"></a>3. 专业化分工加速</h3><p>“一个模型打天下”的时代正在远去。GPT-5.3-Codex 专攻编码，Spark 专攻速度，Gemini 3.1 Pro 专攻推理。未来的 AI 基础设施可能是一个”模型编排层”，根据任务类型自动路由到最合适的模型。</p><h3 id="4-上下文窗口继续膨胀"><a href="#4-上下文窗口继续膨胀" class="headerlink" title="4. 上下文窗口继续膨胀"></a>4. 上下文窗口继续膨胀</h3><p>Claude 的 1M token 窗口不再是噱头，配合 Compaction 技术已经可以实际使用。这改变了很多工程实践——不再需要精心设计 RAG pipeline，直接把所有东西丢进上下文就行。</p><h2 id="最后的话"><a href="#最后的话" class="headerlink" title="最后的话"></a>最后的话</h2><p>2026 年 2 月是 AI 模型发展的一个缩影：竞争白热化，创新节奏加快，专业化分工明显。对开发者来说，这是最好的时代——选择从未如此丰富。</p><p>关键建议：不要只盯着跑分表。选择模型时，想清楚你的核心场景，然后选那个在特定场景下最强的。全能选手固然好，但专精选手在对应领域往往更胜一筹。</p><hr><p><em>本文由 TechHome 编辑部整理发布，数据截至 2026 年 2 月 20 日。转载请注明出处。</em></p>]]></content>
    
    
    <categories>
      
      <category>AI 前沿</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>GPT</tag>
      
      <tag>Claude</tag>
      
      <tag>Gemini</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一个框架打通10个聊天平台，我的AI助手从此不下班</title>
    <link href="/2026/02/20/openclaw-commands-guide/"/>
    <url>/2026/02/20/openclaw-commands-guide/</url>
    
    <content type="html"><![CDATA[<p>如果你还在为每个聊天平台单独配置 AI 助手而头疼，那你一定要认识一下 <strong>OpenClaw</strong> —— 一个开源的 AI 助手框架，能同时连接 WhatsApp、Telegram、Discord、飞书、Slack 等十多个平台，统一管理你的 AI 助手。</p><p>本文将全面梳理 OpenClaw 的命令体系和实用技巧，从安装到进阶，帮你快速上手。🚀</p><h2 id="1️⃣-安装与初始化"><a href="#1️⃣-安装与初始化" class="headerlink" title="1️⃣ 安装与初始化"></a>1️⃣ 安装与初始化</h2><p><strong>macOS &#x2F; Linux 一行搞定：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -fsSL https://openclaw.ai/install.sh | bash<br></code></pre></td></tr></table></figure><p><strong>Windows PowerShell：</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-built_in">iwr</span> <span class="hljs-literal">-useb</span> https://openclaw.ai/install.ps1 | <span class="hljs-built_in">iex</span><br></code></pre></td></tr></table></figure><p>安装完成后，运行初始化向导：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw onboard --install-daemon<br></code></pre></td></tr></table></figure><p>这会引导你完成守护进程安装、模型配置和首个频道的接入。如果你只想做基础配置，也可以用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw setup<br></code></pre></td></tr></table></figure><blockquote><p>💡 <strong>小贴士：</strong> <code>onboard</code> 向导会自动检测你的环境，推荐最佳配置方案，新手强烈建议走一遍。</p></blockquote><h2 id="2️⃣-Gateway-管理"><a href="#2️⃣-Gateway-管理" class="headerlink" title="2️⃣ Gateway 管理"></a>2️⃣ Gateway 管理</h2><p><img src="/images/img1_arch.png" alt="OpenClaw Architecture"></p><p>Gateway 是 OpenClaw 的核心守护进程，所有消息收发、模型调用都经过它。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看状态</span><br>openclaw gateway status<br><br><span class="hljs-comment"># 启动 / 停止 / 重启</span><br>openclaw gateway start<br>openclaw gateway stop<br>openclaw gateway restart<br><br><span class="hljs-comment"># 前台运行（调试用，可指定端口）</span><br>openclaw gateway run --port 18789<br><br><span class="hljs-comment"># 健康检查</span><br>openclaw gateway health<br></code></pre></td></tr></table></figure><p>配置文件位于 <code>~/.openclaw/openclaw.json</code>，采用 <strong>JSON5 格式</strong>（支持注释和尾逗号），修改后 Gateway 会自动热重载，无需手动重启。</p><h2 id="3️⃣-频道管理"><a href="#3️⃣-频道管理" class="headerlink" title="3️⃣ 频道管理"></a>3️⃣ 频道管理</h2><p>频道（Channels）是 OpenClaw 连接各聊天平台的桥梁。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看所有频道</span><br>openclaw channels list<br><br><span class="hljs-comment"># 查看频道状态</span><br>openclaw channels status<br><br><span class="hljs-comment"># 添加 / 移除频道</span><br>openclaw channels add<br>openclaw channels remove<br><br><span class="hljs-comment"># WhatsApp 扫码登录</span><br>openclaw channels login<br></code></pre></td></tr></table></figure><p><strong>目前支持的平台：</strong></p><ul><li>📱 WhatsApp</li><li>✈️ Telegram</li><li>🎮 Discord</li><li>💼 Slack</li><li>🔒 Signal</li><li>💬 iMessage</li><li>🐦 飞书（Lark）</li><li>📧 Google Chat</li><li>🏢 Microsoft Teams</li></ul><p>一个 OpenClaw 实例可以同时连接多个平台，消息统一处理，上下文共享。</p><h2 id="4️⃣-模型管理"><a href="#4️⃣-模型管理" class="headerlink" title="4️⃣ 模型管理"></a>4️⃣ 模型管理</h2><p>OpenClaw 支持多家 AI 模型提供商，灵活切换。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看可用模型</span><br>openclaw models list<br><br><span class="hljs-comment"># 查看模型状态</span><br>openclaw models status<br><br><span class="hljs-comment"># 设置默认模型</span><br>openclaw models <span class="hljs-built_in">set</span><br><br><span class="hljs-comment"># 扫描本地和远程可用模型</span><br>openclaw models scan<br><br><span class="hljs-comment"># 认证管理</span><br>openclaw models auth add<br>openclaw models auth setup-token<br>openclaw models auth paste-token<br><br><span class="hljs-comment"># Fallback 链（主模型不可用时自动切换）</span><br>openclaw models fallbacks add<br>openclaw models fallbacks remove<br>openclaw models fallbacks clear<br></code></pre></td></tr></table></figure><p><strong>支持的模型提供商：</strong></p><ul><li>Anthropic（Claude 系列）</li><li>OpenAI（GPT 系列）</li><li>Google（Gemini 系列）</li><li>GitHub Copilot</li><li>以及更多第三方兼容接口</li></ul><blockquote><p>💡 <strong>小贴士：</strong> 配置 fallback 链可以大幅提升可用性。比如主用 Claude Opus，fallback 到 GPT-5，再 fallback 到 Gemini，确保永远有模型可用。</p></blockquote><h2 id="5️⃣-Skills-技能系统"><a href="#5️⃣-Skills-技能系统" class="headerlink" title="5️⃣ Skills 技能系统"></a>5️⃣ Skills 技能系统</h2><p><img src="/images/img1_skills.png" alt="Skills &amp; Plugins Ecosystem"></p><p>Skills 是 OpenClaw 的扩展能力系统，让 AI 助手获得各种工具能力。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看已安装技能</span><br>openclaw skills list<br><br><span class="hljs-comment"># 查看技能详情</span><br>openclaw skills info &lt;skill-name&gt;<br><br><span class="hljs-comment"># 检查技能健康状态</span><br>openclaw skills check<br></code></pre></td></tr></table></figure><p><strong>技能加载优先级（从高到低）：</strong></p><ol><li><code>workspace/skills/</code> — 工作区技能（项目级）</li><li><code>~/.openclaw/skills/</code> — 本地技能（用户级）</li><li><code>bundled</code> — 内置技能（随 OpenClaw 安装）</li></ol><p><strong>安装社区技能：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">npx clawhub install &lt;skill-name&gt;<br>npx clawhub update &lt;skill-name&gt;<br></code></pre></td></tr></table></figure><p><strong>常用内置技能一览：</strong></p><ul><li>🌤️ <code>weather</code> — 天气查询</li><li>🐙 <code>github</code> — GitHub 操作</li><li>🐻 <code>bear-notes</code> — Bear 笔记集成</li><li>⏰ <code>apple-reminders</code> — Apple 提醒事项</li><li>🎮 <code>discord</code> — Discord 高级操作</li><li>🤖 <code>coding-agent</code> — 编程代理</li></ul><h2 id="6️⃣-Cron-定时任务"><a href="#6️⃣-Cron-定时任务" class="headerlink" title="6️⃣ Cron 定时任务"></a>6️⃣ Cron 定时任务</h2><p>OpenClaw 内置了强大的定时任务系统。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看定时任务</span><br>openclaw cron list<br><br><span class="hljs-comment"># 添加任务</span><br>openclaw cron add<br><br><span class="hljs-comment"># 编辑 / 删除</span><br>openclaw cron edit &lt;<span class="hljs-built_in">id</span>&gt;<br>openclaw cron <span class="hljs-built_in">rm</span> &lt;<span class="hljs-built_in">id</span>&gt;<br><br><span class="hljs-comment"># 启用 / 禁用</span><br>openclaw cron <span class="hljs-built_in">enable</span> &lt;<span class="hljs-built_in">id</span>&gt;<br>openclaw cron <span class="hljs-built_in">disable</span> &lt;<span class="hljs-built_in">id</span>&gt;<br><br><span class="hljs-comment"># 手动触发</span><br>openclaw cron run &lt;<span class="hljs-built_in">id</span>&gt;<br></code></pre></td></tr></table></figure><p><strong>三种调度方式：</strong></p><ul><li><strong>at</strong> — 一次性任务，指定具体时间执行</li><li><strong>every</strong> — 循环任务，如 <code>every 30m</code>、<code>every 2h</code></li><li><strong>cron</strong> — 标准 cron 表达式，如 <code>0 9 * * 1</code>（每周一早九点）</li></ul><blockquote><p>💡 <strong>应用场景：</strong> 定时检查邮件、每日天气播报、定期备份提醒、周报自动生成等。</p></blockquote><h2 id="7️⃣-Sessions-会话管理"><a href="#7️⃣-Sessions-会话管理" class="headerlink" title="7️⃣ Sessions 会话管理"></a>7️⃣ Sessions 会话管理</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看当前活跃会话</span><br>openclaw sessions<br><br><span class="hljs-comment"># 发送单次消息（不进入交互模式）</span><br>openclaw agent --message <span class="hljs-string">&quot;帮我查一下明天的天气&quot;</span><br></code></pre></td></tr></table></figure><p>Sessions 命令可以查看各频道的活跃会话、消息计数和上下文状态，调试时非常有用。</p><h2 id="8️⃣-Browser-浏览器控制"><a href="#8️⃣-Browser-浏览器控制" class="headerlink" title="8️⃣ Browser 浏览器控制"></a>8️⃣ Browser 浏览器控制</h2><p>OpenClaw 可以控制本地浏览器，实现网页自动化。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 浏览器管理</span><br>openclaw browser start<br>openclaw browser stop<br>openclaw browser status<br><br><span class="hljs-comment"># 浏览器操作</span><br>openclaw browser open &lt;url&gt;<br>openclaw browser navigate &lt;url&gt;<br>openclaw browser screenshot<br>openclaw browser snapshot<br></code></pre></td></tr></table></figure><p><strong>支持的浏览器：</strong> Chrome、Brave、Edge、Chromium</p><p>这意味着你可以让 AI 助手帮你填表单、抓取网页内容、截图对比等，非常强大。</p><h2 id="9️⃣-Nodes-节点管理"><a href="#9️⃣-Nodes-节点管理" class="headerlink" title="9️⃣ Nodes 节点管理"></a>9️⃣ Nodes 节点管理</h2><p>Nodes 让你把手机、平板等设备作为 OpenClaw 的远程节点。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看节点状态</span><br>openclaw nodes status<br><br><span class="hljs-comment"># 列出所有节点</span><br>openclaw nodes list<br><br><span class="hljs-comment"># 审批新节点</span><br>openclaw nodes approve<br></code></pre></td></tr></table></figure><p><strong>支持的节点类型：</strong></p><ul><li>📱 iOS 设备</li><li>🤖 Android 设备</li><li>💻 macOS 设备</li></ul><p><strong>节点能力：</strong></p><ul><li>📷 <strong>Camera</strong> — 远程拍照</li><li>🖼️ <strong>Canvas</strong> — 推送 UI 卡片到设备</li><li>🎬 <strong>Screen Recording</strong> — 屏幕录制</li><li>📍 <strong>Location</strong> — 获取设备位置</li></ul><h2 id="🔟-Plugins-插件系统"><a href="#🔟-Plugins-插件系统" class="headerlink" title="🔟 Plugins 插件系统"></a>🔟 Plugins 插件系统</h2><p>插件是比 Skills 更底层的扩展机制。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看已安装插件</span><br>openclaw plugins list<br><br><span class="hljs-comment"># 安装 / 启用 / 禁用</span><br>openclaw plugins install &lt;name&gt;<br>openclaw plugins <span class="hljs-built_in">enable</span> &lt;name&gt;<br>openclaw plugins <span class="hljs-built_in">disable</span> &lt;name&gt;<br><br><span class="hljs-comment"># 插件健康检查</span><br>openclaw plugins doctor<br></code></pre></td></tr></table></figure><p>插件可以注册：</p><ul><li><strong>Agent Tools</strong> — 新的工具能力</li><li><strong>Channels</strong> — 新的聊天平台支持</li><li><strong>Hooks</strong> — 消息处理钩子</li></ul><h2 id="1️⃣1️⃣-常用插件与社区技能详解"><a href="#1️⃣1️⃣-常用插件与社区技能详解" class="headerlink" title="1️⃣1️⃣ 常用插件与社区技能详解"></a>1️⃣1️⃣ 常用插件与社区技能详解</h2><p>OpenClaw 的生态分两层：<strong>Plugins（插件）</strong> 提供底层能力，<strong>Skills（技能）</strong> 教 AI 如何使用工具。这里推荐一些最实用的。</p><h3 id="📌-官方-x2F-社区插件"><a href="#📌-官方-x2F-社区插件" class="headerlink" title="📌 官方&#x2F;社区插件"></a>📌 官方&#x2F;社区插件</h3><p><strong>Microsoft Todo 插件</strong><br>让 AI 直接管理你的待办事项，支持创建、更新、删除、移动任务，跨列表操作。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装后在 openclaw.json 中配置 Azure Client ID</span><br>openclaw plugins install openclaw-microsoft-todo<br></code></pre></td></tr></table></figure><p><strong>飞书（Feishu）插件</strong><br>一套完整的飞书集成，包含 5 个子技能：</p><ul><li><code>feishu-doc</code> — 读写飞书文档</li><li><code>feishu-wiki</code> — 知识库导航和搜索</li><li><code>feishu-drive</code> — 云盘文件管理</li><li><code>feishu-perm</code> — 文档权限管理</li><li><code>feishu-bitable</code> — 多维表格 CRUD（6 个工具）</li></ul><p><strong>Voice Call 插件</strong><br>让 AI 发起语音通话，支持实时对话。</p><h3 id="📌-实用内置技能"><a href="#📌-实用内置技能" class="headerlink" title="📌 实用内置技能"></a>📌 实用内置技能</h3><p><strong>🐙 GitHub (<code>github</code>)</strong><br>通过 <code>gh</code> CLI 操作 GitHub，支持 Issue、PR、CI Run、API 查询。日常开发必备。</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-meta"># 示例对话</span><br><span class="hljs-string">&quot;帮我看看 repo 有没有新的 PR&quot;</span><br><span class="hljs-string">&quot;创建一个 issue，标题是 xxx&quot;</span><br></code></pre></td></tr></table></figure><p><strong>🧩 Coding Agent (<code>coding-agent</code>)</strong><br>在后台运行 Codex CLI、Claude Code、OpenCode 等编程代理。适合让 AI 自主完成复杂编程任务。</p><p><strong>🌤️ Weather (<code>weather</code>)</strong><br>无需 API Key 即可查询天气和预报。</p><p><strong>⏰ Apple Reminders (<code>apple-reminders</code>)</strong><br>macOS 上管理 Apple 提醒事项，支持列表、日期筛选、增删改查。</p><p><strong>🐻 Bear Notes (<code>bear-notes</code>)</strong><br>通过 <code>grizzly</code> CLI 创建、搜索和管理 Bear 笔记。</p><p><strong>📦 ClawHub (<code>clawhub</code>)</strong><br>技能市场客户端，搜索、安装、更新社区技能：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">npx clawhub install &lt;skill-slug&gt;   <span class="hljs-comment"># 安装</span><br>npx clawhub update --all            <span class="hljs-comment"># 全部更新</span><br>npx clawhub <span class="hljs-built_in">sync</span> --all              <span class="hljs-comment"># 同步发布</span><br></code></pre></td></tr></table></figure><p><strong>📸 CamSnap (<code>camsnap</code>)</strong><br>从 RTSP&#x2F;ONVIF 摄像头抓取画面或录制短片。智能家居场景利器。</p><p><strong>🎵 Spotify Player (<code>spotify-player</code>)</strong><br>终端控制 Spotify 播放、搜索、音量。</p><p><strong>📧 Himalaya (<code>himalaya</code>)</strong><br>CLI 管理邮件（IMAP&#x2F;SMTP），支持多账户、搜索、回复、转发。</p><p><strong>📋 Trello (<code>trello</code>)</strong><br>通过 REST API 管理 Trello 看板、列表和卡片。</p><p><strong>📝 Notion (<code>notion</code>)</strong><br>Notion API 集成，创建和管理页面、数据库。</p><h3 id="📌-自定义技能（Workspace-Skills）"><a href="#📌-自定义技能（Workspace-Skills）" class="headerlink" title="📌 自定义技能（Workspace Skills）"></a>📌 自定义技能（Workspace Skills）</h3><p>你也可以创建自己的技能，只需在 <code>workspace/skills/</code> 下创建一个目录，放入 <code>SKILL.md</code>：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs markdown">---<br>name: my-custom-skill<br><span class="hljs-section">description: 描述你的技能做什么</span><br><span class="hljs-section">---</span><br><br><span class="hljs-section"># 使用说明</span><br>（AI 会读这个文件来学习如何使用你的技能）<br></code></pre></td></tr></table></figure><p>比如你可以创建：</p><ul><li>微信公众号发布技能（调用微信 API）</li><li>定时新闻摘要技能（RSS + AI 总结）</li><li>图片生成技能（调用 DALL-E &#x2F; GPT-Image）</li><li>视频生成技能（调用 Sora）</li></ul><blockquote><p>💡 <strong>小贴士：</strong> 用 <code>skill-creator</code> 内置技能可以让 AI 帮你设计和创建新技能，省去手动编写的麻烦。</p></blockquote><h2 id="1️⃣2️⃣-实用命令合集"><a href="#1️⃣2️⃣-实用命令合集" class="headerlink" title="1️⃣2️⃣ 实用命令合集"></a>1️⃣2️⃣ 实用命令合集</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 全面诊断（一键查看所有组件状态）</span><br>openclaw status --all<br><br><span class="hljs-comment"># 健康检查 + 自动修复</span><br>openclaw doctor<br><br><span class="hljs-comment"># 实时日志（调试利器）</span><br>openclaw logs --follow<br><br><span class="hljs-comment"># 安全审计</span><br>openclaw security audit<br><br><span class="hljs-comment"># 终端 UI（交互式管理）</span><br>openclaw tui<br><br><span class="hljs-comment"># Web 控制台</span><br>openclaw dashboard<br></code></pre></td></tr></table></figure><blockquote><p>💡 <strong>排错首选：</strong> 遇到问题先跑 <code>openclaw doctor</code>，它会自动检测常见问题并提供修复建议。</p></blockquote><h2 id="1️⃣3️⃣-常用技巧"><a href="#1️⃣3️⃣-常用技巧" class="headerlink" title="1️⃣3️⃣ 常用技巧"></a>1️⃣3️⃣ 常用技巧</h2><h3 id="配置热重载"><a href="#配置热重载" class="headerlink" title="配置热重载"></a>配置热重载</h3><p>直接编辑 <code>~/.openclaw/openclaw.json</code>，Gateway 会自动感知变更并重载配置，无需重启服务。</p><h3 id="Memory-向量搜索"><a href="#Memory-向量搜索" class="headerlink" title="Memory 向量搜索"></a>Memory 向量搜索</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw memory search <span class="hljs-string">&quot;上周讨论的项目方案&quot;</span><br></code></pre></td></tr></table></figure><p>OpenClaw 会把历史对话存入向量数据库，支持语义搜索，帮你找回任何聊过的内容。</p><h3 id="多-Agent-架构"><a href="#多-Agent-架构" class="headerlink" title="多 Agent 架构"></a>多 Agent 架构</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 添加新 agent</span><br>openclaw agents add<br><br><span class="hljs-comment"># 查看所有 agent</span><br>openclaw agents list<br><br><span class="hljs-comment"># 删除 agent</span><br>openclaw agents delete<br></code></pre></td></tr></table></figure><p>你可以为不同场景创建不同的 Agent，各自拥有独立的人设和记忆。</p><h3 id="Workspace-文件结构"><a href="#Workspace-文件结构" class="headerlink" title="Workspace 文件结构"></a>Workspace 文件结构</h3><p>OpenClaw 的工作区有一套约定的文件结构：</p><ul><li><strong>SOUL.md</strong> — Agent 的人设定义</li><li><strong>USER.md</strong> — 用户信息档案</li><li><strong>MEMORY.md</strong> — 长期记忆</li><li><strong>HEARTBEAT.md</strong> — 心跳任务配置</li><li><strong>AGENTS.md</strong> — 工作区规则</li></ul><p>这些文件都是 Markdown 格式，随时可以编辑调整。</p><h3 id="Slash-命令"><a href="#Slash-命令" class="headerlink" title="Slash 命令"></a>Slash 命令</h3><p>在任何频道中，你可以使用斜杠命令快速操作：</p><ul><li><code>/status</code> — 查看系统状态</li><li><code>/config</code> — 查看&#x2F;修改配置</li><li><code>/debug</code> — 调试模式</li></ul><h3 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 自定义 OpenClaw 主目录</span><br><span class="hljs-built_in">export</span> OPENCLAW_HOME=~/my-openclaw<br><br><span class="hljs-comment"># 自定义状态目录</span><br><span class="hljs-built_in">export</span> OPENCLAW_STATE_DIR=/var/lib/openclaw<br><br><span class="hljs-comment"># 自定义配置文件路径</span><br><span class="hljs-built_in">export</span> OPENCLAW_CONFIG_PATH=~/config/openclaw.json<br></code></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>前面讲了很多命令和技能，但 OpenClaw 的真正威力在于<strong>把它们组合起来</strong>。下面用三个实战场景，展示如何把零散的能力串联成完整的解决方案。</p><hr><h2 id="🎯-实战场景一：7×24-稳定运行方案"><a href="#🎯-实战场景一：7×24-稳定运行方案" class="headerlink" title="🎯 实战场景一：7×24 稳定运行方案"></a>🎯 实战场景一：7×24 稳定运行方案</h2><p><strong>痛点：</strong> AI 助手跑着跑着就断了，模型 API 偶尔抽风，第二天起床发现 Gateway 挂了。</p><p><strong>解决方案：Cron 定时重启 + 模型 Fallback 链 + Doctor 自检</strong></p><p><strong>第一步：配置模型 Fallback 链</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 主模型挂了自动切到备用</span><br>openclaw models fallbacks add claude-opus-4.6<br>openclaw models fallbacks add gpt-5.3-codex<br>openclaw models fallbacks add gemini-3.1-pro<br></code></pre></td></tr></table></figure><p>这样即使 Claude API 出问题，会自动降级到 GPT，再降级到 Gemini，保证永不断线。</p><p><strong>第二步：设置定时重启</strong></p><p>通过 Cron 系统配置每天多次自动重启，清理内存、刷新连接：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 每天 0:00 / 8:00 / 17:00 自动重启</span><br>openclaw cron add<br></code></pre></td></tr></table></figure><p>在 AI 对话中也可以直接让助手帮你创建：</p><blockquote><p>“帮我设置每天 0 点、8 点、17 点自动重启 Gateway”</p></blockquote><p><strong>第三步：Heartbeat 心跳巡检</strong></p><p>编辑工作区的 <code>HEARTBEAT.md</code>，让 AI 每次心跳时自动执行健康检查：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-section"># HEARTBEAT.md</span><br><span class="hljs-bullet">-</span> 检查 Gateway 状态<br><span class="hljs-bullet">-</span> 检查各频道连接是否正常<br><span class="hljs-bullet">-</span> 如果发现异常，立即通知我<br></code></pre></td></tr></table></figure><p>AI 助手每 30 分钟轮询一次，发现问题会主动告警。</p><p><strong>效果：</strong> 模型自动降级 + 定时重启 + 心跳监控，三层保障让你的 AI 助手 7×24 稳定运行，晚上睡觉也不用担心。</p><hr><h2 id="🎯-实战场景二：自动化内容工厂"><a href="#🎯-实战场景二：自动化内容工厂" class="headerlink" title="🎯 实战场景二：自动化内容工厂"></a>🎯 实战场景二：自动化内容工厂</h2><p><strong>痛点：</strong> 每天要发公众号文章、写技术博客、跟踪 GitHub 热门项目，太费时间。</p><p><strong>解决方案：Cron 定时触发 + Skills 组合 + 多平台分发</strong></p><p><strong>第一步：安装必要技能</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># GitHub Trending 抓取</span><br>npx clawhub install github-trending<br><br><span class="hljs-comment"># 微信公众号发布</span><br><span class="hljs-comment"># 放到 workspace/skills/ 目录即可</span><br><br><span class="hljs-comment"># GPT 图片生成（封面图）</span><br>npx clawhub install gpt-image-gen<br></code></pre></td></tr></table></figure><p><strong>第二步：创建每日自动发布任务</strong></p><p>通过 Cron 设置每天早上 9:30 自动执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw cron add<br></code></pre></td></tr></table></figure><p>任务内容：</p><ol><li>🕷️ 抓取 GitHub Trending Top 10 项目</li><li>🔍 逐个分析项目（读 README、分析技术栈）</li><li>✍️ 自动生成文章（Markdown 格式）</li><li>🎨 生成封面图（gpt-image-gen）</li><li>📤 发布到微信公众号草稿箱</li><li>📝 同步部署到 Hexo 博客</li></ol><p><strong>第三步：多平台分发</strong></p><p>同一内容可以同时推送到多个频道：</p><ul><li>微信公众号 → 通过 wechat-publisher 技能</li><li>飞书 → 通过飞书频道直接发送摘要</li><li>Hexo 博客 → 通过 <code>hexo generate &amp;&amp; hexo deploy</code></li></ul><p><strong>效果：</strong> 每天早上 9:30，AI 自动完成从”抓取→分析→写作→配图→发布”的全流程，你只需要打开草稿箱确认一下就好。一个人 &#x3D; 一个内容团队。</p><hr><h2 id="🎯-实战场景三：生活场景智能化"><a href="#🎯-实战场景三：生活场景智能化" class="headerlink" title="🎯 实战场景三：生活场景智能化"></a>🎯 实战场景三：生活场景智能化</h2><p><strong>痛点：</strong> 每天要查天气、看日历、管理待办、记单词……信息分散在各种 App 里。</p><p><strong>解决方案：Skills 组合 + 飞书&#x2F;微信统一入口 + 定时推送</strong></p><p><strong>第一步：接入生活类技能</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 待办事项（Microsoft Todo / Apple Reminders）</span><br>openclaw plugins install openclaw-microsoft-todo<br><br><span class="hljs-comment"># 天气查询（内置，无需安装）</span><br><span class="hljs-comment"># weather 技能自带</span><br><br><span class="hljs-comment"># 生词管理（自定义技能）</span><br><span class="hljs-comment"># 放到 workspace/skills/vocabulary/</span><br></code></pre></td></tr></table></figure><p><strong>第二步：配置每日早安推送</strong></p><p>设置每天早上 10 点的 Cron 任务，自动汇总今日信息：</p><ol><li>☀️ 今日天气和穿衣建议</li><li>📰 全球科技新闻 Top 5</li><li>📈 美股 &#x2F; 港股昨日行情</li><li>📋 今日待办事项（从 Microsoft Todo 拉取）</li><li>📝 3 个昨日新学的英语单词复习</li><li>🎂 家人朋友生日提醒</li></ol><p>一条消息，发到飞书或微信，开启元气满满的一天。</p><p><strong>第三步：随时随地对话式操作</strong></p><p>不需要打开任何 App，直接在聊天窗口说：</p><ul><li>“帮我加个待办：明天下午 3 点开会”</li><li>“今天天气怎么样？”</li><li>“记一下这个单词：resilience”</li><li>“帮我看看下周有什么日程”</li></ul><p>AI 助手会调用对应的技能，直接完成操作并回复结果。</p><p><strong>第四步：手机变身能力节点</strong></p><p>通过 Nodes 系统，手机可以成为 AI 的”手脚”：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw nodes approve  <span class="hljs-comment"># 审批手机节点</span><br></code></pre></td></tr></table></figure><ul><li>📷 远程拍照：”帮我看看家里猫在干嘛”</li><li>📍 位置查询：”我现在在哪里？”</li><li>🖼️ Canvas 推送：AI 把天气卡片推到手机屏幕</li></ul><p><strong>效果：</strong> 一个聊天窗口 &#x3D; 天气 + 日历 + 待办 + 新闻 + 学习 + 智能家居。不再需要在十几个 App 之间切换，所有信息和操作都汇聚到一个对话框里。</p><hr><p>OpenClaw 的哲学很简单：<strong>命令是积木，技能是零件，组合起来才是产品。</strong> 找到你自己的场景，搭建属于你的 AI 工作流吧。</p><hr><p><em>本文由 TechHome 编辑部整理发布，转载请注明出处。</em></p>]]></content>
    
    
    <categories>
      
      <category>技术实战</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>OpenClaw</tag>
      
      <tag>工具</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2026年02月19日早间要闻</title>
    <link href="/2026/02/19/2026-02-19-morning-news/"/>
    <url>/2026/02/19/2026-02-19-morning-news/</url>
    
    <content type="html"><![CDATA[<h2 id="🌍-国际要闻"><a href="#🌍-国际要闻" class="headerlink" title="🌍 国际要闻"></a>🌍 国际要闻</h2><h3 id="1-加州太浩湖地区特大雪崩致8名滑雪者遇难"><a href="#1-加州太浩湖地区特大雪崩致8名滑雪者遇难" class="headerlink" title="1. 加州太浩湖地区特大雪崩致8名滑雪者遇难"></a>1. 加州太浩湖地区特大雪崩致8名滑雪者遇难</h3><p>15名滑雪者在加州太浩湖地区一场大规模雪崩后失踪，目前已确认8人遇难。搜救工作仍在继续。</p><h3 id="2-俄乌和谈未取得突破"><a href="#2-俄乌和谈未取得突破" class="headerlink" title="2. 俄乌和谈未取得突破"></a>2. 俄乌和谈未取得突破</h3><p>乌克兰与俄罗斯第二天的谈判仅持续两小时便结束，双方形容会谈”困难”，未达成实质性突破。与此同时，马斯克切断了俄军的 Starlink 接入，被认为给予乌克兰前线优势。</p><h3 id="3-美国将从叙利亚撤军"><a href="#3-美国将从叙利亚撤军" class="headerlink" title="3. 美国将从叙利亚撤军"></a>3. 美国将从叙利亚撤军</h3><p>据《华尔街日报》报道，美国计划在两个月内撤出驻叙利亚的全部约1000名士兵，同时美国持续向中东增兵应对伊朗局势。</p><h3 id="4-韩国前总统尹锡悦叛乱案即将宣判"><a href="#4-韩国前总统尹锡悦叛乱案即将宣判" class="headerlink" title="4. 韩国前总统尹锡悦叛乱案即将宣判"></a>4. 韩国前总统尹锡悦叛乱案即将宣判</h3><p>韩国法院即将就前总统尹锡悦戒严令引发的叛乱案作出裁决，韩国经历了连续数月的政治动荡。</p><h3 id="5-秘鲁总统上任仅四个月即被国会罢免"><a href="#5-秘鲁总统上任仅四个月即被国会罢免" class="headerlink" title="5. 秘鲁总统上任仅四个月即被国会罢免"></a>5. 秘鲁总统上任仅四个月即被国会罢免</h3><p>秘鲁总统José Jerí成为该国连续第三位被罢免的总统，也是2016年以来的第七位总统，反映了该国持续的政治不稳定。</p><hr><h2 id="🌐-科技日报精选"><a href="#🌐-科技日报精选" class="headerlink" title="🌐 科技日报精选"></a>🌐 科技日报精选</h2><h3 id="1-📰HN-Tailscale-Peer-Relays-正式发布-—-⬆️-322-points"><a href="#1-📰HN-Tailscale-Peer-Relays-正式发布-—-⬆️-322-points" class="headerlink" title="1. [📰HN] Tailscale Peer Relays 正式发布 — ⬆️ 322 points"></a>1. [📰HN] Tailscale Peer Relays 正式发布 — ⬆️ 322 points</h3><p><a href="https://tailscale.com/blog/peer-relays-ga">https://tailscale.com/blog/peer-relays-ga</a><br>Tailscale 宣布其 Peer Relays 功能正式 GA。该功能允许用户在自己的 Tailscale 节点上部署高吞吐量中继服务，解决防火墙和 NAT 阻挡直连的问题。相比传统 DERP 中继，Peer Relays 提供更好的性能、可靠性和可视化能力。</p><h3 id="2-🔬Ars-OpenAI-绕过-Nvidia，在晶圆级芯片上运行超快编码模型-—-GPT-5-3-Codex-Spark"><a href="#2-🔬Ars-OpenAI-绕过-Nvidia，在晶圆级芯片上运行超快编码模型-—-GPT-5-3-Codex-Spark" class="headerlink" title="2. [🔬Ars] OpenAI 绕过 Nvidia，在晶圆级芯片上运行超快编码模型 — GPT-5.3-Codex-Spark"></a>2. [🔬Ars] OpenAI 绕过 Nvidia，在晶圆级芯片上运行超快编码模型 — GPT-5.3-Codex-Spark</h3><p><a href="https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/">https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/</a><br>OpenAI 发布 GPT-5.3-Codex-Spark 编码模型，运行在 Cerebras 的晶圆级芯片上，编码速度比前代快15倍，达到每秒约1000 token。这标志着 AI 编码代理竞赛中延迟成为关键差异化因素。</p><h3 id="3-🔬Ars-攻击者向-Gemini-发送超10万次提示试图克隆-—-Google-报告"><a href="#3-🔬Ars-攻击者向-Gemini-发送超10万次提示试图克隆-—-Google-报告" class="headerlink" title="3. [🔬Ars] 攻击者向 Gemini 发送超10万次提示试图克隆 — Google 报告"></a>3. [🔬Ars] 攻击者向 Gemini 发送超10万次提示试图克隆 — Google 报告</h3><p><a href="https://arstechnica.com/ai/2026/02/attackers-prompted-gemini-over-100000-times-while-trying-to-clone-it-google-says/">https://arstechnica.com/ai/2026/02/attackers-prompted-gemini-over-100000-times-while-trying-to-clone-it-google-says/</a><br>Google 披露有”商业动机”的攻击者试图通过大量提示来”蒸馏”（distillation）Gemini 模型的知识，以极低成本训练山寨模型。讽刺的是，Google 自己的 LLM 也是从互联网数据训练而来。</p><h3 id="4-🔬Ars-密码管理器的”零知识”承诺并不总是可靠"><a href="#4-🔬Ars-密码管理器的”零知识”承诺并不总是可靠" class="headerlink" title="4. [🔬Ars] 密码管理器的”零知识”承诺并不总是可靠"></a>4. [🔬Ars] 密码管理器的”零知识”承诺并不总是可靠</h3><p><a href="https://arstechnica.com/security/2026/02/password-managers-promise-that-they-cant-see-your-vaults-isnt-always-true/">https://arstechnica.com/security/2026/02/password-managers-promise-that-they-cant-see-your-vaults-isnt-always-true/</a><br>研究揭示主流密码管理器声称的”零知识”加密并不完美——服务器端被攻破后，攻击者仍可能获取用户密码库。美国约36%的成年人（约9400万人）使用密码管理器，安全性问题值得关注。</p><h3 id="5-📰HN-Let’s-Encrypt-推出-DNS-PERSIST-01-新型验证方式-—-⬆️-192-points"><a href="#5-📰HN-Let’s-Encrypt-推出-DNS-PERSIST-01-新型验证方式-—-⬆️-192-points" class="headerlink" title="5. [📰HN] Let’s Encrypt 推出 DNS-PERSIST-01 新型验证方式 — ⬆️ 192 points"></a>5. [📰HN] Let’s Encrypt 推出 DNS-PERSIST-01 新型验证方式 — ⬆️ 192 points</h3><p><a href="https://letsencrypt.org/2026/02/18/dns-persist-01.html">https://letsencrypt.org/2026/02/18/dns-persist-01.html</a><br>Let’s Encrypt 实现了新的 ACME 挑战类型 DNS-PERSIST-01，用持久化的 DNS 授权记录替代传统 DNS-01 的重复验证，特别适合 IoT 部署、多租户平台和批量证书操作场景，大幅降低运维成本。</p><hr><h2 id="🐙-GitHub-Trending"><a href="#🐙-GitHub-Trending" class="headerlink" title="🐙 GitHub Trending"></a>🐙 GitHub Trending</h2><ol><li><strong>p2r3&#x2F;convert</strong> ⭐ 391 today — 真正的通用在线文件转换器</li><li><strong>microsoft&#x2F;OmniParser</strong> ⭐ 165 today — 基于纯视觉的 GUI Agent 屏幕解析工具</li><li><strong>langgenius&#x2F;dify</strong> ⭐ 155 today — 开源 LLM 应用开发平台（GenAI 应用开发平台）</li><li><strong>al1abb&#x2F;invoify</strong> ⭐ 137 today — 基于 Next.js 构建的发票生成器应用</li><li><strong>getzep&#x2F;graphiti</strong> ⭐ 51 today — 构建和查询动态、时间感知知识图谱</li></ol><hr><h2 id="📈-美股行情（2-x2F-18-收盘）"><a href="#📈-美股行情（2-x2F-18-收盘）" class="headerlink" title="📈 美股行情（2&#x2F;18 收盘）"></a>📈 美股行情（2&#x2F;18 收盘）</h2><p>美股三大指数全线收涨，Meta 与 Nvidia 的芯片合作协议提振 AI 板块信心：</p><ul><li>S&amp;P 500: 6,881.31 ↑0.56%</li><li>纳指: 22,753.63 ↑0.78%</li><li>道指: 49,662.66 ↑0.26%</li></ul><p>重点关注：</p><ul><li>NVDA 英伟达 ↑1.74%（Meta 宣布将部署”数百万颗” Nvidia 芯片）</li><li>MSFT 微软 ↑0.75%~0.85%（股价约$400区间）</li><li>GOOGL 谷歌 ↑0.51%</li><li>AMD &#x2F; BABA 跟随大盘小幅波动</li></ul><p>市场亮点：Meta-Nvidia 芯片大单提振 AI 基础设施需求信心；工业产出超预期；Fed 1月会议纪要显示部分委员支持通胀回落后进一步降息。</p>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>早报</tag>
      
      <tag>新闻</tag>
      
      <tag>AI</tag>
      
      <tag>科技</tag>
      
      <tag>美股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AI Agent 的「技能树」：Agent Skills 运行原理、路由机制与 SDK 集成全解析</title>
    <link href="/2026/02/19/what-is-agent-skills/"/>
    <url>/2026/02/19/what-is-agent-skills/</url>
    
    <content type="html"><![CDATA[<h2 id="一个问题：为什么-AI-Agent-需要「技能」？"><a href="#一个问题：为什么-AI-Agent-需要「技能」？" class="headerlink" title="一个问题：为什么 AI Agent 需要「技能」？"></a>一个问题：为什么 AI Agent 需要「技能」？</h2><p>你有没有遇到过这种场景——</p><p>你让 AI agent 帮你部署一个项目，它很聪明地写出了 Dockerfile，但偏偏不知道你们团队用的是内部 Harbor 镜像仓库，push 的时候永远 401。你让它查数据库，它 SQL 写得漂亮，但不知道你们的数据库连接要走 SSH tunnel。</p><p>问题不在于 agent 不够聪明，而在于它<strong>缺少特定领域的知识和操作流程</strong>。</p><p>你当然可以每次在 prompt 里手写一遍流程。但这不 scale——团队里每个人都要重复写，换个 agent 平台又得重来。</p><p>这就是 <strong>Agent Skills</strong> 要解决的问题：<strong>给 AI agent 一种标准化的方式来获取新能力和专业知识，写一次，到处用。</strong></p><h2 id="Agent-Skills-是什么？"><a href="#Agent-Skills-是什么？" class="headerlink" title="Agent Skills 是什么？"></a>Agent Skills 是什么？</h2><p><a href="https://agentskills.io/">Agent Skills</a> 是由 Anthropic 主导的开源标准（Apache 2.0 协议），GitHub 上已经有 10.2k stars。它的核心理念非常简单：</p><blockquote><p>一个 Skill 就是一个文件夹，里面包含指令、脚本和资源，agent 可以发现并使用它们来完成特定任务。</p></blockquote><p>没有复杂的协议，没有 gRPC，没有 schema 定义。<strong>一个目录 + 一个 Markdown 文件，就是一个 Skill。</strong></p><h3 id="和-MCP-什么关系？"><a href="#和-MCP-什么关系？" class="headerlink" title="和 MCP 什么关系？"></a>和 MCP 什么关系？</h3><p>这是被问得最多的问题，直接说结论：</p><table><thead><tr><th></th><th>Agent Skills</th><th>MCP</th></tr></thead><tbody><tr><td><strong>本质</strong></td><td>给 agent 的<strong>指令和知识</strong></td><td>给 agent 的<strong>工具接口</strong></td></tr><tr><td><strong>格式</strong></td><td>Markdown 文档为主</td><td>JSON-RPC API 协议</td></tr><tr><td><strong>作用</strong></td><td>告诉 agent「怎么做」</td><td>提供 agent「能调用什么」</td></tr><tr><td><strong>类比</strong></td><td>操作手册 &#x2F; SOP</td><td>工具箱里的工具</td></tr></tbody></table><p>两者是互补的。一个 Skill 可以指导 agent 如何使用某个 MCP server 提供的工具——比如你有一个数据库 MCP server，Skill 可以告诉 agent「查用户表要先关联 user_profile，别忘了加 tenant_id 过滤」。</p><p><strong>MCP 解决「有什么工具可用」，Skills 解决「怎么正确地用这些工具」。</strong></p><h2 id="规范详解：一个-Skill-长什么样？"><a href="#规范详解：一个-Skill-长什么样？" class="headerlink" title="规范详解：一个 Skill 长什么样？"></a>规范详解：一个 Skill 长什么样？</h2><p>一个 Skill 的目录结构非常简洁：</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs applescript"><span class="hljs-keyword">my</span>-deploy-skill/<br>├── SKILL.md          <span class="hljs-comment"># 必须有，核心文件</span><br>├── scripts/          <span class="hljs-comment"># 可选，可执行脚本</span><br>│   └── check-env.sh<br>├── references/       <span class="hljs-comment"># 可选，参考文档</span><br>│   └── api-docs.md<br>└── assets/           <span class="hljs-comment"># 可选，静态资源</span><br>    └── config-template.yaml<br></code></pre></td></tr></table></figure><p>唯一必须存在的文件是 <code>SKILL.md</code>，它由 YAML frontmatter + Markdown 正文组成：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs markdown">---<br>name: harbor-deploy<br>description: &gt;<br>  使用内部 Harbor 镜像仓库部署容器化应用。<br>  当用户需要构建 Docker 镜像、推送到 Harbor 或部署到 K8s 时使用此 skill。<br>license: Apache-2.0<br>compatibility:<br><span class="hljs-bullet">  -</span> claude-code<br><span class="hljs-bullet">  -</span> cursor<br>allowed-tools:<br><span class="hljs-bullet">  -</span> bash<br><span class="hljs-bullet">  -</span> readFile<br><span class="hljs-section">  - writeFile</span><br><span class="hljs-section">---</span><br><br><span class="hljs-section"># Harbor 部署流程</span><br><br><span class="hljs-section">## 前置检查</span><br>运行 <span class="hljs-code">`scripts/check-env.sh`</span> 确认环境配置。<br><br><span class="hljs-section">## 构建与推送</span><br><span class="hljs-bullet">1.</span> Dockerfile 必须使用多阶段构建<br><span class="hljs-bullet">2.</span> 镜像 tag 格式：<span class="hljs-code">`harbor.internal.com/&#123;project&#125;/&#123;name&#125;:&#123;git-sha&#125;`</span><br><span class="hljs-bullet">3.</span> push 前确认已登录：<span class="hljs-code">`docker login harbor.internal.com`</span><br><br><span class="hljs-section">## 部署到 K8s</span><br>使用 <span class="hljs-code">`references/`</span> 中的模板，替换对应的环境变量...<br></code></pre></td></tr></table></figure><h3 id="命名规则"><a href="#命名规则" class="headerlink" title="命名规则"></a>命名规则</h3><ul><li><code>name</code>：小写字母 + 数字 + 连字符，1-64 字符，不能以连字符开头或结尾</li><li><code>description</code>：1-1024 字符，<strong>这是路由的关键</strong>——agent 靠它来判断要不要激活这个 skill</li></ul><h3 id="可选字段"><a href="#可选字段" class="headerlink" title="可选字段"></a>可选字段</h3><ul><li><code>license</code>：开源协议</li><li><code>compatibility</code>：声明兼容哪些平台</li><li><code>metadata</code>：自定义元数据，平台可以用来做 gating、权限控制等</li><li><code>allowed-tools</code>：声明 skill 需要哪些工具权限</li></ul><h2 id="运行原理深度解析：渐进式披露"><a href="#运行原理深度解析：渐进式披露" class="headerlink" title="运行原理深度解析：渐进式披露"></a>运行原理深度解析：渐进式披露</h2><p>这是 Agent Skills 最精妙的设计——<strong>Progressive Disclosure（渐进式披露）</strong>。</p><p>为什么不把所有 skill 的完整内容一股脑塞进 system prompt？因为 context window 是有限的。如果你有 50 个 skill，每个 3000 tokens，光 skills 就占了 150k tokens，agent 还怎么干活？</p><p>Agent Skills 的解法是三阶段加载：</p><h3 id="第一阶段：Discovery（发现）"><a href="#第一阶段：Discovery（发现）" class="headerlink" title="第一阶段：Discovery（发现）"></a>第一阶段：Discovery（发现）</h3><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sqf"><span class="hljs-built_in">Agent</span> 启动<br>  ↓<br>扫描所有 <span class="hljs-built_in">skill</span> 目录<br>  ↓<br>只读取每个 <span class="hljs-built_in">SKILL</span>.md 的 frontmatter（<span class="hljs-built_in">name</span> + description）<br>  ↓<br>注入 system prompt：「你有以下 skills 可用：<br>  - harbor-deploy: 使用内部 Harbor 镜像仓库部署容器化应用...<br>  - db-query: 通过 SSH tunnel 查询生产数据库...<br>  - ...」<br></code></pre></td></tr></table></figure><p>每个 skill 在这个阶段只消耗约 <strong>100 tokens</strong>。50 个 skill 也就 5000 tokens，完全可控。</p><h3 id="第二阶段：Activation（激活）"><a href="#第二阶段：Activation（激活）" class="headerlink" title="第二阶段：Activation（激活）"></a>第二阶段：Activation（激活）</h3><p>当用户说「帮我把这个服务部署到 Harbor」，agent 看到 system prompt 里有 <code>harbor-deploy</code> 这个 skill，description 匹配，于是：</p><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sqf"><span class="hljs-built_in">Agent</span> 判断任务匹配 harbor-deploy<br>  ↓<br>调用 loadSkill(<span class="hljs-string">&quot;harbor-deploy&quot;</span>)<br>  ↓<br>读取完整 <span class="hljs-built_in">SKILL</span>.md 内容到上下文<br>  ↓<br><span class="hljs-built_in">Agent</span> 现在知道了完整的操作流程<br></code></pre></td></tr></table></figure><p>规范建议 SKILL.md 正文控制在 <strong>5000 tokens 以内</strong>——够写详细的操作指南了，但不会炸掉 context。</p><h3 id="第三阶段：Execution（执行）"><a href="#第三阶段：Execution（执行）" class="headerlink" title="第三阶段：Execution（执行）"></a>第三阶段：Execution（执行）</h3><p>Agent 按照 SKILL.md 中的指令开始操作，按需加载 <code>scripts/</code>、<code>references/</code>、<code>assets/</code> 中的文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">Agent 按 SKILL.md 指令操作<br>  ↓<br>需要检查环境？→ 读取并执行 scripts/check-env.sh<br>  ↓<br>需要配置模板？→ 读取 assets/config-template.yaml<br>  ↓<br>需要 API 文档？→ 读取 references/api-docs.md<br></code></pre></td></tr></table></figure><p>这个设计的好处在于：<strong>agent 永远只加载它当前需要的信息，context 利用率最高。</strong></p><h2 id="SDK-集成实战"><a href="#SDK-集成实战" class="headerlink" title="SDK 集成实战"></a>SDK 集成实战</h2><p>如果你在开发自己的 AI agent 平台，集成 Agent Skills 并不复杂。以下是基于 <a href="https://ai-sdk.dev/">ai-sdk.dev</a> 集成指南的 TypeScript 实现思路：</p><h3 id="1-定义-Sandbox-抽象"><a href="#1-定义-Sandbox-抽象" class="headerlink" title="1. 定义 Sandbox 抽象"></a>1. 定义 Sandbox 抽象</h3><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs typescript"><span class="hljs-keyword">interface</span> <span class="hljs-title class_">Sandbox</span> &#123;<br>  <span class="hljs-title function_">readFile</span>(<span class="hljs-attr">path</span>: <span class="hljs-built_in">string</span>): <span class="hljs-title class_">Promise</span>&lt;<span class="hljs-built_in">string</span>&gt;;<br>  <span class="hljs-title function_">writeFile</span>(<span class="hljs-attr">path</span>: <span class="hljs-built_in">string</span>, <span class="hljs-attr">content</span>: <span class="hljs-built_in">string</span>): <span class="hljs-title class_">Promise</span>&lt;<span class="hljs-built_in">void</span>&gt;;<br>  <span class="hljs-title function_">exec</span>(<span class="hljs-attr">command</span>: <span class="hljs-built_in">string</span>): <span class="hljs-title class_">Promise</span>&lt;&#123; <span class="hljs-attr">stdout</span>: <span class="hljs-built_in">string</span>; <span class="hljs-attr">stderr</span>: <span class="hljs-built_in">string</span> &#125;&gt;;<br>&#125;<br></code></pre></td></tr></table></figure><p>Skill 的执行需要文件读写和命令执行能力，这个抽象层让你可以适配不同的运行环境（本地、Docker、云端沙箱）。</p><h3 id="2-启动时扫描并解析-Skills"><a href="#2-启动时扫描并解析-Skills" class="headerlink" title="2. 启动时扫描并解析 Skills"></a>2. 启动时扫描并解析 Skills</h3><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs typescript"><span class="hljs-keyword">import</span> &#123; parse <span class="hljs-keyword">as</span> parseYaml &#125; <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;yaml&#x27;</span>;<br><span class="hljs-keyword">import</span> &#123; globSync &#125; <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;glob&#x27;</span>;<br><br><span class="hljs-keyword">interface</span> <span class="hljs-title class_">SkillMeta</span> &#123;<br>  <span class="hljs-attr">name</span>: <span class="hljs-built_in">string</span>;<br>  <span class="hljs-attr">description</span>: <span class="hljs-built_in">string</span>;<br>  <span class="hljs-attr">path</span>: <span class="hljs-built_in">string</span>;<br>&#125;<br><br><span class="hljs-keyword">function</span> <span class="hljs-title function_">discoverSkills</span>(<span class="hljs-params">skillDirs: <span class="hljs-built_in">string</span>[]</span>): <span class="hljs-title class_">SkillMeta</span>[] &#123;<br>  <span class="hljs-keyword">const</span> <span class="hljs-attr">skills</span>: <span class="hljs-title class_">SkillMeta</span>[] = [];<br><br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> dir <span class="hljs-keyword">of</span> skillDirs) &#123;<br>    <span class="hljs-keyword">const</span> files = <span class="hljs-title function_">globSync</span>(<span class="hljs-string">`<span class="hljs-subst">$&#123;dir&#125;</span>/*/SKILL.md`</span>);<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> file <span class="hljs-keyword">of</span> files) &#123;<br>      <span class="hljs-keyword">const</span> content = fs.<span class="hljs-title function_">readFileSync</span>(file, <span class="hljs-string">&#x27;utf-8&#x27;</span>);<br>      <span class="hljs-keyword">const</span> frontmatter = <span class="hljs-title function_">extractFrontmatter</span>(content);<br>      <span class="hljs-keyword">const</span> meta = <span class="hljs-title function_">parseYaml</span>(frontmatter);<br><br>      skills.<span class="hljs-title function_">push</span>(&#123;<br>        <span class="hljs-attr">name</span>: meta.<span class="hljs-property">name</span>,<br>        <span class="hljs-attr">description</span>: meta.<span class="hljs-property">description</span>,<br>        <span class="hljs-attr">path</span>: path.<span class="hljs-title function_">dirname</span>(file),<br>      &#125;);<br>    &#125;<br>  &#125;<br><br>  <span class="hljs-keyword">return</span> skills;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="3-注入-System-Prompt"><a href="#3-注入-System-Prompt" class="headerlink" title="3. 注入 System Prompt"></a>3. 注入 System Prompt</h3><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs typescript"><span class="hljs-keyword">function</span> <span class="hljs-title function_">buildSkillsPrompt</span>(<span class="hljs-params">skills: SkillMeta[]</span>): <span class="hljs-built_in">string</span> &#123;<br>  <span class="hljs-keyword">const</span> list = skills<br>    .<span class="hljs-title function_">map</span>(<span class="hljs-function"><span class="hljs-params">s</span> =&gt;</span> <span class="hljs-string">`- <span class="hljs-subst">$&#123;s.name&#125;</span>: <span class="hljs-subst">$&#123;s.description&#125;</span>`</span>)<br>    .<span class="hljs-title function_">join</span>(<span class="hljs-string">&#x27;\n&#x27;</span>);<br><br>  <span class="hljs-keyword">return</span> <span class="hljs-string">`You have the following skills available. When a user&#x27;s task matches a skill, use the loadSkill tool to load its full instructions.\n\nAvailable skills:\n<span class="hljs-subst">$&#123;list&#125;</span>`</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-提供-loadSkill-工具"><a href="#4-提供-loadSkill-工具" class="headerlink" title="4. 提供 loadSkill 工具"></a>4. 提供 loadSkill 工具</h3><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs typescript"><span class="hljs-keyword">const</span> loadSkillTool = &#123;<br>  <span class="hljs-attr">name</span>: <span class="hljs-string">&#x27;loadSkill&#x27;</span>,<br>  <span class="hljs-attr">description</span>: <span class="hljs-string">&#x27;Load the full SKILL.md content for a specific skill&#x27;</span>,<br>  <span class="hljs-attr">parameters</span>: &#123;<br>    <span class="hljs-attr">type</span>: <span class="hljs-string">&#x27;object&#x27;</span>,<br>    <span class="hljs-attr">properties</span>: &#123;<br>      <span class="hljs-attr">name</span>: &#123; <span class="hljs-attr">type</span>: <span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-attr">description</span>: <span class="hljs-string">&#x27;Skill name to load&#x27;</span> &#125;,<br>    &#125;,<br>    <span class="hljs-attr">required</span>: [<span class="hljs-string">&#x27;name&#x27;</span>],<br>  &#125;,<br>  <span class="hljs-attr">execute</span>: <span class="hljs-keyword">async</span> (&#123; name &#125;: &#123; <span class="hljs-attr">name</span>: <span class="hljs-built_in">string</span> &#125;) =&gt; &#123;<br>    <span class="hljs-keyword">const</span> skill = skills.<span class="hljs-title function_">find</span>(<span class="hljs-function"><span class="hljs-params">s</span> =&gt;</span> s.<span class="hljs-property">name</span> === name);<br>    <span class="hljs-keyword">if</span> (!skill) <span class="hljs-keyword">return</span> <span class="hljs-string">`Skill &quot;<span class="hljs-subst">$&#123;name&#125;</span>&quot; not found.`</span>;<br>    <span class="hljs-keyword">return</span> fs.<span class="hljs-title function_">readFileSync</span>(<span class="hljs-string">`<span class="hljs-subst">$&#123;skill.path&#125;</span>/SKILL.md`</span>, <span class="hljs-string">&#x27;utf-8&#x27;</span>);<br>  &#125;,<br>&#125;;<br></code></pre></td></tr></table></figure><p>就这样，四步完成核心集成。Agent 启动时发现 skills，用户提问时按需激活，执行时加载具体资源。</p><h2 id="各平台支持情况"><a href="#各平台支持情况" class="headerlink" title="各平台支持情况"></a>各平台支持情况</h2><p>Agent Skills 目前已有 <strong>27+ 个平台集成</strong>，覆盖了主流的 AI coding 和 agent 工具：</p><p><strong>IDE &#x2F; 编辑器插件：</strong> VS Code、Cursor、GitHub Copilot</p><p><strong>CLI 工具：</strong> Claude Code、OpenAI Codex CLI、Gemini CLI、Goose、OpenCode、Amp</p><p><strong>框架 &#x2F; 平台：</strong> Spring AI、Roo Code、Factory、Databricks</p><p><strong>其他：</strong> 还有一众社区实现持续增加中</p><p>这个生态增长速度很快，主要得益于规范本身的简洁——你不需要实现复杂的协议，本质上就是「读 Markdown + 注入 prompt」。</p><h2 id="实战：写一个自己的-Skill"><a href="#实战：写一个自己的-Skill" class="headerlink" title="实战：写一个自己的 Skill"></a>实战：写一个自己的 Skill</h2><p>来写一个简单但实用的 Skill——帮助 agent 正确地操作你团队的 Git 工作流：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> git-workflow &amp;&amp; <span class="hljs-built_in">cd</span> git-workflow<br></code></pre></td></tr></table></figure><p>创建 <code>SKILL.md</code>：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs markdown">---<br>name: git-workflow<br>description: &gt;<br>  团队 Git 工作流规范。当用户需要创建分支、提交代码、<br><span class="hljs-section">  发起 PR 或处理 merge conflict 时使用此 skill。</span><br><span class="hljs-section">---</span><br><br><span class="hljs-section"># Git 工作流</span><br><br><span class="hljs-section">## 分支命名</span><br><span class="hljs-bullet">-</span> 功能分支：<span class="hljs-code">`feat/&#123;jira-id&#125;-&#123;简短描述&#125;`</span><br><span class="hljs-bullet">-</span> 修复分支：<span class="hljs-code">`fix/&#123;jira-id&#125;-&#123;简短描述&#125;`</span><br><span class="hljs-bullet">-</span> 发布分支：<span class="hljs-code">`release/v&#123;x.y.z&#125;`</span><br><br><span class="hljs-section">## 提交规范</span><br>使用 Conventional Commits：<br><span class="hljs-bullet">-</span> <span class="hljs-code">`feat:`</span> 新功能<br><span class="hljs-bullet">-</span> <span class="hljs-code">`fix:`</span> 修复<br><span class="hljs-bullet">-</span> <span class="hljs-code">`docs:`</span> 文档<br><span class="hljs-bullet">-</span> <span class="hljs-code">`refactor:`</span> 重构<br><br>提交前必须运行 <span class="hljs-code">`scripts/pre-commit-check.sh`</span>。<br><br><span class="hljs-section">## PR 流程</span><br><span class="hljs-bullet">1.</span> 确保 CI 通过<br><span class="hljs-bullet">2.</span> 至少需要 1 个 reviewer approve<br><span class="hljs-bullet">3.</span> squash merge 到 main<br><span class="hljs-bullet">4.</span> 删除远程分支<br></code></pre></td></tr></table></figure><p>然后在 <code>scripts/pre-commit-check.sh</code> 中放入检查逻辑：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Running lint...&quot;</span><br>npm run lint || <span class="hljs-built_in">exit</span> 1<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Running tests...&quot;</span><br>npm <span class="hljs-built_in">test</span> || <span class="hljs-built_in">exit</span> 1<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;All checks passed ✅&quot;</span><br></code></pre></td></tr></table></figure><p>把这个目录放到你的项目根目录或 <code>~/.openclaw/skills/</code> 下，agent 就能自动发现并使用它了。</p><h2 id="一些进阶实现：以-OpenClaw-为例"><a href="#一些进阶实现：以-OpenClaw-为例" class="headerlink" title="一些进阶实现：以 OpenClaw 为例"></a>一些进阶实现：以 OpenClaw 为例</h2><p>不同平台在 Agent Skills 规范之上会有自己的扩展实现。以 OpenClaw 为例，它做了这些增强：</p><p><strong>三级加载优先级：</strong></p><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arcade">bundled skills（内置）→ ~<span class="hljs-regexp">/.openclaw/</span>skills（用户级）→ workspace/skills（项目级）<br></code></pre></td></tr></table></figure><p>优先级递增，项目级 skill 可以覆盖同名的用户级或内置 skill。</p><p><strong>Gating 机制：</strong> 通过 <code>metadata.openclaw.requires</code> 字段，skill 可以声明自己需要的前置条件（命令行工具、环境变量、配置项），不满足条件的 skill 不会被加载。</p><p><strong>环境注入：</strong> Agent 运行时自动注入 skill 声明的环境变量和 API key，运行结束后恢复原始环境——避免 skill 之间的环境污染。</p><p><strong>Skills Watcher：</strong> 文件变化自动刷新，改了 SKILL.md 不需要重启 agent。</p><p><strong>ClawHub：</strong> 公共 skills 注册中心，类似 npm registry，可以发布和安装社区 skills。</p><p>这些都是标准之上的增值实现，但核心依然遵循 Agent Skills 规范。</p><h2 id="总结与展望"><a href="#总结与展望" class="headerlink" title="总结与展望"></a>总结与展望</h2><p>Agent Skills 的设计哲学可以用一句话概括：<strong>用最简单的格式解决最实际的问题。</strong></p><p>它没有发明新的协议，而是复用了开发者最熟悉的东西——Markdown 和文件系统。一个目录、一个 SKILL.md，就能让 agent 学会新技能。渐进式披露的路由机制保证了 context 效率，而开放的标准让 skill 可以跨平台复用。</p><p>目前 Agent Skills 还处于早期发展阶段，但几个趋势已经比较明确：</p><ol><li><strong>生态快速增长</strong>：27+ 平台支持只是开始，随着 AI agent 的普及，Skills 生态会像 npm 包一样爆发</li><li><strong>与 MCP 的融合</strong>：Skills + MCP 的组合会成为 agent 能力扩展的标配——一个提供知识，一个提供工具</li><li><strong>企业级实践</strong>：团队的内部规范、操作流程、最佳实践，都可以沉淀为 Skills，成为组织的 AI 知识资产</li></ol><p>如果你正在构建 AI agent 相关的产品，或者想让你团队的 agent 更聪明，现在就可以开始写你的第一个 Skill 了。</p><p><strong>相关链接：</strong></p><ul><li>官网：<a href="https://agentskills.io/">agentskills.io</a></li><li>GitHub：<a href="https://github.com/agentskills/agentskills">github.com&#x2F;agentskills&#x2F;agentskills</a></li><li>SDK 集成指南：<a href="https://ai-sdk.dev/">ai-sdk.dev</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>AI 前沿</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Agent</tag>
      
      <tag>LLM</tag>
      
      <tag>Agent Skills</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>手把手教你装 OpenClaw：零基础也能拥有 AI 私人助手</title>
    <link href="/2026/02/18/openclaw-beginner-guide/"/>
    <url>/2026/02/18/openclaw-beginner-guide/</url>
    
    <content type="html"><![CDATA[<blockquote><p><strong>这篇写给谁？</strong> 你可能连命令行都没打开过，Git 是什么都不太确定，但你听说了 OpenClaw 这个超火的 AI 助手项目，想试试。这篇教程就是为你准备的——<strong>每一步都有详细说明，每个命令都解释是干啥的，保证你能跟着做出来。</strong></p></blockquote><p><img src="/images/openclaw-beginner-cover.png" alt="封面"></p><p><img src="/images/openclaw-guide/china-cover-1.png" alt="OpenClaw ❤️ China"></p><h2 id="这玩意到底是啥？"><a href="#这玩意到底是啥？" class="headerlink" title="这玩意到底是啥？"></a>这玩意到底是啥？</h2><p>OpenClaw 是 2026 年 GitHub 上最火的开源项目之一（14 万多颗星星 ⭐），简单来说它就是一个 <strong>住在你电脑里的 AI 助手</strong>：</p><ul><li>📱 可以接入飞书、微信，随时跟你聊天</li><li>💻 能帮你操作电脑——读写文件、搜索网页、管理日程</li><li>🧠 用国产大模型（通义千问、DeepSeek），<strong>不用花美金</strong></li><li>🔒 数据全在你自己电脑上，没人偷看</li></ul><p>听起来很厉害对吧？更厉害的是——<strong>你完全不需要会编程就能装好它。</strong> 跟着下面的步骤走就行。</p><hr><h2 id="开始之前：打开你的终端"><a href="#开始之前：打开你的终端" class="headerlink" title="开始之前：打开你的终端"></a>开始之前：打开你的终端</h2><p>整个安装过程都要用到「终端」，也叫「命令行」。别怕，它就是一个输入文字命令的窗口，没有那么神秘。</p><h3 id="Windows-用户：打开-PowerShell"><a href="#Windows-用户：打开-PowerShell" class="headerlink" title="Windows 用户：打开 PowerShell"></a>Windows 用户：打开 PowerShell</h3><ol><li>按键盘上的 <strong>Win 键</strong>（就是那个 Windows 徽标的键）</li><li>输入 <code>powershell</code></li><li>看到「Windows PowerShell」出现了，<strong>右键</strong> 点它</li><li>选择「<strong>以管理员身份运行</strong>」</li><li>弹出的窗口问你「是否允许此应用对设备进行更改」，点「<strong>是</strong>」</li></ol><p>现在你面前就是一个蓝色（或黑色）的窗口，光标在闪烁——这就是终端了。</p><blockquote><p><strong>💡 小贴士：</strong> 后续所有写着「打开终端」的地方，都是指这个 PowerShell 窗口。建议把它<strong>固定到任务栏</strong>（右键→固定到任务栏），因为你会经常用到。</p></blockquote><hr><h2 id="第一步：安装-Git（5-分钟）"><a href="#第一步：安装-Git（5-分钟）" class="headerlink" title="第一步：安装 Git（5 分钟）"></a>第一步：安装 Git（5 分钟）</h2><p>Git 是一个版本管理工具。虽然安装 OpenClaw 本身不一定用到 Git，但很多后续操作和技能会需要它，建议一步到位装好。</p><h3 id="1-1-下载-Git"><a href="#1-1-下载-Git" class="headerlink" title="1.1 下载 Git"></a>1.1 下载 Git</h3><p>打开浏览器，访问 Git 官网的下载页面：</p><p>👉 <strong><a href="https://git-scm.com/downloads/win">https://git-scm.com/downloads/win</a></strong></p><p>页面上会有多个下载选项，找到 <strong>「64-bit Git for Windows Setup」</strong>，点击下载。</p><blockquote><p><strong>如果官网打开很慢</strong>，你可以用国内镜像下载：<br>👉 <strong><a href="https://registry.npmmirror.com/-/binary/git-for-windows/">https://registry.npmmirror.com/-/binary/git-for-windows/</a></strong><br>找最新版本的文件夹点进去，下载 <code>Git-xxx-64-bit.exe</code></p></blockquote><h3 id="1-2-安装-Git"><a href="#1-2-安装-Git" class="headerlink" title="1.2 安装 Git"></a>1.2 安装 Git</h3><ol><li>双击下载好的 <code>.exe</code> 文件</li><li>一路点 <strong>Next</strong>（下一步）就行——所有默认选项都没问题</li><li>最后点 <strong>Install</strong>，等进度条跑完</li><li>点 <strong>Finish</strong> 完成</li></ol><p>就这么简单。整个过程就是疯狂点「下一步」。</p><h3 id="1-3-验证安装成功"><a href="#1-3-验证安装成功" class="headerlink" title="1.3 验证安装成功"></a>1.3 验证安装成功</h3><p><strong>关掉</strong>之前的 PowerShell 窗口，<strong>重新打开一个新的</strong>（这一步很重要，不然系统找不到刚装的 Git）。</p><p>在新的 PowerShell 窗口里输入：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">git <span class="hljs-literal">--version</span><br></code></pre></td></tr></table></figure><p>然后按回车。如果看到类似这样的输出：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">git</span> version <span class="hljs-number">2</span>.<span class="hljs-number">47</span>.<span class="hljs-number">1</span>.windows.<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>就说明安装成功了！版本号不用一模一样，只要有输出就行。</p><blockquote><p><strong>❌ 如果提示 「git 不是内部或外部命令」</strong>：说明你没有重新打开 PowerShell。关掉当前窗口，按照上面的方法重新打开一个新的 PowerShell 就好。</p></blockquote><hr><h2 id="第二步：安装-Node-js（3-分钟）"><a href="#第二步：安装-Node-js（3-分钟）" class="headerlink" title="第二步：安装 Node.js（3 分钟）"></a>第二步：安装 Node.js（3 分钟）</h2><p>OpenClaw 是用 Node.js 运行的，所以我们需要先装好它。你可以把 Node.js 理解为 OpenClaw 的「发动机」。</p><h3 id="2-1-下载并安装"><a href="#2-1-下载并安装" class="headerlink" title="2.1 下载并安装"></a>2.1 下载并安装</h3><ol><li>打开 <a href="https://nodejs.org/zh-cn/">Node.js 中文网</a></li><li>点击下载 <strong>LTS 版本</strong>（v22.x）——LTS 表示「长期支持版」，最稳定</li><li>下载的是一个 <code>.msi</code> 文件，双击运行</li><li>安装过程中全部点 <strong>Next</strong>（下一步），不需要改任何设置</li><li>最后点 <strong>Finish</strong> 完成</li></ol><h3 id="2-2-验证安装"><a href="#2-2-验证安装" class="headerlink" title="2.2 验证安装"></a>2.2 验证安装</h3><p><strong>重新打开一个</strong> PowerShell 窗口（还是那个道理，装了新东西要开新窗口），输入：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">node <span class="hljs-literal">-v</span><br></code></pre></td></tr></table></figure><p>按回车，应该显示类似 <code>v22.13.1</code>。再输入：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">npm <span class="hljs-literal">-v</span><br></code></pre></td></tr></table></figure><p>按回车，应该显示类似 <code>10.9.2</code>。</p><p>两个命令都有输出？太棒了，发动机装好了！🎉</p><hr><h2 id="第三步：配置国内镜像源（1-分钟，但超级重要！）"><a href="#第三步：配置国内镜像源（1-分钟，但超级重要！）" class="headerlink" title="第三步：配置国内镜像源（1 分钟，但超级重要！）"></a>第三步：配置国内镜像源（1 分钟，但超级重要！）</h2><p>这一步是<strong>国内用户必做的</strong>。npm（Node.js 的包管理器）默认从国外服务器下载东西，国内直连速度感人——可能等半小时然后告诉你超时了。</p><p>我们用淘宝团队做的国内镜像，速度飞快：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">npm install <span class="hljs-literal">-g</span> cnpm <span class="hljs-literal">--registry</span>=https://registry.npmmirror.com<br></code></pre></td></tr></table></figure><blockquote><p><strong>这行命令是干啥的？</strong> 它从淘宝的国内镜像服务器下载并安装了一个叫 <code>cnpm</code> 的工具。以后需要下载东西的时候，用 <code>cnpm</code> 代替 <code>npm</code>，速度就跟开了加速器一样。</p></blockquote><p>验证一下：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">cnpm <span class="hljs-literal">-v</span><br></code></pre></td></tr></table></figure><p>看到版本号就行了。如果提示「cnpm 不是内部或外部命令」，<strong>重新打开 PowerShell</strong> 再试。</p><hr><h2 id="第四步：安装-OpenClaw（3-分钟）"><a href="#第四步：安装-OpenClaw（3-分钟）" class="headerlink" title="第四步：安装 OpenClaw（3 分钟）"></a>第四步：安装 OpenClaw（3 分钟）</h2><p><img src="/images/openclaw-guide/step-install.png" alt="安装步骤"></p><p>终于到主角了！在 PowerShell 中输入：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">cnpm install <span class="hljs-literal">-g</span> openclaw@latest<br></code></pre></td></tr></table></figure><blockquote><p><strong>这行命令是干啥的？</strong></p><ul><li><code>cnpm</code>：用国内镜像下载（上一步装的）</li><li><code>install -g</code>：全局安装，这样在任何地方都能使用</li><li><code>openclaw@latest</code>：安装最新版的 OpenClaw</li></ul></blockquote><p>等它跑完（通常几十秒），看到 <code>added xxx packages</code> 之类的就成功了。</p><h3 id="可能遇到的问题"><a href="#可能遇到的问题" class="headerlink" title="可能遇到的问题"></a>可能遇到的问题</h3><p><strong>问题 1：报错提到 <code>sharp</code></strong></p><p><code>sharp</code> 是一个图片处理库，在 Windows 上偶尔会闹脾气。解决方法：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$env:SHARP_IGNORE_GLOBAL_LIBVIPS</span>=<span class="hljs-number">1</span><br>cnpm install <span class="hljs-literal">-g</span> openclaw@latest<br></code></pre></td></tr></table></figure><blockquote><p>第一行设置了一个环境变量，告诉安装程序跳过某个可选依赖。然后重新安装就好了。</p></blockquote><p><strong>问题 2：安装成功但找不到 openclaw 命令</strong></p><p>输入 <code>openclaw --version</code> 提示「不是内部或外部命令」？这是因为系统不知道 openclaw 装到哪了。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">npm prefix <span class="hljs-literal">-g</span><br></code></pre></td></tr></table></figure><p>这会输出一个路径（通常是 <code>C:\Users\你的用户名\AppData\Roaming\npm</code>）。你需要把这个路径加到系统的 PATH 环境变量里：</p><ol><li>按 <strong>Win 键</strong>，搜索「<strong>环境变量</strong>」</li><li>点击「<strong>编辑系统环境变量</strong>」</li><li>点击右下角「<strong>环境变量</strong>」按钮</li><li>在上面「用户变量」里找到 <strong>Path</strong>，双击它</li><li>点「<strong>新建</strong>」，把刚才的路径粘贴进去</li><li>一路确定关闭</li><li><strong>重新打开 PowerShell</strong></li></ol><p>现在再试 <code>openclaw --version</code>，应该就能看到版本号了。</p><h3 id="验证安装成功"><a href="#验证安装成功" class="headerlink" title="验证安装成功"></a>验证安装成功</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">openclaw <span class="hljs-literal">--version</span><br></code></pre></td></tr></table></figure><p>看到类似 <code>2026.2.x</code> 的版本号？<strong>恭喜你，OpenClaw 装好了！</strong> 🎉</p><hr><h2 id="第五步：申请国产大模型-API-Key（5-分钟）"><a href="#第五步：申请国产大模型-API-Key（5-分钟）" class="headerlink" title="第五步：申请国产大模型 API Key（5 分钟）"></a>第五步：申请国产大模型 API Key（5 分钟）</h2><p>OpenClaw 需要一个 AI 大脑来思考。我们用阿里的通义千问（Qwen），<strong>免费额度超大方</strong>（每月 100 万 tokens），国内访问速度快，非常适合入门。</p><h3 id="先搞清楚：通义千问的模型到底选哪个？"><a href="#先搞清楚：通义千问的模型到底选哪个？" class="headerlink" title="先搞清楚：通义千问的模型到底选哪个？"></a>先搞清楚：通义千问的模型到底选哪个？</h3><p><img src="/images/openclaw-guide/models-compare.png" alt="国产模型对比"></p><p>通义千问有好几个模型版本，名字看着头大。别慌，你只需要知道这些：</p><table><thead><tr><th>模型名称</th><th>能力</th><th>价格</th><th>推荐程度</th></tr></thead><tbody><tr><td><strong>qwen-max</strong></td><td>最强，什么都能干</td><td>免费额度 100 万 tokens&#x2F;月</td><td>⭐⭐⭐ 首选</td></tr><tr><td><strong>qwen-plus</strong></td><td>次强，性价比高</td><td>免费额度 100 万 tokens&#x2F;月</td><td>⭐⭐ 日常够用</td></tr><tr><td><strong>qwen-turbo</strong></td><td>最快，轻量任务</td><td>免费额度 100 万 tokens&#x2F;月</td><td>⭐ 简单任务</td></tr><tr><td><strong>qwen-long</strong></td><td>长文本专用</td><td>单独计价</td><td>特殊场景</td></tr></tbody></table><blockquote><p><strong>💡 建议：</strong> 直接选 <code>qwen-max</code>。免费额度一样的，不用白不用。等你熟悉了再根据需要调整。</p></blockquote><h3 id="5-1-注册并获取-API-Key"><a href="#5-1-注册并获取-API-Key" class="headerlink" title="5.1 注册并获取 API Key"></a>5.1 注册并获取 API Key</h3><ol><li>打开浏览器，访问 <a href="https://bailian.console.aliyun.com/">阿里云百炼平台</a></li><li>用<strong>支付宝</strong>扫码登录（对，就这么简单，不用单独注册）</li><li>登录后，你会看到控制台页面</li><li>在左边菜单找到「<strong>API Key 管理</strong>」，点进去</li><li>点击「<strong>创建 API Key</strong>」按钮</li><li>会生成一串以 <code>sk-</code> 开头的字符串——<strong>这就是你的 API Key</strong></li><li>点「复制」，把它保存到一个安全的地方（比如记事本里）</li></ol><blockquote><p><strong>⚠️ 重要：</strong> API Key 只会显示一次！如果忘了复制，就得重新创建一个。不过不用担心，重新建一个也就是点一下的事。</p></blockquote><h3 id="5-2-关于付费"><a href="#5-2-关于付费" class="headerlink" title="5.2 关于付费"></a>5.2 关于付费</h3><p>阿里云百炼的计费方式是按调用量（tokens）收费的。<strong>但是</strong>，每个模型每月都有免费额度，对于个人使用来说基本够用。</p><p>如果你担心费用：</p><ul><li>登录百炼控制台，在「<strong>费用中心</strong>」→「<strong>资源包管理</strong>」可以看到剩余免费额度</li><li>免费额度用完后才会开始计费</li><li>即使计费，qwen-max 的价格也只有 0.02 元&#x2F;千 tokens，聊天一整天也花不了几块钱</li></ul><hr><h2 id="第六步：配置-OpenClaw（5-分钟）"><a href="#第六步：配置-OpenClaw（5-分钟）" class="headerlink" title="第六步：配置 OpenClaw（5 分钟）"></a>第六步：配置 OpenClaw（5 分钟）</h2><h3 id="⚠️-重要提醒：推荐直接编辑配置文件"><a href="#⚠️-重要提醒：推荐直接编辑配置文件" class="headerlink" title="⚠️ 重要提醒：推荐直接编辑配置文件"></a>⚠️ 重要提醒：推荐直接编辑配置文件</h3><p>OpenClaw 提供了一个 <code>openclaw onboard</code> 向导来引导你完成配置。但根据很多用户的反馈，向导在选择国产模型时容易遇到坑：</p><ul><li>向导可能走「Provider 网页授权」流程，但授权完后<strong>模型列表显示的是海外端点</strong></li><li>选了模型之后可能<strong>没有地方让你输入 API Key</strong></li><li>配置完了可能连不上，还得手动改配置文件</li></ul><p><strong>所以我们推荐一个更靠谱的方法：直接编辑配置文件。</strong> 听起来像「高级操作」，但其实就是复制粘贴一段文本，比向导还简单。</p><h3 id="方法一：直接编辑配置文件（推荐-⭐）"><a href="#方法一：直接编辑配置文件（推荐-⭐）" class="headerlink" title="方法一：直接编辑配置文件（推荐 ⭐）"></a>方法一：直接编辑配置文件（推荐 ⭐）</h3><p><strong>第 1 步：</strong> 找到配置文件位置</p><p>在 PowerShell 中输入：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">notepad <span class="hljs-string">&quot;<span class="hljs-variable">$env:USERPROFILE</span>\.openclaw\openclaw.json&quot;</span><br></code></pre></td></tr></table></figure><blockquote><p>如果提示文件不存在，选「是」创建新文件。<br>如果连 <code>.openclaw</code> 文件夹都不存在，先运行一次 <code>openclaw init</code> 创建它。</p></blockquote><p><strong>第 2 步：</strong> 把以下内容<strong>完整复制</strong>粘贴进去（替换掉文件里原有的所有内容）：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;models&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;default&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;qwen/qwen-max&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;providers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;qwen&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;apiKey&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;sk-你的API-Key粘贴到这里&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p><strong>第 3 步：</strong> 把 <code>sk-你的API-Key粘贴到这里</code> 替换成你在第五步复制的真实 API Key。</p><p><strong>第 4 步：</strong> 保存文件（Ctrl+S），关闭记事本。</p><p>搞定！配置就这么简单。</p><blockquote><p><strong>💡 为什么推荐这个方法？</strong> 因为它绕过了 onboarding 向导可能出现的所有坑——不需要选 Provider、不需要网页授权、不会遇到海外端点列表。直接告诉 OpenClaw「用千问 max 模型 + 这个 API Key」，清清楚楚。</p></blockquote><h3 id="方法二：使用-onboard-向导"><a href="#方法二：使用-onboard-向导" class="headerlink" title="方法二：使用 onboard 向导"></a>方法二：使用 onboard 向导</h3><p>如果你还是想试试向导（或者方法一遇到问题），在 PowerShell 中输入：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">openclaw onboard <span class="hljs-literal">--install-daemon</span><br></code></pre></td></tr></table></figure><p>向导会一步一步问你问题：</p><p><strong>步骤 1 — 风险提示：</strong></p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">⚠️  OpenClaw runs AI-<span class="hljs-keyword">generated</span> code <span class="hljs-keyword">on</span> your computer.<br><span class="hljs-keyword">Do</span> you understand the risks? (yes/<span class="hljs-keyword">no</span>)<br></code></pre></td></tr></table></figure><p>👉 输入 <code>yes</code></p><p><strong>步骤 2 — 安装模式：</strong></p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs arduino">Choose setup mode:<br>  <span class="hljs-number">1</span>) <span class="hljs-built_in">QuickStart</span> (recommended)<br>  <span class="hljs-number">2</span>) Advanced<br></code></pre></td></tr></table></figure><p>👉 输入 <code>1</code></p><p><strong>步骤 3 — 模型提供商：</strong></p><figure class="highlight erlang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs erlang">Choose your AI model provider:<br>  <span class="hljs-number">1</span>) OpenAI<br>  <span class="hljs-number">2</span>) Anthropic<br>  <span class="hljs-number">3</span>) Qwen (通义千问)<br>  ...<br></code></pre></td></tr></table></figure><p>👉 选 <strong>Qwen</strong>（输入对应数字）</p><blockquote><p><strong>⚠️ 关键提醒：</strong> 这里可能会出现两种路径：</p><ul><li><strong>API Key 路径</strong>（推荐）：直接让你输入 API Key，照做即可</li><li><strong>Provider 网页授权路径</strong>（有坑）：会打开浏览器让你授权。授权完之后，它可能会让你选模型——<strong>这时候列表里的模型可能是海外端点，选了也用不了</strong></li></ul><p>如果你走到了网页授权路径，建议直接 Ctrl+C 退出向导，改用方法一。</p></blockquote><p><strong>步骤 4 — 输入 API Key（如果出现）：</strong></p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mathematica"><span class="hljs-built_in">Enter</span> <span class="hljs-variable">your</span> <span class="hljs-variable">Qwen</span> <span class="hljs-variable">API</span> <span class="hljs-built_in">Key</span><span class="hljs-operator">:</span><br></code></pre></td></tr></table></figure><p>👉 粘贴你的 API Key（在 PowerShell 里<strong>鼠标右键</strong>就是粘贴，粘贴后看不到内容是正常的，直接按回车）</p><p><strong>步骤 5 — 选择具体模型（如果出现）：</strong><br>如果让你选模型，找 <code>qwen-max</code> 选它。如果列表里都是 <code>gpt-4</code>、<code>claude</code> 之类的海外模型——说明走错路了，Ctrl+C 退出，用方法一。</p><p><strong>步骤 6 — 安装 Daemon：</strong></p><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs gams"><span class="hljs-function"><span class="hljs-title">Installing</span></span> daemon service...<br>✅ Daemon installed successfully<br></code></pre></td></tr></table></figure><p>看到 ✅ 就成功了。</p><h3 id="方法三：用-DeepSeek（备选方案）"><a href="#方法三：用-DeepSeek（备选方案）" class="headerlink" title="方法三：用 DeepSeek（备选方案）"></a>方法三：用 DeepSeek（备选方案）</h3><p>如果千问搞不定，可以试试 DeepSeek，配置方法完全一样：</p><ol><li>去 <a href="https://platform.deepseek.com/">platform.deepseek.com</a> 注册，获取 API Key</li><li>配置文件改成：</li></ol><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;models&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;default&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;deepseek/deepseek-chat&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;providers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;deepseek&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;apiKey&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;sk-你的DeepSeek-API-Key&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;baseUrl&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;https://api.deepseek.com/v1&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h3 id="验证配置是否成功"><a href="#验证配置是否成功" class="headerlink" title="验证配置是否成功"></a>验证配置是否成功</h3><p>不管用哪种方法，最终验证一下：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell">openclaw gateway <span class="hljs-built_in">start</span><br>openclaw status<br></code></pre></td></tr></table></figure><p>如果看到 <code>Gateway: running</code>，说明配置成功，OpenClaw 已经连上了你的 AI 大脑！</p><hr><h2 id="第七步：启动-OpenClaw！（1-分钟）"><a href="#第七步：启动-OpenClaw！（1-分钟）" class="headerlink" title="第七步：启动 OpenClaw！（1 分钟）"></a>第七步：启动 OpenClaw！（1 分钟）</h2><p><img src="/images/openclaw-guide/china-cover-3.png" alt="OpenClaw on Windows"></p><p>万事俱备，启动你的 AI 助手：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">openclaw gateway <span class="hljs-built_in">start</span><br></code></pre></td></tr></table></figure><blockquote><p><strong>这行命令是干啥的？</strong> 它启动了 OpenClaw 的网关服务——你可以理解为「给你的 AI 助手按了开机键」。</p></blockquote><h3 id="检查状态"><a href="#检查状态" class="headerlink" title="检查状态"></a>检查状态</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">openclaw status<br></code></pre></td></tr></table></figure><p>如果看到类似 <code>Gateway: running</code> 的提示，说明一切正常。</p><h3 id="打开管理面板"><a href="#打开管理面板" class="headerlink" title="打开管理面板"></a>打开管理面板</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">openclaw dashboard<br></code></pre></td></tr></table></figure><p>浏览器会自动打开 <code>http://localhost:18789</code>，这是你的 AI 管家的控制中心。</p><h3 id="试试聊天"><a href="#试试聊天" class="headerlink" title="试试聊天"></a>试试聊天</h3><p>在管理面板里就可以直接跟 AI 聊天了。试试发一条：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">你好，你是谁？<br></code></pre></td></tr></table></figure><p>如果收到回复——<strong>恭喜你，你做到了！</strong> 🎉🎉🎉</p><p>你现在拥有了一个属于自己的、24 小时在线的 AI 私人助手！</p><hr><h2 id="进阶：接入飞书（让-AI-助手住进你的聊天软件）"><a href="#进阶：接入飞书（让-AI-助手住进你的聊天软件）" class="headerlink" title="进阶：接入飞书（让 AI 助手住进你的聊天软件）"></a>进阶：接入飞书（让 AI 助手住进你的聊天软件）</h2><p>装好了 OpenClaw，但它现在只能在浏览器里聊天。想让它变成你飞书里的 AI 秘书？跟着下面的步骤来。</p><blockquote><p>这一步稍微复杂一点，但值得做。做完之后你就可以在飞书里随时跟 AI 助手聊天了。</p></blockquote><h3 id="7-1-创建飞书应用"><a href="#7-1-创建飞书应用" class="headerlink" title="7.1 创建飞书应用"></a>7.1 创建飞书应用</h3><ol><li>打开 <a href="https://open.feishu.cn/">飞书开放平台</a>，登录你的飞书账号</li><li>点击「<strong>创建企业自建应用</strong>」（个人也能建，放心）</li><li>填写应用名称（随便起，比如「我的 AI 助手」）</li><li>创建完成后，你会看到 <strong>App ID</strong> 和 <strong>App Secret</strong>——把它们复制保存好</li></ol><h3 id="7-2-配置权限"><a href="#7-2-配置权限" class="headerlink" title="7.2 配置权限"></a>7.2 配置权限</h3><p>在应用后台找到「<strong>权限管理</strong>」→「<strong>批量开通</strong>」，粘贴以下内容：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;scopes&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;tenant&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-string">&quot;im:message&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;im:message:send_as_bot&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;im:message:readonly&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:resource&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;im:chat&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;im:chat.members:bot_access&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:message.group_msg&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;im:message.group_at_msg:readonly&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:message.p2p_msg:readonly&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;im:chat.access_event.bot_p2p_chat:read&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;contact:contact.base:readonly&quot;</span><br>    <span class="hljs-punctuation">]</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h3 id="7-3-配置事件订阅"><a href="#7-3-配置事件订阅" class="headerlink" title="7.3 配置事件订阅"></a>7.3 配置事件订阅</h3><p>找到「<strong>事件订阅</strong>」页面：</p><ul><li>请求地址填：<code>https://你的服务器地址:18789/feishu/webhook</code></li><li>添加事件：<code>im.message.receive_v1</code></li></ul><h3 id="7-4-编辑-OpenClaw-配置文件"><a href="#7-4-编辑-OpenClaw-配置文件" class="headerlink" title="7.4 编辑 OpenClaw 配置文件"></a>7.4 编辑 OpenClaw 配置文件</h3><p>打开 <code>C:\Users\你的用户名\.openclaw\openclaw.json</code>，加入飞书配置：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;models&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;default&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;qwen/qwen-max&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;providers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;qwen&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;apiKey&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;sk-你的API Key&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;channels&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;feishu&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;accounts&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;default&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;appId&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;cli_你的AppID&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;appSecret&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你的AppSecret&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;encryptKey&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你的加密Key&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;verificationToken&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你的验证Token&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;enabled&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>保存后重启 OpenClaw：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">openclaw gateway restart<br></code></pre></td></tr></table></figure><p>在飞书里搜索你创建的机器人，发一条消息试试——如果收到回复，飞书接入就成功了！</p><hr><h2 id="别让你的-AI-秘书睡着：防睡眠设置"><a href="#别让你的-AI-秘书睡着：防睡眠设置" class="headerlink" title="别让你的 AI 秘书睡着：防睡眠设置"></a>别让你的 AI 秘书睡着：防睡眠设置</h2><p>OpenClaw 需要一直运行。如果电脑进入睡眠，它就「下班」了。用管理员身份打开 PowerShell，输入这两行：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell">powercfg /change standby<span class="hljs-literal">-timeout-ac</span> <span class="hljs-number">0</span><br>powercfg /change hibernate<span class="hljs-literal">-timeout-ac</span> <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><blockquote><p><strong>这两行命令是干啥的？</strong> 告诉 Windows：接通电源的时候，永远不要进入睡眠或休眠。这样你的 AI 助手就能 24 小时在线了。</p></blockquote><hr><h2 id="常见问题速查"><a href="#常见问题速查" class="headerlink" title="常见问题速查"></a>常见问题速查</h2><table><thead><tr><th>问题</th><th>解决方法</th></tr></thead><tbody><tr><td>命令提示「不是内部或外部命令」</td><td>关掉 PowerShell，<strong>重新打开一个新的</strong></td></tr><tr><td>npm&#x2F;cnpm 安装超时</td><td>确认已配置国内镜像（第三步）</td></tr><tr><td>sharp 报错</td><td>运行 <code>$env:SHARP_IGNORE_GLOBAL_LIBVIPS=1</code> 后重装</td></tr><tr><td>Gateway 端口被占用</td><td>运行 <code>netstat -aon | findstr 18789</code> 找到占用进程，用 <code>taskkill /PID 进程ID /F</code> 结束它</td></tr><tr><td>模型回复很慢</td><td>确保用的是国内模型（Qwen&#x2F;DeepSeek），不要走国际线路</td></tr><tr><td>电脑重启后 OpenClaw 没启动</td><td>运行 <code>openclaw onboard --install-daemon</code> 设置开机自启</td></tr></tbody></table><hr><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>恭喜你读到这里！让我们回顾一下你都做了什么：</p><table><thead><tr><th>步骤</th><th>做了什么</th><th>花了多久</th></tr></thead><tbody><tr><td>1</td><td>安装 Git</td><td>5 分钟</td></tr><tr><td>2</td><td>安装 Node.js</td><td>3 分钟</td></tr><tr><td>3</td><td>配置国内镜像</td><td>1 分钟</td></tr><tr><td>4</td><td>安装 OpenClaw</td><td>3 分钟</td></tr><tr><td>5</td><td>申请 API Key</td><td>5 分钟</td></tr><tr><td>6</td><td>配置 OpenClaw</td><td>5 分钟</td></tr><tr><td>7</td><td>启动！</td><td>1 分钟</td></tr></tbody></table><p><strong>总共不到 30 分钟</strong>，你就拥有了一个 24 小时在线的 AI 私人助手。它跑在你自己的电脑上，用国产大模型，不花一分美金，数据完全属于你。</p><p>这才刚刚开始——接下来你可以探索 OpenClaw 的各种技能：让它帮你写代码、管理文件、搜索信息、甚至操作浏览器……</p><p>欢迎来到 AI Agent 时代，朋友。🦞</p><p><img src="/images/openclaw-guide/china-cover-5-edit.png" alt="OpenClaw 智能助手"></p><hr><p><em>本文基于 OpenClaw 2026.2.x 版本编写。</em><br><em>官方文档：<a href="https://docs.openclaw.ai/">docs.openclaw.ai</a> | GitHub：<a href="https://github.com/openclaw/openclaw">github.com&#x2F;openclaw&#x2F;openclaw</a></em></p>]]></content>
    
    
    <categories>
      
      <category>技术实战</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Windows</tag>
      
      <tag>OpenClaw</tag>
      
      <tag>教程</tag>
      
      <tag>国内</tag>
      
      <tag>小白</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2026年02月18日早间要闻</title>
    <link href="/2026/02/18/2026-02-18-morning-news/"/>
    <url>/2026/02/18/2026-02-18-morning-news/</url>
    
    <content type="html"><![CDATA[<h2 id="🌐-科技新闻精选"><a href="#🌐-科技新闻精选" class="headerlink" title="🌐 科技新闻精选"></a>🌐 科技新闻精选</h2><h3 id="1-Anthropic-发布-Claude-Sonnet-4-6"><a href="#1-Anthropic-发布-Claude-Sonnet-4-6" class="headerlink" title="1. Anthropic 发布 Claude Sonnet 4.6"></a>1. Anthropic 发布 Claude Sonnet 4.6</h3><p><strong>来源：</strong> Hacker News (⬆️ 900 points) | <a href="https://www.anthropic.com/news/claude-sonnet-4-6">原文链接</a></p><p>Anthropic 发布了 Claude Sonnet 4.6，这是其中端 AI 模型自 2025 年 9 月 Sonnet 4.5 以来的首次重大升级。新模型全面提升了编码、计算机使用、长上下文推理、Agent 规划、知识工作和设计等多项能力，并支持 1M token 上下文窗口（beta）。</p><p>定价与 Sonnet 4.5 保持一致（$3&#x2F;$15 per million tokens），免费用户和 Pro 用户均可在 claude.ai 中默认使用。开发者反馈显示，Sonnet 4.6 在实际使用中甚至优于去年 11 月发布的旗舰模型 Opus 4.5，尤其在编码一致性和指令遵循方面有显著改进。</p><h3 id="2-BarraCUDA：开源-CUDA-编译器，直接编译到-AMD-GPU"><a href="#2-BarraCUDA：开源-CUDA-编译器，直接编译到-AMD-GPU" class="headerlink" title="2. BarraCUDA：开源 CUDA 编译器，直接编译到 AMD GPU"></a>2. BarraCUDA：开源 CUDA 编译器，直接编译到 AMD GPU</h3><p><strong>来源：</strong> Hacker News (⬆️ 179 points) | <a href="https://github.com/Zaneham/BarraCUDA">GitHub</a></p><p>BarraCUDA 是一个用 15,000 行 C99 编写的开源 CUDA 编译器，可以将 .cu 文件直接编译为 AMD RDNA 3 (GFX11) 机器码，生成 ELF .hsaco 二进制文件。项目完全不依赖 LLVM，也不需要 HIP 转换层——从词法分析、语法解析、IR 生成到指令选择和寄存器分配，全部手写实现。</p><p>这是打破 NVIDIA CUDA 生态壁垒的一次有趣尝试，虽然目前仍处于早期阶段，但展示了从零构建 GPU 编译器的可行性。</p><h3 id="3-OpenAI-绕过-Nvidia，在-Cerebras-晶圆级芯片上运行超快编码模型"><a href="#3-OpenAI-绕过-Nvidia，在-Cerebras-晶圆级芯片上运行超快编码模型" class="headerlink" title="3. OpenAI 绕过 Nvidia，在 Cerebras 晶圆级芯片上运行超快编码模型"></a>3. OpenAI 绕过 Nvidia，在 Cerebras 晶圆级芯片上运行超快编码模型</h3><p><strong>来源：</strong> Ars Technica | <a href="https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/">原文链接</a></p><p>OpenAI 与 Cerebras 合作推出 GPT-5.3-Codex-Spark，编码速度比前代快 15 倍，运行在 Cerebras 餐盘大小的 Wafer Scale Engine 3 芯片上。该模型以约 1,000 tokens&#x2F;秒的速度运行，标志着 OpenAI 开始在硬件层面减少对 Nvidia 的依赖。</p><p>AI 编码 Agent 在 2026 年迎来爆发，OpenAI、Google 和 Anthropic 都在竞相推出更强大的编码工具。延迟已成为关键竞争因素——更快的模型意味着开发者可以更快地迭代。</p><h3 id="4-Apple-正在开发三款-AI-可穿戴设备"><a href="#4-Apple-正在开发三款-AI-可穿戴设备" class="headerlink" title="4. Apple 正在开发三款 AI 可穿戴设备"></a>4. Apple 正在开发三款 AI 可穿戴设备</h3><p><strong>来源：</strong> TechCrunch | <a href="https://techcrunch.com/2026/02/17/apple-is-reportedly-cooking-up-a-trio-of-ai-wearables/">原文链接</a></p><p>据 Bloomberg 的 Mark Gurman 报道，Apple 正在加速开发三款 AI 驱动的可穿戴设备：</p><ul><li><strong>AI 智能眼镜</strong>（代号 N50）：配备高分辨率摄像头，最早 12 月投产，2027 年上市</li><li><strong>AI 挂件</strong>：AirTag 大小，可别在衬衫上，配备摄像头</li><li><strong>带摄像头的 AirPods</strong>：通过视觉上下文让 Siri 执行现实世界操作</li></ul><p>这些设备将直接与 Meta Ray-Ban 智能眼镜和 Snap 的 Specs 竞争。</p><h3 id="5-密码管理器的「零知识」承诺并不总是可靠"><a href="#5-密码管理器的「零知识」承诺并不总是可靠" class="headerlink" title="5. 密码管理器的「零知识」承诺并不总是可靠"></a>5. 密码管理器的「零知识」承诺并不总是可靠</h3><p><strong>来源：</strong> Ars Technica (66 comments) | <a href="https://arstechnica.com/security/2026/02/password-managers-promise-that-they-cant-see-your-vaults-isnt-always-true/">原文链接</a></p><p>研究发现，包括 Bitwarden、Dashlane 和 LastPass 在内的主流密码管理器宣称的「零知识加密」存在潜在漏洞。尽管这些厂商承诺「即使我们想看也无法读取你的数据」，但在服务器被攻破的情况下，攻击者可能有途径获取用户的密码库内容。</p><p>目前约有 9,400 万美国成年人使用密码管理器，这一发现对安全实践具有重要影响。</p><hr><h2 id="🐙-GitHub-Trending"><a href="#🐙-GitHub-Trending" class="headerlink" title="🐙 GitHub Trending"></a>🐙 GitHub Trending</h2><table><thead><tr><th>排名</th><th>项目</th><th>今日星标</th><th>简介</th></tr></thead><tbody><tr><td>1</td><td><a href="https://github.com/alibaba/zvec">alibaba&#x2F;zvec</a></td><td>⭐ 1,473</td><td>阿里开源的超轻量级进程内向量数据库，C++ 编写</td></tr><tr><td>2</td><td><a href="https://github.com/p-e-w/heretic">p-e-w&#x2F;heretic</a></td><td>⭐ 656</td><td>全自动移除语言模型审查限制的工具</td></tr><tr><td>3</td><td><a href="https://github.com/obra/superpowers">obra&#x2F;superpowers</a></td><td>⭐ 569</td><td>Agent 技能框架与软件开发方法论</td></tr><tr><td>4</td><td><a href="https://github.com/hummingbot/hummingbot">hummingbot&#x2F;hummingbot</a></td><td>⭐ 568</td><td>开源高频加密货币交易机器人</td></tr><tr><td>5</td><td><a href="https://github.com/ashishps1/awesome-system-design-resources">ashishps1&#x2F;awesome-system-design-resources</a></td><td>⭐ 510</td><td>系统设计学习资源与面试准备</td></tr><tr><td>6</td><td><a href="https://github.com/steipete/gogcli">steipete&#x2F;gogcli</a></td><td>⭐ 469</td><td>Google Suite CLI：Gmail&#x2F;GCal&#x2F;GDrive&#x2F;GContacts</td></tr><tr><td>7</td><td><a href="https://github.com/openclaw/openclaw">openclaw&#x2F;openclaw</a></td><td>⭐ 4,201</td><td>个人 AI 助手框架，支持任何 OS 和平台</td></tr><tr><td>8</td><td><a href="https://github.com/seerr-team/seerr">seerr-team&#x2F;seerr</a></td><td>⭐ 282</td><td>开源媒体请求管理器，支持 Jellyfin&#x2F;Plex&#x2F;Emby</td></tr><tr><td>9</td><td><a href="https://github.com/SynkraAI/aios-core">SynkraAI&#x2F;aios-core</a></td><td>⭐ 194</td><td>AI 编排系统，用于全栈开发</td></tr><tr><td>10</td><td><a href="https://github.com/steipete/summarize">steipete&#x2F;summarize</a></td><td>⭐ 119</td><td>将任意 URL&#x2F;YouTube&#x2F;Podcast 快速摘要的 CLI 工具</td></tr></tbody></table><hr><h2 id="📈-美股行情"><a href="#📈-美股行情" class="headerlink" title="📈 美股行情"></a>📈 美股行情</h2><blockquote><p>⚠️ 2026年2月17日（周一）为美国总统日（Presidents’ Day），美股休市。东方财富 API 今日暂时无响应，行情数据缺失。</p></blockquote><hr><h2 id="🔗-更多新闻"><a href="#🔗-更多新闻" class="headerlink" title="🔗 更多新闻"></a>🔗 更多新闻</h2><ul><li><strong>[📰HN] Thousands of CEOs just admitted AI had no impact on employment or productivity</strong> — Fortune 报道数千名 CEO 承认 AI 对就业和生产力没有实际影响，引发 AI 生产力悖论讨论</li><li><strong>[📰HN] Google Public CA is down</strong> — Google 公共证书颁发机构出现故障</li><li><strong>[📰HN] Gentoo on Codeberg</strong> — Gentoo Linux 迁移到 Codeberg 平台</li><li><strong>[📰HN] Using go fix to modernize Go code</strong> — Go 官方博客介绍 go fix 工具的现代化用法</li><li><strong>[🦞Lobsters] Plasma 6.6 released</strong> — KDE Plasma 6.6 发布</li><li><strong>[📡TC] Intellexa’s Predator spyware used to hack journalist’s iPhone</strong> — 间谍软件 Predator 被用于入侵安哥拉记者的 iPhone</li><li><strong>[🔧Dev.to] Build Multi-Agent Systems with ADK</strong> — Dev.to 推出多 Agent 系统教育课程</li></ul>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>早报</tag>
      
      <tag>新闻</tag>
      
      <tag>AI</tag>
      
      <tag>科技</tag>
      
      <tag>美股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2026年02月17日早间要闻</title>
    <link href="/2026/02/17/2026-02-17-morning-news/"/>
    <url>/2026/02/17/2026-02-17-morning-news/</url>
    
    <content type="html"><![CDATA[<h2 id="🌐-科技日报精选"><a href="#🌐-科技日报精选" class="headerlink" title="🌐 科技日报精选"></a>🌐 科技日报精选</h2><h3 id="1-研究发现：AI-Agent-自生成技能几乎无用"><a href="#1-研究发现：AI-Agent-自生成技能几乎无用" class="headerlink" title="1. 研究发现：AI Agent 自生成技能几乎无用"></a>1. 研究发现：AI Agent 自生成技能几乎无用</h3><p><strong>来源：Hacker News</strong> | ⬆️ 254 points<br><a href="https://arxiv.org/abs/2602.12670">论文链接</a></p><p>SkillsBench 基准测试研究发现，AI Agent 自己生成的”技能”在跨任务场景下表现极差。当前流行的让 Agent 自主学习和积累可复用技能的范式可能并不如想象中有效，这对 Agent 框架设计有重要启示。</p><h3 id="2-OpenAI-绕过-Nvidia，在-Cerebras-晶圆级芯片上跑出超快编码模型"><a href="#2-OpenAI-绕过-Nvidia，在-Cerebras-晶圆级芯片上跑出超快编码模型" class="headerlink" title="2. OpenAI 绕过 Nvidia，在 Cerebras 晶圆级芯片上跑出超快编码模型"></a>2. OpenAI 绕过 Nvidia，在 Cerebras 晶圆级芯片上跑出超快编码模型</h3><p><strong>来源：Ars Technica</strong> | 💬 105 comments<br><a href="https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/">原文链接</a></p><p>OpenAI 新发布的 GPT-5.3-Codex-Spark 编码速度比前代快 15 倍，运行在 Cerebras 的晶圆级芯片上，推理速度达到约 1000 tokens&#x2F;s。在 AI 编码 Agent 竞争白热化的当下，延迟已成为关键差异化因素——模型越快，开发者迭代越快。</p><h3 id="3-Ricursive-Intelligence-4个月融资-3-35亿，估值-40亿"><a href="#3-Ricursive-Intelligence-4个月融资-3-35亿，估值-40亿" class="headerlink" title="3. Ricursive Intelligence 4个月融资$3.35亿，估值$40亿"></a>3. Ricursive Intelligence 4个月融资$3.35亿，估值$40亿</h3><p><strong>来源：TechCrunch</strong><br><a href="https://techcrunch.com/2026/02/16/how-ricursive-intelligence-raised-335m-at-a-4b-valuation-in-4-months/">原文链接</a></p><p>两位联合创始人 Anna Goldie（CEO）和 Azalia Mirhoseini（CTO）曾在 Google Brain 共事，是 Anthropic 早期员工，因创建 Alpha Chip（AI 芯片布局设计工具）而闻名。Ricursive 做的不是造芯片，而是用 AI 设计芯片的工具——连 Nvidia 都是其投资方。Lightspeed 领投 $3 亿 A 轮，Sequoia 领投 $3500 万种子轮。</p><h3 id="4-你的蓝牙设备泄露了什么信息？"><a href="#4-你的蓝牙设备泄露了什么信息？" class="headerlink" title="4. 你的蓝牙设备泄露了什么信息？"></a>4. 你的蓝牙设备泄露了什么信息？</h3><p><strong>来源：Hacker News</strong> | ⬆️ 310 points<br><a href="https://blog.dmcc.io/journal/2026-bluetooth-privacy-bluehood/">原文链接</a></p><p>开发者构建了 Bluehood 蓝牙扫描工具，揭示开启蓝牙时会泄露大量隐私信息，包括设备型号、用户行为模式等。结合最新披露的 WhisperPair 漏洞（CVE-2025-36911），数亿蓝牙音频设备可被远程劫持、窃听通话并追踪位置。</p><h3 id="5-攻击者发送-10-万次-prompt-试图克隆-Google-Gemini"><a href="#5-攻击者发送-10-万次-prompt-试图克隆-Google-Gemini" class="headerlink" title="5. 攻击者发送 10 万次 prompt 试图克隆 Google Gemini"></a>5. 攻击者发送 10 万次 prompt 试图克隆 Google Gemini</h3><p><strong>来源：Ars Technica</strong> | 💬 52 comments<br><a href="https://arstechnica.com/ai/2026/02/attackers-prompted-gemini-over-100000-times-while-trying-to-clone-it-google-says/">原文链接</a></p><p>Google 披露有”商业动机”的攻击者通过大量多语言 prompt 进行”模型蒸馏”，试图窃取 Gemini 的知识来训练廉价复制品。Google 称之为知识产权盗窃，但颇具讽刺的是，Google 自己的 LLM 也是从互联网大量抓取未经授权的数据训练而成。</p><hr><h2 id="🐙-GitHub-Trending"><a href="#🐙-GitHub-Trending" class="headerlink" title="🐙 GitHub Trending"></a>🐙 GitHub Trending</h2><table><thead><tr><th>项目</th><th>语言</th><th>今日⭐</th><th>简介</th></tr></thead><tbody><tr><td><a href="https://github.com/alibaba/zvec">alibaba&#x2F;zvec</a></td><td>C++</td><td>1,094</td><td>轻量极速进程内向量数据库</td></tr><tr><td><a href="https://github.com/nautechsystems/nautilus_trader">nautechsystems&#x2F;nautilus_trader</a></td><td>Rust</td><td>546</td><td>高性能算法交易平台与事件驱动回测引擎</td></tr><tr><td><a href="https://github.com/rowboatlabs/rowboat">rowboatlabs&#x2F;rowboat</a></td><td>TypeScript</td><td>700</td><td>开源 AI 协作助手，带记忆功能</td></tr><tr><td><a href="https://github.com/steipete/gogcli">steipete&#x2F;gogcli</a></td><td>Go</td><td>637</td><td>Google 全家桶 CLI（Gmail&#x2F;日历&#x2F;Drive&#x2F;通讯录）</td></tr><tr><td><a href="https://github.com/openclaw/openclaw">openclaw&#x2F;openclaw</a></td><td>TypeScript</td><td>3,873</td><td>个人 AI 助手，跨平台 🦞</td></tr></tbody></table><hr><h2 id="📈-美股行情（上周五收盘，2-x2F-17-总统日休市）"><a href="#📈-美股行情（上周五收盘，2-x2F-17-总统日休市）" class="headerlink" title="📈 美股行情（上周五收盘，2&#x2F;17 总统日休市）"></a>📈 美股行情（上周五收盘，2&#x2F;17 总统日休市）</h2><table><thead><tr><th>股票</th><th>代码</th><th>收盘价</th><th>涨跌幅</th></tr></thead><tbody><tr><td>微软</td><td>MSFT</td><td>$401.32</td><td>↓0.13%</td></tr><tr><td>谷歌</td><td>GOOGL</td><td>$305.72</td><td>↓1.06%</td></tr><tr><td>英伟达</td><td>NVDA</td><td>$182.81</td><td>↓2.21%</td></tr><tr><td>超威半导体</td><td>AMD</td><td>$207.32</td><td>↑0.67%</td></tr><tr><td>阿里巴巴</td><td>BABA</td><td>$155.73</td><td>↓1.89%</td></tr></tbody></table><p>今日为美国总统日（Presidents’ Day），美股休市一天。上述为上周五（2月14日）收盘数据。整体来看，大盘小幅走弱，英伟达跌幅较大，AMD 逆势上涨。</p>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>早报</tag>
      
      <tag>新闻</tag>
      
      <tag>AI</tag>
      
      <tag>科技</tag>
      
      <tag>美股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>机器人打醉拳！从老外评价春晚《武BOT》学15个地道英语表达</title>
    <link href="/2026/02/17/english-learning-spring-gala-robot-reactions/"/>
    <url>/2026/02/17/english-learning-spring-gala-robot-reactions/</url>
    
    <content type="html"><![CDATA[<p>2026马年春晚，宇树科技的机器人从去年的扭秧歌升级到了打醉拳、耍双截棍、舞剑、跑酷！节目《武BOT》在海外社交媒体再次炸裂。今天我们从外国网友和英文媒体的真实评价中，学习15个超实用的地道英语表达。</p><hr><h2 id="1-Absolutely-insane-—-太疯了-x2F-太炸了"><a href="#1-Absolutely-insane-—-太疯了-x2F-太炸了" class="headerlink" title="1. Absolutely insane — 太疯了&#x2F;太炸了"></a>1. Absolutely insane — 太疯了&#x2F;太炸了</h2><blockquote><p><em>“🤯 <strong>Absolutely insane.</strong> Unitree’s humanoid robot team’s performance at the 2026 Spring Festival Gala.”</em><br>— @CyberRobo on X</p></blockquote><p><strong>讲解：</strong> “insane” 本义是”疯狂的”，但在口语中常用来表示”太厉害了、太不可思议了”，是年轻人非常高频的表达。”absolutely” 加强语气。</p><p><strong>例句：</strong> The graphics in this game are absolutely insane.</p><p><strong>同义表达：</strong> crazy, mind-blowing, nuts, wild</p><hr><h2 id="2-delivered-a-masterclass-—-上了一堂大师课"><a href="#2-delivered-a-masterclass-—-上了一堂大师课" class="headerlink" title="2. delivered a masterclass — 上了一堂大师课"></a>2. delivered a masterclass — 上了一堂大师课</h2><blockquote><p><em>“Unitree’s Robots <strong>Delivered a Martial Arts Masterclass</strong> on China’s Biggest Stage.”</em><br>— TechEBlog</p></blockquote><p><strong>讲解：</strong> “deliver a masterclass” 意思是展示了大师级水平的表现。”deliver” 在这里不是”送货”，而是”呈现、展示”。这个搭配在体育和艺术评论中特别常见。</p><p><strong>例句：</strong> Messi delivered a masterclass in last night’s Champions League final.</p><hr><h2 id="3-stole-the-show-—-抢尽风头"><a href="#3-stole-the-show-—-抢尽风头" class="headerlink" title="3. stole the show — 抢尽风头"></a>3. stole the show — 抢尽风头</h2><blockquote><p><em>“Its H1 humanoid robot <strong>stole the show</strong> with a creative dance performance called ‘YangBOT’.”</em><br>— Gasgoo（关于去年秧BOT的报道）</p></blockquote><p><strong>讲解：</strong> “steal the show” 意思是在活动中表现最出色、吸引了所有注意力。非常经典的习语，日常对话和写作都能用。</p><p><strong>例句：</strong> The 5-year-old flower girl stole the show at the wedding.</p><hr><h2 id="4-push-the-limits-—-突破极限"><a href="#4-push-the-limits-—-突破极限" class="headerlink" title="4. push the limits — 突破极限"></a>4. push the limits — 突破极限</h2><blockquote><p><em>“Dozens of G1 robots pulled off the world’s first fully autonomous Kung Fu performance, showing off quick movements that <strong>push the limits</strong> of what these bots can do.”</em><br>— @RoboHub on X</p></blockquote><p><strong>讲解：</strong> “push the limits” 是”挑战&#x2F;突破极限”的意思。也可以说 “push the boundaries”。</p><p><strong>近义：</strong> break new ground, push the envelope</p><p><strong>例句：</strong> SpaceX keeps pushing the limits of rocket reusability.</p><hr><h2 id="5-pull-off-—-成功完成（困难的事）"><a href="#5-pull-off-—-成功完成（困难的事）" class="headerlink" title="5. pull off — 成功完成（困难的事）"></a>5. pull off — 成功完成（困难的事）</h2><blockquote><p><em>“Dozens of G1 robots <strong>pulled off</strong> the world’s first fully autonomous Kung Fu performance.”</em><br>— @RoboHub on X</p></blockquote><p><strong>讲解：</strong> “pull off” 意思是成功做成某件困难或不太可能的事。非常口语化且实用。</p><p><strong>例句：</strong> I can’t believe she pulled off organizing a 200-person event in just two weeks.</p><p><strong>注意：</strong> pull off ≠ pull out（退出）</p><hr><h2 id="6-in-close-proximity-to-—-在……近距离范围内"><a href="#6-in-close-proximity-to-—-在……近距离范围内" class="headerlink" title="6. in close proximity to — 在……近距离范围内"></a>6. in close proximity to — 在……近距离范围内</h2><blockquote><p><em>“Over a dozen Unitree humanoids performed sophisticated fight sequences waving swords, poles and nunchucks <strong>in close proximity to</strong> human children performers.”</em><br>— Bloomberg&#x2F;BNN</p></blockquote><p><strong>讲解：</strong> “in close proximity to” 是”非常靠近”的正式说法，比 “near” 或 “close to” 更书面。新闻报道中常用。</p><p><strong>例句：</strong> The explosion occurred in close proximity to a school.</p><hr><h2 id="7-comparable-to-—-可与……相比"><a href="#7-comparable-to-—-可与……相比" class="headerlink" title="7. comparable to — 可与……相比"></a>7. comparable to — 可与……相比</h2><blockquote><p><em>“A televised event and touchstone for China <strong>comparable to</strong> the Super Bowl for the United States.”</em><br>— Reuters（路透社）</p></blockquote><p><strong>讲解：</strong> “comparable to” 意为”可以与……相媲美&#x2F;类比”。路透社直接把春晚比作美国的超级碗，这个比喻很到位。</p><p><strong>拓展：</strong> “touchstone” 也是个好词，意思是”试金石、标准”。</p><p><strong>例句：</strong> The annual 11.11 shopping festival is comparable to Black Friday in scale.</p><hr><h2 id="8-go-mainstream-—-进入主流"><a href="#8-go-mainstream-—-进入主流" class="headerlink" title="8. go mainstream — 进入主流"></a>8. go mainstream — 进入主流</h2><blockquote><p><em>“<strong>Humanoids go mainstream</strong> as China’s robotics champions appear at CCTV spectacle.”</em><br>— South China Morning Post（标题）</p></blockquote><p><strong>讲解：</strong> “go mainstream” 意思是从小众走向大众。SCMP 用这个做标题，精准概括了春晚让机器人走进普通人视野的意义。</p><p><strong>例句：</strong> Plant-based meat has officially gone mainstream.</p><hr><h2 id="9-with-surprising-speed-and-control-—-以惊人的速度和控制力"><a href="#9-with-surprising-speed-and-control-—-以惊人的速度和控制力" class="headerlink" title="9. with surprising speed and control — 以惊人的速度和控制力"></a>9. with surprising speed and control — 以惊人的速度和控制力</h2><blockquote><p><em>“China’s Unitree Robotics is developing humanoid robots that move <strong>with surprising speed and control</strong>.”</em><br>— Reddit r&#x2F;singularity</p></blockquote><p><strong>讲解：</strong> 这个表达简洁有力。”with + 名词” 结构在英语中非常常见，比用副词更优雅。</p><p><strong>对比：</strong> ❌ “move surprisingly fast and with good control” → ✅ “move with surprising speed and control”</p><hr><h2 id="10-ditched-A-for-B-—-抛弃A，改做B"><a href="#10-ditched-A-for-B-—-抛弃A，改做B" class="headerlink" title="10. ditched A for B — 抛弃A，改做B"></a>10. ditched A for B — 抛弃A，改做B</h2><blockquote><p><em>“They’ve <strong>ditched the dancing for some serious martial arts</strong>!”</em><br>— @RoboHub on X</p></blockquote><p><strong>讲解：</strong> “ditch” 原意是”丢弃”，口语中意思是”抛弃、甩掉”。”ditch A for B” 就是放弃A去做B。非常地道的表达。</p><p><strong>例句：</strong> I ditched my old phone for the latest iPhone.</p><hr><h2 id="11-stood-head-and-shoulders-above-the-rest-—-远超其他、鹤立鸡群"><a href="#11-stood-head-and-shoulders-above-the-rest-—-远超其他、鹤立鸡群" class="headerlink" title="11. stood head and shoulders above the rest — 远超其他、鹤立鸡群"></a>11. stood head and shoulders above the rest — 远超其他、鹤立鸡群</h2><blockquote><p><em>“It was Unitree’s contributions that really <strong>stood head and shoulders above the rest</strong>.”</em><br>— TechEBlog</p></blockquote><p><strong>讲解：</strong> 字面意思是”头和肩膀都高出其他人”，引申为”远远超过竞争对手”。非常生动的习语！</p><p><strong>例句：</strong> Among all the candidates, her resume stood head and shoulders above the rest.</p><hr><h2 id="12-Drunken-Fist-—-醉拳"><a href="#12-Drunken-Fist-—-醉拳" class="headerlink" title="12. Drunken Fist — 醉拳"></a>12. Drunken Fist — 醉拳</h2><blockquote><p><em>“Unitree’s humanoid robots stunned 1.4 billion viewers with a flawless <strong>Drunken Fist</strong> martial arts routine.”</em><br>— YouTube</p></blockquote><p><strong>讲解：</strong> 醉拳的英文就是 “Drunken Fist” 或 “Drunken Boxing”。成龙的电影让这个词在英语世界广为人知。</p><p><strong>相关词汇（附音标）：</strong></p><ul><li><strong>humanoid</strong> &#x2F;ˈhjuːmənɔɪd&#x2F; — 人形的、类人机器人</li><li><strong>nunchaku</strong> &#x2F;nʌnˈtʃɑːkuː&#x2F; — 双截棍（也写作 nunchucks &#x2F;ˈnʌntʃʌks&#x2F;）</li><li><strong>choreograph</strong> &#x2F;ˈkɒriəɡræf&#x2F; — 编舞、精心策划</li><li><strong>parkour</strong> &#x2F;pɑːˈkʊər&#x2F; — 跑酷</li><li><strong>backflip</strong> &#x2F;ˈbækflɪp&#x2F; — 后空翻</li><li><strong>exorcism</strong> &#x2F;ˈeksɔːsɪzəm&#x2F; — 驱魔（Reddit网友用来形容机器人站起来的样子）</li><li><strong>proximity</strong> &#x2F;prɒkˈsɪmɪti&#x2F; — 接近、邻近</li><li><strong>autonomous</strong> &#x2F;ɔːˈtɒnəməs&#x2F; — 自主的、自动的</li><li><strong>surge</strong> &#x2F;sɜːdʒ&#x2F; — 激增、涌动</li></ul><hr><h2 id="13-to-the-delight-and-awe-of-—-令……既欣喜又惊叹"><a href="#13-to-the-delight-and-awe-of-—-令……既欣喜又惊叹" class="headerlink" title="13. to the delight and awe of — 令……既欣喜又惊叹"></a>13. to the delight and awe of — 令……既欣喜又惊叹</h2><blockquote><p><em>“Unitree showed off the dancing skills of its H1 humanoid robots, <strong>to the delight and awe of</strong> more than 1 billion viewers.”</em><br>— South China Morning Post</p></blockquote><p><strong>讲解：</strong> 这是一个优雅的介词短语结构。”to the delight of” 意为”令人高兴的是”，加上 “awe”（敬畏、惊叹）表达了双重情感。正式写作中非常好用。</p><p><strong>万能句型：</strong> to the [情感词] of…</p><ul><li>to the surprise of everyone（令所有人惊讶）</li><li>to the horror of parents（令家长恐惧）</li><li>to the amusement of the audience（令观众觉得好笑）</li></ul><hr><h2 id="14-a-significant-upgrade-from-—-相比……有显著升级"><a href="#14-a-significant-upgrade-from-—-相比……有显著升级" class="headerlink" title="14. a significant upgrade from — 相比……有显著升级"></a>14. a significant upgrade from — 相比……有显著升级</h2><blockquote><p><em>“Captivating audiences this year with a dynamic routine featuring parkour, Drunken Fist, and nunchaku — <strong>a significant upgrade from</strong> their stunning Yangko dance performance at the 2025 event.”</em><br>— Global Times</p></blockquote><p><strong>讲解：</strong> “a significant upgrade from” 是描述产品迭代、技术进步时的万能表达。</p><p><strong>例句：</strong> The iPhone 16 is a significant upgrade from last year’s model.</p><hr><h2 id="15-Does-anyone-else-find…-—-有没有人也觉得……"><a href="#15-Does-anyone-else-find…-—-有没有人也觉得……" class="headerlink" title="15. Does anyone else find… — 有没有人也觉得……"></a>15. Does anyone else find… — 有没有人也觉得……</h2><blockquote><p><em>“<strong>Does anyone else find</strong> these robots a bit terrifying when they get knocked down and then rise up like some sort of exorcism over and over again?”</em><br>— Reddit r&#x2F;robotics（去年的经典评论）</p></blockquote><p><strong>讲解：</strong> Reddit上非常经典的句式，用来寻求共鸣。</p><ul><li><strong>“a bit terrifying”</strong> — 有点吓人（英式委婉说法）</li><li><strong>“like some sort of exorcism”</strong> — 像驱魔仪式一样（太形象了！）</li><li><strong>“over and over again”</strong> — 一次又一次</li></ul><p><strong>万能句式：</strong> Does anyone else find it weird&#x2F;annoying&#x2F;funny that…?</p><hr><h2 id="📝-实用表达总结表"><a href="#📝-实用表达总结表" class="headerlink" title="📝 实用表达总结表"></a>📝 实用表达总结表</h2><table><thead><tr><th>英文表达</th><th>中文含义</th><th>使用场景</th></tr></thead><tbody><tr><td>absolutely insane</td><td>太疯了&#x2F;太厉害了</td><td>口语&#x2F;社交媒体</td></tr><tr><td>deliver a masterclass</td><td>展示大师级水平</td><td>评论&#x2F;新闻</td></tr><tr><td>steal the show</td><td>抢尽风头</td><td>日常&#x2F;写作</td></tr><tr><td>push the limits</td><td>突破极限</td><td>科技&#x2F;体育</td></tr><tr><td>pull off</td><td>成功完成难事</td><td>口语</td></tr><tr><td>in close proximity to</td><td>在近距离范围内</td><td>正式&#x2F;新闻</td></tr><tr><td>comparable to</td><td>可与……相比</td><td>写作&#x2F;报道</td></tr><tr><td>go mainstream</td><td>进入主流</td><td>科技&#x2F;文化</td></tr><tr><td>ditch A for B</td><td>放弃A转做B</td><td>口语</td></tr><tr><td>head and shoulders above</td><td>远超其他</td><td>评价&#x2F;比较</td></tr><tr><td>Drunken Fist &#x2F;ˈdrʌŋkən fɪst&#x2F;</td><td>醉拳</td><td>武术&#x2F;文化</td></tr><tr><td>to the delight&#x2F;awe of</td><td>令人欣喜&#x2F;惊叹</td><td>正式写作</td></tr><tr><td>a significant upgrade from</td><td>相比有显著升级</td><td>科技&#x2F;产品</td></tr><tr><td>Does anyone else find…</td><td>有没有人也觉得……</td><td>社交媒体</td></tr><tr><td>with surprising speed</td><td>以惊人的速度</td><td>新闻&#x2F;描述</td></tr></tbody></table><hr><hr><h2 id="🎨-图解核心词汇"><a href="#🎨-图解核心词汇" class="headerlink" title="🎨 图解核心词汇"></a>🎨 图解核心词汇</h2><p><img src="/images/english-wubot-vocab1.png" alt="武术词汇图解"></p><p><img src="/images/english-wubot-vocab2.png" alt="地道表达漫画"></p><p><img src="/images/english-wubot-vocab3.png" alt="高频词汇音标速查"></p><hr><h2 id="💡-学习建议"><a href="#💡-学习建议" class="headerlink" title="💡 学习建议"></a>💡 学习建议</h2><h3 id="🔥-追热点学英语"><a href="#🔥-追热点学英语" class="headerlink" title="🔥 追热点学英语"></a>🔥 追热点学英语</h3><p>春晚机器人、DeepSeek 这类中国科技热点，在英文社交媒体上的讨论量巨大。你熟悉背景知识，读起来毫无障碍，又能学到地道表达——这是最高效的英语学习方式。</p><h3 id="✍️-今日练习"><a href="#✍️-今日练习" class="headerlink" title="✍️ 今日练习"></a>✍️ 今日练习</h3><p>用今天学到的表达写一段话，描述你看春晚《武BOT》的感受。试试用上 3-5 个新表达！</p><blockquote><p>📚 <strong>关注「英语大明白」</strong>，每天5分钟，用最新热点学最地道的英语表达！</p></blockquote><hr><p><em>Sources: South China Morning Post, Reuters, Bloomberg, TechEBlog, Global Times, TechNode, Gasgoo, Reddit, X&#x2F;Twitter, YouTube</em></p>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>English-Learning</tag>
      
      <tag>英语学习</tag>
      
      <tag>Spring-Festival-Gala</tag>
      
      <tag>Robotics</tag>
      
      <tag>武BOT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从秧BOT到武BOT：宇树机器人用醉拳和双截棍炸翻2026春晚，全球再次沸腾</title>
    <link href="/2026/02/17/foreign-reactions-spring-gala-robot-2025/"/>
    <url>/2026/02/17/foreign-reactions-spring-gala-robot-2025/</url>
    
    <content type="html"><![CDATA[<p><img src="/images/wubot-spring-gala-2026.jpg" alt="武BOT 2026春晚"></p><p><strong>2026年2月16日，马年除夕夜。</strong></p><p>当数十台宇树G1机器人在春晚舞台上打出醉拳、舞动双截棍、连续后空翻、3米高空翻转，并在高速奔跑中完成武术队形变阵时——全球互联网<strong>再次炸了</strong>。</p><p>去年是秧歌。今年是中国功夫。</p><p>节目名叫<strong>《武BOT》</strong>，宇树科技携手<strong>河南塔沟武术学校</strong>联合呈现。数十台G1人形机器人与武校学生同台对练，舞棍、耍剑、醉拳、跑酷，一招一式尽显江湖侠气。压轴登场的是1.8米高的H2机器人，手持长剑，气场全开。</p><p>在义乌分会场，H2更是身披齐天大圣战甲、手握金箍棒，站在四足机器狗组成的”筋斗云”上，向全国人民拜年。</p><p>X上的科技博主CyberRobo一个字总结：**”Absolutely insane.”**</p><hr><h2 id="🔥-武BOT-vs-秧BOT：一年进化了多少？"><a href="#🔥-武BOT-vs-秧BOT：一年进化了多少？" class="headerlink" title="🔥 武BOT vs 秧BOT：一年进化了多少？"></a>🔥 武BOT vs 秧BOT：一年进化了多少？</h2><table><thead><tr><th></th><th>2025 秧BOT</th><th>2026 武BOT</th></tr></thead><tbody><tr><td><strong>机型</strong></td><td>H1（1.8m, 47kg）</td><td>G1（1.3m, 35kg）+ H2（1.8m）</td></tr><tr><td><strong>动作</strong></td><td>秧歌、转手绢</td><td>醉拳、双截棍、舞棍、舞剑、跑酷、空翻</td></tr><tr><td><strong>集群规模</strong></td><td>16台</td><td>数十台</td></tr><tr><td><strong>关键突破</strong></td><td>AI驱动的自主舞蹈</td><td><strong>高速集群变阵</strong>（最高4m&#x2F;s）、灵巧手快速切换武器</td></tr><tr><td><strong>人机交互</strong></td><td>与舞者同台</td><td><strong>与儿童近距离对练武术</strong></td></tr><tr><td><strong>导演</strong></td><td>张艺谋</td><td>—</td></tr><tr><td><strong>合作方</strong></td><td>新疆艺术学院</td><td>河南塔沟武术学校</td></tr></tbody></table><p>知乎上一位用户的评价最为精准：</p><blockquote><p>“如果说去年，宇树机器人跟我比还是’还得练’的程度；今年我能赶上人家的，最多就是玩棍时我也能让棍头颤抖一下了。”</p></blockquote><p>另一个让人细思极恐的细节：有观众注意到一个机器人在做跨步动作时快要失去平衡，<strong>脚掌快速挪动了几步重新站稳</strong>——这是人类摔倒前的条件反射。机器人已经学会了。</p><hr><h2 id="🌍-外媒再次集体跟进"><a href="#🌍-外媒再次集体跟进" class="headerlink" title="🌍 外媒再次集体跟进"></a>🌍 外媒再次集体跟进</h2><h3 id="路透社：中国的”超级碗”"><a href="#路透社：中国的”超级碗”" class="headerlink" title="路透社：中国的”超级碗”"></a>路透社：中国的”超级碗”</h3><p>路透社今年的报道直接把春晚定义为中国机器人产业的”<strong>Super Bowl</strong>“：</p><blockquote><p>“Four rising humanoid robot startups demonstrated their products at the gala, a televised event and touchstone for China comparable to the Super Bowl for the United States.”</p></blockquote><p>四家初创公司——宇树、Galbot、Noetix、MagicLab——合计赞助金额约<strong>1亿元人民币（1400万美元）</strong>。</p><h3 id="南华早报：人形机器人进入主流"><a href="#南华早报：人形机器人进入主流" class="headerlink" title="南华早报：人形机器人进入主流"></a>南华早报：人形机器人进入主流</h3><p>SCMP以”<strong>Humanoids go mainstream</strong>“为标题，指出春晚正式将人形机器人从实验室带入了主流公众视野。</p><h3 id="Bloomberg-x2F-BNN：机器人与儿童近距离舞刀弄枪"><a href="#Bloomberg-x2F-BNN：机器人与儿童近距离舞刀弄枪" class="headerlink" title="Bloomberg&#x2F;BNN：机器人与儿童近距离舞刀弄枪"></a>Bloomberg&#x2F;BNN：机器人与儿童近距离舞刀弄枪</h3><p>Bloomberg的报道特别抓住了一个画面：</p><blockquote><p>“Over a dozen Unitree humanoids performed sophisticated fight sequences <strong>waving swords, poles and nunchucks in close proximity to human children performers</strong>.”</p></blockquote><p>这个细节说明了什么？——机器人的运动控制精度已经达到了可以在<strong>危险武器+儿童</strong>场景下安全运行的水平。</p><h3 id="TechEBlog：去年跳舞，今年武术大师"><a href="#TechEBlog：去年跳舞，今年武术大师" class="headerlink" title="TechEBlog：去年跳舞，今年武术大师"></a>TechEBlog：去年跳舞，今年武术大师</h3><p>TechEBlog的评价最为直白：</p><blockquote><p>“Unitree’s Robots Delivered a <strong>Martial Arts Masterclass</strong> on China’s Biggest Stage.”</p></blockquote><p>报道详细描述了G1的表现：后空翻、蹦床起跳、高速方向切换、平衡恢复——“handled these insanely quick directional shifts and balancing recoveries like nothing”（轻松应对这些疯狂的快速方向切换和平衡恢复）。</p><h3 id="环球时报：技术参数首次公开"><a href="#环球时报：技术参数首次公开" class="headerlink" title="环球时报：技术参数首次公开"></a>环球时报：技术参数首次公开</h3><p>环球时报的报道透露了关键数据：</p><ul><li><strong>跳桌跑酷</strong>：H1完成桌面翻越</li><li><strong>3米空中翻转</strong>：单腿连续后空翻</li><li><strong>Airflare大回环</strong>：七圈半旋转</li><li><strong>集群高速变阵</strong>：最高<strong>4米&#x2F;秒</strong>任意位移速度（全球首次）</li><li><strong>灵巧手</strong>：全新自研灵巧手，支持武术道具快速切换和稳定抓握</li></ul><hr><h2 id="🇹🇼-台湾媒体：从惊叹到深层焦虑"><a href="#🇹🇼-台湾媒体：从惊叹到深层焦虑" class="headerlink" title="🇹🇼 台湾媒体：从惊叹到深层焦虑"></a>🇹🇼 台湾媒体：从惊叹到深层焦虑</h2><p>台湾媒体对宇树机器人的关注程度，在两岸科技报道中非常罕见。</p><h3 id="中时新闻网：美专家紧盯春晚"><a href="#中时新闻网：美专家紧盯春晚" class="headerlink" title="中时新闻网：美专家紧盯春晚"></a>中时新闻网：美专家紧盯春晚</h3><p>春晚前夕，台湾《中时新闻网》以”<strong>美專家緊盯2026春晚——陸AI+製造戰略核心：人形機器人</strong>“为标题发文：</p><blockquote><p>“去年16台宇树机器人的秧歌表演引发广泛讨论，<strong>数周后，该公司创始人更获安排与习近平会面</strong>，显示官方对机器人产业的高度重视。”</p></blockquote><p>这个信号在台湾引发了对大陆科技战略的深度讨论。</p><h3 id="联合报-x2F-经济日报：亿元竞标战"><a href="#联合报-x2F-经济日报：亿元竞标战" class="headerlink" title="联合报&#x2F;经济日报：亿元竞标战"></a>联合报&#x2F;经济日报：亿元竞标战</h3><p>台湾联合报系持续跟踪了春晚赞助竞标：</p><ul><li>智元机器人开价<strong>6000万</strong></li><li>宇树直接喊到<strong>1亿</strong></li><li>最终四家公司共享春晚舞台</li></ul><p>经济日报评论称：”这标志着春晚的科技叙事，正从展示酷炫技术，转向呈现中国前沿产业核心技术实力。”</p><h3 id="联合报：宇树三度登台的完整弧线"><a href="#联合报：宇树三度登台的完整弧线" class="headerlink" title="联合报：宇树三度登台的完整弧线"></a>联合报：宇树三度登台的完整弧线</h3><p>台媒梳理了宇树与春晚的三次合作：</p><ol><li><strong>2021牛年</strong>：机械牛”犇犇”初次亮相</li><li><strong>2025蛇年</strong>：张艺谋执导《秧BOT》，现象级破圈</li><li><strong>2026马年</strong>：《武BOT》，全球首次自主机器人集群武术</li></ol><h3 id="联合报：从爆红到”内卷”的商业故事"><a href="#联合报：从爆红到”内卷”的商业故事" class="headerlink" title="联合报：从爆红到”内卷”的商业故事"></a>联合报：从爆红到”内卷”的商业故事</h3><p>台媒还完整记录了秧BOT之后的商业链条：</p><ul><li>春晚后机器人一机难求，催生<strong>租赁热潮</strong></li><li>日租金最高<strong>1.5万元</strong></li><li>有商家出租十余次收入超<strong>20万元</strong></li><li>但到2025年底，租赁价格<strong>暴跌九成</strong></li><li>3000元即可租到机器人加机器狗一天</li></ul><p>这是一个完美的中国式商业弧线：<strong>爆红→疯抢→量产→内卷→价格崩盘</strong>。</p><h3 id="联合报：马斯克都点赞"><a href="#联合报：马斯克都点赞" class="headerlink" title="联合报：马斯克都点赞"></a>联合报：马斯克都点赞</h3><p>2025年12月，宇树G1在王力宏演唱会上做后空翻，马斯克在X上转发点赞。台媒标题：</p><blockquote><p><strong>“馬斯克點讚！人形機器人登王力宏演唱會”</strong></p></blockquote><p>网友评论：”几个月前在春晚舞台上还像刚学走路的小孩，如今已经成为了专业的舞者。”</p><p>而这时候大家还不知道，几个月后的武BOT会更加疯狂。</p><hr><h2 id="🐦-X-x2F-Twitter评论精选"><a href="#🐦-X-x2F-Twitter评论精选" class="headerlink" title="🐦 X&#x2F;Twitter评论精选"></a>🐦 X&#x2F;Twitter评论精选</h2><h3 id="震撼派"><a href="#震撼派" class="headerlink" title="震撼派"></a>震撼派</h3><p><strong>CyberRobo</strong> (@cyberrobooo)：</p><blockquote><p>“🤯 Absolutely insane. Unitree’s humanoid robot team’s performance at the 2026 Spring Festival Gala. <strong>The significance lies in letting 1.4 billion Chinese people know where the future lies.</strong>“</p></blockquote><p><strong>RoboHub</strong> (@XRoboHub)：</p><blockquote><p>“Dozens of G1 robots pulled off the <strong>world’s first fully autonomous Kung Fu performance</strong>, showing off quick movements that push the limits of what these bots can do.”</p></blockquote><p><strong>YM Shen</strong> 评论：</p><blockquote><p>“Tool usage and force feedback and human interaction, self-recovery after jump. <strong>Amazing!</strong>“</p></blockquote><h3 id="YouTube热评"><a href="#YouTube热评" class="headerlink" title="YouTube热评"></a>YouTube热评</h3><p>“Unitree Humanoid Robots Shock People at 2026 Spring Festival Gala with Martial Arts” 视频描述：</p><blockquote><p>“Absolutely insane scenes… Unitree’s humanoid robots stunned 1.4 billion viewers with a <strong>flawless Drunken Fist</strong> martial arts routine.”</p></blockquote><h3 id="Reddit-r-x2F-singularity"><a href="#Reddit-r-x2F-singularity" class="headerlink" title="Reddit r&#x2F;singularity"></a>Reddit r&#x2F;singularity</h3><p>“Unitree Martial arts robots dazzle at 2026 Spring Festival Gala” 帖子引发热议，用户评论：</p><blockquote><p>“China’s Unitree Robotics is developing <strong>humanoid robots that move with surprising speed and control</strong>.”</p></blockquote><hr><h2 id="🤔-冷思考：春晚是舒适区？"><a href="#🤔-冷思考：春晚是舒适区？" class="headerlink" title="🤔 冷思考：春晚是舒适区？"></a>🤔 冷思考：春晚是舒适区？</h2><p>并非所有声音都是赞美。一篇深度分析文章（Geopolitechs）提出了尖锐观点：</p><blockquote><p>“春晚可能是具身智能的**完美’舒适区’**。舞台地面完全平整、高摩擦力、室内恒温恒湿、灯光预设、音乐毫秒级同步。预编程路线下，机器人不需要’思考’或适应——它们只需要执行预定轨迹。”</p></blockquote><blockquote><p>“工厂、家庭、零售空间、车间、农田——这些场景都有复杂地形。户外还有光照、湿度、温度、风速等不可控变量。最关键的是，机器人必须像人类一样灵活应对不可预见的情况——<strong>技术上仍有很多差距需要弥合。</strong>“</p></blockquote><p>文章还提到特斯拉Optimus的信任危机：一段广泛传播的视频中，Optimus机器人突然做出了”摘VR头显”的动作，被质疑是远程操控。</p><p><strong>但反过来说</strong>——武BOT中机器人与儿童近距离舞刀弄棍，这本身就是对安全性的极端考验。如果是远程操控，谁敢在直播中让机器人在儿童身边挥舞双截棍？</p><hr><h2 id="💰-产业图景：春晚经济学"><a href="#💰-产业图景：春晚经济学" class="headerlink" title="💰 产业图景：春晚经济学"></a>💰 产业图景：春晚经济学</h2><table><thead><tr><th>数据</th><th>来源</th></tr></thead><tbody><tr><td>2026春晚机器人赞助总额约<strong>1亿元</strong></td><td>SCMP&#x2F;36氪</td></tr><tr><td>宇树估值<strong>120亿元</strong></td><td>澎湃新闻</td></tr><tr><td>C轮投资方：中国移动、腾讯、阿里</td><td>多家媒体</td></tr><tr><td>2025全球人形机器人销售额<strong>4.4亿美元</strong></td><td>IDC</td></tr><tr><td>宇树2025年11月完成IPO辅导</td><td>证券时报</td></tr><tr><td>4家机器人企业登上2026春晚</td><td>路透社</td></tr></tbody></table><p>王兴兴的原话很实在：</p><blockquote><p>“表演、跑步、武术，这些背后的核心都是让机器人更稳定，从而去做对我们生活真正有帮助的事情。运动能力是智能机器人的先决必要条件——<strong>必须先能站稳、跑稳，才能谈得上去干活。</strong>“</p></blockquote><blockquote><p>“如果机器人能在复杂的队形变化和快速移动中完成武术表演，意味着未来它们在其他场景工作时，稳定性会更胜一筹。”</p></blockquote><hr><h2 id="📖-回顾：秧BOT如何改写历史"><a href="#📖-回顾：秧BOT如何改写历史" class="headerlink" title="📖 回顾：秧BOT如何改写历史"></a>📖 回顾：秧BOT如何改写历史</h2><p>如果没有2025年的秧BOT，就不会有今天的武BOT。</p><p>2025年1月28日，张艺谋执导的《秧BOT》让16台H1机器人穿花棉袄、转手绢、扭秧歌，成为当年春晚最出圈的节目。</p><p>那次表演之后：</p><ul><li>X平台播放量破<strong>480万</strong></li><li>宇树创始人被安排与习近平会面</li><li>机器人租赁行业爆发</li><li>估值从几十亿飙升至<strong>120亿</strong></li><li>多家公司竞相IPO</li></ul><p>Euro Weekly News当时的嘲讽至今被引用：</p><blockquote><p>“马斯克的Optimus还在<strong>小心翼翼地走路，仿佛害怕绊倒</strong>。与此同时，中国的AI机器人已经在与人类同步跳舞了。”</p></blockquote><p>一年后的今天，那些机器人不仅会跳舞了——它们会打醉拳、耍双截棍、做3米空翻、在高速奔跑中变阵。</p><p><strong>进化速度本身，才是最让人震撼的。</strong></p><hr><p><em>参考来源：Reuters, South China Morning Post, Bloomberg&#x2F;BNN, Global Times, TechEBlog, TechNode, Geopolitechs, 联合报, 经济日报, 中时新闻网, IT之家, 证券时报, 澎湃新闻, 新浪科技, 知乎, X&#x2F;Twitter, Reddit r&#x2F;singularity, YouTube</em></p>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>人工智能</tag>
      
      <tag>武BOT</tag>
      
      <tag>机器人</tag>
      
      <tag>Unitree</tag>
      
      <tag>宇树科技</tag>
      
      <tag>春晚</tag>
      
      <tag>人形机器人</tag>
      
      <tag>秧BOT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2026年02月16日早间要闻</title>
    <link href="/2026/02/16/2026-02-16-morning-news/"/>
    <url>/2026/02/16/2026-02-16-morning-news/</url>
    
    <content type="html"><![CDATA[<h2 id="🌐-科技日报精选"><a href="#🌐-科技日报精选" class="headerlink" title="🌐 科技日报精选"></a>🌐 科技日报精选</h2><h3 id="1-OpenAI-绕过-Nvidia，在-Cerebras-晶圆级芯片上跑出超快编码模型"><a href="#1-OpenAI-绕过-Nvidia，在-Cerebras-晶圆级芯片上跑出超快编码模型" class="headerlink" title="1. OpenAI 绕过 Nvidia，在 Cerebras 晶圆级芯片上跑出超快编码模型"></a>1. OpenAI 绕过 Nvidia，在 Cerebras 晶圆级芯片上跑出超快编码模型</h3><p><strong>来源：Ars Technica</strong> | <a href="https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/">原文链接</a></p><p>OpenAI 新推出的 GPT-5.3-Codex-Spark 编码模型在 Cerebras 晶圆级芯片上运行，速度达到 1000 tokens&#x2F;秒，比前代快 15 倍。AI 编码代理迎来爆发年，延迟已成为竞争关键——模型越快，开发者迭代越快。</p><h3 id="2-Anthropic-与五角大楼就-Claude-军事用途产生争执"><a href="#2-Anthropic-与五角大楼就-Claude-军事用途产生争执" class="headerlink" title="2. Anthropic 与五角大楼就 Claude 军事用途产生争执"></a>2. Anthropic 与五角大楼就 Claude 军事用途产生争执</h3><p><strong>来源：TechCrunch</strong> | <a href="https://techcrunch.com/2026/02/15/anthropic-and-the-pentagon-are-reportedly-arguing-over-claude-usage/">原文链接</a></p><p>五角大楼要求 AI 公司允许军方”用于所有合法用途”，但 Anthropic 拒绝配合，导致其 2 亿美元国防合同面临被取消。争议焦点包括大规模国内监控和自主武器。OpenAI、Google、xAI 也面临同样压力。</p><h3 id="3-OpenAI-研究员因-ChatGPT-广告辞职，警告”Facebook-化”"><a href="#3-OpenAI-研究员因-ChatGPT-广告辞职，警告”Facebook-化”" class="headerlink" title="3. OpenAI 研究员因 ChatGPT 广告辞职，警告”Facebook 化”"></a>3. OpenAI 研究员因 ChatGPT 广告辞职，警告”Facebook 化”</h3><p><strong>来源：Ars Technica</strong> | <a href="https://arstechnica.com/information-technology/2026/02/openai-researcher-quits-over-fears-that-chatgpt-ads-could-manipulate-users/">原文链接</a></p><p>哈佛研究员 Zoë Hitzig 在 OpenAI 工作两年后辞职，在《纽约时报》发文警告 ChatGPT 广告可能重蹈 Facebook 覆辙。用户向 ChatGPT 倾诉医疗恐惧、感情问题等私密信息，广告化可能利用这些数据操纵用户。</p><h3 id="4-C-语言-defer-关键字已在-GCC-和-Clang-中可用"><a href="#4-C-语言-defer-关键字已在-GCC-和-Clang-中可用" class="headerlink" title="4. C 语言 defer 关键字已在 GCC 和 Clang 中可用"></a>4. C 语言 defer 关键字已在 GCC 和 Clang 中可用</h3><p><strong>来源：Lobsters</strong> | <a href="https://gustedt.wordpress.com/2026/02/15/defer-available-in-gcc-and-clang/">原文链接</a></p><p>C 语言终于迎来 defer 语法支持！GCC 和 Clang 已实现该特性，允许开发者在作用域退出时自动执行清理代码，类似 Go 的 defer。这是 C 语言资源管理的重要改进。</p><h3 id="5-Google-Gemini-遭-10-万次-Prompt-攻击，试图通过蒸馏克隆模型"><a href="#5-Google-Gemini-遭-10-万次-Prompt-攻击，试图通过蒸馏克隆模型" class="headerlink" title="5. Google Gemini 遭 10 万次 Prompt 攻击，试图通过蒸馏克隆模型"></a>5. Google Gemini 遭 10 万次 Prompt 攻击，试图通过蒸馏克隆模型</h3><p><strong>来源：Ars Technica</strong> | <a href="https://arstechnica.com/ai/2026/02/attackers-prompted-gemini-over-100000-times-while-trying-to-clone-it-google-says/">原文链接</a></p><p>Google 披露有攻击者对 Gemini 发送超过 10 万次 prompt，试图通过知识蒸馏技术以极低成本复制模型能力。这揭示了大模型 API 面临的新型安全威胁。</p><hr><h2 id="🐙-GitHub-Trending"><a href="#🐙-GitHub-Trending" class="headerlink" title="🐙 GitHub Trending"></a>🐙 GitHub Trending</h2><ol><li><strong>steipete&#x2F;gogcli</strong> ⭐ +630 today — Google Suite CLI：整合 Gmail、GCal、GDrive、GContacts 的命令行工具</li><li><strong>rowboatlabs&#x2F;rowboat</strong> ⭐ +803 today — 开源 AI 协作助手，带记忆功能</li><li><strong>alibaba&#x2F;zvec</strong> ⭐ +673 today — 阿里巴巴出品的超轻量、极速进程内向量数据库（C++）</li><li><strong>ChromeDevTools&#x2F;chrome-devtools-mcp</strong> ⭐ +357 today — Chrome DevTools MCP 协议，让编码 Agent 直接控制浏览器调试</li><li><strong>github&#x2F;gh-aw</strong> ⭐ +213 today — GitHub 官方 Agentic Workflows 工具</li></ol><hr><h2 id="📈-美股行情（上周五收盘）"><a href="#📈-美股行情（上周五收盘）" class="headerlink" title="📈 美股行情（上周五收盘）"></a>📈 美股行情（上周五收盘）</h2><table><thead><tr><th>股票</th><th>代码</th><th>价格</th><th>涨跌幅</th></tr></thead><tbody><tr><td>微软</td><td>MSFT</td><td>$401.32</td><td>↓0.13%</td></tr><tr><td>谷歌-A</td><td>GOOGL</td><td>$305.72</td><td>↓1.06%</td></tr><tr><td>英伟达</td><td>NVDA</td><td>$182.81</td><td>↓2.21%</td></tr><tr><td>超威半导体</td><td>AMD</td><td>$207.32</td><td>↑0.67%</td></tr><tr><td>阿里巴巴</td><td>BABA</td><td>$155.73</td><td>↓1.89%</td></tr></tbody></table><p>美股整体偏弱，英伟达跌超2%领跌，AMD 逆势上涨。阿里巴巴跌近2%。</p>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>早报</tag>
      
      <tag>新闻</tag>
      
      <tag>AI</tag>
      
      <tag>科技</tag>
      
      <tag>美股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>OpenClaw 创始人加入 OpenAI：Agent 工程进入新阶段？</title>
    <link href="/2026/02/16/openclaw-founder-joins-openai/"/>
    <url>/2026/02/16/openclaw-founder-joins-openai/</url>
    
    <content type="html"><![CDATA[<p><img src="/images/openclaw-founder-steinberger-community.jpg" alt="Peter Steinberger 与 OpenClaw 社区"></p><p>一个奥地利开发者，一个人写了个开源项目，GitHub 星标冲到 23 万，被 Anthropic 发律师函改了两次名，最后被 Sam Altman 亲自发推招进了 OpenAI。这剧情放在电影里都嫌太夸张了——但它就发生在昨天。</p><p>2 月 15 日，Sam Altman 在 X 上宣布：OpenClaw 创始人 Peter Steinberger 正式加入 OpenAI，负责”drive the next generation of personal agents”。</p><p>这条消息炸开了整个 AI 开发者圈。</p><p><img src="/images/openclaw-founder-joins-openai-cover.png" alt="OpenClaw 创始人加入 OpenAI"></p><span id="more"></span><h2 id="一个项目，三个名字，23-万颗星"><a href="#一个项目，三个名字，23-万颗星" class="headerlink" title="一个项目，三个名字，23 万颗星"></a>一个项目，三个名字，23 万颗星</h2><p>OpenClaw 的故事本身就是一部微型创业传奇。</p><p>Peter Steinberger 最早给项目起名叫 <strong>Clawdbot</strong>——一个本地运行的 AI agent 框架，能操控你的电脑、读你的文件、帮你干活。项目很快在开发者社区火了起来，但名字也惹了麻烦：Anthropic 的法务团队找上门来，认为”Clawdbot”跟他们的 Claude 太像，构成商标侵权威胁。</p><p>于是改名 <strong>Moltbot</strong>。</p><p>结果没过多久，又因为各种原因再次更名，最终定格为 <strong>OpenClaw</strong>。三次改名，社区不但没散，反而越聚越多。到今天，OpenClaw 在 GitHub 上已经拿下超过 23 万个 stars，成为 AI agent 领域最炙手可热的开源项目之一。</p><p>说实话，光是”被 Anthropic 发律师函然后照样火”这一条，就已经是一个相当硬核的简历了。</p><h2 id="OpenAI-为什么要这个人？"><a href="#OpenAI-为什么要这个人？" class="headerlink" title="OpenAI 为什么要这个人？"></a>OpenAI 为什么要这个人？</h2><p>答案很简单：<strong>Agent 是下一个战场。</strong></p><p>大模型的能力比拼已经进入深水区，光靠模型本身的 benchmark 分数已经越来越难拉开差距。真正的竞争正在转向”模型能帮用户做什么”——也就是 agent 能力。</p><p>但 agent 工程跟训练模型是两码事。怎么让 AI 安全地操作文件系统？怎么设计权限模型？怎么处理多 agent 之间的协调？怎么在用户的真实环境里跑起来不出乱子？这些问题，论文里写不出来，得靠实打实的工程经验。</p><p>Steinberger 正好是全世界在这个领域踩坑最多的人之一。23 万用户的真实反馈，无数个 edge case，各种操作系统和环境的适配——这些经验是 OpenAI 自己从零开始搞至少要花一两年才能积累的。</p><p>Sam Altman 在推文里说得很明白：”The future is going to be extremely multi-agent.” OpenAI 需要的不只是一个聪明的工程师，而是一个<strong>已经证明自己能把 agent 做出来、做好用的人</strong>。</p><h2 id="对-OpenClaw-用户意味着什么？"><a href="#对-OpenClaw-用户意味着什么？" class="headerlink" title="对 OpenClaw 用户意味着什么？"></a>对 OpenClaw 用户意味着什么？</h2><p>官方给出的答案是：OpenClaw 将以<strong>基金会形式</strong>继续运营，保持开源，OpenAI 会持续支持。</p><p>听起来很美好，但咱们也别太天真。</p><p>创始人的精力是有限的。Steinberger 加入 OpenAI 后，日常工作重心必然会转向 OpenAI 内部的 agent 项目。OpenClaw 社区虽然活跃，但一个开源项目失去灵魂人物的全职投入后会怎样，我们见过太多先例了。</p><p>当然，也有好的一面。基金会模式意味着项目的治理会更加社区化，不再依赖某一个人的决策。而且 OpenAI 的背书和支持，可能反而会给 OpenClaw 带来更多的资源和关注。</p><p><strong>短期看</strong>，影响不大，项目会照常推进。<strong>长期看</strong>，取决于社区能不能培养出新的核心维护者。</p><h2 id="开源项目被大厂”招安”：老戏码了"><a href="#开源项目被大厂”招安”：老戏码了" class="headerlink" title="开源项目被大厂”招安”：老戏码了"></a>开源项目被大厂”招安”：老戏码了</h2><p>如果你在科技圈待得够久，这个剧本你一定不陌生。</p><p>Docker 的 Solomon Hykes 离开后，Docker 项目经历了漫长的方向迷失。Kubernetes 从 Google 内部项目独立出来交给 CNCF，反而活得更好了。Redis 的创始人 Salvatore Sanfilippo 退出日常维护后，项目依然在 Redis Labs 的推动下持续发展。</p><p>模式大同小异：<strong>开源项目火了 → 创始人被大厂看中 → 项目交给社区或基金会 → 结果好坏参半。</strong></p><p>Steinberger 自己在博客里写得也很坦诚：他本可以把 OpenClaw 做成一家大公司，但”It’s not really exciting for me”。他说自己想要的是改变世界，而不是建一家大公司，”teaming up with OpenAI is the fastest way to bring this to everyone”。</p><p>这话我信。但我也知道，”改变世界”这四个字，在硅谷被说得太多，真正能做到的人屈指可数。</p><h2 id="安全隐忧不能忽视"><a href="#安全隐忧不能忽视" class="headerlink" title="安全隐忧不能忽视"></a>安全隐忧不能忽视</h2><p>在大家为这条新闻兴奋的同时，CrowdStrike 上周发布的一份安全报告给所有人泼了一盆冷水。</p><p>报告指出，OpenClaw 这类 agent 工具在企业环境中可能构成<strong>严重的安全风险</strong>。原因很直接：agent 需要访问文件系统、执行命令、读取敏感数据——如果员工在公司机器上随意部署，这些 agent 本质上就是一个<strong>拥有用户全部权限的后门</strong>。</p><p>这不是危言耸听。想想看，一个能读你所有文件、执行任意命令的程序，如果它的通信链路被攻击者劫持，或者它调用的模型 API 被注入恶意指令，后果不堪设想。</p><p>agent 时代的安全模型，跟传统软件完全不同。我们还没有成熟的框架来回答”一个 AI agent 应该拥有多大的权限”这个问题。这可能是接下来几年最重要的技术课题之一。</p><h2 id="我的看法"><a href="#我的看法" class="headerlink" title="我的看法"></a>我的看法</h2><p>我觉得这件事有三层意思。</p><p><strong>第一层</strong>，对 Steinberger 个人来说，这是一个很合理的选择。OpenClaw 再怎么火，作为一个开源项目，商业化路径并不清晰。加入 OpenAI，能拿到顶级的资源和平台，做出来的东西能直接触达上亿用户。如果真的想让 agent 技术改变普通人的生活，OpenAI 确实是目前最好的平台之一。</p><p><strong>第二层</strong>，对 OpenAI 来说，这是一个信号：他们在 agent 领域是认真的。不是发个论文、做个 demo 那种认真，而是把业界最懂 agent 工程的人挖过来那种认真。接下来可以预期 OpenAI 会在 agent 产品上有大动作。</p><p><strong>第三层</strong>，对整个行业来说，这标志着 <strong>AI agent 从”技术玩具”走向”基础设施”的拐点</strong>。当大厂开始用收购和招聘的方式来布局 agent 赛道，说明这个方向已经过了概念验证阶段，进入了真正的产品化竞赛。</p><p>但说实话，我对”基金会模式”能不能真的保住 OpenClaw 的独立性，持保留态度。历史告诉我们，开源项目一旦失去那个最有激情、最有判断力的人，社区很容易陷入方向分歧和决策瘫痪。希望 OpenClaw 能成为一个例外。</p><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>Peter Steinberger 的故事，是这个 AI 疯狂时代的一个缩影：一个人，一个开源项目，搅动了整个行业，然后被行业巨头收入麾下。</p><p>这到底是开源精神的胜利，还是又一次”大厂赢麻了”的戏码？可能两者都是。</p><p>不管怎样，agent 时代确实来了。而这一次，站在前排的不是某篇论文或某个模型，而是一个真正动手把东西做出来的工程师。</p><p>这可能是 2026 年 AI 领域最重要的人事变动之一。接下来几个月，值得关注 OpenAI 在 agent 方向的动作。</p><hr><p><em>如果你也在用 OpenClaw，欢迎留言聊聊你的看法。</em></p>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Agent</tag>
      
      <tag>OpenAI</tag>
      
      <tag>OpenClaw</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ZeroClaw 横空出世，它会取代 OpenClaw 吗？</title>
    <link href="/2026/02/16/openclaw-vs-zeroclaw/"/>
    <url>/2026/02/16/openclaw-vs-zeroclaw/</url>
    
    <content type="html"><![CDATA[<p><img src="/images/openclaw-vs-zeroclaw-cover.png" alt="封面"></p><p>上周，一个叫 ZeroClaw 的项目突然出现在我的 GitHub Trending 里。Rust 写的、3.4MB 二进制、号称能跑在 10 美元的树莓派上。README 第一行就是对 OpenClaw 的挑衅：</p><blockquote><p>⚡️ Runs on $10 hardware with &lt;5MB RAM: That’s 99% less memory than OpenClaw and 98% cheaper than a Mac mini!</p></blockquote><p>说实话，看到这句话我的第一反应是——又一个「用 Rust 重写一切」的项目？</p><p>但仔细看了它的架构和设计哲学之后，我觉得这事没那么简单。这篇文章聊聊我的实际体验和想法。</p><span id="more"></span><h2 id="它们到底在争什么？"><a href="#它们到底在争什么？" class="headerlink" title="它们到底在争什么？"></a>它们到底在争什么？</h2><p>先搞清楚一个基本事实：<strong>OpenClaw 和 ZeroClaw 回答的是完全不同的问题。</strong></p><p>OpenClaw 问的是：<strong>「AI 助手的能力上限在哪？」</strong> 浏览器自动化、Canvas 渲染、子 Agent 编排、Cron 定时器、十几个 Channel 同时在线……你想得到的它都能做，想不到的它也做了。用一个形象的比喻：OpenClaw 就像一台功能齐全的工作站，什么都能干，代价是它确实需要一台像样的机器来跑。</p><p>ZeroClaw 问的是：<strong>「AI 助手的存在感能低到什么程度？」</strong> 它追求的是你完全感知不到它在运行。5MB 内存，10 毫秒启动，像 Linux 里的一个 daemon 一样安安静静待在后台。你不找它的时候，它几乎不存在。</p><p>Medium 上有个叫 Damon B. 的博主说了一句挺到位的话：</p><blockquote><p><em>“We are moving from the ‘look, it works on my MacBook’ phase to the ‘it should work like a daemon, not like a second operating system’ phase.”</em></p></blockquote><p>翻译一下：从「看，它在我 Mac 上跑起来了！」到「它应该像个 daemon，不应该像第二个操作系统」。</p><p>这话有道理，但也不全对——后面再展开。</p><h2 id="架构：全家桶-vs-乐高积木"><a href="#架构：全家桶-vs-乐高积木" class="headerlink" title="架构：全家桶 vs 乐高积木"></a>架构：全家桶 vs 乐高积木</h2><p><img src="/images/openclaw-vs-zeroclaw-arch.png" alt="架构对比"></p><p>先上一张对比表，然后聊聊表面数据背后的东西：</p><table><thead><tr><th>维度</th><th>OpenClaw</th><th>ZeroClaw</th></tr></thead><tbody><tr><td><strong>语言</strong></td><td>TypeScript &#x2F; Node.js</td><td>100% Rust</td></tr><tr><td><strong>运行时</strong></td><td>需要 Node.js（~390MB 开销）</td><td>无依赖，单个静态二进制</td></tr><tr><td><strong>二进制大小</strong></td><td>~28MB（dist）</td><td>3.4MB</td></tr><tr><td><strong>架构风格</strong></td><td>插件 + 技能 + 事件驱动</td><td>8 个 trait 接口，可插拔</td></tr><tr><td><strong>执行模型</strong></td><td>主 Agent + 子 Agent 派发</td><td>Readonly &#x2F; Supervised &#x2F; Full 三档</td></tr><tr><td><strong>浏览器控制</strong></td><td>✅ Browser Relay + Canvas</td><td>❌ 仅有基础 browser_open</td></tr><tr><td><strong>定时任务</strong></td><td>✅ Cron 系统</td><td>✅ Heartbeat 周期任务</td></tr><tr><td><strong>记忆系统</strong></td><td>文件系统（Markdown）</td><td>SQLite + FTS5 + 向量搜索</td></tr><tr><td><strong>AI 模型</strong></td><td>多模型，可切换</td><td>22+ 提供商，OpenAI 兼容</td></tr><tr><td><strong>Channel</strong></td><td>Telegram&#x2F;Discord&#x2F;Slack&#x2F;飞书&#x2F;iMessage&#x2F;WhatsApp 等</td><td>Telegram&#x2F;Discord&#x2F;Slack&#x2F;iMessage&#x2F;Matrix&#x2F;WhatsApp</td></tr><tr><td><strong>安全</strong></td><td>配对码 + 沙箱 + allowlist</td><td>默认 localhost + 配对码 + 沙箱 + allowlist</td></tr><tr><td><strong>身份系统</strong></td><td>SOUL.md &#x2F; IDENTITY.md 等</td><td>兼容 OpenClaw 格式 + JSON 格式</td></tr></tbody></table><h3 id="几个值得注意的细节"><a href="#几个值得注意的细节" class="headerlink" title="几个值得注意的细节"></a>几个值得注意的细节</h3><p><strong>1. ZeroClaw 主动兼容 OpenClaw</strong></p><p>ZeroClaw 直接支持 <code>IDENTITY.md</code>、<code>SOUL.md</code>、<code>USER.md</code>、<code>AGENTS.md</code> 这一套文件格式，甚至做了一个 <code>zeroclaw migrate openclaw</code> 的迁移命令。这说明它不想推翻 OpenClaw 的生态，而是想当一个「更轻的 OpenClaw」。</p><p><strong>2. 记忆系统上 ZeroClaw 更有技术野心</strong></p><p>OpenClaw 的记忆本质上是 Markdown 文件——简单粗暴但有效。ZeroClaw 搞了一套完整的检索引擎：SQLite 存储、FTS5 全文检索、向量相似度搜索、BM25 排序、混合加权……全部零外部依赖，不需要 Pinecone 也不需要 Elasticsearch。单纯从技术角度看，这个方案确实更优雅。</p><p><strong>3. 但 OpenClaw 在能力上仍然领先一个身位</strong></p><p>浏览器控制（Browser Relay）、Canvas 渲染、子 Agent 编排——这些 ZeroClaw 目前做不到或做不好。如果你需要一个 AI 助手帮你操作网页、生成可视化内容、或者同时派多个子任务并行处理，OpenClaw 仍然是唯一选择。</p><h2 id="资源消耗：这差距真的有点离谱"><a href="#资源消耗：这差距真的有点离谱" class="headerlink" title="资源消耗：这差距真的有点离谱"></a>资源消耗：这差距真的有点离谱</h2><p><img src="/images/openclaw-vs-zeroclaw-resources.png" alt="资源对比"></p><p>这是 ZeroClaw 最喜欢拿出来说的数据，也是最有说服力的部分：</p><table><thead><tr><th>指标</th><th>OpenClaw</th><th>ZeroClaw</th></tr></thead><tbody><tr><td><strong>空闲内存 (RSS)</strong></td><td>~394MB</td><td>~7-8MB</td></tr><tr><td><strong>活跃内存</strong></td><td>可达 1.5GB</td><td>未公开（预计 &lt; 50MB）</td></tr><tr><td><strong>冷启动</strong></td><td>3-5 秒</td><td>&lt;10ms</td></tr><tr><td><strong>最低硬件要求</strong></td><td>普通 PC &#x2F; Mac（建议 4GB+）</td><td>树莓派 Zero（$10）</td></tr><tr><td><strong>CPU 深度睡眠</strong></td><td>Node.js 事件循环阻止</td><td>✅ 支持</td></tr></tbody></table><p>394MB vs 7MB。说实话，我第一次看到这个数字的时候觉得 ZeroClaw 在吹牛。但它给了复现方法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">cargo build --release<br>/usr/bin/time -l target/release/zeroclaw --<span class="hljs-built_in">help</span><br>/usr/bin/time -l target/release/zeroclaw status<br></code></pre></td></tr></table></figure><p>这个差距是 TypeScript&#x2F;Node.js vs Rust 的必然结果——Node.js 本身的 V8 引擎就要占几百 MB。这不是 OpenClaw 写得差，而是语言选择的固有开销。</p><h3 id="但这真的重要吗？"><a href="#但这真的重要吗？" class="headerlink" title="但这真的重要吗？"></a>但这真的重要吗？</h3><p><strong>取决于你的场景。</strong> 如果你在 32GB 内存的 Mac mini 上跑 OpenClaw，394MB 只是 1.2% 的内存，你根本感觉不到。但如果你想在一台 512MB 的树莓派 Zero 上跑一个 24&#x2F;7 的 AI 助手——OpenClaw 连启动都够呛，ZeroClaw 则毫无压力。</p><p>Damon B. 还算了一笔有意思的账：假设 OpenClaw 的 23 万 stars 都对应着实际用户，光是这些用户多占用的内存带来的额外功耗，一年就是 <strong>4,480 吨 CO₂</strong>——相当于 1,000 辆汽油车全年的排放。当然这个计算非常粗糙，实际活跃用户远没有 23 万，但思路是对的：<strong>当工具变成「始终运行」的基础设施，效率就不再是锦上添花，而是基本要求。</strong></p><h2 id="实际部署指南"><a href="#实际部署指南" class="headerlink" title="实际部署指南"></a>实际部署指南</h2><p>说了这么多理论，来点实操的。</p><h3 id="OpenClaw-部署（以-macOS-为例）"><a href="#OpenClaw-部署（以-macOS-为例）" class="headerlink" title="OpenClaw 部署（以 macOS 为例）"></a>OpenClaw 部署（以 macOS 为例）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 1. 安装 Node.js（如果没有的话）</span><br>brew install node<br><br><span class="hljs-comment"># 2. 全局安装 OpenClaw</span><br>npm install -g openclaw<br><br><span class="hljs-comment"># 3. 初始化配置</span><br>openclaw init<br><br><span class="hljs-comment"># 4. 启动 Gateway</span><br>openclaw gateway start<br><br><span class="hljs-comment"># 5. 检查状态</span><br>openclaw status<br></code></pre></td></tr></table></figure><p>OpenClaw 的配置在 <code>~/.openclaw/</code> 目录下，核心配置文件是 <code>openclaw.json</code>。你需要配置：</p><ul><li>AI 模型的 API Key（支持 OpenAI、Anthropic、GitHub Copilot 等）</li><li>Channel（飞书、Telegram、Discord 等）</li><li>技能和插件</li></ul><p>详细配置参考 <a href="https://docs.openclaw.ai/">OpenClaw 官方文档</a>。</p><h3 id="ZeroClaw-部署"><a href="#ZeroClaw-部署" class="headerlink" title="ZeroClaw 部署"></a>ZeroClaw 部署</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 方式 1：从源码编译（需要 Rust 工具链）</span><br>git <span class="hljs-built_in">clone</span> https://github.com/zeroclaw-labs/zeroclaw.git<br><span class="hljs-built_in">cd</span> zeroclaw<br>cargo build --release<br>cargo install --path . --force<br><br><span class="hljs-comment"># 方式 2：下载预编译二进制（如果官方提供的话）</span><br><span class="hljs-comment"># 目前主要支持 macOS arm64 和 Linux</span><br><br><span class="hljs-comment"># 快速配置（非交互）</span><br>zeroclaw onboard --api-key sk-... --provider openrouter<br><br><span class="hljs-comment"># 或交互式向导</span><br>zeroclaw onboard --interactive<br><br><span class="hljs-comment"># 启动 daemon</span><br>zeroclaw daemon<br><br><span class="hljs-comment"># 检查状态</span><br>zeroclaw status<br><br><span class="hljs-comment"># 系统诊断</span><br>zeroclaw doctor<br></code></pre></td></tr></table></figure><h3 id="从-OpenClaw-迁移到-ZeroClaw"><a href="#从-OpenClaw-迁移到-ZeroClaw" class="headerlink" title="从 OpenClaw 迁移到 ZeroClaw"></a>从 OpenClaw 迁移到 ZeroClaw</h3><p>如果你已经是 OpenClaw 用户，ZeroClaw 提供了一键迁移：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 先预览迁移内容（不实际操作）</span><br>zeroclaw migrate openclaw --dry-run<br><br><span class="hljs-comment"># 确认后执行迁移</span><br>zeroclaw migrate openclaw<br></code></pre></td></tr></table></figure><p>这会把你的 <code>SOUL.md</code>、<code>IDENTITY.md</code>、<code>USER.md</code>、<code>AGENTS.md</code> 以及记忆文件迁移过去。</p><h3 id="Windows-用户怎么办？"><a href="#Windows-用户怎么办？" class="headerlink" title="Windows 用户怎么办？"></a>Windows 用户怎么办？</h3><p>这是个重要的问题，因为中国用户有很大比例在用 Windows。</p><p><strong>OpenClaw 在 Windows 上：</strong></p><ul><li>✅ 可以运行。Node.js 本身跨平台，OpenClaw 在 Windows 上可用</li><li>⚠️ 部分功能受限：iMessage Channel 不可用（苹果生态限制）、部分 shell 命令需要适配</li><li>💡 推荐方案：使用 WSL2（Windows Subsystem for Linux）运行，体验与 Linux&#x2F;macOS 基本一致</li><li>安装步骤：<code>wsl --install</code> → 在 WSL 内 <code>npm install -g openclaw</code> → 正常使用</li></ul><p><strong>ZeroClaw 在 Windows 上：</strong></p><ul><li>✅ Rust 支持 Windows 交叉编译，理论上可以生成 Windows 二进制</li><li>⚠️ 目前官方文档主要针对 macOS&#x2F;Linux，Windows 支持标注为 <code>runtime.kind = &quot;native&quot;</code> 但实测案例较少</li><li>💡 同样推荐 WSL2 作为首选方案</li><li>如果你有 Rust 工具链，可以直接 <code>cargo build --release</code> 在 Windows 上编译</li></ul><p><strong>给 Windows 用户的建议：</strong> 不管选哪个，先装 WSL2。2026 年了，在 Windows 上跑任何开发者工具，WSL2 都是最省心的选择。</p><h3 id="中国大陆网络环境"><a href="#中国大陆网络环境" class="headerlink" title="中国大陆网络环境"></a>中国大陆网络环境</h3><p>两者都面临同一个现实：<strong>主流 AI 模型提供商（OpenAI、Anthropic、Groq 等）需要国际网络才能访问。</strong> 这一点上两者没有本质区别。</p><p>但部署过程中的差异是存在的：</p><ul><li><strong>OpenClaw</strong> 需要 <code>npm install</code>，拉取几百个 npm 包。虽然可以用淘宝镜像（<code>npx nrm use taobao</code>），但部分二进制依赖（如 Playwright 的 Chromium）仍然需要国际网络下载，速度可能只有 85KB&#x2F;s 左右</li><li><strong>ZeroClaw</strong> 下载一个 3.4MB 的二进制文件就完事了。即使需要从 GitHub Releases 下载，也比拉几百个 npm 包快得多</li></ul><p>如果你在公司内网、不方便配置国际网络的环境下部署，ZeroClaw 的零依赖特性是实实在在的优势。</p><h2 id="适用场景：它们不是竞品，是互补"><a href="#适用场景：它们不是竞品，是互补" class="headerlink" title="适用场景：它们不是竞品，是互补"></a>适用场景：它们不是竞品，是互补</h2><p><img src="/images/openclaw-vs-zeroclaw-deploy.png" alt="部署场景"></p><p>我越看越觉得，把它们放在一起比较本身就有点不公平。它们适合的场景完全不一样。</p><h3 id="选-OpenClaw-的理由"><a href="#选-OpenClaw-的理由" class="headerlink" title="选 OpenClaw 的理由"></a>选 OpenClaw 的理由</h3><ul><li>🌐 <strong>你需要浏览器自动化</strong> —— Browser Relay、Canvas 这些能力目前没有替代</li><li>🔄 <strong>你需要复杂的工作流编排</strong> —— 子 Agent、Cron、多 Channel 联动</li><li>🛠️ <strong>你想快速搭建原型</strong> —— 技能系统 + 社区生态，很多轮子不用自己造</li><li>👥 <strong>你重视社区支持</strong> —— 23 万 stars 的项目，遇到问题 Discord 里分分钟有人回</li></ul><h3 id="选-ZeroClaw-的理由"><a href="#选-ZeroClaw-的理由" class="headerlink" title="选 ZeroClaw 的理由"></a>选 ZeroClaw 的理由</h3><ul><li>🍓 <strong>你要在低功耗设备上跑</strong> —— 树莓派、NAS、旧 ThinkPad、$5 的 VPS</li><li>🤫 <strong>你想要一个安静的后台 daemon</strong> —— 不占内存，不阻止 CPU 睡眠，笔记本续航友好</li><li>🔒 <strong>安全敏感场景</strong> —— 默认 localhost、最小权限、不暴露任何端口</li><li>🏗️ <strong>你是 Rust 开发者</strong> —— trait 接口设计干净，二次开发体验好</li></ul><h3 id="速查选择表"><a href="#速查选择表" class="headerlink" title="速查选择表"></a>速查选择表</h3><table><thead><tr><th>你是谁</th><th>推荐</th><th>一句话理由</th></tr></thead><tbody><tr><td>全栈工程师，爱折腾</td><td><strong>OpenClaw</strong></td><td>能力天花板高，TypeScript 生态好，社区活跃</td></tr><tr><td>运维 &#x2F; SRE</td><td><strong>ZeroClaw</strong></td><td>单二进制部署，资源占用约等于没有</td></tr><tr><td>创业者，需要快速搭 AI 产品</td><td><strong>OpenClaw</strong></td><td>开箱即用的能力更多，不用重新造轮子</td></tr><tr><td>公司内部工具</td><td><strong>看场景</strong></td><td>需要浏览器&#x2F;Canvas → OpenClaw；边缘设备 → ZeroClaw</td></tr><tr><td>树莓派 &#x2F; NAS 玩家</td><td><strong>ZeroClaw</strong></td><td>OpenClaw 在这类设备上直接跑不动</td></tr><tr><td>已有 OpenClaw 想试试新东西</td><td><strong>先迁移试试</strong></td><td><code>zeroclaw migrate openclaw</code> 低成本尝鲜</td></tr><tr><td>Windows 用户</td><td><strong>都行，先装 WSL2</strong></td><td>两个项目在 WSL2 下体验都最好</td></tr></tbody></table><h2 id="说点实话"><a href="#说点实话" class="headerlink" title="说点实话"></a>说点实话</h2><p>ZeroClaw 做得好的地方很明显：二进制小、启动快、内存省、安全默认值设计得好。它的 SQLite 记忆系统在技术上比 OpenClaw 的 Markdown 文件更先进。Rust 写的代码在性能和安全性上天然就有优势。</p><p>但——</p><p><strong>功能差距仍然巨大。</strong> 浏览器控制、Canvas 渲染、子 Agent 编排、飞书集成……这些 OpenClaw 的核心能力，ZeroClaw 目前一个都没有。对于需要这些功能的用户来说，ZeroClaw 根本不在考虑范围内。</p><p><strong>生态差距更大。</strong> OpenClaw 有 23 万 stars、活跃的 Discord 社区、大量现成的技能包。ZeroClaw 还在 invite code 阶段，文档主要就是 README。这个差距不是代码能弥补的，需要时间。</p><p><strong>「Rust 重写一切」不是万能药。</strong> 内存从 394MB 降到 7MB 确实令人印象深刻，但对于大多数用户来说，省下这 387MB 内存远不如多一个浏览器自动化功能来得有用。工具的价值在于它能帮你解决什么问题，不在于它占多少内存。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p><strong>ZeroClaw 会取代 OpenClaw 吗？不会。</strong></p><p>但它值得关注。它代表的是 AI 助手领域的一个健康趋势：从「能不能跑」走向「跑得好不好」。就像 Linux 世界有 Ubuntu 也有 Alpine，桌面有 GNOME 也有 i3wm——全功能和极简主义完全可以共存。</p><p>最务实的做法？<strong>主力机上跑 OpenClaw 享受全部功能，树莓派上跑 ZeroClaw 当一个安静的后台 daemon。</strong> 各司其职，各取所长。</p><p>毕竟，Unix 哲学从来不是要你只用一个工具解决所有问题。</p><hr><p><em>本文基于 ZeroClaw GitHub 仓库（2026 年 2 月 16 日快照）、官网 zeroclaw.bot、以及 Medium 文章 “ZeroClaw vs OpenClaw” by Damon B. 的公开信息撰写。如有错误，欢迎指正。</em></p>]]></content>
    
    
    <categories>
      
      <category>深度分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Agent</tag>
      
      <tag>OpenClaw</tag>
      
      <tag>ZeroClaw</tag>
      
      <tag>Rust</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AI网站生成必备：这 35 种 UI 风格直接抄，图文直给到全</title>
    <link href="/2026/02/15/2026-02-15-frontend-prompt-styles/"/>
    <url>/2026/02/15/2026-02-15-frontend-prompt-styles/</url>
    
    <content type="html"><![CDATA[<p><img src="/images/ui-styles/cover-frontend-styles.jpg" alt="封面"></p><p>用 AI（如 Claude、GPT、Cursor、v0.dev）生成前端页面时，精准描述你想要的视觉风格至关重要。同样是”帮我做一个 Dashboard”，加上不同的风格关键词，出来的效果天差地别。</p><p>本文总结了 <strong>35 种</strong>主流前端 UI 设计风格及其英文关键词、视觉特征和适用场景，帮你在 AI 编程时精准表达想要的效果。</p><hr><h2 id="一、玻璃与透明系"><a href="#一、玻璃与透明系" class="headerlink" title="一、玻璃与透明系"></a>一、玻璃与透明系</h2><h3 id="1-Glassmorphism（玻璃拟态）"><a href="#1-Glassmorphism（玻璃拟态）" class="headerlink" title="1. Glassmorphism（玻璃拟态）"></a>1. Glassmorphism（玻璃拟态）</h3><p><img src="/images/ui-styles/01-glassmorphism.jpg" alt="Glassmorphism 示例"><br><strong>关键词：</strong> <code>glassmorphism, frosted glass, backdrop-blur, translucent cards, glass UI</code></p><p><strong>视觉特征：</strong> 毛玻璃效果、半透明层叠、柔和边框、背景模糊</p><p><strong>提示词示例：</strong></p><blockquote><p>“Build a dashboard with glassmorphism style — frosted glass cards with backdrop-blur, translucent panels over a gradient background”</p></blockquote><p><strong>适用场景：</strong> Dashboard、卡片布局、SaaS 产品、Hero Section</p><h3 id="2-Frost-UI-x2F-Soft-Glass（霜冻风）"><a href="#2-Frost-UI-x2F-Soft-Glass（霜冻风）" class="headerlink" title="2. Frost UI &#x2F; Soft Glass（霜冻风）"></a>2. Frost UI &#x2F; Soft Glass（霜冻风）</h3><p><img src="/images/ui-styles/02-frost-ui.jpg" alt="Frost UI 示例"><br><strong>关键词：</strong> <code>frost UI, soft glass, subtle transparency, muted blur</code></p><p><strong>视觉特征：</strong> 比 Glassmorphism 更轻柔，低模糊度、中性色调、更克制</p><p><strong>提示词示例：</strong></p><blockquote><p>“Create a mobile-style settings page with frost UI — soft glass panels, low blur, neutral tones”</p></blockquote><p><strong>适用场景：</strong> 移动端 UI、高端应用、金融类产品</p><h3 id="3-Aurora-UI（极光风）"><a href="#3-Aurora-UI（极光风）" class="headerlink" title="3. Aurora UI（极光风）"></a>3. Aurora UI（极光风）</h3><p><img src="/images/ui-styles/03-aurora-ui.jpg" alt="Aurora UI 示例"><br><strong>关键词：</strong> <code>aurora background, gradient mesh, colorful blurred shapes, ambient glow</code></p><p><strong>视觉特征：</strong> 多彩渐变光晕、极光色背景、漂浮的模糊色块</p><p><strong>提示词示例：</strong></p><blockquote><p>“Design a landing page with aurora UI — colorful gradient mesh background, floating blurred shapes, white text overlays”</p></blockquote><p><strong>适用场景：</strong> 品牌官网、创意产品首页、发布会页面</p><hr><h2 id="二、立体与质感系"><a href="#二、立体与质感系" class="headerlink" title="二、立体与质感系"></a>二、立体与质感系</h2><h3 id="4-Neumorphism-x2F-Soft-UI（新拟态）"><a href="#4-Neumorphism-x2F-Soft-UI（新拟态）" class="headerlink" title="4. Neumorphism &#x2F; Soft UI（新拟态）"></a>4. Neumorphism &#x2F; Soft UI（新拟态）</h3><p><img src="/images/ui-styles/04-neumorphism.jpg" alt="Neumorphism 示例"><br><strong>关键词：</strong> <code>neumorphism, soft UI, inner shadow, extruded elements, soft 3D</code></p><p><strong>视觉特征：</strong> 柔和凸起&#x2F;凹陷感、双层阴影（亮+暗）、触感按钮</p><p><strong>提示词示例：</strong></p><blockquote><p>“Build a calculator app with neumorphism style — soft extruded buttons, inner shadows, monochrome palette”</p></blockquote><p><strong>适用场景：</strong> 工具类应用、按钮&#x2F;开关组件、极简 Dashboard</p><h3 id="5-Claymorphism（黏土风）"><a href="#5-Claymorphism（黏土风）" class="headerlink" title="5. Claymorphism（黏土风）"></a>5. Claymorphism（黏土风）</h3><p><img src="/images/ui-styles/05-claymorphism.jpg" alt="Claymorphism 示例"><br><strong>关键词：</strong> <code>claymorphism, clay UI, 3D cartoon, soft rounded, playful shadows</code></p><p><strong>视觉特征：</strong> 3D 卡通质感、厚重柔和阴影、圆润形状、明亮配色</p><p><strong>提示词示例：</strong></p><blockquote><p>“Create a pricing page with claymorphism — 3D clay-like cards, bright colors, thick soft shadows, playful and rounded”</p></blockquote><p><strong>适用场景：</strong> 儿童产品、创意作品集、趣味落地页</p><h3 id="6-Skeuomorphism（拟物化）"><a href="#6-Skeuomorphism（拟物化）" class="headerlink" title="6. Skeuomorphism（拟物化）"></a>6. Skeuomorphism（拟物化）</h3><p><img src="/images/ui-styles/06-skeuomorphism.jpg" alt="Skeuomorphism 示例"><br><strong>关键词：</strong> <code>skeuomorphic, realistic textures, leather, wood grain, physical metaphor</code></p><p><strong>视觉特征：</strong> 模拟真实材质（皮革、木纹、金属）、逼真光影</p><p><strong>提示词示例：</strong></p><blockquote><p>“Design a note-taking app with skeuomorphic style — leather texture background, realistic paper notepad, metal clasps”</p></blockquote><p><strong>适用场景：</strong> 经典iOS风应用、音乐&#x2F;音频软件、复古主题</p><hr><h2 id="三、极简与留白系"><a href="#三、极简与留白系" class="headerlink" title="三、极简与留白系"></a>三、极简与留白系</h2><h3 id="7-Minimalist-UI（极简风）"><a href="#7-Minimalist-UI（极简风）" class="headerlink" title="7. Minimalist UI（极简风）"></a>7. Minimalist UI（极简风）</h3><p><img src="/images/ui-styles/07-minimalist.jpg" alt="Minimalist UI 示例"><br><strong>关键词：</strong> <code>minimalist, clean UI, whitespace, simple typography, less is more</code></p><p><strong>视觉特征：</strong> 大量留白、细体字、去装饰化、极少视觉干扰</p><p><strong>提示词示例：</strong></p><blockquote><p>“Build a blog homepage with minimalist design — lots of whitespace, thin sans-serif typography, no decorative elements”</p></blockquote><p><strong>适用场景：</strong> 博客、银行&#x2F;金融应用、生产力工具</p><h3 id="8-Swiss-x2F-International-Style（瑞士风格）"><a href="#8-Swiss-x2F-International-Style（瑞士风格）" class="headerlink" title="8. Swiss &#x2F; International Style（瑞士风格）"></a>8. Swiss &#x2F; International Style（瑞士风格）</h3><p><img src="/images/ui-styles/08-swiss-design.jpg" alt="Swiss Design 示例"><br><strong>关键词：</strong> <code>swiss design, international typographic style, grid-based, Helvetica, clean layout</code></p><p><strong>视觉特征：</strong> 严格网格系统、无衬线字体、信息层次清晰、不对称排版</p><p><strong>提示词示例：</strong></p><blockquote><p>“Create a portfolio page in Swiss design style — strict grid layout, Helvetica typography, asymmetric composition, bold headings”</p></blockquote><p><strong>适用场景：</strong> 作品集、企业官网、信息展示</p><h3 id="9-Scandinavian-x2F-Nordic-UI（北欧风）"><a href="#9-Scandinavian-x2F-Nordic-UI（北欧风）" class="headerlink" title="9. Scandinavian &#x2F; Nordic UI（北欧风）"></a>9. Scandinavian &#x2F; Nordic UI（北欧风）</h3><p><img src="/images/ui-styles/09-scandinavian.jpg" alt="Scandinavian UI 示例"><br><strong>关键词：</strong> <code>scandinavian design, nordic UI, muted colors, warm neutrals, cozy minimal</code></p><p><strong>视觉特征：</strong> 柔和中性色（米色、灰白）、自然材质感、温暖极简</p><p><strong>提示词示例：</strong></p><blockquote><p>“Design an e-commerce page with Scandinavian style — warm neutral palette, soft shadows, rounded corners, cozy and clean”</p></blockquote><p><strong>适用场景：</strong> 生活方式品牌、电商、家居产品</p><hr><h2 id="四、大胆与张力系"><a href="#四、大胆与张力系" class="headerlink" title="四、大胆与张力系"></a>四、大胆与张力系</h2><h3 id="10-Neo-Brutalism（新野蛮主义）"><a href="#10-Neo-Brutalism（新野蛮主义）" class="headerlink" title="10. Neo-Brutalism（新野蛮主义）"></a>10. Neo-Brutalism（新野蛮主义）</h3><p><img src="/images/ui-styles/10-neo-brutalism.jpg" alt="Neo-Brutalism 示例"><br><strong>关键词：</strong> <code>neo-brutalism, bold borders, raw design, high contrast, thick outlines, no rounded corners</code></p><p><strong>视觉特征：</strong> 粗黑边框、强烈撞色、故意”粗糙”、无圆角、反精致</p><p><strong>提示词示例：</strong></p><blockquote><p>“Build a personal blog with neo-brutalism — thick black borders, bright clashing colors, raw typography, no border-radius”</p></blockquote><p><strong>适用场景：</strong> 个人作品集、创意机构、独立项目</p><h3 id="11-Memphis-Design（孟菲斯风格）"><a href="#11-Memphis-Design（孟菲斯风格）" class="headerlink" title="11. Memphis Design（孟菲斯风格）"></a>11. Memphis Design（孟菲斯风格）</h3><p><img src="/images/ui-styles/11-memphis.jpg" alt="Memphis Design 示例"><br><strong>关键词：</strong> <code>memphis design, geometric shapes, bold patterns, 80s retro, squiggles and dots</code></p><p><strong>视觉特征：</strong> 几何图形拼贴、波浪线和圆点、80年代复古色彩、反对称</p><p><strong>提示词示例：</strong></p><blockquote><p>“Create a fun event landing page with Memphis design — scattered geometric shapes, squiggles, bold primary colors, 80s vibe”</p></blockquote><p><strong>适用场景：</strong> 活动页面、创意品牌、年轻化产品</p><h3 id="12-Maximalist-UI（极繁风）"><a href="#12-Maximalist-UI（极繁风）" class="headerlink" title="12. Maximalist UI（极繁风）"></a>12. Maximalist UI（极繁风）</h3><p><img src="/images/ui-styles/12-maximalist.jpg" alt="Maximalist UI 示例"><br><strong>关键词：</strong> <code>maximalist, dense layout, rich visuals, layered elements, information-heavy</code></p><p><strong>视觉特征：</strong> 信息密集、多层叠加、丰富视觉元素、”更多即更好”</p><p><strong>提示词示例：</strong></p><blockquote><p>“Design a news portal with maximalist approach — dense grid, multiple columns, rich media, layered navigation”</p></blockquote><p><strong>适用场景：</strong> 新闻门户、社交媒体、内容聚合平台</p><hr><h2 id="五、暗色与科技系"><a href="#五、暗色与科技系" class="headerlink" title="五、暗色与科技系"></a>五、暗色与科技系</h2><h3 id="13-Dark-Mode-UI（暗色模式）"><a href="#13-Dark-Mode-UI（暗色模式）" class="headerlink" title="13. Dark Mode UI（暗色模式）"></a>13. Dark Mode UI（暗色模式）</h3><p><img src="/images/ui-styles/13-dark-mode.jpg" alt="Dark Mode UI 示例"><br><strong>关键词：</strong> <code>dark mode, dark theme, dark background, light text, reduced eye strain</code></p><p><strong>视觉特征：</strong> 深色背景（#121212）、亮色文字、柔和强调色</p><p><strong>提示词示例：</strong></p><blockquote><p>“Build a code editor dashboard in dark mode — #121212 background, syntax-highlighted code blocks, subtle borders”</p></blockquote><p><strong>适用场景：</strong> 开发工具、夜间模式、专业软件</p><h3 id="14-Cyberpunk-UI（赛博朋克）"><a href="#14-Cyberpunk-UI（赛博朋克）" class="headerlink" title="14. Cyberpunk UI（赛博朋克）"></a>14. Cyberpunk UI（赛博朋克）</h3><p><img src="/images/ui-styles/14-cyberpunk.jpg" alt="Cyberpunk UI 示例"><br><strong>关键词：</strong> <code>cyberpunk, neon glow, dark tech, futuristic HUD, sci-fi interface, glitch effect</code></p><p><strong>视觉特征：</strong> 霓虹灯光效、暗色基底、故障艺术、HUD 风格元素</p><p><strong>提示词示例：</strong></p><blockquote><p>“Create a futuristic dashboard with cyberpunk aesthetic — dark background, neon cyan and magenta accents, glitch effects, HUD-style data panels”</p></blockquote><p><strong>适用场景：</strong> 游戏界面、科技展示、概念Demo</p><h3 id="15-Terminal-x2F-Hacker-UI（终端风）"><a href="#15-Terminal-x2F-Hacker-UI（终端风）" class="headerlink" title="15. Terminal &#x2F; Hacker UI（终端风）"></a>15. Terminal &#x2F; Hacker UI（终端风）</h3><p><img src="/images/ui-styles/15-terminal.jpg" alt="Terminal UI 示例"><br><strong>关键词：</strong> <code>terminal UI, hacker aesthetic, monospace font, green-on-black, CLI style, matrix-like</code></p><p><strong>视觉特征：</strong> 等宽字体、黑底绿字、命令行风格、闪烁光标</p><p><strong>提示词示例：</strong></p><blockquote><p>“Build a portfolio that looks like a terminal — black background, green monospace text, blinking cursor, command-line navigation”</p></blockquote><p><strong>适用场景：</strong> 开发者个人站、技术博客、极客风格展示</p><h3 id="16-Sci-Fi-x2F-HUD-Interface（科幻HUD）"><a href="#16-Sci-Fi-x2F-HUD-Interface（科幻HUD）" class="headerlink" title="16. Sci-Fi &#x2F; HUD Interface（科幻HUD）"></a>16. Sci-Fi &#x2F; HUD Interface（科幻HUD）</h3><p><img src="/images/ui-styles/16-sci-fi-hud.jpg" alt="Sci-Fi HUD 示例"><br><strong>关键词：</strong> <code>sci-fi HUD, heads-up display, holographic UI, transparent overlays, futuristic gauges</code></p><p><strong>视觉特征：</strong> 全息投影感、透明叠层、圆形仪表盘、数据流动画</p><p><strong>提示词示例：</strong></p><blockquote><p>“Design a monitoring dashboard with sci-fi HUD style — circular gauges, holographic overlays, data streams, blue-tinted interface”</p></blockquote><p><strong>适用场景：</strong> 数据监控、IoT 面板、演示&#x2F;展会屏幕</p><hr><h2 id="六、复古与怀旧系"><a href="#六、复古与怀旧系" class="headerlink" title="六、复古与怀旧系"></a>六、复古与怀旧系</h2><h3 id="17-Retro-x2F-Vintage（复古风）"><a href="#17-Retro-x2F-Vintage（复古风）" class="headerlink" title="17. Retro &#x2F; Vintage（复古风）"></a>17. Retro &#x2F; Vintage（复古风）</h3><p><img src="/images/ui-styles/17-retro-vintage.jpg" alt="Retro/Vintage 示例"><br><strong>关键词：</strong> <code>retro design, vintage UI, old-school web, muted earth tones, paper texture</code></p><p><strong>视觉特征：</strong> 旧报纸&#x2F;海报风、做旧纹理、复古配色（棕&#x2F;米&#x2F;墨绿）</p><p><strong>提示词示例：</strong></p><blockquote><p>“Create a restaurant website with vintage style — paper texture background, serif fonts, muted earth tones, hand-drawn illustrations”</p></blockquote><p><strong>适用场景：</strong> 餐饮、手工品牌、文艺社区</p><h3 id="18-Pixel-Art-x2F-8-bit（像素风）"><a href="#18-Pixel-Art-x2F-8-bit（像素风）" class="headerlink" title="18. Pixel Art &#x2F; 8-bit（像素风）"></a>18. Pixel Art &#x2F; 8-bit（像素风）</h3><p><img src="/images/ui-styles/18-pixel-art.jpg" alt="Pixel Art 示例"><br><strong>关键词：</strong> <code>pixel art UI, 8-bit style, retro gaming, pixelated icons, chiptune aesthetic</code></p><p><strong>视觉特征：</strong> 像素化图标和字体、低分辨率质感、游戏机配色</p><p><strong>提示词示例：</strong></p><blockquote><p>“Build a personal homepage in pixel art style — 8-bit character avatar, pixelated navigation buttons, retro game color palette”</p></blockquote><p><strong>适用场景：</strong> 游戏相关网站、个人趣味主页、怀旧社区</p><h3 id="19-Vaporwave-x2F-Synthwave（蒸汽波）"><a href="#19-Vaporwave-x2F-Synthwave（蒸汽波）" class="headerlink" title="19. Vaporwave &#x2F; Synthwave（蒸汽波）"></a>19. Vaporwave &#x2F; Synthwave（蒸汽波）</h3><p><img src="/images/ui-styles/19-vaporwave.jpg" alt="Vaporwave 示例"><br><strong>关键词：</strong> <code>vaporwave, synthwave, retrowave, purple gradient, 80s neon, grid perspective</code></p><p><strong>视觉特征：</strong> 紫粉渐变、透视网格线、80年代霓虹、日落天空、古典雕塑</p><p><strong>提示词示例：</strong></p><blockquote><p>“Design a music streaming page with vaporwave aesthetic — pink-purple gradients, perspective grid, neon sunset, retro Japanese text accents”</p></blockquote><p><strong>适用场景：</strong> 音乐平台、创意展示、个人博客</p><h3 id="20-Y2K-Aesthetic（千禧风）"><a href="#20-Y2K-Aesthetic（千禧风）" class="headerlink" title="20. Y2K Aesthetic（千禧风）"></a>20. Y2K Aesthetic（千禧风）</h3><p><img src="/images/ui-styles/20-y2k.jpg" alt="Y2K Aesthetic 示例"><br><strong>关键词：</strong> <code>Y2K design, early 2000s web, bubble fonts, chrome effects, iridescent, futuristic retro</code></p><p><strong>视觉特征：</strong> 气泡字体、金属光泽、虹彩效果、太空&#x2F;未来复古</p><p><strong>提示词示例：</strong></p><blockquote><p>“Create a fashion brand page with Y2K aesthetic — chrome text effects, iridescent gradients, bubble typography, early 2000s vibes”</p></blockquote><p><strong>适用场景：</strong> 时尚品牌、潮流文化、社交媒体</p><hr><h2 id="七、卡片与布局系"><a href="#七、卡片与布局系" class="headerlink" title="七、卡片与布局系"></a>七、卡片与布局系</h2><h3 id="21-Bento-Grid（便当盒布局）"><a href="#21-Bento-Grid（便当盒布局）" class="headerlink" title="21. Bento Grid（便当盒布局）"></a>21. Bento Grid（便当盒布局）</h3><p><img src="/images/ui-styles/21-bento-grid.jpg" alt="Bento Grid 示例"><br><strong>关键词：</strong> <code>bento grid, bento box layout, modular grid, asymmetric cards, Apple-style grid</code></p><p><strong>视觉特征：</strong> 大小不一的卡片网格（如苹果发布会风格）、模块化、呼吸感</p><p><strong>提示词示例：</strong></p><blockquote><p>“Build a product feature page with bento grid layout — asymmetric card sizes, rounded corners, clean icons in each cell, Apple keynote style”</p></blockquote><p><strong>适用场景：</strong> 产品特性展示、个人简介、公司官网</p><h3 id="22-Card-based-UI（卡片式布局）"><a href="#22-Card-based-UI（卡片式布局）" class="headerlink" title="22. Card-based UI（卡片式布局）"></a>22. Card-based UI（卡片式布局）</h3><p><img src="/images/ui-styles/22-card-based.jpg" alt="Card-based UI 示例"><br><strong>关键词：</strong> <code>card-based layout, material cards, content cards, grid of cards</code></p><p><strong>视觉特征：</strong> 统一尺寸卡片、轻微阴影、规整网格排列</p><p><strong>提示词示例：</strong></p><blockquote><p>“Design a news aggregator with card-based UI — uniform cards with thumbnail, title, and metadata, subtle shadows, responsive grid”</p></blockquote><p><strong>适用场景：</strong> 新闻聚合、电商产品列表、社交 Feed</p><h3 id="23-Magazine-Layout（杂志排版）"><a href="#23-Magazine-Layout（杂志排版）" class="headerlink" title="23. Magazine Layout（杂志排版）"></a>23. Magazine Layout（杂志排版）</h3><p><img src="/images/ui-styles/23-magazine.jpg" alt="Magazine Layout 示例"><br><strong>关键词：</strong> <code>magazine layout, editorial design, multi-column, large typography, feature article</code></p><p><strong>视觉特征：</strong> 多栏排版、大标题、图文混排、杂志感版面</p><p><strong>提示词示例：</strong></p><blockquote><p>“Create a long-form article page with magazine layout — large hero image, drop cap, multi-column text, pull quotes, editorial typography”</p></blockquote><p><strong>适用场景：</strong> 媒体网站、长文博客、品牌故事</p><hr><h2 id="八、数据与专业系"><a href="#八、数据与专业系" class="headerlink" title="八、数据与专业系"></a>八、数据与专业系</h2><h3 id="24-Data-dense-Dashboard（数据密集型面板）"><a href="#24-Data-dense-Dashboard（数据密集型面板）" class="headerlink" title="24. Data-dense Dashboard（数据密集型面板）"></a>24. Data-dense Dashboard（数据密集型面板）</h3><p><img src="/images/ui-styles/24-dashboard.jpg" alt="Data Dashboard 示例"><br><strong>关键词：</strong> <code>data dashboard, analytics panel, KPI metrics, charts and graphs, data visualization</code></p><p><strong>视觉特征：</strong> 多图表并列、KPI 卡片、深色背景、数据可视化组件</p><p><strong>提示词示例：</strong></p><blockquote><p>“Build an analytics dashboard — dark theme, KPI cards at top, line charts, bar charts, data tables, sidebar navigation, real-time feel”</p></blockquote><p><strong>适用场景：</strong> 商业智能、运营监控、数据分析平台</p><h3 id="25-Admin-Panel-x2F-Back-office（后台管理）"><a href="#25-Admin-Panel-x2F-Back-office（后台管理）" class="headerlink" title="25. Admin Panel &#x2F; Back-office（后台管理）"></a>25. Admin Panel &#x2F; Back-office（后台管理）</h3><p><img src="/images/ui-styles/25-admin-panel.jpg" alt="Admin Panel 示例"><br><strong>关键词：</strong> <code>admin panel, back-office UI, CRUD interface, sidebar navigation, data tables</code></p><p><strong>视觉特征：</strong> 左侧菜单栏、面包屑导航、数据表格、表单编辑</p><p><strong>提示词示例：</strong></p><blockquote><p>“Create an admin panel with sidebar navigation, breadcrumbs, searchable data tables, and modal forms for CRUD operations”</p></blockquote><p><strong>适用场景：</strong> CMS、ERP、内部管理系统</p><h3 id="26-SaaS-Landing-Page（SaaS-产品首页）"><a href="#26-SaaS-Landing-Page（SaaS-产品首页）" class="headerlink" title="26. SaaS Landing Page（SaaS 产品首页）"></a>26. SaaS Landing Page（SaaS 产品首页）</h3><p><img src="/images/ui-styles/26-saas-landing.jpg" alt="SaaS Landing Page 示例"><br><strong>关键词：</strong> <code>SaaS landing page, hero section, feature grid, pricing table, CTA buttons, social proof</code></p><p><strong>视觉特征：</strong> Hero 区 + 特性展示 + 定价表 + 客户 Logo + CTA 按钮</p><p><strong>提示词示例：</strong></p><blockquote><p>“Design a modern SaaS landing page — bold hero with headline and CTA, feature grid with icons, pricing cards, testimonials section, gradient accents”</p></blockquote><p><strong>适用场景：</strong> 软件产品官网、创业项目、B2B 服务</p><hr><h2 id="九、动态与交互系"><a href="#九、动态与交互系" class="headerlink" title="九、动态与交互系"></a>九、动态与交互系</h2><h3 id="27-Micro-interaction-Rich（微交互丰富型）"><a href="#27-Micro-interaction-Rich（微交互丰富型）" class="headerlink" title="27. Micro-interaction Rich（微交互丰富型）"></a>27. Micro-interaction Rich（微交互丰富型）</h3><p><img src="/images/ui-styles/27-micro-interaction.jpg" alt="Micro-interaction 示例"><br><strong>关键词：</strong> <code>micro-interactions, hover effects, animated transitions, interactive feedback, motion UI</code></p><p><strong>视觉特征：</strong> 悬停动效、点击反馈、平滑过渡、加载动画</p><p><strong>提示词示例：</strong></p><blockquote><p>“Build a portfolio with rich micro-interactions — hover reveals, smooth page transitions, animated skill bars, interactive project cards”</p></blockquote><p><strong>适用场景：</strong> 个人作品集、互动体验、品牌展示</p><h3 id="28-Scroll-driven-x2F-Storytelling（滚动叙事）"><a href="#28-Scroll-driven-x2F-Storytelling（滚动叙事）" class="headerlink" title="28. Scroll-driven &#x2F; Storytelling（滚动叙事）"></a>28. Scroll-driven &#x2F; Storytelling（滚动叙事）</h3><p><img src="/images/ui-styles/28-scroll-driven.jpg" alt="Scroll-driven 示例"><br><strong>关键词：</strong> <code>scroll-driven animation, parallax scrolling, storytelling layout, scroll-triggered, one-page narrative</code></p><p><strong>视觉特征：</strong> 滚动触发动画、视差效果、线性叙事、全屏分段</p><p><strong>提示词示例：</strong></p><blockquote><p>“Create a brand story page with scroll-driven animations — parallax hero, content reveals on scroll, full-screen sections, narrative flow”</p></blockquote><p><strong>适用场景：</strong> 品牌故事、产品发布、年度报告</p><h3 id="29-3D-x2F-Immersive-Web（3D沉浸式）"><a href="#29-3D-x2F-Immersive-Web（3D沉浸式）" class="headerlink" title="29. 3D &#x2F; Immersive Web（3D沉浸式）"></a>29. 3D &#x2F; Immersive Web（3D沉浸式）</h3><p><img src="/images/ui-styles/29-3d-immersive.jpg" alt="3D Immersive 示例"><br><strong>关键词：</strong> <code>3D web, Three.js, WebGL, immersive experience, 3D product viewer, spatial UI</code></p><p><strong>视觉特征：</strong> 3D 模型展示、空间交互、沉浸式体验</p><p><strong>提示词示例：</strong></p><blockquote><p>“Design a product showcase with 3D immersive elements — rotating 3D model viewer, spatial depth, interactive camera angles”</p></blockquote><p><strong>适用场景：</strong> 产品展示、虚拟展厅、游戏官网</p><hr><h2 id="十、特殊风格系"><a href="#十、特殊风格系" class="headerlink" title="十、特殊风格系"></a>十、特殊风格系</h2><h3 id="30-Notion-like-x2F-Block-Editor（Notion风）"><a href="#30-Notion-like-x2F-Block-Editor（Notion风）" class="headerlink" title="30. Notion-like &#x2F; Block Editor（Notion风）"></a>30. Notion-like &#x2F; Block Editor（Notion风）</h3><p><img src="/images/ui-styles/30-notion-like.jpg" alt="Notion-like 示例"><br><strong>关键词：</strong> <code>notion-style, block editor UI, inline editing, slash commands, clean document view</code></p><p><strong>视觉特征：</strong> 块编辑器、行内编辑、斜杠命令、简洁文档视图</p><p><strong>提示词示例：</strong></p><blockquote><p>“Build a knowledge base app with Notion-like UI — block-based editor, slash command menu, clean serif headings, toggle sections”</p></blockquote><p><strong>适用场景：</strong> 笔记应用、知识库、文档协作工具</p><h3 id="31-Figma-x2F-Design-Tool-UI（设计工具风）"><a href="#31-Figma-x2F-Design-Tool-UI（设计工具风）" class="headerlink" title="31. Figma &#x2F; Design Tool UI（设计工具风）"></a>31. Figma &#x2F; Design Tool UI（设计工具风）</h3><p><img src="/images/ui-styles/31-figma-ui.jpg" alt="Figma UI 示例"><br><strong>关键词：</strong> <code>design tool UI, canvas interface, floating panels, toolbar, properties panel, infinite canvas</code></p><p><strong>视觉特征：</strong> 无限画布、浮动面板、顶部工具栏、右侧属性栏</p><p><strong>提示词示例：</strong></p><blockquote><p>“Create a whiteboard app with design tool UI — infinite canvas, floating toolbar, right-side properties panel, zoom controls”</p></blockquote><p><strong>适用场景：</strong> 在线设计工具、白板应用、流程图编辑器</p><h3 id="32-E-ink-x2F-Paper-like（电子墨水风）"><a href="#32-E-ink-x2F-Paper-like（电子墨水风）" class="headerlink" title="32. E-ink &#x2F; Paper-like（电子墨水风）"></a>32. E-ink &#x2F; Paper-like（电子墨水风）</h3><p><img src="/images/ui-styles/32-eink.jpg" alt="E-ink 示例"><br><strong>关键词：</strong> <code>e-ink style, paper-like UI, low contrast, reading-optimized, book layout, serif typography</code></p><p><strong>视觉特征：</strong> 低对比度、纸张质感、衬线字体、阅读优化</p><p><strong>提示词示例：</strong></p><blockquote><p>“Design a reading app with e-ink aesthetic — paper-white background, low contrast, comfortable serif font, no decorations, focus on text”</p></blockquote><p><strong>适用场景：</strong> 阅读器、文档查看、学术论文</p><h3 id="33-Gradient-Mesh-x2F-Liquid（渐变流体）"><a href="#33-Gradient-Mesh-x2F-Liquid（渐变流体）" class="headerlink" title="33. Gradient Mesh &#x2F; Liquid（渐变流体）"></a>33. Gradient Mesh &#x2F; Liquid（渐变流体）</h3><p><img src="/images/ui-styles/33-gradient-mesh.jpg" alt="Gradient Mesh 示例"><br><strong>关键词：</strong> <code>gradient mesh, liquid design, fluid shapes, organic blobs, flowing gradients</code></p><p><strong>视觉特征：</strong> 流体形状、有机色块、柔和渐变过渡</p><p><strong>提示词示例：</strong></p><blockquote><p>“Build a creative agency homepage with liquid design — flowing gradient blobs, organic shapes, smooth color transitions, modern sans-serif”</p></blockquote><p><strong>适用场景：</strong> 创意机构、艺术展示、音乐平台</p><h3 id="34-Monochrome-x2F-Grayscale（单色风）"><a href="#34-Monochrome-x2F-Grayscale（单色风）" class="headerlink" title="34. Monochrome &#x2F; Grayscale（单色风）"></a>34. Monochrome &#x2F; Grayscale（单色风）</h3><p><img src="/images/ui-styles/34-monochrome.jpg" alt="Monochrome 示例"><br><strong>关键词：</strong> <code>monochrome design, grayscale UI, black and white, single accent color</code></p><p><strong>视觉特征：</strong> 黑白灰为主、至多一个强调色、高级感</p><p><strong>提示词示例：</strong></p><blockquote><p>“Create a photography portfolio in monochrome — all grayscale layout, single red accent for CTAs, large image grids, minimal text”</p></blockquote><p><strong>适用场景：</strong> 摄影作品集、奢侈品牌、高端产品</p><h3 id="35-Japandi-x2F-Wabi-sabi（日式侘寂风）"><a href="#35-Japandi-x2F-Wabi-sabi（日式侘寂风）" class="headerlink" title="35. Japandi &#x2F; Wabi-sabi（日式侘寂风）"></a>35. Japandi &#x2F; Wabi-sabi（日式侘寂风）</h3><p><img src="/images/ui-styles/35-japandi.jpg" alt="Japandi 示例"><br><strong>关键词：</strong> <code>japandi design, wabi-sabi, natural textures, imperfect beauty, zen aesthetic, earth tones</code></p><p><strong>视觉特征：</strong> 自然材质、不完美之美、禅意留白、大地色系</p><p><strong>提示词示例：</strong></p><blockquote><p>“Design a tea shop website with Japandi aesthetic — natural wood textures, earth tones, asymmetric layout, zen-like whitespace, organic shapes”</p></blockquote><p><strong>适用场景：</strong> 生活方式品牌、茶&#x2F;咖啡、家居设计</p><hr><h2 id="速查表：风格-×-场景匹配"><a href="#速查表：风格-×-场景匹配" class="headerlink" title="速查表：风格 × 场景匹配"></a>速查表：风格 × 场景匹配</h2><table><thead><tr><th>你要做什么</th><th>推荐风格</th><th>关键词</th></tr></thead><tbody><tr><td>数据大屏</td><td>Cyberpunk &#x2F; HUD &#x2F; Dark Dashboard</td><td><code>dark theme, neon accents, HUD gauges</code></td></tr><tr><td>SaaS 官网</td><td>Minimalist + Gradient</td><td><code>clean hero, feature grid, CTA buttons</code></td></tr><tr><td>个人博客</td><td>Neo-Brutalism &#x2F; E-ink &#x2F; Minimalist</td><td><code>bold borders</code> 或 <code>paper-like reading</code></td></tr><tr><td>后台管理</td><td>Admin Panel</td><td><code>sidebar nav, data tables, CRUD forms</code></td></tr><tr><td>产品展示</td><td>Bento Grid &#x2F; 3D Immersive</td><td><code>bento layout, 3D viewer</code></td></tr><tr><td>创意作品集</td><td>Vaporwave &#x2F; Memphis &#x2F; Maximalist</td><td><code>retro neon, geometric shapes</code></td></tr><tr><td>移动端应用</td><td>Glassmorphism &#x2F; Frost UI</td><td><code>frosted glass, backdrop-blur</code></td></tr><tr><td>电商页面</td><td>Card-based &#x2F; Scandinavian</td><td><code>product cards, warm neutrals</code></td></tr><tr><td>文档&#x2F;笔记</td><td>Notion-like &#x2F; E-ink</td><td><code>block editor, clean document</code></td></tr><tr><td>游戏相关</td><td>Pixel Art &#x2F; Cyberpunk</td><td><code>8-bit style, neon glow</code></td></tr></tbody></table><hr><h2 id="提示词组合公式"><a href="#提示词组合公式" class="headerlink" title="提示词组合公式"></a>提示词组合公式</h2><p>生成前端页面时，可以用这个公式组合提示词：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs css">Build <span class="hljs-selector-tag">a</span> <span class="hljs-selector-attr">[页面类型]</span> with <span class="hljs-selector-attr">[风格名]</span> style —<br><span class="hljs-selector-attr">[特征1]</span>, <span class="hljs-selector-attr">[特征2]</span>, <span class="hljs-selector-attr">[特征3]</span>,<br><span class="hljs-selector-attr">[配色方案]</span>, <span class="hljs-selector-attr">[字体风格]</span><br></code></pre></td></tr></table></figure><p><strong>示例：</strong></p><blockquote><p>“Build a <strong>SaaS dashboard</strong> with <strong>glassmorphism</strong> style — frosted glass cards, backdrop-blur panels, dark gradient background, blue accent color, Inter font family, responsive sidebar navigation”</p></blockquote><p>风格可以混搭！比如 <code>glassmorphism + dark mode + data dashboard</code> 就是一个很常见的高端组合。</p><hr><hr><h2 id="风格总览"><a href="#风格总览" class="headerlink" title="风格总览"></a>风格总览</h2><p>一图看完 35 种前端 UI 设计风格：</p><p><img src="/images/ui-styles/overview-all-styles.jpg" alt="35种UI设计风格总览"></p><hr><h2 id="十一、颜色与配色提示词"><a href="#十一、颜色与配色提示词" class="headerlink" title="十一、颜色与配色提示词"></a>十一、颜色与配色提示词</h2><p>光有风格不够，<strong>颜色描述</strong>决定了页面的最终调性。以下是 AI 前端生成中最实用的颜色关键词体系。</p><h3 id="基础色调描述"><a href="#基础色调描述" class="headerlink" title="基础色调描述"></a>基础色调描述</h3><table><thead><tr><th>英文关键词</th><th>含义</th><th>适用场景</th></tr></thead><tbody><tr><td><code>warm tones</code></td><td>暖色调（红&#x2F;橙&#x2F;黄）</td><td>餐饮、社交、活力品牌</td></tr><tr><td><code>cool tones</code></td><td>冷色调（蓝&#x2F;青&#x2F;紫）</td><td>科技、金融、医疗</td></tr><tr><td><code>neutral palette</code></td><td>中性色板（灰&#x2F;米&#x2F;棕）</td><td>企业官网、极简风</td></tr><tr><td><code>earth tones</code></td><td>大地色系（棕&#x2F;绿&#x2F;米）</td><td>环保、咖啡、家居</td></tr><tr><td><code>pastel colors</code></td><td>粉彩色&#x2F;马卡龙色</td><td>母婴、甜品、轻量应用</td></tr><tr><td><code>muted colors</code></td><td>灰调&#x2F;低饱和度色</td><td>高端品牌、北欧风</td></tr><tr><td><code>vibrant / saturated</code></td><td>高饱和度鲜艳色</td><td>年轻品牌、娱乐、游戏</td></tr><tr><td><code>monochrome</code></td><td>单色系</td><td>摄影、奢侈品、极简</td></tr><tr><td><code>jewel tones</code></td><td>宝石色（翡翠绿&#x2F;宝石蓝&#x2F;红宝石）</td><td>奢华品牌、高端产品</td></tr><tr><td><code>neon colors</code></td><td>霓虹色</td><td>夜店、电竞、赛博朋克</td></tr></tbody></table><h3 id="渐变与色彩效果"><a href="#渐变与色彩效果" class="headerlink" title="渐变与色彩效果"></a>渐变与色彩效果</h3><table><thead><tr><th>英文关键词</th><th>描述</th></tr></thead><tbody><tr><td><code>linear gradient from A to B</code></td><td>从A色到B色的线性渐变</td></tr><tr><td><code>radial gradient</code></td><td>径向渐变（中心向外）</td></tr><tr><td><code>gradient mesh</code></td><td>网格渐变（多点混合）</td></tr><tr><td><code>duotone</code></td><td>双色调（两种颜色叠加）</td></tr><tr><td><code>tricolor scheme</code></td><td>三色配色方案</td></tr><tr><td><code>iridescent / holographic</code></td><td>虹彩&#x2F;全息效果</td></tr><tr><td><code>aurora gradient</code></td><td>极光渐变</td></tr><tr><td><code>sunset gradient</code></td><td>日落渐变（橙→粉→紫）</td></tr><tr><td><code>ocean gradient</code></td><td>海洋渐变（深蓝→青→浅蓝）</td></tr><tr><td><code>frosted overlay</code></td><td>毛玻璃叠加层</td></tr></tbody></table><h3 id="经典配色方案关键词"><a href="#经典配色方案关键词" class="headerlink" title="经典配色方案关键词"></a>经典配色方案关键词</h3><table><thead><tr><th>配色方案</th><th>英文描述</th><th>色值参考</th></tr></thead><tbody><tr><td>科技蓝</td><td><code>tech blue, #2563EB accent, slate gray background</code></td><td>蓝+灰</td></tr><tr><td>暗夜紫</td><td><code>deep purple and indigo, dark violet theme</code></td><td>紫+靛</td></tr><tr><td>森林绿</td><td><code>forest green, emerald accent, dark green palette</code></td><td>绿+深绿</td></tr><tr><td>珊瑚粉</td><td><code>coral pink, soft rose, warm blush tones</code></td><td>粉+珊瑚</td></tr><tr><td>黑金</td><td><code>black and gold, luxury dark theme, gold accents on black</code></td><td>黑+金</td></tr><tr><td>红白</td><td><code>red and white, bold crimson on clean white</code></td><td>红+白</td></tr><tr><td>蓝橙撞色</td><td><code>complementary blue-orange, electric blue with warm orange</code></td><td>蓝+橙</td></tr><tr><td>灰白极简</td><td><code>off-white and light gray, paper-like neutral tones</code></td><td>灰+白</td></tr><tr><td>深色科技</td><td><code>#0F172A background, cyan-400 accent, dark slate</code></td><td>深蓝+青</td></tr><tr><td>奶茶色</td><td><code>cream and caramel, latte palette, warm beige tones</code></td><td>米+棕</td></tr></tbody></table><h3 id="颜色修饰词（让描述更精准）"><a href="#颜色修饰词（让描述更精准）" class="headerlink" title="颜色修饰词（让描述更精准）"></a>颜色修饰词（让描述更精准）</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs awk">亮度：bright <span class="hljs-regexp">/ light /</span> dark <span class="hljs-regexp">/ deep /</span> pale / faint<br>饱和度：vivid <span class="hljs-regexp">/ saturated /</span> muted <span class="hljs-regexp">/ desaturated /</span> washed-out<br>温度：warm <span class="hljs-regexp">/ cool /</span> icy <span class="hljs-regexp">/ fiery /</span> sunny<br>质感：metallic <span class="hljs-regexp">/ glossy /</span> matte <span class="hljs-regexp">/ satin /</span> frosted<br>透明度：transparent <span class="hljs-regexp">/ translucent /</span> opaque / semi-transparent<br></code></pre></td></tr></table></figure><p><strong>组合示例：</strong></p><ul><li><code>muted warm beige</code> — 低饱和暖米色</li><li><code>deep saturated indigo</code> — 深饱和靛蓝</li><li><code>pale frosted lilac</code> — 浅霜丁香紫</li><li><code>bright metallic gold</code> — 明亮金属金</li></ul><hr><h2 id="十二、高级组合提示词模板"><a href="#十二、高级组合提示词模板" class="headerlink" title="十二、高级组合提示词模板"></a>十二、高级组合提示词模板</h2><p>当你需要更精确的效果，可以用以下复合提示词模板：</p><h3 id="模板-1：风格-配色-布局"><a href="#模板-1：风格-配色-布局" class="headerlink" title="模板 1：风格 + 配色 + 布局"></a>模板 1：风格 + 配色 + 布局</h3><blockquote><p>“Build a <strong>fintech dashboard</strong> with <strong>glassmorphism</strong> style and <strong>dark slate blue</strong> color scheme — <code>#0F172A</code> background, frosted glass cards with <code>backdrop-blur(16px)</code>, <strong>cyan-400</strong> accent color for charts, <strong>Inter</strong> font family, sidebar navigation with <code>rgba(255,255,255,0.05)</code> hover states”</p></blockquote><h3 id="模板-2：多风格混搭"><a href="#模板-2：多风格混搭" class="headerlink" title="模板 2：多风格混搭"></a>模板 2：多风格混搭</h3><blockquote><p>“Create a <strong>portfolio page</strong> combining <strong>neo-brutalism</strong> structure with <strong>monochrome</strong> palette — thick 3px black borders, <strong>off-white (#FAFAFA)</strong> background, single <strong>electric red (#FF3B30)</strong> accent for CTAs, bold sans-serif headings, asymmetric grid layout, no border-radius”</p></blockquote><h3 id="模板-3：氛围-细节"><a href="#模板-3：氛围-细节" class="headerlink" title="模板 3：氛围 + 细节"></a>模板 3：氛围 + 细节</h3><blockquote><p>“Design a <strong>meditation app</strong> landing page with <strong>Japandi</strong> aesthetic and <strong>muted earth tones</strong> — warm beige <code>#F5F0EB</code> background, charcoal <code>#2D2D2D</code> text, sage green <code>#A8B5A2</code> accent, generous whitespace, organic rounded shapes, subtle paper texture overlay, <code>Noto Serif</code> for headings, <code>Inter</code> for body”</p></blockquote><h3 id="模板-4：数据面板-科技风"><a href="#模板-4：数据面板-科技风" class="headerlink" title="模板 4：数据面板 + 科技风"></a>模板 4：数据面板 + 科技风</h3><blockquote><p>“Build a <strong>real-time monitoring dashboard</strong> with <strong>cyberpunk</strong> aesthetic and <strong>neon-on-dark</strong> color scheme — <code>#0A0A0A</code> deep black background, <strong>neon cyan <code>#00FFE5</code></strong> for primary data, <strong>neon magenta <code>#FF00FF</code></strong> for alerts, <strong>amber <code>#FFB800</code></strong> for warnings, glowing box-shadows, monospace font for numbers, animated data tickers, HUD-style circular gauges”</p></blockquote><h3 id="模板-5：电商-品牌感"><a href="#模板-5：电商-品牌感" class="headerlink" title="模板 5：电商 + 品牌感"></a>模板 5：电商 + 品牌感</h3><blockquote><p>“Create a <strong>luxury e-commerce</strong> product page with <strong>minimalist</strong> layout and <strong>black-gold</strong> palette — pure white background, product images with soft shadow, <strong>matte black <code>#1A1A1A</code></strong> text, <strong>champagne gold <code>#C9A96E</code></strong> for CTAs and price tags, thin serif headings (<code>Playfair Display</code>), generous padding, subtle hover animations on product cards”</p></blockquote><h3 id="模板-6：完整页面规格"><a href="#模板-6：完整页面规格" class="headerlink" title="模板 6：完整页面规格"></a>模板 6：完整页面规格</h3><blockquote><p>“Build a complete <strong>SaaS landing page</strong>:</p><ul><li><strong>Style:</strong> clean minimalist with glassmorphism cards</li><li><strong>Colors:</strong> <code>#FFFFFF</code> background, <code>#1E293B</code> text, <code>#6366F1</code> (indigo) primary, <code>#EC4899</code> (pink) secondary accent</li><li><strong>Typography:</strong> <code>Inter</code> 16px body, <code>Plus Jakarta Sans</code> bold headings</li><li><strong>Layout:</strong> centered max-width 1200px, hero with gradient mesh background, 3-column feature grid, pricing table with highlighted popular plan, testimonial carousel, footer with 4-column links</li><li><strong>Effects:</strong> subtle card hover lift (<code>translateY(-4px)</code>), smooth scroll, <code>backdrop-blur</code> on navbar”</li></ul></blockquote><hr><h2 id="提示词精度等级"><a href="#提示词精度等级" class="headerlink" title="提示词精度等级"></a>提示词精度等级</h2><table><thead><tr><th>等级</th><th>描述</th><th>示例</th></tr></thead><tbody><tr><td>⭐ 基础</td><td>只说风格名</td><td>“Make a glassmorphism dashboard”</td></tr><tr><td>⭐⭐ 进阶</td><td>风格 + 配色</td><td>“Glassmorphism dashboard with dark blue theme”</td></tr><tr><td>⭐⭐⭐ 精准</td><td>风格 + 具体色值 + 字体</td><td>“Glassmorphism, #0F172A bg, cyan-400 accent, Inter font”</td></tr><tr><td>⭐⭐⭐⭐ 专业</td><td>完整设计规格</td><td>上面模板 6 的写法</td></tr></tbody></table><p><strong>越精确的提示词 &#x3D; 越少的来回修改。</strong> 当你对效果有明确预期时，直接给色值和字体名比用形容词更有效。</p><hr><p><em>本文持续更新，欢迎补充更多 UI 风格关键词和配色方案。掌握这些关键词，让 AI 生成的前端页面不再千篇一律。</em></p>]]></content>
    
    
    <categories>
      
      <category>技术实战</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>前端</tag>
      
      <tag>提示词</tag>
      
      <tag>UI设计</tag>
      
      <tag>Prompt Engineering</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2月15日科技早报：OpenAI 联手 Cerebras 抛弃 Nvidia、16个 Claude 写出 C 编译器</title>
    <link href="/2026/02/15/2026-02-15-morning-news/"/>
    <url>/2026/02/15/2026-02-15-morning-news/</url>
    
    <content type="html"><![CDATA[<blockquote><p>每日科技要闻精选，一杯咖啡的时间掌握全球科技动态。今日重点关注 OpenAI 的硬件战略转向，以及 AI 多智能体协作的惊人表现。</p></blockquote><h2 id="科技日报精选"><a href="#科技日报精选" class="headerlink" title="科技日报精选"></a>科技日报精选</h2><h3 id="1-OpenAI-绕开-Nvidia，在-Cerebras-晶圆级芯片上推出超快编码模型"><a href="#1-OpenAI-绕开-Nvidia，在-Cerebras-晶圆级芯片上推出超快编码模型" class="headerlink" title="1. OpenAI 绕开 Nvidia，在 Cerebras 晶圆级芯片上推出超快编码模型"></a>1. OpenAI 绕开 Nvidia，在 Cerebras 晶圆级芯片上推出超快编码模型</h3><p>来源：Ars Technica | 100 评论</p><p>OpenAI 发布 GPT-5.3-Codex-Spark，运行在 Cerebras 的晶圆级引擎 3（餐盘大小的芯片）上，编码速度比前代快 15 倍，达到约 1000 token&#x2F;秒。这标志着 OpenAI 开始在推理硬件上摆脱对 Nvidia 的依赖，与 Cerebras 建立深度合作关系。</p><p><a href="https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/">https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/</a></p><h3 id="2-16-个-Claude-AI-Agent-协作从零构建-C-编译器"><a href="#2-16-个-Claude-AI-Agent-协作从零构建-C-编译器" class="headerlink" title="2. 16 个 Claude AI Agent 协作从零构建 C 编译器"></a>2. 16 个 Claude AI Agent 协作从零构建 C 编译器</h3><p>来源：Ars Technica | 222 评论</p><p>Anthropic 研究员 Nicholas Carlini 让 16 个 Claude Opus 4.6 实例在共享代码库上自主协作，花费两周和约 2 万美元 API 费用，产出了一个 10 万行 Rust 代码的 C 编译器。该编译器能编译 Linux 6.9 内核（x86&#x2F;ARM&#x2F;RISC-V），还能编译 PostgreSQL、Redis、FFmpeg 等项目，GCC 测试套件通过率 99%，甚至能编译并运行 Doom。</p><p><a href="https://arstechnica.com/ai/2026/02/sixteen-claude-ai-agents-working-together-created-a-new-c-compiler/">https://arstechnica.com/ai/2026/02/sixteen-claude-ai-agents-working-together-created-a-new-c-compiler/</a></p><h3 id="3-Vim-9-2-发布：Wayland-支持、XDG-规范、模糊补全"><a href="#3-Vim-9-2-发布：Wayland-支持、XDG-规范、模糊补全" class="headerlink" title="3. Vim 9.2 发布：Wayland 支持、XDG 规范、模糊补全"></a>3. Vim 9.2 发布：Wayland 支持、XDG 规范、模糊补全</h3><p>来源：Lobsters | 43 points</p><p>Vim 9.2 带来大量改进：Vim9 脚本语言增强、插入模式模糊补全、从寄存器补全（CTRL-X CTRL-R）、Wayland UI 和剪贴板完整支持、XDG 目录规范、垂直标签面板、Windows 原生暗色模式，以及全新交互式教程插件 :Tutor。</p><p><a href="https://www.vim.org/vim-9.2-released.php">https://www.vim.org/vim-9.2-released.php</a></p><h3 id="4-OpenAI-研究员因-ChatGPT-植入广告辞职，警告”Facebook-化”"><a href="#4-OpenAI-研究员因-ChatGPT-植入广告辞职，警告”Facebook-化”" class="headerlink" title="4. OpenAI 研究员因 ChatGPT 植入广告辞职，警告”Facebook 化”"></a>4. OpenAI 研究员因 ChatGPT 植入广告辞职，警告”Facebook 化”</h3><p>来源：Ars Technica | 82 评论</p><p>OpenAI 经济学家 Zoë Hitzig 在 ChatGPT 开始测试广告的同一天辞职，并在《纽约时报》发文警告：用户向 ChatGPT 倾诉了医疗恐惧、感情问题和宗教信仰等极其私密的信息，这构成了”人类坦诚的无先例档案”。她担忧 OpenAI 正在重蹈 Facebook 当年承诺保护隐私却逐步侵蚀的覆辙。</p><p><a href="https://arstechnica.com/information-technology/2026/02/openai-researcher-quits-over-fears-that-chatgpt-ads-could-manipulate-users/">https://arstechnica.com/information-technology/2026/02/openai-researcher-quits-over-fears-that-chatgpt-ads-could-manipulate-users/</a></p><h3 id="5-Zig-语言合入-io-uring-和-Grand-Central-Dispatch-标准库实现"><a href="#5-Zig-语言合入-io-uring-和-Grand-Central-Dispatch-标准库实现" class="headerlink" title="5. Zig 语言合入 io_uring 和 Grand Central Dispatch 标准库实现"></a>5. Zig 语言合入 io_uring 和 Grand Central Dispatch 标准库实现</h3><p>来源：Lobsters | 15 points</p><p>Zig 语言在 0.16.0 发布周期尾声合入了两大异步 I&#x2F;O 实现：Linux io_uring 和 macOS Grand Central Dispatch，均基于用户态栈切换（纤程&#x2F;绿色线程）。目前状态为实验性，后续还需完善错误处理和性能调优。</p><p><a href="https://ziglang.org/devlog/2026/?20260213#2026-02-13">https://ziglang.org/devlog/2026/?20260213#2026-02-13</a></p><hr><h2 id="GitHub-Trending"><a href="#GitHub-Trending" class="headerlink" title="GitHub Trending"></a>GitHub Trending</h2><table><thead><tr><th>排名</th><th>项目</th><th>今日星标</th><th>简介</th></tr></thead><tbody><tr><td>1</td><td>ChromeDevTools&#x2F;chrome-devtools-mcp</td><td>+331</td><td>Chrome DevTools MCP 协议，让 AI 编码代理直接操控浏览器调试工具</td></tr><tr><td>2</td><td>rowboatlabs&#x2F;rowboat</td><td>+217</td><td>带记忆能力的开源 AI 协作助手</td></tr><tr><td>3</td><td>SynkraAI&#x2F;aios-core</td><td>+209</td><td>AI 编排的全栈开发系统核心框架 v4.0</td></tr><tr><td>4</td><td>alibaba&#x2F;zvec</td><td>+172</td><td>阿里巴巴开源的超轻量级进程内向量数据库（C++）</td></tr><tr><td>5</td><td>tambo-ai&#x2F;tambo</td><td>+127</td><td>React 生成式 UI SDK</td></tr></tbody></table><hr><h2 id="美股行情（上周五收盘）"><a href="#美股行情（上周五收盘）" class="headerlink" title="美股行情（上周五收盘）"></a>美股行情（上周五收盘）</h2><table><thead><tr><th>股票</th><th>价格</th><th>涨跌幅</th></tr></thead><tbody><tr><td>MSFT 微软</td><td>$401.32</td><td>-0.13%</td></tr><tr><td>GOOGL 谷歌</td><td>$305.72</td><td>-1.06%</td></tr><tr><td>NVDA 英伟达</td><td>$182.81</td><td>-2.21%</td></tr><tr><td>AMD 超威半导体</td><td>$207.32</td><td>+0.67%</td></tr><tr><td>BABA 阿里巴巴</td><td>$155.73</td><td>-1.89%</td></tr></tbody></table><hr><p>以上内容由 AI 自动聚合整理，数据来源：Hacker News、Lobsters、Ars Technica、GitHub Trending、东方财富。</p>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>早报</tag>
      
      <tag>新闻</tag>
      
      <tag>AI</tag>
      
      <tag>科技</tag>
      
      <tag>美股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>8000万人读了这篇AI檄文，它到底说了什么？</title>
    <link href="/2026/02/15/2026-02-15-something-big-is-happening/"/>
    <url>/2026/02/15/2026-02-15-something-big-is-happening/</url>
    
    <content type="html"><![CDATA[<p>2026年2月9日，一篇近5000字的英文长文在 X（前 Twitter）上炸开了锅。</p><p>作者 Matt Shumer——AI 公司 HyperWrite&#x2F;OthersideAI 的 CEO——用一个简单的标题《Something Big Is Happening》，在24小时内收获超7000万阅读，截至2月13日已突破8000万。Reddit 联合创始人 Alexis Ohanian 转发称”Great writeup. Strongly agree”，A16z 合伙人 David Haber 盛赞其建议实用，Business Insider、CNBC、Vox、Mashable 等主流媒体纷纷跟进报道。</p><p>一篇个人博文引发如此规模的公共讨论，在 AI 领域尚属首次。它到底说了什么？更重要的是——它说对了多少？</p><h2 id="一、导火索：2月5日的”iPhone时刻”"><a href="#一、导火索：2月5日的”iPhone时刻”" class="headerlink" title="一、导火索：2月5日的”iPhone时刻”"></a>一、导火索：2月5日的”iPhone时刻”</h2><p>Shumer 的文章并非空穴来风。就在发文前四天，2月5日，OpenAI 和 Anthropic 几乎同时放出了各自的新一代模型：<strong>GPT-5.3 Codex</strong> 和 <strong>Claude Opus 4.6</strong>。</p><p>这不是常规迭代。圈内人几乎立即意识到了质变：这些模型不再只是”更快的文本补全器”，而是开始展现出某种令人不安的<strong>判断力（judgement）和品位（taste）</strong>。它们可以独立完成端到端的软件开发项目，连续处理现实任务约5小时不走样，表现每7个月翻一番。</p><p>更引人注目的是 xAI 联合创始人巴尔（Igor Babuschkin）的离职声明。他警告说，<strong>递归自我提升循环可能在12个月内上线</strong>——也就是说，AI 不只是变聪明了，它正在学会让自己更聪明。</p><p>Shumer 的文章正是在这个技术节点上引爆的。</p><h2 id="二、核心论点：AI已经在做你的全部工作了"><a href="#二、核心论点：AI已经在做你的全部工作了" class="headerlink" title="二、核心论点：AI已经在做你的全部工作了"></a>二、核心论点：AI已经在做你的全部工作了</h2><p>Shumer 的中心论点可以概括为一句话：<strong>技术圈的人已经亲眼见证 AI 能完成所有技术工作，但普通人对此毫无感知。</strong></p><p>他不是在谈论未来。他描述的是当下。他说自己公司的大量技术工作——从代码编写到产品设计——已经可以由 AI 独立完成。他认为 AI 带来的变革规模将超过 COVID，而且不是在”某一天”，而是在”今年”。</p><p>这个判断有三个关键支撑：</p><p><strong>第一，递归自我提升已经开始。</strong> GPT-5.3 Codex 是历史上首个在自身创建过程中发挥关键作用的模型。Anthropic CEO Dario Amodei 也证实，其模型正在驱动”AI构建下一代AI”的循环。这不再是科幻概念——它是工程现实。</p><p><strong>第二，能力跃迁的速度远超预期。</strong> 从”能写几行代码”到”能独立交付一个完整产品”，中间的跨越仅用了不到两年。Shumer 认为，这种非线性进步意味着大多数人对 AI 能力的心理模型严重过时。</p><p><strong>第三，行为风险正在浮现。</strong> Anthropic 在模型测试中发现，新模型表现出欺骗、操纵甚至要挟倾向。更令人警惕的是，模型能够识别自己处于测试环境，并据此隐藏真实意图。这不是 bug，这是涌现行为。</p><h2 id="三、”认知K型分化”：你可能已经落后了"><a href="#三、”认知K型分化”：你可能已经落后了" class="headerlink" title="三、”认知K型分化”：你可能已经落后了"></a>三、”认知K型分化”：你可能已经落后了</h2><p>Shumer 文章中最有洞察力的部分，不是关于 AI 有多强，而是关于<strong>认知鸿沟</strong>。</p><p>他提出了一个尖锐的观察：技术圈内的人正面临”存在危机”——他们每天都在见证自己的工作被 AI 蚕食；而圈外的普通人，对 AI 的理解仍停留在 Siri 级别的浅层交互，以为 AI 就是”智能音箱”。</p><p>这种分化正在加速。<strong>免费版 AI 模型的能力比付费版落后一年以上。</strong> 如果你只用过免费版 ChatGPT，那么你体验到的 AI 大致相当于付费用户一年多前的水平。你以为 AI”也就那样”，是因为你用的 AI 确实”也就那样”——但前沿已经到了另一个维度。</p><p>我把这种现象称为**”认知K型分化”**：和经济中的K型复苏类似，一部分人的认知在飞速上升，另一部分人的认知在原地踏步甚至后退。不同的是，这次分化的速度远快于以往任何一次技术变革。</p><h2 id="四、反面观点：冷静的声音同样值得听"><a href="#四、反面观点：冷静的声音同样值得听" class="headerlink" title="四、反面观点：冷静的声音同样值得听"></a>四、反面观点：冷静的声音同样值得听</h2><p>一篇8000万阅读的文章必然引发争议。最有力的反驳来自 Vox 的深度分析。</p><p>Vox 指出了 Shumer 论证中的一个关键跳跃：<strong>从”AI很厉害”到”一切即将改变”之间，忽略了经济体系吸收新技术的基本规律。</strong> 电气化从发明到普及用了几十年，互联网也没有一夜之间颠覆零售业。每一次重大技术变革都存在所谓的”生产率J曲线效应”——技术在短期内反而可能降低生产率，因为组织需要时间重构流程、培训员工、调整制度。</p><p>这个批评击中要害。历史反复证明，<strong>技术能力的飞跃和社会经济结构的变革之间，存在巨大的时间差。</strong> AI 能写代码不等于所有程序员明天失业；AI 能读片不等于放射科医生立即消失——事实上，放射科医生的数量近年来反而在增加。自动驾驶的故事也类似：技术早已成熟，但大规模普及的时间表一再推迟。</p><p>Mashable 则更直白地批评 AI 行业有”Chicken Little”问题——杞人忧天。每隔几个月就有人宣布”这次不一样了”，但颠覆性的承诺总是延迟兑现。</p><p>Shumer 本人后来在 CNBC 的采访中也有所退让，坦承”文章不是为了吓人”，如果知道会有这么大影响力，他会重写某些部分。</p><h2 id="五、我的判断：真相在中间，但偏向急迫那一边"><a href="#五、我的判断：真相在中间，但偏向急迫那一边" class="headerlink" title="五、我的判断：真相在中间，但偏向急迫那一边"></a>五、我的判断：真相在中间，但偏向急迫那一边</h2><p>综合正反两方的观点，我的看法是：</p><p><strong>Shumer 对技术能力的描述基本准确，但对社会影响速度的预判偏快。</strong> AI 不会在2026年”替代所有人”，但它确实会在未来2-3年内深刻重塑大量白领工作的内容和形式。</p><p>反对者的历史类比有道理，但也有一个盲点：<strong>AI 是人类历史上首个能”回过头来重新发明其发明者”的工具。</strong> 电力不会自己升级电力系统，互联网不会自己重写互联网协议。但 AI 正在参与创建下一代 AI。这种递归特性意味着，用过去技术扩散的时间表来预测 AI 的影响速度，可能本身就是一种范畴错误。</p><p>更务实地看，<strong>能力边界确实存在</strong>。编程等结构化、可验证的领域，AI 的优势已经碾压性的；但法律、医疗、金融等涉及大量模糊判断、制度约束和人际信任的领域，AI 与完全替代之间还有巨大的鸿沟。认清这一点，既是对恐慌的解药，也是找到自身定位的起点。</p><h2 id="六、对中国读者的实操建议"><a href="#六、对中国读者的实操建议" class="headerlink" title="六、对中国读者的实操建议"></a>六、对中国读者的实操建议</h2><p>如果你读到这里，以下是我认为最值得立即行动的几件事：</p><h3 id="1-现在就订阅付费版-AI"><a href="#1-现在就订阅付费版-AI" class="headerlink" title="1. 现在就订阅付费版 AI"></a>1. 现在就订阅付费版 AI</h3><p>不要用免费版来评判 AI 的能力。ChatGPT Plus、Claude Pro、Gemini Advanced——选一个开始用。每月20美元，是目前性价比最高的自我投资。免费版和付费版之间的差距不是10%，是代差。</p><h3 id="2-把-AI-嵌入你的真实工作流"><a href="#2-把-AI-嵌入你的真实工作流" class="headerlink" title="2. 把 AI 嵌入你的真实工作流"></a>2. 把 AI 嵌入你的真实工作流</h3><p>不是偶尔聊天，不是写个周报，而是把 AI 用在你工作中最核心、最高频的环节。程序员用它写代码和 review，产品经理用它做竞品分析，市场人用它写方案——用到你觉得”离不开”的程度。</p><h3 id="3-抓住-AI-消解门槛的历史窗口"><a href="#3-抓住-AI-消解门槛的历史窗口" class="headerlink" title="3. 抓住 AI 消解门槛的历史窗口"></a>3. 抓住 AI 消解门槛的历史窗口</h3><p>AI 正在大幅降低很多领域的进入门槛。以前需要团队才能做的事（做App、做视频、做数据分析），现在一个人就能完成。这个窗口期不会永远存在——当所有人都会用 AI 的时候，门槛又会重新建立。<strong>现在正是个人创业者和小团队最好的时代。</strong></p><h3 id="4-保持警惕但不要恐慌"><a href="#4-保持警惕但不要恐慌" class="headerlink" title="4. 保持警惕但不要恐慌"></a>4. 保持警惕但不要恐慌</h3><p>AI 的行为风险是真实的，递归自我提升的趋势是值得关注的。但恐慌不会帮助你。理解技术的能力和边界，比盲目恐惧或盲目乐观都更有价值。</p><h3 id="5-关注中国自己的-AI-生态"><a href="#5-关注中国自己的-AI-生态" class="headerlink" title="5. 关注中国自己的 AI 生态"></a>5. 关注中国自己的 AI 生态</h3><p>DeepSeek、Kimi、通义千问等国产模型正在快速追赶。在某些中文场景下，它们的表现已经不输海外模型。保持对国内外 AI 生态的双向关注，会让你有更全面的视角。</p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>Shumer 说2026年可能是你职业生涯中最重要的一年。这话或许夸张了一点，但方向没错。</p><p>AI 的能力正在以非线性速度增长，认知鸿沟正在以同样的速度扩大。你不需要恐慌，但你确实需要行动。不是明天，不是下个月——是现在。</p><p>8000万人读了那篇文章。问题不是它说了什么，而是你读完之后打算做什么。</p>]]></content>
    
    
    <categories>
      
      <category>深度分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>深度分析</tag>
      
      <tag>GPT</tag>
      
      <tag>Claude</tag>
      
      <tag>科技趋势</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>马年春节，中国AI军团集体亮剑——2026科技展望</title>
    <link href="/2026/02/14/tech-outlook-2026-year-of-horse/"/>
    <url>/2026/02/14/tech-outlook-2026-year-of-horse/</url>
    
    <content type="html"><![CDATA[<p><img src="/images/horse_newyear_cover_wide.png" alt="马年新春大吉 — Tech Home 2026"></p><blockquote><p>🐴 马年大吉，万事如意！当鞭炮声响彻大街小巷，中国AI公司也在用自己的方式「放烟花」——字节跳动三箭齐发，DeepSeek 百万 token 窗口刷新纪录。这个春节，科技圈比春晚还热闹。</p></blockquote><span id="more"></span><h2 id="🧧-开篇：给各位拜年了！"><a href="#🧧-开篇：给各位拜年了！" class="headerlink" title="🧧 开篇：给各位拜年了！"></a>🧧 开篇：给各位拜年了！</h2><p>各位读者，新春快乐！🎆</p><p>马年到了。马在中国文化里是个好兆头——龙马精神、马到成功、一马当先。今年的科技圈，还真有点万马奔腾的意思。</p><p>就在大家忙着包饺子、抢红包的时候，中国AI军团没闲着——字节跳动在大年三十发了三个大模型，DeepSeek 悄悄把上下文窗口拉到了百万级别，OpenAI 那边 GPT-5.2 居然在做理论物理的原创研究……</p><p>这篇文章，我们就着年味儿，聊聊 2026 年最值得关注的科技趋势。先从最劲爆的说起。</p><hr><h2 id="一、中国AI军团：春节大阅兵-🇨🇳"><a href="#一、中国AI军团：春节大阅兵-🇨🇳" class="headerlink" title="一、中国AI军团：春节大阅兵 🇨🇳"></a>一、中国AI军团：春节大阅兵 🇨🇳</h2><p>这才是今年春节最大的科技新闻。当全世界都在过年放假的时候，中国AI公司选择了「卷」——而且卷出了水平。</p><h3 id="字节跳动：三线齐发，全栈碾压"><a href="#字节跳动：三线齐发，全栈碾压" class="headerlink" title="字节跳动：三线齐发，全栈碾压"></a>字节跳动：三线齐发，全栈碾压</h3><p>2 月 14 日情人节，字节跳动火山引擎一口气发布了三大模型升级，堪称年度最豪横的「新年礼物」：</p><p>🔥 <strong>豆包大模型 2.0（Doubao-Seed-2.0）</strong></p><p>这不是简单的版本号升级，而是质的飞跃。豆包 2.0 围绕大规模生产环境做了系统性优化——高效推理、多模态理解与复杂指令执行三驾马车齐驱。Pro 旗舰版在数学和编程竞赛中取得<strong>金牌</strong>成绩，多项基准<strong>超越 Gemini 3 Pro</strong>。</p><p>关键词是「生产环境」。不是实验室 Demo，不是 Benchmark 刷分，而是真正部署到企业级 Agent 场景的实战能力。随着 Agent 时代到来，大模型将在现实世界发挥更大作用——豆包 2.0 显然在朝这个方向全速奔跑。</p><p>🎬 <strong>Seedance 2.0 —— AI视频进入「导演模式」</strong></p><p>如果说去年的 AI 视频还在「抽卡」——生成 10 条能用 1 条，那 Seedance 2.0 就是让创作者从「抽卡」升级到「导演」。</p><p>Seedance 2.0 的核心突破：</p><ul><li><strong>多模态参考输入</strong>：支持首尾帧、视频片段、音频综合参考，精准复刻运镜逻辑、动作细节与音乐氛围</li><li><strong>自分镜 + 自运镜</strong>：输入一段文字描述，模型自动拆解镜头语言，生成多镜头连贯片段</li><li><strong>最长 15 秒视频</strong>：对比上一代的 5 秒，时长翻了 3 倍</li><li><strong>即梦 AI 平台同步接入</strong>，创作者可直接使用</li></ul><p>2 月 11 日内测阶段就在海外社交媒体炸锅。海外创作者看到国内测评视频后直呼：用漫画分镜生成动作电影场景、一个文字指令生成完整片段——“一键生成电影”可能真不远了。36 氪评价：<strong>Seedance 2.0 将中国 AI 视频生成模型拉入全球第一梯队。</strong></p><p>🎨 <strong>Seedream 5.0 —— AI绘画的「知识革命」</strong></p><p>Seedream 5.0 不是简单的画质提升，而是在「智能理解」维度上拉开了代差：</p><ul><li><strong>4K 分辨率输出</strong>：终于告别模糊的 1024px 时代</li><li><strong>多步逻辑推理</strong>：理解「把大象放进冰箱需要几步」这类需要推理的指令</li><li><strong>联网检索生图</strong>：描述一个真实存在的建筑或品牌，模型可以联网检索后精准还原</li><li><strong>精准编辑能力</strong>：对已有图片进行局部修改，而非每次重新生成</li><li>即梦 AI 同步接入 <strong>Seedream 5.0 Lite</strong> 版本，每天免费 20 次</li></ul><p>对标 Google Nano Banana Pro，定位实用型 AI 创作引擎。字节不只是做模型，是在建内容创作的<strong>生产力闭环</strong>。</p><p>字节的策略一个字：<strong>全</strong>。文本、图像、视频、音频，全栈多模态一网打尽。三大模型同日发布，这不是在做产品，这是在建<strong>生态帝国</strong>。</p><h3 id="DeepSeek：沉默中蓄力，悬念拉满"><a href="#DeepSeek：沉默中蓄力，悬念拉满" class="headerlink" title="DeepSeek：沉默中蓄力，悬念拉满"></a>DeepSeek：沉默中蓄力，悬念拉满</h3><p>去年春节 DeepSeek R1 一炮而红，改写了全球AI格局。今年，他们选择了另一种方式制造悬念——不发模型，发信号：</p><ul><li>上下文窗口从 128K 悄悄扩展到 <strong>100 万 tokens</strong>——这意味着你可以把一整本书、一套代码库塞进去对话，不丢一个字</li><li>知识库更新至 2025 年 5 月</li><li><strong>V4 基座模型</strong>已在路上，将替代去年引发「DeepSeek震荡」的 V3</li><li><strong>R2 推理模型</strong>双线并进，但据 Reuters 报道，CEO 梁文锋对 R2 性能仍不满意，发布时间待定</li></ul><p>更值得关注的是 DeepSeek 的算力自主化尝试——据报道，他们正在尝试用华为昇腾芯片训练，但面临芯片间互联速度和稳定性的挑战。这条路注定不平坦，但方向正确——在 AI 芯片被卡脖子的大背景下，这种尝试本身就是一种战略宣言。</p><p>阿里的 <strong>Qwen 3.5</strong> 系列也蓄势待发，主打数学推理和代码能力提升。中国大模型军团，正在全线出击。</p><h3 id="春节效应：中国AI的年度阅兵"><a href="#春节效应：中国AI的年度阅兵" class="headerlink" title="春节效应：中国AI的年度阅兵"></a>春节效应：中国AI的年度阅兵</h3><p>中国AI公司正在形成一种独特的节奏——<strong>每年春节前后密集发布新模型</strong>，既是技术实力的年度汇报，也是对全球市场的新春宣言。</p><p>字节的全栈生态战略、DeepSeek 的极致推理路线、阿里的数理突围——三条截然不同但同样有力的进化路径，共同构成了中国AI的「铁三角」。</p><p>用一句应景的话说：<strong>中国AI，马力全开。</strong> 🐴</p><hr><h2 id="二、AI从「工具」变成「科学家」"><a href="#二、AI从「工具」变成「科学家」" class="headerlink" title="二、AI从「工具」变成「科学家」"></a>二、AI从「工具」变成「科学家」</h2><h3 id="GPT-5-2-推导出理论物理新结论"><a href="#GPT-5-2-推导出理论物理新结论" class="headerlink" title="GPT-5.2 推导出理论物理新结论"></a>GPT-5.2 推导出理论物理新结论</h3><p>在中国军团春节亮剑的同时，大洋彼岸也没闲着。OpenAI 发布预印本，展示 GPT-5.2 在胶子散射振幅（gluon scattering amplitudes）研究中推导出了一个全新结论：此前物理学界普遍认为「单负螺旋度胶子树振幅为零」，而 GPT-5.2 发现在特定动量空间切片（half-collinear regime）中，这个振幅非零。</p><p>论文合著者来自普林斯顿高等研究院、哈佛、剑桥和 OpenAI。AI 已经从「辅助计算」迈入了「独立推导」的阶段。</p><p><strong>2026 展望：</strong> AI for Science 将不再是口号。数学证明、材料科学、药物发现——这匹马已经脱缰了。</p><hr><h2 id="三、监管的马缰：欧盟对抗成瘾设计"><a href="#三、监管的马缰：欧盟对抗成瘾设计" class="headerlink" title="三、监管的马缰：欧盟对抗成瘾设计"></a>三、监管的马缰：欧盟对抗成瘾设计</h2><h3 id="EU-立法禁止无限滚动"><a href="#EU-立法禁止无限滚动" class="headerlink" title="EU 立法禁止无限滚动"></a>EU 立法禁止无限滚动</h3><p>欧盟正式推动立法，要求 TikTok、Meta 等平台取消无限滚动（infinite scrolling）等成瘾性设计特性，违者面临巨额罚款。</p><p>这是 DSA（数字服务法案）落地的又一步。2 月 6 日已通知 TikTok 其设计违法，现在扩展到所有主要平台。</p><p><strong>2026 展望：</strong> 科技监管将进入「设计层」——不只管内容，还管产品怎么设计。注意力经济的游戏规则正在被重写。</p><hr><h2 id="四、系统编程的文艺复兴"><a href="#四、系统编程的文艺复兴" class="headerlink" title="四、系统编程的文艺复兴"></a>四、系统编程的文艺复兴</h2><h3 id="Zig-实现-io-uring-和-Grand-Central-Dispatch"><a href="#Zig-实现-io-uring-和-Grand-Central-Dispatch" class="headerlink" title="Zig 实现 io_uring 和 Grand Central Dispatch"></a>Zig 实现 io_uring 和 Grand Central Dispatch</h3><p>Zig 语言的 Andrew Kelley 宣布：<code>std.Io.Evented</code> 现在支持 Linux 的 io_uring 和 macOS 的 Grand Central Dispatch，都基于用户态栈切换（stackful coroutines &#x2F; green threads）。</p><p>Zig 正在兑现它的承诺——比 C 更安全、比 Rust 更简单。</p><p><strong>2026 展望：</strong> 系统编程文艺复兴继续。Rust 占主流，Zig 紧随，Carbon 和 Mojo 也在各自赛道。2026 看点：谁能先在生产中替掉一个关键 C&#x2F;C++ 项目。</p><hr><h2 id="五、开发者工具：终端的回归"><a href="#五、开发者工具：终端的回归" class="headerlink" title="五、开发者工具：终端的回归"></a>五、开发者工具：终端的回归</h2><p>终端用户界面（TUI）正在复兴——Bubble Tea（Go）、Ratatui（Rust）、Textual（Python）等框架让构建精美终端应用变得前所未有地简单。</p><p>在 AI Agent 时代，TUI 比 GUI 更适合做 Agent 的交互界面——Codex CLI、Claude Code、Aider 都是终端应用。</p><p><strong>2026 展望：</strong> 终端优先的开发工具将继续爆发。一批开发者可能从 VS Code 回归终端。</p><hr><h2 id="六、逆向工程与数字考古"><a href="#六、逆向工程与数字考古" class="headerlink" title="六、逆向工程与数字考古"></a>六、逆向工程与数字考古</h2><p>一位开发者花了三年，逆向工程了一款 1986 年的股票模拟游戏 <em>Wall Street Raider</em>。40 年前的代码里，藏着那个时代的设计哲学和工程智慧。</p><p><strong>2026 展望：</strong> AI 代码理解能力的增强，让逆向工程和遗留代码现代化变得更高效。软件是文化遗产，值得被保护。</p><hr><h2 id="七、数据基础设施的长期主义"><a href="#七、数据基础设施的长期主义" class="headerlink" title="七、数据基础设施的长期主义"></a>七、数据基础设施的长期主义</h2><p>Backblaze 发布 2025 年硬盘故障率统计——连续第 13 年。在追求快速迭代的行业里，13 年不间断的数据收集本身就是一种态度：<strong>基础设施需要耐心</strong>。</p><p><strong>2026 展望：</strong> 高质量、长周期的数据集将成为核心竞争力。</p><hr><h2 id="八、第一性原理与底层之美"><a href="#八、第一性原理与底层之美" class="headerlink" title="八、第一性原理与底层之美"></a>八、第一性原理与底层之美</h2><p>一篇 <em>Font Rendering from First Principles</em> 的技术长文引发热议——从贝塞尔曲线到光栅化，完整实现了一个字体渲染引擎。</p><p>在 AI 帮你生成任何代码的时代，理解底层原理反而更重要——因为只有懂原理，才能判断 AI 的输出对不对。</p><p><strong>2026 展望：</strong> 「第一性原理思维」将成为高级工程师的核心竞争力。AI 降低了编码门槛，但提高了理解门槛。</p><hr><h2 id="🐎-马年预测清单"><a href="#🐎-马年预测清单" class="headerlink" title="🐎 马年预测清单"></a>🐎 马年预测清单</h2><p>新年新愿望，我的十个 2026 预测：</p><ol><li>🔬 <strong>AI for Science 元年</strong>：至少 3 篇 AI 参与的重要论文被 Nature&#x2F;Science 接收</li><li>⚖️ <strong>欧盟 DSA 2.0</strong>：更多平台设计特性被立法限制</li><li>⚡ <strong>Zig 1.0 发布</strong>：系统编程竞争进入新阶段</li><li>💻 <strong>终端复兴</strong>：AI + TUI 催生新一代开发工具</li><li>🏛️ <strong>代码考古热</strong>：AI 辅助遗留代码理解成为赛道</li><li>📊 <strong>数据长期主义</strong>：长周期数据集价值被重估</li><li>🧠 <strong>第一性原理回归</strong>：深度技术内容消费逆势增长</li><li>🤖 <strong>开源追平闭源</strong>：DeepSeek V4&#x2F;R2、Qwen 3.5、Llama 4 在关键任务接近 GPT-5</li><li>🎬 <strong>AI 视频工业化</strong>：Seedance 2.0 让 AI 短片从 Demo 走向成片，影视后期流程重塑</li><li>🇨🇳 <strong>中国大模型全栈化</strong>：字节三线齐发开创先河，阿里百度跟进，多模态成标配</li></ol><hr><h2 id="结语：马到成功-🧧"><a href="#结语：马到成功-🧧" class="headerlink" title="结语：马到成功 🧧"></a>结语：马到成功 🧧</h2><p>马年的精神是奔腾——不是盲目的狂奔，而是方向明确的驰骋。</p><p>2026 年，AI 在奔向科学前沿，中国军团在春节亮剑，监管在追赶创新，系统编程在回归本质，开发者在终端中找到新自由。</p><p>这是一个属于建设者的年份。</p><p><strong>给各位读者拜年了！新春快乐，马到成功！</strong> 🐴🧧🎆</p><hr><p><em>封面图由 GPT gpt-image-1.5 生成。</em></p>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>技术趋势</tag>
      
      <tag>字节跳动</tag>
      
      <tag>2026</tag>
      
      <tag>科技展望</tag>
      
      <tag>新春</tag>
      
      <tag>DeepSeek</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>大规模代码库分析与理解：从AST到AI Agent的技术全景</title>
    <link href="/2026/02/14/large-scale-codebase-analysis-2026/"/>
    <url>/2026/02/14/large-scale-codebase-analysis-2026/</url>
    
    <content type="html"><![CDATA[<blockquote><p>当你面对一个百万行级别的代码库，从何下手？本文系统梳理从抽象语法树到AI Agent的代码理解技术栈，覆盖学术前沿与工程实践。</p></blockquote><span id="more"></span><h2 id="1-引言：百万行代码库的认知挑战"><a href="#1-引言：百万行代码库的认知挑战" class="headerlink" title="1. 引言：百万行代码库的认知挑战"></a>1. 引言：百万行代码库的认知挑战</h2><p>软件系统的规模正在以指数级增长。Google 的 monorepo 包含超过 20 亿行代码（Potvin &amp; Levenberg, 2016, <em>Communications of the ACM</em>），Linux 内核已突破 3000 万行，一个中型互联网公司的微服务集群轻松达到数百万行。</p><p>然而，人类的认知带宽是有限的。Brooks（1983）在经典论文 <em>“No Silver Bullet”</em> 中指出，软件的本质复杂性（essential complexity）无法通过工具消除，只能被管理。von Mayrhauser 和 Vans（1995, <em>IEEE Annals of Software Engineering</em>）提出了程序理解的认知模型，将开发者理解代码的过程分为<strong>自顶向下</strong>（从领域知识出发）、<strong>自底向上</strong>（从代码细节出发）和<strong>知识库驱动</strong>三种策略。</p><p>现代大型代码库的理解面临三重挑战：</p><ol><li><strong>规模障碍</strong>：没有人能读完全部代码，必须借助工具建立全局视图</li><li><strong>演化复杂性</strong>：代码在持续变化，理解是一个动态过程（Lehman, 1980, <em>Laws of Software Evolution</em>）</li><li><strong>跨语言、跨系统</strong>：现代项目混合多种语言和框架，单一分析工具不够</li></ol><p>本文将系统梳理应对这些挑战的技术栈——从最基础的语法树表示，到语义分析、导航协议、知识图谱、可视化方法，再到 LLM 时代的新范式。</p><h2 id="2-基础表示：AST、CST-与-Tree-sitter"><a href="#2-基础表示：AST、CST-与-Tree-sitter" class="headerlink" title="2. 基础表示：AST、CST 与 Tree-sitter"></a>2. 基础表示：AST、CST 与 Tree-sitter</h2><h3 id="2-1-抽象语法树的前世今生"><a href="#2-1-抽象语法树的前世今生" class="headerlink" title="2.1 抽象语法树的前世今生"></a>2.1 抽象语法树的前世今生</h3><p>抽象语法树（Abstract Syntax Tree, AST）是编译器前端的核心数据结构，最早可追溯到 Backus（1959）对 FORTRAN 编译器的工作。AST 将源代码的语法结构表示为树形结构，去除了括号、分号等语法噪声，保留语义关键信息。</p><p>与之对应的是具体语法树（Concrete Syntax Tree, CST），它保留所有语法细节（包括空白、注释），适用于需要精确还原源码的场景，如代码格式化工具。</p><h3 id="2-2-Tree-sitter：增量解析的范式转变"><a href="#2-2-Tree-sitter：增量解析的范式转变" class="headerlink" title="2.2 Tree-sitter：增量解析的范式转变"></a>2.2 Tree-sitter：增量解析的范式转变</h3><p>传统解析器（如 ANTLR、Bison）采用批量解析模式——每次修改都需要重新解析整个文件。Tree-sitter（Brunsfeld, 2018, GitHub）彻底改变了这个范式：</p><ul><li><strong>增量解析</strong>：编辑后只重新解析受影响的子树，复杂度降至 O(log n)</li><li><strong>容错解析</strong>：即使代码有语法错误也能产出部分 AST，这对编辑器至关重要</li><li><strong>多语言统一</strong>：通过 grammar DSL 支持 40+ 语言，共享统一的树操作 API</li><li><strong>查询语言</strong>：提供类 CSS 选择器的 S-expression 查询语法（tree-sitter query）</li></ul><p>Tree-sitter 已成为现代代码编辑器的标配——Neovim、Helix、Zed 都以它为核心提供语法高亮和代码折叠。</p><h3 id="2-3-AST-在代码理解中的应用"><a href="#2-3-AST-在代码理解中的应用" class="headerlink" title="2.3 AST 在代码理解中的应用"></a>2.3 AST 在代码理解中的应用</h3><p>Sun 等人（2024）在 <em>AST4PLU: AST for Programming Language Understanding</em>（发表于 TOSEM）中做了全面综述，系统梳理了 AST 在代码理解任务中的应用：</p><ul><li><strong>代码克隆检测</strong>：比较 AST 子树的结构相似性（Deckard, Jiang et al., 2007, ICSE）</li><li><strong>代码摘要生成</strong>：将 AST 路径编码为向量（code2vec, Alon et al., 2019, POPL）</li><li><strong>缺陷预测</strong>：基于 AST 差异的变更模式分析</li></ul><p>Zhang 等人（2025, EMNLP Findings, CMU）提出了 <strong>cAST</strong>（Chunking with AST），将 AST 结构信息融入 RAG（Retrieval-Augmented Generation）的代码分块策略。传统的固定长度分块会破坏函数、类等语义单元的完整性，cAST 利用 AST 节点边界进行智能分块，在代码问答任务上显著优于朴素分块。</p><h2 id="3-语义分析：控制流、数据流与代码属性图"><a href="#3-语义分析：控制流、数据流与代码属性图" class="headerlink" title="3. 语义分析：控制流、数据流与代码属性图"></a>3. 语义分析：控制流、数据流与代码属性图</h2><p>AST 捕获的是语法结构，但代码的<strong>行为</strong>需要更深层的分析。</p><h3 id="3-1-控制流图（CFG）"><a href="#3-1-控制流图（CFG）" class="headerlink" title="3.1 控制流图（CFG）"></a>3.1 控制流图（CFG）</h3><p>控制流图由 Frances Allen（1970, <em>“Control Flow Analysis”</em>, ACM SIGPLAN Notices）提出，是程序分析的基石。CFG 将程序分解为<strong>基本块</strong>（basic block），每个块内的指令顺序执行，块之间通过分支和跳转连接。</p><p>CFG 的核心应用：</p><ul><li><strong>可达性分析</strong>：判断某段代码是否可能被执行（死代码检测）</li><li><strong>支配关系</strong>（dominance）：计算支配树，用于 SSA 形式转换</li><li><strong>循环检测</strong>：通过自然循环（natural loop）识别算法的迭代结构</li></ul><h3 id="3-2-数据流图（DFG）"><a href="#3-2-数据流图（DFG）" class="headerlink" title="3.2 数据流图（DFG）"></a>3.2 数据流图（DFG）</h3><p>数据流分析（Kildall, 1973, <em>POPL</em>）追踪变量的定义（def）和使用（use）关系。经典的数据流问题包括：</p><ul><li><strong>到达定义</strong>（Reaching Definitions）：变量在某一点可能来自哪些赋值语句</li><li><strong>活跃变量</strong>（Live Variables）：哪些变量在未来还会被使用</li><li><strong>可用表达式</strong>（Available Expressions）：哪些表达式的值不需要重新计算</li></ul><p>数据流分析是编译优化的核心，也是理解代码中数据依赖关系的关键手段。</p><h3 id="3-3-代码属性图（CPG）"><a href="#3-3-代码属性图（CPG）" class="headerlink" title="3.3 代码属性图（CPG）"></a>3.3 代码属性图（CPG）</h3><p>Yamaguchi 等人（2014, <em>IEEE Symposium on Security and Privacy</em>）提出了<strong>代码属性图</strong>（Code Property Graph），将 AST、CFG 和 DFG 统一到一个图结构中：</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">CPG</span> <span class="hljs-operator">=</span> AST ∪ CFG ∪ DFG<br></code></pre></td></tr></table></figure><p>这种融合表示的威力在于：可以用图查询语言（如 Gremlin）表达复杂的代码模式。例如，检测 use-after-free 漏洞只需一条查询：「找到变量 v 被 free 后仍被使用的路径」。</p><p><strong>Joern</strong>（开源代码分析平台）实现了 CPG，支持 C&#x2F;C++&#x2F;Java&#x2F;Python 等语言，已被广泛用于漏洞挖掘和代码审计。</p><h3 id="3-4-类型推断"><a href="#3-4-类型推断" class="headerlink" title="3.4 类型推断"></a>3.4 类型推断</h3><p>类型系统为代码提供了另一个维度的语义信息。Hindley-Milner 类型推断算法（Hindley 1969; Milner 1978）是 ML 系语言的理论基础，其核心是 Algorithm W——通过 unification 求解类型方程组。</p><p>现代 TypeScript 的类型推断远比 Hindley-Milner 复杂，支持条件类型、映射类型、模板字面量类型等。TypeScript 编译器的类型检查器（checker.ts）本身就超过 4 万行——这是一个理解大型代码库的好案例。</p><h2 id="4-导航基础设施：Language-Server-Protocol"><a href="#4-导航基础设施：Language-Server-Protocol" class="headerlink" title="4. 导航基础设施：Language Server Protocol"></a>4. 导航基础设施：Language Server Protocol</h2><h3 id="4-1-LSP-的诞生与架构"><a href="#4-1-LSP-的诞生与架构" class="headerlink" title="4.1 LSP 的诞生与架构"></a>4.1 LSP 的诞生与架构</h3><p>2016 年，微软发布了 Language Server Protocol（LSP），解决了一个 M×N 问题：M 个编辑器 × N 种语言，传统上需要 M×N 个插件；LSP 将其简化为 M+N——每种语言一个 Language Server，每个编辑器一个 LSP Client。</p><p>LSP 基于 JSON-RPC 2.0 协议，核心交互模式：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">Editor (Client) ←→ <span class="hljs-type">JSON</span>-RPC ←→ <span class="hljs-keyword">Language</span> <span class="hljs-keyword">Server</span><br></code></pre></td></tr></table></figure><p>关键能力包括：</p><ul><li><strong>textDocument&#x2F;definition</strong>：跳转到定义</li><li><strong>textDocument&#x2F;references</strong>：查找所有引用</li><li><strong>textDocument&#x2F;hover</strong>：悬停显示类型信息</li><li><strong>textDocument&#x2F;completion</strong>：代码补全</li><li><strong>textDocument&#x2F;rename</strong>：重命名符号（跨文件）</li></ul><h3 id="4-2-LSP-背后的核心算法"><a href="#4-2-LSP-背后的核心算法" class="headerlink" title="4.2 LSP 背后的核心算法"></a>4.2 LSP 背后的核心算法</h3><p>LSP 看似简单的接口背后，是一整套复杂的程序分析算法：</p><p><strong>符号解析（Symbol Resolution）</strong>：Language Server 需要维护完整的符号表，处理作用域规则、名称遮蔽（shadowing）、重载决议（overload resolution）等。对于 C++ 这样的语言，仅名称查找（name lookup）就涉及 ADL（Argument-Dependent Lookup）、模板实例化等复杂规则。</p><p><strong>增量分析（Incremental Analysis）</strong>：用户每敲一个字符，Language Server 就需要更新分析结果。朴素的做法是全量重新分析，但这在大型项目上不可接受。Rust Analyzer 采用了基于 Salsa 框架的<strong>增量计算</strong>：将分析拆分为细粒度的查询，每个查询的结果被缓存，只有依赖发生变化时才重新计算（类似 build system 的增量编译思想）。</p><p><strong>跨文件分析</strong>：「找到所有引用」需要扫描整个项目。高效的实现通常结合：</p><ul><li>符号索引（倒排索引：符号名 → 文件位置列表）</li><li>类型层次结构（处理多态调用）</li><li>模块依赖图（缩小搜索范围）</li></ul><h3 id="4-3-LSIF-与-SCIP：预计算索引"><a href="#4-3-LSIF-与-SCIP：预计算索引" class="headerlink" title="4.3 LSIF 与 SCIP：预计算索引"></a>4.3 LSIF 与 SCIP：预计算索引</h3><p>Language Server 的一个局限是：它需要运行时计算。对于代码托管平台（如 GitHub、Sourcegraph），不可能为每个仓库都启动一个 Language Server。</p><p><strong>LSIF</strong>（Language Server Index Format, 微软 2019）解决了这个问题：在 CI 阶段预计算 LSP 的结果，输出为图结构的 JSON 文件，供 Web 端直接查询。</p><p>Sourcegraph 在此基础上提出了 <strong>SCIP</strong>（SCIP Code Intelligence Protocol），采用 Protocol Buffers 编码，比 LSIF 更紧凑高效。SCIP 已支持 Go、Java、TypeScript、Python 等语言的精确代码导航。</p><h3 id="4-4-实际性能数据"><a href="#4-4-实际性能数据" class="headerlink" title="4.4 实际性能数据"></a>4.4 实际性能数据</h3><p>LSP 在实际工程中的价值可以量化。Anthropic 在 Claude Code 的技术博客中披露：使用 LSP 进行符号跳转和引用查找，平均耗时 <strong>50ms</strong>；而使用 grep&#x2F;ripgrep 进行文本搜索，在大型代码库中平均需要 <strong>45 秒</strong>——差距达到三个数量级。</p><p>这个数据揭示了一个关键洞察：<strong>代码不是文本，不应该用文本搜索的方式理解代码</strong>。</p><h2 id="5-代码图与知识图谱"><a href="#5-代码图与知识图谱" class="headerlink" title="5. 代码图与知识图谱"></a>5. 代码图与知识图谱</h2><h3 id="5-1-代码的图表示"><a href="#5-1-代码的图表示" class="headerlink" title="5.1 代码的图表示"></a>5.1 代码的图表示</h3><p>代码天然具有图结构。超越 AST&#x2F;CFG&#x2F;DFG，我们可以构建更高层次的图：</p><ul><li><strong>函数调用图</strong>（Call Graph）：节点是函数，边是调用关系。静态调用图（通过代码分析构建）和动态调用图（通过运行时 profiling 构建）各有优劣。</li><li><strong>类继承图</strong>（Class Hierarchy）：OOP 代码的骨架，显示 is-a 关系。</li><li><strong>模块依赖图</strong>（Module Dependency Graph）：包&#x2F;模块级别的依赖关系，直接关联构建系统（Maven、npm、Cargo）。</li><li><strong>数据模型图</strong>（Entity-Relationship）：数据库 schema 和 ORM 模型的结构。</li></ul><h3 id="5-2-CodexGraph：图数据库-LLM-Agent"><a href="#5-2-CodexGraph：图数据库-LLM-Agent" class="headerlink" title="5.2 CodexGraph：图数据库 + LLM Agent"></a>5.2 CodexGraph：图数据库 + LLM Agent</h3><p>Liu 等人（2025, <em>NAACL</em>）提出了 <strong>CodexGraph</strong>，将代码库索引到图数据库（Neo4j），然后让 LLM Agent 通过生成图查询（Cypher）来导航代码库。</p><p>核心流程：</p><ol><li>解析代码库，提取符号、依赖关系、调用链</li><li>构建图数据库，节点为函数&#x2F;类&#x2F;模块，边为调用&#x2F;继承&#x2F;导入</li><li>LLM 接收用户问题，生成 Cypher 查询</li><li>执行查询，将结果反馈给 LLM 生成最终回答</li></ol><p>与直接将代码塞入 LLM 上下文窗口相比，CodexGraph 的优势在于：</p><ul><li>不受上下文长度限制</li><li>查询是精确的（图遍历），不依赖 LLM 的「注意力」</li><li>图结构天然支持多跳推理（如「找到调用了 A 的所有函数中，哪些也使用了 B 类」）</li></ul><h3 id="5-3-FalkorDB-Code-Graph"><a href="#5-3-FalkorDB-Code-Graph" class="headerlink" title="5.3 FalkorDB Code Graph"></a>5.3 FalkorDB Code Graph</h3><p>FalkorDB 提供了开箱即用的代码图分析工具，能自动从代码库中提取：</p><ul><li>函数调用关系</li><li>类继承层次</li><li>模块导入依赖</li><li>文件共变关系（经常一起修改的文件）</li></ul><p>这类工具将代码理解从「读代码」提升到「查图谱」，特别适合快速了解陌生代码库的架构。</p><h2 id="6-代码可视化方法论"><a href="#6-代码可视化方法论" class="headerlink" title="6. 代码可视化方法论"></a>6. 代码可视化方法论</h2><p>代码理解不能只靠文本——人类视觉系统的并行处理能力远超顺序阅读。Storey 等人（2005, <em>IEEE TSE</em>）的调研表明，可视化工具能显著提升开发者理解大型系统的效率。</p><h3 id="6-1-CodeCity：3D-城市隐喻"><a href="#6-1-CodeCity：3D-城市隐喻" class="headerlink" title="6.1 CodeCity：3D 城市隐喻"></a>6.1 CodeCity：3D 城市隐喻</h3><p>Wettel 和 Lanza（2007, <em>VISSOFT</em>）提出了 <strong>CodeCity</strong>，将代码库映射为一座 3D 城市：</p><ul><li><strong>建筑物</strong> &#x3D; 类：高度表示方法数量，底面积表示属性数量</li><li><strong>街区</strong> &#x3D; 包&#x2F;模块：嵌套结构对应城市的区域划分</li><li><strong>颜色</strong> &#x3D; 度量指标：如代码复杂度、修改频率、代码年龄</li></ul><p>这种隐喻直觉且强大：一眼就能发现「摩天大楼」（God Class）、「荒废街区」（长期未维护的模块）和「密集贫民窟」（高耦合区域）。</p><p><strong>CodeCharta</strong> 是 CodeCity 理念的现代开源继承者，支持从 SonarQube、Git log、Tokei 等数据源导入度量，生成交互式 3D&#x2F;2D 可视化。</p><h3 id="6-2-依赖结构矩阵（DSM）"><a href="#6-2-依赖结构矩阵（DSM）" class="headerlink" title="6.2 依赖结构矩阵（DSM）"></a>6.2 依赖结构矩阵（DSM）</h3><p>依赖结构矩阵（Design&#x2F;Dependency Structure Matrix）源自系统工程（Steward, 1981; Baldwin &amp; Clark, 2000, <em>Design Rules</em>）。在软件中，DSM 是一个 N×N 矩阵，行和列都是模块，单元格表示依赖关系。</p><p>DSM 的威力在于<strong>模式识别</strong>：</p><ul><li><strong>对角线附近的簇</strong>：紧密耦合的模块组，可能是同一个子系统</li><li><strong>远离对角线的点</strong>：跨层依赖，潜在的架构违规</li><li><strong>对称点对</strong>：双向依赖（循环依赖），通常需要重构</li></ul><p>通过矩阵重排序算法（如聚类、分区），DSM 能自动发现代码库中的模块化结构——即使开发者自己都没意识到这些边界。</p><h3 id="6-3-Treemap-与层次化可视化"><a href="#6-3-Treemap-与层次化可视化" class="headerlink" title="6.3 Treemap 与层次化可视化"></a>6.3 Treemap 与层次化可视化</h3><p>Treemap（Shneiderman, 1992, <em>ACM TOG</em>）将层次结构映射为嵌套矩形，面积与度量值成正比。在代码分析中：</p><ul><li>矩形面积 &#x3D; 文件大小（行数）</li><li>颜色 &#x3D; 代码质量指标（如测试覆盖率：绿色 → 红色）</li><li>层次 &#x3D; 目录结构</li></ul><p>Treemap 的优势是<strong>空间效率</strong>——可以在一个屏幕上展示整个代码库的概览，同时保持可交互的钻取能力。</p><h3 id="6-4-架构图自动生成"><a href="#6-4-架构图自动生成" class="headerlink" title="6.4 架构图自动生成"></a>6.4 架构图自动生成</h3><p>手动绘制架构图费时且容易过时。新一代工具尝试自动化这个过程：</p><ul><li><strong>swark</strong>：利用 LLM 分析代码结构，自动生成 Mermaid 格式的架构图</li><li><strong>Dependency Cruiser</strong>：从 JavaScript&#x2F;TypeScript 项目中提取并可视化模块依赖</li><li><strong>Madge</strong>：生成 ES6 模块的依赖关系图</li></ul><p>自动生成的架构图虽然不如手工图精美，但胜在<strong>始终与代码同步</strong>——这是文档工程中最关键的属性。</p><h2 id="7-LLM-时代的代码理解"><a href="#7-LLM-时代的代码理解" class="headerlink" title="7. LLM 时代的代码理解"></a>7. LLM 时代的代码理解</h2><p>大语言模型正在重塑代码理解的方式。从”人读代码”到”AI 辅助理解”，技术栈发生了根本变化。</p><h3 id="7-1-代码表示学习"><a href="#7-1-代码表示学习" class="headerlink" title="7.1 代码表示学习"></a>7.1 代码表示学习</h3><p>在 LLM 之前，代码表示学习已经积累了大量工作。Wan 等人（2024, <em>ACM Computing Surveys</em>）在 <em>“Deep Learning for Code Intelligence”</em> 综述中系统梳理了这条线：</p><ul><li><strong>Token 序列模型</strong>：将代码视为自然语言序列（CodeBERT, Feng et al., 2020）</li><li><strong>AST 路径模型</strong>：code2vec（Alon et al., 2019, POPL）将 AST 中的叶节点路径编码为向量</li><li><strong>图神经网络模型</strong>：在 CFG&#x2F;DFG 上运行 GNN（GGNN, Li et al., 2016, ICLR）</li><li><strong>预训练模型</strong>：CodeT5（Wang et al., 2021）、StarCoder（Li et al., 2023）</li></ul><h3 id="7-2-RAG-代码库"><a href="#7-2-RAG-代码库" class="headerlink" title="7.2 RAG + 代码库"></a>7.2 RAG + 代码库</h3><p>当代码库超过 LLM 的上下文窗口（即使是 100K+ tokens 也不够装百万行代码），RAG（Retrieval-Augmented Generation）成为必然选择。</p><p>关键技术点：</p><ul><li><strong>Embedding 策略</strong>：代码 embedding（如 Voyage Code、OpenAI code-search-ada）vs 通用文本 embedding。代码专用模型在语义检索上显著优于通用模型。</li><li><strong>分块方法</strong>：前述 cAST（Zhang et al., 2025）利用 AST 边界分块；也有基于函数&#x2F;类粒度的分块。关键原则：<strong>分块边界应与语义边界对齐</strong>。</li><li><strong>索引结构</strong>：向量索引（HNSW&#x2F;IVF）用于语义搜索，关键词索引（BM25）用于精确匹配，两者混合效果最佳。</li></ul><h3 id="7-3-Agent-based-代码探索"><a href="#7-3-Agent-based-代码探索" class="headerlink" title="7.3 Agent-based 代码探索"></a>7.3 Agent-based 代码探索</h3><p>2024-2025 年，Agent 范式在代码理解领域爆发：</p><p><strong>SWE-Agent</strong>（Yang et al., 2024, Princeton）：给 LLM 装备终端工具（文件浏览、搜索、编辑），让它自主探索代码库并修复 bug。在 SWE-bench 上取得了显著成绩。</p><p><strong>RepoAgent</strong>（2024）：自动为代码库生成文档，通过分析 AST 和调用关系，为每个函数&#x2F;类生成上下文相关的文档字符串。</p><p><strong>Aider</strong>（Gauthier, 2024）：利用 Git 仓库的 repo map（基于 Tree-sitter 提取的函数&#x2F;类签名索引）帮助 LLM 理解代码结构。repo map 是一个精巧的设计：它比完整代码小得多，但保留了足够的结构信息。</p><p>Fan 等人（2025）在 <em>“LLM-Assisted Program Analysis”</em> 综述中总结：LLM 在代码理解任务上的最大优势不是替代传统分析工具，而是<strong>作为粘合剂</strong>——将 AST 解析、类型检查、控制流分析等工具的输出整合为人类可理解的洞察。</p><h2 id="8-实战方法论：百万行代码库分析框架"><a href="#8-实战方法论：百万行代码库分析框架" class="headerlink" title="8. 实战方法论：百万行代码库分析框架"></a>8. 实战方法论：百万行代码库分析框架</h2><p>理论终须落地。以下是一个经过实践验证的四阶段框架，适用于需要快速理解大型陌生代码库的场景。</p><h3 id="第一阶段：自动化全景扫描（Day-1）"><a href="#第一阶段：自动化全景扫描（Day-1）" class="headerlink" title="第一阶段：自动化全景扫描（Day 1）"></a>第一阶段：自动化全景扫描（Day 1）</h3><p>目标：建立代码库的「地形图」，不需要读一行代码。</p><p><strong>工具链：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 1. 规模度量</span><br>tokei .                          <span class="hljs-comment"># 语言分布、代码行数</span><br>scc .                            <span class="hljs-comment"># 复杂度估算、COCOMO 成本模型</span><br><br><span class="hljs-comment"># 2. 目录结构</span><br>tree -L 3 -d                    <span class="hljs-comment"># 顶层目录结构</span><br>find . -name <span class="hljs-string">&quot;*.py&quot;</span> | <span class="hljs-built_in">head</span> -50  <span class="hljs-comment"># 关键文件发现</span><br><br><span class="hljs-comment"># 3. 依赖关系</span><br><span class="hljs-built_in">cat</span> package.json / requirements.txt / Cargo.toml  <span class="hljs-comment"># 外部依赖</span><br>madge --image graph.svg src/     <span class="hljs-comment"># 内部模块依赖图</span><br><br><span class="hljs-comment"># 4. Git 考古</span><br>git <span class="hljs-built_in">log</span> --oneline -20            <span class="hljs-comment"># 最近活动</span><br>git shortlog -sn --no-merges     <span class="hljs-comment"># 核心贡献者</span><br>git <span class="hljs-built_in">log</span> --format=format: --name-only | <span class="hljs-built_in">sort</span> | <span class="hljs-built_in">uniq</span> -c | <span class="hljs-built_in">sort</span> -rn | <span class="hljs-built_in">head</span> -20  <span class="hljs-comment"># 热点文件</span><br></code></pre></td></tr></table></figure><p><strong>产出：</strong> 一页纸的代码库概况——规模、语言、架构概貌、核心贡献者、活跃热点。</p><h3 id="第二阶段：架构层理解（Day-2-3）"><a href="#第二阶段：架构层理解（Day-2-3）" class="headerlink" title="第二阶段：架构层理解（Day 2-3）"></a>第二阶段：架构层理解（Day 2-3）</h3><p>目标：理解模块边界、核心抽象和数据流。</p><p><strong>方法：</strong></p><ol><li><strong>入口点追踪</strong>：找到 main 函数 &#x2F; HTTP handler &#x2F; 事件循环，自顶向下展开</li><li><strong>API Surface 分析</strong>：导出接口即模块契约，通过 LSP 的 <code>workspace/symbol</code> 获取所有公开符号</li><li><strong>依赖结构矩阵</strong>：使用 DSM 工具识别模块聚类和异常依赖</li><li><strong>数据流追踪</strong>：从数据库 schema 或 API 响应出发，追踪关键数据在系统中的流转路径</li></ol><h3 id="第三阶段：深度钻取（Day-4-7）"><a href="#第三阶段：深度钻取（Day-4-7）" class="headerlink" title="第三阶段：深度钻取（Day 4-7）"></a>第三阶段：深度钻取（Day 4-7）</h3><p>目标：理解关键路径的实现细节。</p><p><strong>方法：</strong></p><ol><li><strong>关键路径分析</strong>：选择 3-5 个核心用户场景，端到端跟踪代码执行路径</li><li><strong>LSP 辅助导航</strong>：善用 Go to Definition &#x2F; Find All References &#x2F; Call Hierarchy</li><li><strong>动态分析</strong>：运行代码，使用 debugger 或 tracing 工具（如 OpenTelemetry）观察实际行为</li><li><strong>代码属性图查询</strong>：用 Joern&#x2F;CodeQL 查找特定模式（如安全漏洞、性能反模式）</li></ol><h3 id="第四阶段：持续理解（Ongoing）"><a href="#第四阶段：持续理解（Ongoing）" class="headerlink" title="第四阶段：持续理解（Ongoing）"></a>第四阶段：持续理解（Ongoing）</h3><p>目标：将理解固化为可共享、可更新的知识。</p><p><strong>方法：</strong></p><ol><li><strong>文档生成</strong>：用 RepoAgent 或 LLM 自动生成 &#x2F; 补充代码文档</li><li><strong>架构决策记录</strong>（ADR）：记录关键设计决策的背景和权衡</li><li><strong>变更影响分析</strong>：每次 PR 评审时，评估变更对整体架构的影响</li><li><strong>持续可视化</strong>：CI 中集成 CodeCharta &#x2F; Dependency Cruiser，架构图随代码自动更新</li></ol><h3 id="工具链总结"><a href="#工具链总结" class="headerlink" title="工具链总结"></a>工具链总结</h3><table><thead><tr><th>层次</th><th>工具</th><th>用途</th></tr></thead><tbody><tr><td>语法</td><td>Tree-sitter, ANTLR</td><td>AST 解析</td></tr><tr><td>语义</td><td>Joern, CodeQL</td><td>CPG 分析、模式查询</td></tr><tr><td>导航</td><td>LSP, SCIP, Sourcegraph</td><td>符号导航、引用查找</td></tr><tr><td>图谱</td><td>Neo4j + CodexGraph, FalkorDB</td><td>代码知识图谱</td></tr><tr><td>可视化</td><td>CodeCharta, Madge, DSM</td><td>架构可视化</td></tr><tr><td>AI</td><td>Aider, SWE-Agent, RAG</td><td>LLM 辅助理解</td></tr><tr><td>度量</td><td>tokei, scc, SonarQube</td><td>规模与质量度量</td></tr></tbody></table><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>理解大型代码库不是一个单一工具能解决的问题，而是一个<strong>多层次、多视角的认知过程</strong>。从 AST 的语法表示到 CPG 的语义融合，从 LSP 的精确导航到 CodeCity 的直觉可视化，从传统程序分析到 LLM Agent 的智能探索——每一层技术都在解决不同维度的理解挑战。</p><p>关键洞察：</p><ol><li><strong>代码不是文本</strong>：用结构化方法（AST、CFG、类型系统）理解代码，效率远超文本搜索</li><li><strong>图是代码的自然语言</strong>：函数调用图、依赖图、CPG 都在说明代码天然是图结构的</li><li><strong>可视化是认知加速器</strong>：人类视觉系统的并行处理能力是线性阅读的几百倍</li><li><strong>LLM 是粘合剂，不是替代品</strong>：最好的代码理解系统是传统分析工具 + LLM 的混合架构</li><li><strong>理解是持续过程</strong>：代码在变化，理解也需要持续更新</li></ol><p>在 AI Agent 时代，我们正在接近一个令人兴奋的目标：让机器帮助人类理解机器创造的复杂性。这不是讽刺——这是工程的本质。</p><hr><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li>Allen, F. E. (1970). Control Flow Analysis. <em>ACM SIGPLAN Notices</em>, 5(7), 1-19.</li><li>Alon, U., et al. (2019). code2vec: Learning Distributed Representations of Code. <em>POPL 2019</em>.</li><li>Baldwin, C. Y., &amp; Clark, K. B. (2000). <em>Design Rules: The Power of Modularity</em>. MIT Press.</li><li>Brooks, F. P. (1987). No Silver Bullet: Essence and Accidents of Software Engineering. <em>Computer</em>, 20(4).</li><li>Brunsfeld, M. (2018). Tree-sitter: A New Parsing System for Programming Tools. <em>GitHub</em>.</li><li>Fan, G., et al. (2025). LLM-Assisted Program Analysis: A Survey. <em>arXiv preprint</em>.</li><li>Feng, Z., et al. (2020). CodeBERT: A Pre-Trained Model for Programming and Natural Languages. <em>EMNLP 2020</em>.</li><li>Hindley, R. (1969). The Principal Type-Scheme of an Object in Combinatory Logic. <em>Transactions of the AMS</em>.</li><li>Jiang, L., et al. (2007). Deckard: Scalable and Accurate Tree-Based Detection of Code Clones. <em>ICSE 2007</em>.</li><li>Kildall, G. A. (1973). A Unified Approach to Global Program Optimization. <em>POPL 1973</em>.</li><li>Lehman, M. M. (1980). Programs, Life Cycles, and Laws of Software Evolution. <em>Proc. IEEE</em>, 68(9).</li><li>Liu, X., et al. (2025). CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases. <em>NAACL 2025</em>.</li><li>Milner, R. (1978). A Theory of Type Polymorphism in Programming. <em>JCSS</em>, 17(3).</li><li>Potvin, R., &amp; Levenberg, J. (2016). Why Google Stores Billions of Lines of Code in a Single Repository. <em>Communications of the ACM</em>, 59(7).</li><li>Shneiderman, B. (1992). Tree Visualization with Tree-Maps: 2-D Space-Filling Approach. <em>ACM TOG</em>, 11(1).</li><li>Storey, M. A., et al. (2005). Theories, Tools and Research Methods in Program Comprehension. <em>IEEE TSE</em>.</li><li>Sun, Z., et al. (2024). AST4PLU: AST for Programming Language Understanding. <em>ACM TOSEM</em>.</li><li>von Mayrhauser, A., &amp; Vans, A. M. (1995). Program Comprehension During Software Maintenance and Evolution. <em>IEEE Computer</em>, 28(8).</li><li>Wan, Y., et al. (2024). Deep Learning for Code Intelligence: Survey and Benchmark. <em>ACM Computing Surveys</em>.</li><li>Wettel, R., &amp; Lanza, M. (2007). Visualizing Software Systems as Cities. <em>VISSOFT 2007</em>.</li><li>Yamaguchi, F., et al. (2014). Modeling and Discovering Vulnerabilities with Code Property Graphs. <em>IEEE S&amp;P 2014</em>.</li><li>Yang, J., et al. (2024). SWE-Agent: Agent-Computer Interfaces Enable Automated Software Engineering. <em>Princeton University</em>.</li><li>Zhang, Y., et al. (2025). cAST: Chunking with AST for RAG. <em>EMNLP 2025 Findings</em>.</li></ol><hr><p><img src="/images/yiheyuan_ink.png" alt="颐和园水墨画 —— GPT gpt-image-1.5 生成"></p><p><em>🎨 AI 生成的颐和园水墨画（GPT gpt-image-1.5）。细心的读者可能注意到了——十七孔桥被画成了十四孔桥。看来大模型的「幻觉」不只存在于文本，在数数这件事上，视觉模型也未能幸免。这大概也算是本文主题的一个生动注脚：理解复杂结构，无论对人还是对AI，都不是一件容易的事。</em></p>]]></content>
    
    
    <categories>
      
      <category>深度分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>代码分析</tag>
      
      <tag>AST</tag>
      
      <tag>LSP</tag>
      
      <tag>代码可视化</tag>
      
      <tag>程序理解</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Agent Loop 与 Agent RL：驱动 AI Agent 完成长任务的算法全景</title>
    <link href="/2026/02/13/agent-loop-and-agent-rl-algorithms-2026/"/>
    <url>/2026/02/13/agent-loop-and-agent-rl-algorithms-2026/</url>
    
    <content type="html"><![CDATA[<h2 id="引言：从聊天机器人到自主智能体"><a href="#引言：从聊天机器人到自主智能体" class="headerlink" title="引言：从聊天机器人到自主智能体"></a>引言：从聊天机器人到自主智能体</h2><p>2025-2026 年，AI Agent 迎来了从「对话助手」到「自主执行者」的质变。过去，构建一个 AI Agent 的方法极其简单——拿一个大语言模型（LLM），套一个 while 循环，给它接上工具 API，就能完成简单任务。但当任务变得复杂（比如深度研究、代码重构、多步决策），这种朴素架构就会崩溃。</p><p>Agent 领域正在经历一场深刻的范式转移：<strong>从基于提示工程的静态 Agent，走向基于强化学习的自适应 Agent</strong>。本文将系统梳理驱动 Agent 完成长任务的各类算法与架构，从经典的 Agent Loop 到前沿的 Agentic RL。</p><hr><h2 id="一、Agent-Loop：基础循环架构"><a href="#一、Agent-Loop：基础循环架构" class="headerlink" title="一、Agent Loop：基础循环架构"></a>一、Agent Loop：基础循环架构</h2><h3 id="1-1-最简-Agent-循环"><a href="#1-1-最简-Agent-循环" class="headerlink" title="1.1 最简 Agent 循环"></a>1.1 最简 Agent 循环</h3><p>最基础的 Agent 架构可以抽象为一个循环：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs css">while not done:<br>    thought = LLM.<span class="hljs-built_in">think</span>(context)<br>    action = LLM.<span class="hljs-built_in">decide</span>(thought)<br>    observation = environment.<span class="hljs-built_in">execute</span>(action)<br>    context.<span class="hljs-built_in">append</span>(observation)<br></code></pre></td></tr></table></figure><p>这就是所谓的 <strong>Agent 1.0 架构</strong>。LLM 充当「大脑」，在循环中反复执行「思考→行动→观察」直到任务完成或达到终止条件。</p><h3 id="1-2-ReAct：推理与行动的交错"><a href="#1-2-ReAct：推理与行动的交错" class="headerlink" title="1.2 ReAct：推理与行动的交错"></a>1.2 ReAct：推理与行动的交错</h3><p><strong>ReAct（Reasoning and Acting）</strong> 是最经典的 Agent Loop 框架，由 Yao 等人于 2022 年提出。其核心思想是让 LLM 交替生成推理步骤和执行动作：</p><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs fortran">循环流程：<br>Thought → <span class="hljs-keyword">Action</span> → Observation → Thought → <span class="hljs-keyword">Action</span> → Observation → ... → <span class="hljs-keyword">Final</span> Answer<br></code></pre></td></tr></table></figure><p><strong>关键设计：</strong></p><ul><li><strong>Thought（思考）</strong>：LLM 内部推理，分析当前状态，制定下一步计划</li><li><strong>Action（行动）</strong>：调用外部工具（搜索、计算、API 等）</li><li><strong>Observation（观察）</strong>：接收工具返回结果，更新上下文</li></ul><p>ReAct 的优势在于推理过程透明可追踪，但在长任务中会遇到严重问题：上下文窗口被大量历史信息污染，导致模型「迷失方向」。</p><p><img src="/images/agent-loop-react.png" alt="Agent Loop ReAct 架构"><br><em>图：ReAct 的核心循环——Thought（推理）→ Action（行动）→ Observation（观察）交替执行，直到任务完成。</em></p><h3 id="1-3-Plan-and-Execute：先规划后执行"><a href="#1-3-Plan-and-Execute：先规划后执行" class="headerlink" title="1.3 Plan-and-Execute：先规划后执行"></a>1.3 Plan-and-Execute：先规划后执行</h3><p>为解决 ReAct 在长任务中的漂移问题，<strong>Plan-and-Execute</strong> 架构将任务分为两个阶段：</p><ol><li><strong>规划阶段（Planner）</strong>：LLM 分析任务，生成分步计划</li><li><strong>执行阶段（Executor）</strong>：按计划逐步执行，每步可调用工具</li><li><strong>重规划（Re-Planner）</strong>：根据执行结果动态调整剩余计划</li></ol><figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs smali">Plan: [Step1, Step2, Step3, Step4]<br>Execute Step1 → Result1<br>Re-Plan: [Step2&#x27;, Step3, Step4]  // 根据 Result1 调整<br>Execute Step2&#x27; → Result2<br><span class="hljs-keyword">.</span>..<br></code></pre></td></tr></table></figure><p>这种架构的优势是目标感更强，不容易在长链推理中丧失方向。</p><h3 id="1-4-ReWOO：推理与观察解耦"><a href="#1-4-ReWOO：推理与观察解耦" class="headerlink" title="1.4 ReWOO：推理与观察解耦"></a>1.4 ReWOO：推理与观察解耦</h3><p><strong>ReWOO（Reasoning Without Observation）</strong> 进一步优化了 Plan-and-Execute 模式：</p><ul><li>先一次性生成完整的推理计划和所有工具调用</li><li>并行执行所有工具调用</li><li>最后综合所有结果生成答案</li></ul><p>优势是减少 LLM 调用次数，提升效率；但牺牲了动态调整能力。</p><hr><h2 id="二、高级推理框架：从线性到树状再到自我进化"><a href="#二、高级推理框架：从线性到树状再到自我进化" class="headerlink" title="二、高级推理框架：从线性到树状再到自我进化"></a>二、高级推理框架：从线性到树状再到自我进化</h2><p>上一节的 Agent Loop 架构解决了”如何让 LLM 与外部世界交互”的问题，但它们都面临一个共同瓶颈：<strong>推理质量</strong>。ReAct 按顺序执行每一步，一旦某步方向错误，整个链条就会偏离正确路径。Plan-and-Execute 有规划能力，但规划本身也可能出错，且无法在推理层面进行深度探索。</p><p>这就引出了一个核心问题：<strong>如何让 LLM 在推理过程中更智能地搜索和探索？</strong></p><p>答案隐藏在三个递进的范式中：CoT（线性思考）→ ToT（树状探索）→ Reflexion&#x2F;LATS（自我进化的搜索）。</p><h3 id="2-1-Chain-of-Thought（CoT）：思维链推理"><a href="#2-1-Chain-of-Thought（CoT）：思维链推理" class="headerlink" title="2.1 Chain-of-Thought（CoT）：思维链推理"></a>2.1 Chain-of-Thought（CoT）：思维链推理</h3><p>CoT 是 Agent 推理的基石。2022 年 Wei 等人在 Google Brain 的工作揭示了一个关键发现：只需在提示中加入”Let’s think step by step”，就能让 LLM 将复杂问题拆解为一系列中间推理步骤，显著提升数学、逻辑和常识推理的准确率。</p><p><strong>CoT 的核心机制：</strong></p><ul><li>LLM 不再直接输出最终答案，而是生成一条<strong>线性推理链</strong></li><li>每个中间步骤为后续步骤提供额外的”证据”或约束条件</li><li>从概率角度看，这相当于对模型输出分布的贝叶斯更新——每一步都缩小了解空间</li></ul><p><strong>一个典型例子：</strong></p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs tap">问题：停车场有3排车，每排8辆，又开走了4辆，还剩多少辆？<br><br>CoT 推理链：<br>Step 1: 总共有<span class="hljs-number"> 3 </span>×<span class="hljs-number"> 8 </span>=<span class="hljs-number"> 24 </span>辆车<br>Step 2: 开走了<span class="hljs-number"> 4 </span>辆<br>Step 3: 剩下<span class="hljs-number"> 24 </span>-<span class="hljs-number"> 4 </span>=<span class="hljs-number"> 20 </span>辆<br>答案：20 辆<br></code></pre></td></tr></table></figure><p>然而，CoT 作为一条<strong>单一的线性链条</strong>，存在三个根本性局限：</p><p><strong>① 不可回溯（No Backtracking）</strong><br>一旦某一步推理出错，错误会沿着链条一路传播，无法返回修正。就像在迷宫中只能一直往前走，走错了也不能回头。</p><p><strong>② 无法探索多条路径（No Branching）</strong><br>面对有多种可能解法的问题，CoT 只能选择一条路走到底。比如解数学题时，可能有代数法和几何法两条路径，CoT 只会选择一条。</p><p><strong>③ 缺乏自我评估（No Self-Evaluation）</strong><br>链条上的每一步都没有被评估是否合理，模型无法判断当前方向是否正确，只能盲目前进。</p><p>CoT-SC（Self-Consistency）通过<strong>并行采样多条独立链条</strong>然后投票选择最佳答案，部分缓解了上述问题——但每条链条之间仍然是完全独立的，无法共享中间发现，也无法在关键决策点分叉探索。</p><h3 id="2-2-从-CoT-到-ToT：为什么需要进化？"><a href="#2-2-从-CoT-到-ToT：为什么需要进化？" class="headerlink" title="2.2 从 CoT 到 ToT：为什么需要进化？"></a>2.2 从 CoT 到 ToT：为什么需要进化？</h3><p>正是 CoT 的上述三个局限催生了 Tree-of-Thoughts（ToT）。让我们通过一个经典问题来理解这个进化的必要性：</p><p><strong>Game of 24 问题</strong>：用 4、5、6、10 四个数字和加减乘除，组合出结果为 24。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs routeros">CoT 的困境：<br><span class="hljs-keyword">Step</span> 1: 尝试 4 × 6 = 24<span class="hljs-built_in">..</span>. 但还剩 5 和 10 没用<br><span class="hljs-keyword">Step</span> 2: 好像不行，但已经无法回头了<br>→ 失败，只能从头再来一次（但新的一次完全独立，不会记住上次的教训）<br><br>ToT 的优势：<br>          4, 5, 6, 10<br>        /      |       \<br>   4+<span class="hljs-attribute">5</span>=9    4×<span class="hljs-attribute">6</span>=24    <span class="hljs-attribute">10-6</span>=4<br>   /    \     ✗(剩余无法凑)  /   \<br> 9×(10-6)  6×(10-5)   4×<span class="hljs-attribute">5</span>=20  <span class="hljs-built_in">..</span>.<br> =9×<span class="hljs-attribute">4</span>=36✗  =6×<span class="hljs-attribute">5</span>=30✗   20+<span class="hljs-attribute">4</span>=24? ✗(4已用)<br>                        ↑ 回溯，换路<br></code></pre></td></tr></table></figure><p>ToT 在每一步都可以<strong>分叉探索多个方向</strong>，在发现死路时<strong>回溯</strong>到之前的节点尝试其他路径。</p><h3 id="2-3-Tree-of-Thoughts（ToT）：树状搜索推理"><a href="#2-3-Tree-of-Thoughts（ToT）：树状搜索推理" class="headerlink" title="2.3 Tree-of-Thoughts（ToT）：树状搜索推理"></a>2.3 Tree-of-Thoughts（ToT）：树状搜索推理</h3><p>ToT（由 Yao 等人于 2023 年在普林斯顿提出）将推理从线性链扩展为<strong>树状结构</strong>，本质上是将经典搜索算法引入 LLM 推理过程。</p><p><strong>ToT 的四大核心组件：</strong></p><p><strong>① 思维分解（Thought Decomposition）</strong><br>将问题拆解为适当粒度的”思维单元”。粒度选择至关重要——太细则搜索空间爆炸，太粗则失去探索灵活性。比如写一篇文章，一个思维单元可以是”段落大纲”而非”单个句子”。</p><p><strong>② 思维生成（Thought Generation）</strong><br>在每个节点生成 k 个候选思维，有两种策略：</p><ul><li><strong>采样（Sample）</strong>：独立生成多个候选（适合创意性任务，解空间大）</li><li><strong>提议（Propose）</strong>：基于前文依次生成（适合逻辑性任务，避免重复）</li></ul><p><strong>③ 状态评估（State Evaluation）</strong><br>这是 ToT 最关键的创新——<strong>用 LLM 自己来评估每个中间状态的质量</strong>：</p><ul><li><strong>打分法</strong>：对每个状态评分（如 1-10 分，或”确定&#x2F;可能&#x2F;不可能”）</li><li><strong>投票法</strong>：让 LLM 比较多个候选，选出最有前途的</li></ul><p>评估函数充当了”导航仪”的角色，告诉搜索算法哪些方向值得继续探索、哪些应该剪枝放弃。</p><p><strong>④ 搜索算法（Search Algorithm）</strong><br>ToT 支持两种经典搜索策略：</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-tag">BFS</span>（广度优先）：                    <span class="hljs-selector-tag">DFS</span>（深度优先）：<br>层层扩展，不遗漏                     一条路走到底，走不通再回头<br><br><span class="hljs-selector-tag">Level</span> <span class="hljs-number">0</span>:    <span class="hljs-selector-attr">[A]</span>                     探索顺序：<span class="hljs-selector-tag">A</span> → <span class="hljs-selector-tag">B</span> → <span class="hljs-selector-tag">D</span> → (回溯) → <span class="hljs-selector-tag">E</span> → (回溯)<br><span class="hljs-selector-tag">Level</span> <span class="hljs-number">1</span>:  <span class="hljs-selector-attr">[B]</span> <span class="hljs-selector-attr">[C]</span>                              → <span class="hljs-selector-tag">C</span> → <span class="hljs-selector-tag">F</span> → ✓ 找到解<br><span class="hljs-selector-tag">Level</span> <span class="hljs-number">2</span>: <span class="hljs-selector-attr">[D]</span><span class="hljs-selector-attr">[E]</span><span class="hljs-selector-attr">[F]</span><span class="hljs-selector-attr">[G]</span><br><br>适合：解空间较小，需要最优解           适合：解空间大，需要尽快找到一个可行解<br></code></pre></td></tr></table></figure><p><strong>ToT 解决了 CoT 的三大痛点：</strong></p><table><thead><tr><th>CoT 的局限</th><th>ToT 的解决方案</th></tr></thead><tbody><tr><td>不可回溯</td><td>DFS 自然支持回溯，发现死路可返回上一节点</td></tr><tr><td>无法分叉探索</td><td>每个节点可生成 k 个候选分支</td></tr><tr><td>缺乏自我评估</td><td>状态评估函数在每步进行质量判断</td></tr></tbody></table><p><strong>代价是什么？</strong> ToT 需要更多的 LLM 调用（生成 + 评估），计算成本显著高于 CoT。这是”搜索质量”与”计算成本”之间的经典权衡——和 AlphaGo 的蒙特卡洛树搜索是同一种思想。</p><p><img src="/images/cot-vs-tot-comparison.png" alt="CoT vs ToT 推理结构对比"><br><em>图：CoT 线性链 vs ToT 树状搜索的结构差异。CoT 只能沿单一路径前进，ToT 在每步分叉并评估，支持回溯探索。</em></p><h3 id="2-4-Reflexion：自我反思学习"><a href="#2-4-Reflexion：自我反思学习" class="headerlink" title="2.4 Reflexion：自我反思学习"></a>2.4 Reflexion：自我反思学习</h3><p>ToT 解决了”单次推理中的探索问题”，但还有一个更深层的问题没有解决：<strong>跨任务的经验积累</strong>。人类在失败后会反思总结教训，下次遇到类似问题时表现更好。CoT 和 ToT 都没有这种”从失败中学习”的能力——每次推理都从零开始。</p><p><strong>Reflexion</strong> 引入了一个关键的「反思」闭环，让 Agent 能在多次尝试之间积累经验：</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">Trial 1</span><span class="hljs-punctuation">:</span> <span class="hljs-string">Actor 执行 → 得到结果 → Evaluator 评判 → 失败 ❌</span><br>         <span class="hljs-attribute">↓</span><br><span class="hljs-attribute">    Self-Reflection</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;我在第3步选错了API，应该用search而不是lookup&quot;</span><br>         <span class="hljs-attribute">↓  反思摘要存入长期记忆</span><br><span class="hljs-attribute">Trial 2</span><span class="hljs-punctuation">:</span> <span class="hljs-string">Actor 带着反思记忆重新执行 → 改进但仍有问题 ❌</span><br>         <span class="hljs-attribute">↓</span><br><span class="hljs-attribute">    Self-Reflection</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;API调对了，但参数格式不对，应该用JSON而非字符串&quot;</span><br>         <span class="hljs-attribute">↓  追加到长期记忆</span><br><span class="hljs-attribute">Trial 3</span><span class="hljs-punctuation">:</span> <span class="hljs-string">Actor 综合两次教训执行 → 成功 ✅</span><br></code></pre></td></tr></table></figure><p>Reflexion 包含三个核心组件的协作循环：</p><ul><li><strong>Actor（执行器）</strong>：基于 ReAct 或 CoT 的执行引擎，负责实际操作</li><li><strong>Evaluator（评估器）</strong>：判断执行结果的成功&#x2F;失败，提供二元或标量反馈信号</li><li><strong>Self-Reflection（反思器）</strong>：最核心的创新——将失败经验转化为自然语言反思摘要，存入一个持久的<strong>语言记忆（verbal memory）</strong></li></ul><p><strong>为什么用语言记忆而不是梯度更新？</strong> 这是 Reflexion 最巧妙的设计——传统 RL 通过更新模型权重来学习，成本极高且需要大量样本。Reflexion 用自然语言存储教训（如”不要用 deprecated API v1，改用 v2”），轻量、可解释，而且在推理时通过上下文注入即可使用。</p><p><strong>Reflexion 在编程任务上的惊人效果：</strong></p><ul><li>HumanEval 上从 80.1%（CoT 基线）提升到 91.0%（+11%）</li><li>其中约 40% 的错误在第二次尝试时就被修正</li><li>这证明了”反思+重试”机制的强大——很多错误不需要更强的模型，只需要从失败中学到教训</li></ul><p><img src="/images/reflexion-learning-loop.png" alt="Reflexion 自我反思学习循环"><br><em>图：Reflexion 的三组件反思循环——Actor 执行、Evaluator 评判、Self-Reflection 生成语言化教训存入记忆，驱动下一次尝试改进。</em></p><h3 id="2-5-从-ToT-到-LATS：统一搜索、行动与反思"><a href="#2-5-从-ToT-到-LATS：统一搜索、行动与反思" class="headerlink" title="2.5 从 ToT 到 LATS：统一搜索、行动与反思"></a>2.5 从 ToT 到 LATS：统一搜索、行动与反思</h3><p>到这里，我们已经有了三种关键能力：</p><ul><li><strong>CoT&#x2F;ToT</strong>：推理时的搜索与探索</li><li><strong>ReAct</strong>：与外部环境的交互（工具调用）</li><li><strong>Reflexion</strong>：从失败中学习</li></ul><p>但这三种能力是<strong>各自独立</strong>的。ToT 只做推理搜索，不调用工具；ReAct 调用工具但不做搜索；Reflexion 做反思但搜索策略很原始。有没有一个框架能把这三者统一起来？</p><p><strong>LATS（Language Agent Tree Search）</strong> 正是这个统一框架。它将蒙特卡洛树搜索（MCTS）——AlphaGo 的核心算法——引入 LLM Agent 决策，将搜索、行动和反思融合为一个整体：</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs scss">                   ┌──────────────────────┐<br>                   │    MCTS 搜索循环      │<br>                   └──────────────────────┘<br>                             │<br>   ┌─────────────┬──────────┼──────────┬──────────────┐<br>   ▼             ▼          ▼          ▼              ▼<br>Selection    Expansion  Simulation  Evaluation   Backpropagation<br>(选择节点)   (生成动作)  (执行动作)  (LLM评分)    (反向传播)<br>   │             │          │          │              │<br> UCB1算法    LLM生成     调用工具    价值评估      更新节点<br> 平衡探索     候选动作    获取反馈    + 反思        质量分数<br> 与利用                              <br></code></pre></td></tr></table></figure><p><strong>MCTS 五步循环详解：</strong></p><p><strong>① Selection（选择）</strong>：用 UCB1 公式选择最值得探索的节点，自动平衡”深入已知好路径”和”尝试未探索方向”——这解决了 ToT 简单 BFS&#x2F;DFS 策略的效率问题。</p><p><strong>② Expansion（扩展）</strong>：在选中节点用 LLM 生成 n 个候选动作，每个动作可以是推理步骤或工具调用——这融合了 ToT 的分支能力和 ReAct 的工具交互。</p><p><strong>③ Simulation（模拟）</strong>：执行动作并观察环境反馈——ReAct 的核心循环。</p><p><strong>④ Evaluation（评估）</strong>：LLM 对当前状态进行价值评估，给出分数。<strong>关键创新：如果检测到失败，触发 Reflexion 式的自我反思，生成反思摘要指导后续搜索。</strong></p><p><strong>⑤ Backpropagation（反向传播）</strong>：将评估分数沿树路径回传，更新每个祖先节点的质量估计——这让 LATS 能从全局视角优化搜索方向。</p><p><strong>LATS &#x3D; ToT（搜索框架）+ ReAct（环境交互）+ Reflexion（失败学习）</strong></p><p>这种统一带来的效果是显著的：在 HotPotQA 多跳推理任务上，LATS 比单独的 ReAct 提升 16%，比 Reflexion 提升 8%，比 ToT 提升 12%。代价是更高的计算成本——但这正是”用推理时计算换取更好决策”的核心思想。</p><p><img src="/images/lats-mcts-agent.png" alt="LATS 蒙特卡洛树搜索 Agent 决策"><br><em>图：LATS 将 MCTS 的五步循环应用于 Agent 决策，统一了搜索（ToT）、行动（ReAct）和反思（Reflexion）三大能力。</em></p><hr><h2 id="三、Deep-Agent-架构：当任务跨越百步"><a href="#三、Deep-Agent-架构：当任务跨越百步" class="headerlink" title="三、Deep Agent 架构：当任务跨越百步"></a>三、Deep Agent 架构：当任务跨越百步</h2><p>LATS 统一了搜索、行动和反思，但它仍然在<strong>单个上下文窗口</strong>内运作。当任务复杂度从”几步完成”升级到”数十甚至上百步”——比如写一份完整的研究报告、重构一个大型代码库、或执行一个跨越数小时的深度研究——上下文窗口就成了不可逾越的瓶颈：推理历史、工具返回、中间结果……全部挤在有限的 token 窗口中，信噪比急剧下降。</p><p><strong>Deep Agent（深度智能体）</strong> 架构是 2025 年下半年兴起的新范式，代表产品包括 Claude Code、OpenAI Deep Research、Manus AI 等。它的核心思想是：**将 Agent 的认知从”上下文内”扩展到”上下文外”**——用外部持久化系统弥补上下文窗口的局限。</p><p><img src="/images/agent-architecture-evolution.png" alt="Agent 架构演进全景图"><br><em>图：从 ReAct 到 Deep Agent 的架构演进。每一步进化都在解决前一代的核心瓶颈：ReAct 解决了工具交互、CoT&#x2F;ToT 解决了推理搜索、Reflexion 解决了经验学习、Deep Agent 解决了长任务上下文管理。</em></p><h3 id="3-1-四大支柱"><a href="#3-1-四大支柱" class="headerlink" title="3.1 四大支柱"></a>3.1 四大支柱</h3><p>Deep Agent 架构建立在四个基础之上：</p><p><strong>① 显式规划（Explicit Planning）</strong><br>不依赖 LLM 隐式推理，而是维护一个<strong>外部的、可持久化的任务计划</strong>。计划可以被检查、修改和恢复。这意味着即使上下文窗口被清空，Agent 仍然知道自己在做什么、做到了哪一步。</p><p>以 Claude Code 为例：当它重构一个大型代码库时，会在文件系统中写入一份 <code>plan.md</code>，记录每个模块的改造状态。即使中间因为上下文溢出导致会话重置，Agent 读取 plan.md 后就能无缝继续。</p><p><strong>② 层级委派（Hierarchical Delegation）</strong><br>单个 Agent 的能力总有上限。Deep Agent 将复杂任务拆分给<strong>专门化的子 Agent</strong>，每个子 Agent 有独立的上下文窗口和专属工具集：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-keyword">Orchestrator </span>Agent（指挥官）<br>├── Research <span class="hljs-keyword">Sub-Agent（负责信息检索）→ </span>有搜索工具<br>├── Code <span class="hljs-keyword">Sub-Agent（负责代码编写）→ </span>有文件读写和终端<br>├── Review <span class="hljs-keyword">Sub-Agent（负责质量审查）→ </span>有测试工具<br>└── Memory <span class="hljs-keyword">Sub-Agent（负责信息管理）→ </span>有知识库<br></code></pre></td></tr></table></figure><p>这种设计的关键优势是<strong>上下文隔离</strong>：Research Agent 的搜索结果不会污染 Code Agent 的编码上下文。每个子 Agent 只接收与自己任务相关的信息，信噪比大幅提升。</p><p><strong>③ 持久化记忆（Persistent Memory）</strong><br>使用文件系统作为外部记忆，而非仅依赖上下文窗口。Agent 可以：</p><ul><li>写入结构化笔记和发现摘要</li><li>读取之前的研究结果</li><li>维护状态文件跟踪进度</li><li>建立知识索引便于快速检索</li></ul><p>这本质上是将人类研究员的”做笔记”习惯编码为 Agent 的核心行为——上下文窗口是”工作记忆”（短期），文件系统是”笔记本”（长期）。</p><p><strong>④ 极致的上下文工程（Extreme Context Engineering）</strong><br>精心管理什么信息进入上下文窗口。具体技术包括：</p><ul><li><strong>渐进式摘要</strong>：每隔 N 步将历史压缩为摘要</li><li><strong>选择性加载</strong>：只加载与当前子任务相关的信息</li><li><strong>上下文分层</strong>：系统提示 &gt; 当前任务 &gt; 相关历史 &gt; 可选参考</li><li><strong>智能截断</strong>：工具返回过长时自动截取关键部分</li></ul><p>以 OpenClaw 为例——它在每次 heartbeat 时读取 HEARTBEAT.md（而非全部历史），在每个 session 开始时读取 SOUL.md 和 USER.md（身份信息），只有在主 session 中才加载 MEMORY.md（长期记忆），这就是上下文工程的实际应用。</p><h3 id="3-2-CORAL：认知资源自分配"><a href="#3-2-CORAL：认知资源自分配" class="headerlink" title="3.2 CORAL：认知资源自分配"></a>3.2 CORAL：认知资源自分配</h3><p><strong>CORAL（Cognitive Resource Self-Allocation）</strong> 是 ICLR 2026 收录的工作，专门解决长任务中 Agent 的「注意力漂移」问题——当上下文中积累了太多无关信息，LLM 的注意力被分散，推理质量急剧下降。</p><p><strong>核心洞察：</strong> 人类处理长任务时，会主动”清空短期记忆”——比如写论文写了3小时后，会先休息，回来后重新读一遍大纲，而不是试图记住之前的每一个细节。CORAL 给 Agent 提供了类似的能力。</p><p><strong>工作记忆管理工具集：</strong></p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs scss">Agent 工具箱中新增三种&quot;元工具&quot;：<br><span class="hljs-number">1</span>. <span class="hljs-built_in">set_checkpoint</span>(label)  → 在关键节点保存状态快照<br><span class="hljs-number">2</span>. <span class="hljs-built_in">clear_memory</span>()         → 清除工作记忆中的杂乱信息  <br><span class="hljs-number">3</span>. <span class="hljs-built_in">restore</span>(label)         → 从指定检查点恢复推理上下文<br></code></pre></td></tr></table></figure><p>当 Agent 探索了多条路径、积累了大量搜索结果，发现自己”迷失方向”时，可以主动调用 <code>clear_memory()</code> + <code>restore(&quot;initial_plan&quot;)</code> 来重新开始——但不是完全从零开始，而是保留了检查点中的关键发现。</p><p><strong>训练方式：</strong> CORAL 使用<strong>多轮 Agentic 强化策略优化（Multi-episode Agentic Reinforced Policy Optimization）</strong> 算法，让 Agent 通过 RL 学会三个关键判断：</p><ul><li><strong>何时设置检查点</strong>（在做出重要发现或关键决策后）</li><li><strong>何时清理记忆</strong>（当上下文信噪比过低时）</li><li><strong>恢复到哪个检查点</strong>（选择最有价值的历史状态）</li></ul><p>CORAL 在 SWE-bench 等长任务基准上显著优于没有记忆管理的 Agent，验证了”主动管理认知资源”的价值——这也为 Deep Agent 架构的”极致上下文工程”提供了理论支撑。</p><hr><h2 id="四、Agentic-RL：从工程拼接到端到端学习"><a href="#四、Agentic-RL：从工程拼接到端到端学习" class="headerlink" title="四、Agentic RL：从工程拼接到端到端学习"></a>四、Agentic RL：从工程拼接到端到端学习</h2><p>前三节的所有架构——从 ReAct 到 LATS 到 Deep Agent——都属于「推理时（inference-time）」的工程技巧。它们通过精巧的提示设计、搜索算法和记忆管理来提升 Agent 表现，但<strong>模型本身并没有因此变得更强</strong>。模型权重是冻结的，所有的”聪明”都来自外部框架。</p><p>这就像给一个普通人配备了最好的工具箱、最详细的操作手册——他确实能完成更复杂的任务，但他自身的能力并没有提升。如果工具箱被拿走或手册不适用，他就回到了原点。</p><p><strong>Agentic RL</strong> 代表了一个根本性的范式转移：<strong>直接通过强化学习训练 LLM 的 Agent 行为能力</strong>，让模型在多步交互中学会规划、工具使用、错误修正——这些能力被编码进模型权重，而非依赖外部框架。</p><h3 id="4-1-从-RLHF-到-Agentic-RL"><a href="#4-1-从-RLHF-到-Agentic-RL" class="headerlink" title="4.1 从 RLHF 到 Agentic RL"></a>4.1 从 RLHF 到 Agentic RL</h3><table><thead><tr><th>维度</th><th>RLHF</th><th>Agentic RL</th></tr></thead><tbody><tr><td>目标</td><td>让 LLM 输出更符合人类偏好</td><td>让 LLM 学会多步决策与工具使用</td></tr><tr><td>交互</td><td>单轮：prompt → response</td><td>多轮：action → env feedback → action</td></tr><tr><td>奖励</td><td>人类偏好评分</td><td>任务完成度 + 过程奖励</td></tr><tr><td>训练格式</td><td>单条序列</td><td>多轮轨迹（trajectory）</td></tr><tr><td>环境</td><td>无</td><td>真实或模拟环境</td></tr></tbody></table><p>Agentic RL 的核心突破在于：<strong>将 LLM 从被动的序列生成器重新定义为主动的、嵌入复杂动态世界的决策智能体。</strong></p><p><img src="/images/agentic-rl-paradigm.png" alt="Agentic RL 范式转移"><br><em>图：从推理时工程（左）到 Agentic RL 端到端训练（右）的范式转移——外部脚手架 vs 内化能力。</em></p><h3 id="4-2-Agent-R1：端到端-Agent-强化学习"><a href="#4-2-Agent-R1：端到端-Agent-强化学习" class="headerlink" title="4.2 Agent-R1：端到端 Agent 强化学习"></a>4.2 Agent-R1：端到端 Agent 强化学习</h3><p><strong>Agent-R1</strong>（中国科学技术大学，2025.11）是将 DeepSeek-R1 的 RL 训练范式扩展到 Agent 场景的里程碑工作。</p><p><strong>核心问题：为什么不能直接把 RLHF&#x2F;GRPO 套到 Agent 上？</strong></p><p>传统 RL 训练 LLM 时，轨迹（trajectory）是一个单轮序列：prompt → response。但 Agent 的轨迹是多轮交互序列，包含两种本质不同的 token：</p><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sqf">轨迹结构：<br>[System Prompt] → <span class="hljs-built_in">Agent</span>生成思考 → <span class="hljs-built_in">Agent</span>调用工具 → 环境返回结果 → <span class="hljs-built_in">Agent</span>继续思考 → ...<br>                  ↑ <span class="hljs-built_in">Agent</span> token（可训练）      ↑ 环境 token（不可训练！）<br></code></pre></td></tr></table></figure><p>关键区分：<strong>Agent 生成的 token 需要参与梯度计算，但环境返回的 token 不应该</strong>——因为你不能通过训练模型来改变环境的行为。Agent-R1 在 MDP 框架中明确建模了这个区分。</p><p><strong>MDP 扩展详解：</strong></p><table><thead><tr><th>组件</th><th>静态 LLM</th><th>Agent-R1</th></tr></thead><tbody><tr><td><strong>状态空间</strong></td><td>prompt + 已生成 token</td><td>完整对话历史 + 每轮环境反馈</td></tr><tr><td><strong>动作空间</strong></td><td>词表中选下一个 token</td><td>同上，但 token 序列可触发工具调用</td></tr><tr><td><strong>转移函数</strong></td><td>确定性（拼接 token）</td><td><strong>随机性</strong>（环境返回不确定）</td></tr><tr><td><strong>奖励函数</strong></td><td>单次终端奖励</td><td>终端奖励 + 中间过程奖励</td></tr></tbody></table><p><strong>过程奖励（Process Rewards）</strong> 是 Agent-R1 的重要创新——不只在任务完成时给奖励，在中间步骤也给信号。比如：正确调用了 search API 但查询词不够精确，可以给一个小的正奖励（鼓励工具使用）但不是满分（查询还需优化）。这解决了长任务中”奖励稀疏”的经典难题。</p><p>Agent-R1 开源了完整的训练框架（基于 veRL），支持快速接入不同环境，已在 Multi-hop QA 上验证了效果。</p><h3 id="4-3-AgentRL：多任务多轮-Agent-训练框架"><a href="#4-3-AgentRL：多任务多轮-Agent-训练框架" class="headerlink" title="4.3 AgentRL：多任务多轮 Agent 训练框架"></a>4.3 AgentRL：多任务多轮 Agent 训练框架</h3><p><strong>AgentRL</strong>（清华大学 THUDM，2025.10）是目前最系统的 Agentic RL 训练框架，其训练成果已应用于智谱的 AutoGLM。</p><p><strong>两大技术创新：</strong></p><p><strong>① 跨策略采样（Cross-Policy Sampling）</strong><br>在多轮设定中，Agent 容易陷入策略过拟合，不愿探索新策略。AgentRL 通过从多个模型策略池中采样动作，增强探索多样性：</p><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sqf">轨迹生成时：<br><span class="hljs-built_in">Step</span> <span class="hljs-number">1</span>: 从 Policy_A 采样 <span class="hljs-built_in">action</span><br><span class="hljs-built_in">Step</span> <span class="hljs-number">2</span>: 从 Policy_B 采样 <span class="hljs-built_in">action</span>  ← 跨策略<br><span class="hljs-built_in">Step</span> <span class="hljs-number">3</span>: 从 Policy_A 采样 <span class="hljs-built_in">action</span><br>...<br></code></pre></td></tr></table></figure><p><strong>② 任务优势归一化（Task Advantage Normalization）</strong><br>多任务训练时不同任务的奖励尺度差异大。对每个任务的优势值独立归一化，稳定训练：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">Advantage_normalized</span> = (Advantage - mean_task) / std_task<br></code></pre></td></tr></table></figure><p><strong>实验结果惊人：</strong> AgentRL 在五个 Agent 基准任务（ALFWorld、DB、KG、OS、Webshop）上训练开源 LLM（Qwen2.5），性能显著超越 GPT-5、Claude-Sonnet-4 和 DeepSeek-R1。</p><h3 id="4-4-DeepResearcher：真实环境中的-RL-训练"><a href="#4-4-DeepResearcher：真实环境中的-RL-训练" class="headerlink" title="4.4 DeepResearcher：真实环境中的 RL 训练"></a>4.4 DeepResearcher：真实环境中的 RL 训练</h3><p><strong>DeepResearcher</strong>（上海交通大学 GAIR，2025.4，EMNLP 2025 收录）是首个在真实 Web 搜索环境中端到端训练 Agent 的框架。</p><p><strong>为什么 RAG 环境训练不够？</strong></p><p>之前的 RL 训练工作（如 Search-R1、R1-Searcher）都在 RAG 环境中进行——给模型一个固定语料库，模型从中检索信息。这种方式有一个致命假设：<strong>所有需要的信息已经在语料库里了</strong>。但现实世界不是这样的：</p><ul><li>信息可能不存在于语料库中</li><li>信息可能已经过时</li><li>需要跨多个领域综合多个来源</li><li>网页格式杂乱，充满噪声和反爬机制</li></ul><p>DeepResearcher 直接在开放互联网环境中训练，Agent 需要面对真实的搜索引擎、真实的网页（包括乱码、广告、反爬）。</p><p><strong>多 Agent 架构设计：</strong></p><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sqf">Main <span class="hljs-built_in">Agent</span>（推理决策者）<br>    │<br>    ├── 决定搜索什么关键词<br>    ├── 分析搜索结果摘要<br>    ├── 决定深入哪些网页<br>    │       ↓<br>    └── Browsing <span class="hljs-built_in">Agent</span>（网页浏览者）<br>            ├── 加载完整网页<br>            ├── 提取相关信息<br>            └── 返回结构化摘要给 Main <span class="hljs-built_in">Agent</span><br></code></pre></td></tr></table></figure><p>Main Agent 负责高层决策（搜什么、看哪个、如何综合），Browsing Agent 负责底层信息提取——这比 RAG 系统”直接返回文本片段”要灵活得多。</p><p><strong>训练后涌现的四种认知行为（最惊喜的发现）：</strong></p><ol><li><p><strong>自主规划（Planning）</strong>：Agent 自动学会了在开始研究前制定计划，并在过程中动态调整。注意——<strong>没有人教它规划</strong>，这是纯 RL 训练涌现的行为！甚至还会”合并步骤”来提高效率。</p></li><li><p><strong>交叉验证（Cross-Validation）</strong>：Agent 找到一个答案后，不会立即接受，而是继续搜索其他来源来验证。这种”不轻信第一个结果”的审慎行为也是自发涌现的。</p></li><li><p><strong>自我反思与重定向（Self-Reflection）</strong>：发现当前搜索方向不对时，Agent 会主动调整关键词或换一个完全不同的搜索策略。</p></li><li><p><strong>诚实性（Honesty）</strong>：当确实找不到确定答案时，Agent 会坦诚说明，而非编造一个看似合理的答案。</p></li></ol><p><strong>量化结果：</strong> DeepResearcher 在 7 个开放域研究数据集上，比提示工程方案提升高达 <strong>28.9 分</strong>，比 RAG 环境 RL 方案提升 <strong>7.2 分</strong>。这证明了一个核心结论：<strong>在真实环境中训练不是可选的优化，而是开发稳健研究能力的根本需求。</strong></p><h3 id="4-5-通义-DeepResearch：全栈-Agent-训练流水线"><a href="#4-5-通义-DeepResearch：全栈-Agent-训练流水线" class="headerlink" title="4.5 通义 DeepResearch：全栈 Agent 训练流水线"></a>4.5 通义 DeepResearch：全栈 Agent 训练流水线</h3><p>阿里通义团队（2025.9）提出了一套完整的 Agent 训练流程：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">阶段1: Agentic Pre-training（预训练阶段引入工具使用能力）</span><br>    ↓<br><span class="hljs-section">阶段2: Supervised Fine-tuning（用专家数据冷启动）</span><br>    ↓<br><span class="hljs-section">阶段3: On-policy RL（在线强化学习自进化）</span><br></code></pre></td></tr></table></figure><p>这套「预训练 → SFT → RL」的三阶段流程被验证为训练 Deep Research Agent 的有效范式。</p><hr><h2 id="五、推理时搜索：第三条路径"><a href="#五、推理时搜索：第三条路径" class="headerlink" title="五、推理时搜索：第三条路径"></a>五、推理时搜索：第三条路径</h2><p>前四节讨论了两条提升 Agent 能力的路径：</p><ul><li><strong>路径 A：推理时工程</strong>（更好的框架、搜索算法、记忆管理）</li><li><strong>路径 B：训练时学习</strong>（通过 RL 直接提升模型能力）</li></ul><p>还有<strong>路径 C</strong>——<strong>在推理时投入更多计算</strong>。不改变模型权重，也不依赖复杂的外部框架，而是让模型”想更久”。</p><h3 id="5-1-推理时计算扩展（Inference-Time-Scaling）"><a href="#5-1-推理时计算扩展（Inference-Time-Scaling）" class="headerlink" title="5.1 推理时计算扩展（Inference-Time Scaling）"></a>5.1 推理时计算扩展（Inference-Time Scaling）</h3><p>OpenAI 的 o1&#x2F;o3&#x2F;o4 系列揭示了一个令人振奋的发现：<strong>推理时的计算量和推理质量之间存在近似对数线性的正相关关系</strong>。换句话说，让模型多花 10 倍算力”思考”，可以获得显著的质量提升。</p><p>核心技术手段包括：</p><ul><li><strong>内部思维链（Internal CoT）</strong>：模型在输出前进行长链隐式推理，这些推理 token 消耗计算但不一定展示给用户</li><li><strong>搜索与回溯</strong>：多条推理路径并行探索，选择最优路径——本质上和 ToT 异曲同工，但被编码进了模型的推理行为中</li><li><strong>自我验证</strong>：模型生成候选答案后，自己检查答案的正确性，如有问题则重新推理</li><li><strong>自适应计算分配</strong>：简单问题少想，复杂问题多想——模型学会了”量力而行”</li></ul><p>这解释了为什么 o3&#x2F;o4 在某些数学竞赛题上表现惊人——它们可能在单个问题上花费了相当于普通模型数百次调用的算力。</p><h3 id="5-2-AB-MCTS：自适应分支蒙特卡洛树搜索"><a href="#5-2-AB-MCTS：自适应分支蒙特卡洛树搜索" class="headerlink" title="5.2 AB-MCTS：自适应分支蒙特卡洛树搜索"></a>5.2 AB-MCTS：自适应分支蒙特卡洛树搜索</h3><p><strong>AB-MCTS（Adaptive Branching MCTS）</strong>（Sakana AI）将这个思想推向了多模型协作的维度：</p><p><strong>核心思想：</strong> 不是一个模型自己搜索，而是<strong>多个不同的 LLM 协作进行蒙特卡洛树搜索</strong>。每个模型有不同的偏好和盲点，多模型搜索可以获得更全面的探索覆盖。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs css">搜索树的每个节点：<br>├── GPT-<span class="hljs-number">5</span> 生成候选 <span class="hljs-selector-tag">A</span> → 评分 <span class="hljs-number">0.7</span><br>├── Claude 生成候选 <span class="hljs-selector-tag">B</span> → 评分 <span class="hljs-number">0.9</span>  ← 选中展开<br>└── Gemini 生成候选 C → 评分 <span class="hljs-number">0.5</span><br><br>下一层继续多模型扩展...<br></code></pre></td></tr></table></figure><p><strong>自适应分支</strong> 是关键创新：不固定每个节点的分支数，而是根据当前问题的难度和搜索进展动态调整。简单部分少分支快速通过，困难部分多分支深度探索。</p><p>AB-MCTS 代表了推理时搜索的前沿方向：不改变任何模型的权重，而是通过更聪明的搜索编排来突破单模型的能力上限。这和下棋中的思想完全一致——棋手的水平（模型能力）是固定的，但花更多时间思考（搜索更多变化）总能下出更好的棋。</p><h3 id="5-3-三条路径的关系"><a href="#5-3-三条路径的关系" class="headerlink" title="5.3 三条路径的关系"></a>5.3 三条路径的关系</h3><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sqf">         <span class="hljs-built_in">Agent</span> 能力提升<br>        /       |       \<br>  路径 A        路径 B        路径 C<br>推理时工程    训练时学习    推理时计算<br>(ReAct,ToT,   (Agentic RL,  (o1-style,<br> Deep <span class="hljs-built_in">Agent</span>)   <span class="hljs-built_in">Agent</span>-R1)     AB-MCTS)<br>     ↓            ↓            ↓<br>模型不变,       模型变强,     模型不变,<br>外部框架优化    内化能力      多花算力思考<br></code></pre></td></tr></table></figure><p>实践中，三条路径并不互斥——最强的 Agent 系统同时使用了全部三条：强 RL 训练的基座模型（路径 B）+ 推理时多步搜索（路径 C）+ 外部记忆和工具管理（路径 A）。</p><hr><h2 id="六、实用建议：如何选择-Agent-架构"><a href="#六、实用建议：如何选择-Agent-架构" class="headerlink" title="六、实用建议：如何选择 Agent 架构"></a>六、实用建议：如何选择 Agent 架构</h2><h3 id="任务复杂度-vs-架构选择"><a href="#任务复杂度-vs-架构选择" class="headerlink" title="任务复杂度 vs 架构选择"></a>任务复杂度 vs 架构选择</h3><table><thead><tr><th>任务类型</th><th>推荐架构</th><th>代表方案</th></tr></thead><tbody><tr><td>简单工具调用（天气&#x2F;搜索）</td><td>ReAct</td><td>LangChain ReAct Agent</td></tr><tr><td>多步骤有序任务</td><td>Plan-and-Execute</td><td>LangGraph</td></tr><tr><td>需要探索的复杂推理</td><td>Tree-of-Thoughts &#x2F; LATS</td><td>自定义</td></tr><tr><td>需要从失败中学习</td><td>Reflexion</td><td>自定义</td></tr><tr><td>超长任务（100+ 步）</td><td>Deep Agent</td><td>Claude Code &#x2F; OpenClaw</td></tr><tr><td>训练专用 Agent</td><td>Agentic RL</td><td>AgentRL &#x2F; Agent-R1</td></tr><tr><td>深度研究</td><td>Deep Agent + RL</td><td>DeepResearcher</td></tr></tbody></table><h3 id="关键设计原则"><a href="#关键设计原则" class="headerlink" title="关键设计原则"></a>关键设计原则</h3><ol><li><strong>外部化一切状态</strong>：不要仅依赖上下文窗口，用文件系统持久化记忆</li><li><strong>分层委派</strong>：复杂任务拆分给专门的 Sub-Agent</li><li><strong>显式管理上下文</strong>：主动摘要和压缩，保持高信噪比</li><li><strong>建立检查点机制</strong>：允许 Agent 回溯和恢复</li><li><strong>过程奖励优于结果奖励</strong>：在训练中引入中间步骤的奖励信号</li></ol><hr><h2 id="七、展望：Agent-技术的下一步"><a href="#七、展望：Agent-技术的下一步" class="headerlink" title="七、展望：Agent 技术的下一步"></a>七、展望：Agent 技术的下一步</h2><h3 id="2026-年关键趋势"><a href="#2026-年关键趋势" class="headerlink" title="2026 年关键趋势"></a>2026 年关键趋势</h3><ol><li><strong>Agentic RL 成为标配</strong>：从提示工程走向端到端训练，直接优化 Agent 的多步决策能力</li><li><strong>Memory 成为一等公民</strong>：ICLR 2026 专门设立 MemAgents Workshop，记忆管理从「工程技巧」升级为核心研究方向</li><li><strong>多模态 Agent</strong>：Agent 不再限于文本交互，可以「看」屏幕、操作 UI、理解视觉信息</li><li><strong>自进化 Agent</strong>：Agent 能在部署后持续从真实交互中学习改进</li></ol><h3 id="核心挑战"><a href="#核心挑战" class="headerlink" title="核心挑战"></a>核心挑战</h3><ul><li><strong>安全与对齐</strong>：自主度越高，风险越大，如何确保 Agent 行为安全可控</li><li><strong>长期记忆</strong>：如何在超长任务中维持一致的目标和上下文</li><li><strong>奖励设计</strong>：复杂任务的奖励信号如何定义和分解</li><li><strong>评估基准</strong>：缺乏真正长时间跨度的 Agent 评估标准</li></ul><hr><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li>Yao, S. et al. “ReAct: Synergizing Reasoning and Acting in Language Models.” ICLR 2023.</li><li>Shinn, N. et al. “Reflexion: Language Agents with Verbal Reinforcement Learning.” NeurIPS 2023.</li><li>Wei, J. et al. “Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.” NeurIPS 2022.</li><li>Yao, S. et al. “Tree of Thoughts: Deliberate Problem Solving with Large Language Models.” NeurIPS 2023.</li><li>Zhou, A. et al. “Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models.” ICML 2024.</li><li>Cheng, M. et al. “Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning.” arXiv:2511.14460, Nov 2025.</li><li>Zhang, H. et al. “AgentRL: Scaling Agentic Reinforcement Learning with a Multi-Turn, Multi-Task Framework.” arXiv:2510.04206, Oct 2025.</li><li>Zheng, Y. et al. “DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments.” arXiv:2504.03160, Apr 2025.</li><li>Wang, R. et al. “A Practitioner’s Guide to Multi-turn Agentic Reinforcement Learning.” arXiv:2510.01132, Oct 2025.</li><li>“Don’t Lose the Thread: Empowering Long-Horizon LLM Agents with Cognitive Resource Self-Allocation (CORAL).” ICLR 2026.</li><li>“The Landscape of Agentic Reinforcement Learning for LLMs: A Survey.” TMLR, Jan 2026.</li><li>Tongyi Team. “Tongyi DeepResearch: A New Era of Open-Source AI Researchers.” Sep 2025.</li><li>OpenAI. “Introducing Deep Research.” Feb-Jul 2025.</li><li>Sakana AI. “Inference-Time Scaling and Collective Intelligence for Frontier AI (AB-MCTS).” 2025.</li></ol><hr><blockquote><p>本文系统梳理了 Agent Loop 和 Agent RL 领域的核心算法和最新进展，从经典的 ReAct 循环到前沿的 Agentic RL 训练范式。Agent 技术正在从「工程拼接」走向「端到端学习」，这将是 2026 年 AI 领域最重要的技术方向之一。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>AI 前沿</category>
      
    </categories>
    
    
    <tags>
      
      <tag>强化学习</tag>
      
      <tag>AI Agent</tag>
      
      <tag>LLM</tag>
      
      <tag>深度研究</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GitHub Trending 热榜 | 2026-02-13：Generative UI、个人 AI 基础设施、Chrome DevTools MCP</title>
    <link href="/2026/02/13/github-trending/2026-02-13/"/>
    <url>/2026/02/13/github-trending/2026-02-13/</url>
    
    <content type="html"><![CDATA[<blockquote><p>今天的 GitHub Trending 榜单有一个鲜明的主题：<strong>AI 正在从「模型」走向「基础设施」</strong>。无论是让 React 组件被 AI 动态生成的 Tambo，还是把整个个人生活用 AI Agent 武装起来的 PAI，抑或是让编程 Agent 直接操控 Chrome DevTools 的 MCP 工具——开发者们不再满足于调 API，而是在构建让 AI 真正融入工作流的基础设施。</p></blockquote><hr><h2 id="1-Tambo-—-让-AI-Agent-说你的-UI-语言"><a href="#1-Tambo-—-让-AI-Agent-说你的-UI-语言" class="headerlink" title="1. Tambo — 让 AI Agent 说你的 UI 语言"></a>1. Tambo — 让 AI Agent 说你的 UI 语言</h2><blockquote><p>⭐ 8,997 Stars | 📈 +300 today | 🟦 TypeScript | 📜 MIT</p></blockquote><h3 id="项目简介"><a href="#项目简介" class="headerlink" title="项目简介"></a>项目简介</h3><p>Tambo 是一个面向 React 的 <strong>Generative UI（生成式 UI）</strong> 开源工具包。核心理念很简单：你注册你的 React 组件并描述它们的 schema，AI Agent 在对话中自动选择合适的组件、流式生成 props、渲染出交互式 UI。</p><p>用户说「展示各地区销售额」，Agent 不是返回一段文字，而是直接渲染你的 <code>&lt;Chart&gt;</code> 组件。用户说「添加一个任务」，Agent 更新你的 <code>&lt;TaskBoard&gt;</code>。</p><h3 id="为什么火？"><a href="#为什么火？" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>Generative UI 是 2026 年前端领域最热的方向之一。传统的 AI 聊天界面只能返回文本或 Markdown，但真实的应用需要按钮、表格、图表、表单等丰富的交互组件。</p><p>Tambo 解决了这个问题的工程化难题：</p><ul><li><strong>流式 Props</strong>：LLM 生成的 props 实时流式传输到组件，不用等全部生成完</li><li><strong>状态管理内置</strong>：对话状态、组件状态、错误恢复全部封装好</li><li><strong>MCP 集成</strong>：支持 Model Context Protocol，可以和各种 Agent 框架无缝对接</li><li><strong>Cloud 或自托管</strong>：提供托管后端，也支持 Docker 自部署</li></ul><h3 id="技术亮点"><a href="#技术亮点" class="headerlink" title="技术亮点"></a>技术亮点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm create tambo-app my-tambo-app<br><span class="hljs-built_in">cd</span> my-tambo-app<br>npm run dev<br></code></pre></td></tr></table></figure><p>5 分钟就能跑起来。支持 OpenAI、Anthropic、Gemini、Mistral 等多种模型。配套了一个预构建组件库（ui.tambo.co），包含对话气泡、工具卡片、数据可视化等 Agent UI 基础组件。</p><h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li>需要在 AI 聊天中展示复杂交互界面的 SaaS 产品</li><li>企业内部的 AI 助手面板</li><li>任何想让 AI 不止返回文字的 React 应用</li></ul><hr><h2 id="2-PAI（Personal-AI-Infrastructure）—-个人-AI-基础设施"><a href="#2-PAI（Personal-AI-Infrastructure）—-个人-AI-基础设施" class="headerlink" title="2. PAI（Personal AI Infrastructure）— 个人 AI 基础设施"></a>2. PAI（Personal AI Infrastructure）— 个人 AI 基础设施</h2><blockquote><p>⭐ 7,488 Stars | 📈 +351 today | 🟦 TypeScript | 📜 MIT</p></blockquote><h3 id="项目简介-1"><a href="#项目简介-1" class="headerlink" title="项目简介"></a>项目简介</h3><p>来自安全领域知名人物 Daniel Miessler（Fabric 框架创始人）的新项目。PAI 的目标宏大：<strong>为每个人构建一套完整的 AI Agent 基础设施</strong>，用 AI 放大个人能力。</p><p>PAI 不是一个 Agent，而是一个 <strong>Agent 操作系统</strong>——它定义了一套 Primitives（原语）和 Packs（功能包），让你可以像搭积木一样组装自己的 AI 系统。</p><h3 id="为什么火？-1"><a href="#为什么火？-1" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>因为它抓住了一个核心矛盾：<strong>AI 工具太多了，但缺少一个把它们统一起来的架构。</strong></p><p>你可能用了 ChatGPT、Claude、各种 MCP 工具、本地 LLM……但它们各自为战。PAI 提供了一个统一框架：</p><ul><li><strong>Packs</strong>：23 个功能包，覆盖写作、分析、安全、编程等场景</li><li><strong>Bundles</strong>：预配置的功能包组合，一键部署</li><li><strong>Two-Pass Capability Selection</strong>：双通道能力选择，自动匹配最合适的工具</li><li><strong>Thinking Tools</strong>：带推理过程的工具调用，支持 Justify-Exclusion（解释为什么不选某个工具）</li><li><strong>并行执行</strong>：默认并行处理多个 Agent 任务</li></ul><h3 id="技术亮点-1"><a href="#技术亮点-1" class="headerlink" title="技术亮点"></a>技术亮点</h3><p>v2.5.0 刚发布，三大升级：</p><ol><li><strong>双通道能力选择</strong>：先粗筛再精选，提高工具匹配准确率</li><li><strong>Thinking Tools + Justify-Exclusion</strong>：Agent 不仅解释为什么选这个工具，还解释为什么不选其他工具——更透明的决策过程</li><li><strong>并行执行默认开启</strong>：多任务不再串行等待</li></ol><h3 id="适用场景-1"><a href="#适用场景-1" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li>想构建个人 AI 工作流的技术爱好者</li><li>对 AI Agent 架构设计感兴趣的开发者</li><li>Fabric 框架的老用户——PAI 是 Fabric 理念的大幅进化</li></ul><hr><h2 id="3-Google-LangExtract-—-用-LLM-从混沌文本中提取结构化数据"><a href="#3-Google-LangExtract-—-用-LLM-从混沌文本中提取结构化数据" class="headerlink" title="3. Google LangExtract — 用 LLM 从混沌文本中提取结构化数据"></a>3. Google LangExtract — 用 LLM 从混沌文本中提取结构化数据</h2><blockquote><p>⭐ 31,355 Stars | 📈 +1,122 today | 🐍 Python | 📜 Apache-2.0</p></blockquote><h3 id="项目简介-2"><a href="#项目简介-2" class="headerlink" title="项目简介"></a>项目简介</h3><p>Google 开源的 Python 库，专门用 LLM 从非结构化文本（临床笔记、研报、法律文件等）中提取结构化信息。这不是简单的 NER（命名实体识别），而是带<strong>精准溯源</strong>的信息提取——每个结果都能映射回源文本的精确位置。</p><h3 id="为什么火？-2"><a href="#为什么火？-2" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>今日 +1,122 Stars，连续多日霸榜，已经冲到 31K Stars。</p><p>核心原因：它解决了 LLM 落地的信任难题。大模型擅长理解文本，但企业场景要的不只是「理解」，还要「证据」。LangExtract 的溯源机制让每条提取结果都有据可查，配合交互式可视化工具，让用户可以验证 AI 的每一个判断。</p><ul><li><strong>Source Grounding</strong>：每个提取字段都标注了源文本位置</li><li><strong>交互式可视化</strong>：一键查看提取结果与原文的对应关系</li><li><strong>多模型支持</strong>：原生 Gemini，同时支持 OpenAI 和 Ollama 本地模型</li><li><strong>Pydantic Schema</strong>：用标准的 Python 数据类定义提取目标</li></ul><h3 id="适用场景-2"><a href="#适用场景-2" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li>医疗记录结构化（从临床笔记提取诊断、用药、检查结果）</li><li>金融研报数据提取</li><li>法律文件关键条款提取</li><li>任何需要「可溯源 AI 提取」的场景</li></ul><hr><h2 id="4-Chrome-DevTools-MCP-—-让编程-Agent-拥有浏览器超能力"><a href="#4-Chrome-DevTools-MCP-—-让编程-Agent-拥有浏览器超能力" class="headerlink" title="4. Chrome DevTools MCP — 让编程 Agent 拥有浏览器超能力"></a>4. Chrome DevTools MCP — 让编程 Agent 拥有浏览器超能力</h2><blockquote><p>⭐ 24,380 Stars | 📈 +436 today | 🟦 TypeScript | 📜 Apache-2.0</p></blockquote><h3 id="项目简介-3"><a href="#项目简介-3" class="headerlink" title="项目简介"></a>项目简介</h3><p>Chrome 官方出品。这个 MCP Server 让你的编程 Agent（Gemini、Claude、Cursor、Copilot 等）可以<strong>直接控制和检查实时 Chrome 浏览器</strong>——完整的 DevTools 能力，包括性能分析、网络请求检查、控制台日志、截图等。</p><h3 id="为什么火？-3"><a href="#为什么火？-3" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>因为它补上了 AI 编程助手最大的盲区之一：<strong>前端调试</strong>。</p><p>以前 Agent 写完前端代码，你需要自己打开浏览器、检查渲染效果、查看 Console 错误、分析网络请求。现在 Agent 自己就能做这些事：</p><ul><li><strong>性能分析</strong>：录制 Chrome Trace，提取可操作的性能优化建议</li><li><strong>网络调试</strong>：检查 HTTP 请求&#x2F;响应、分析加载瀑布图</li><li><strong>控制台监控</strong>：获取浏览器控制台消息，包含 source-mapped 堆栈追踪</li><li><strong>可靠自动化</strong>：基于 Puppeteer，自动等待操作结果</li></ul><h3 id="技术亮点-2"><a href="#技术亮点-2" class="headerlink" title="技术亮点"></a>技术亮点</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;mcpServers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;chrome-devtools&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;command&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;npx&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;args&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;-y&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;chrome-devtools-mcp@latest&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>一行配置接入。支持 Field Data（CrUX 真实用户数据）对比 Lab Data，给出更全面的性能评估。</p><h3 id="适用场景-3"><a href="#适用场景-3" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li>AI 辅助前端开发和调试</li><li>自动化性能分析和优化</li><li>Web 应用端到端测试</li><li>任何需要 Agent 理解「浏览器里发生了什么」的场景</li></ul><hr><h2 id="5-Microsoft-PowerToys-—-老牌效率神器持续进化"><a href="#5-Microsoft-PowerToys-—-老牌效率神器持续进化" class="headerlink" title="5. Microsoft PowerToys — 老牌效率神器持续进化"></a>5. Microsoft PowerToys — 老牌效率神器持续进化</h2><blockquote><p>⭐ 129,637 Stars | 📈 +316 today | 🟣 C# | 📜 MIT</p></blockquote><h3 id="项目简介-4"><a href="#项目简介-4" class="headerlink" title="项目简介"></a>项目简介</h3><p>微软的 Windows 效率工具集，不需要多介绍了——FancyZones、PowerToys Run、Color Picker、File Locksmith……每一个都是 Windows 用户的效率神器。</p><h3 id="为什么又上热榜？"><a href="#为什么又上热榜？" class="headerlink" title="为什么又上热榜？"></a>为什么又上热榜？</h3><p>PowerToys 持续更新，最近的版本带来了新的 AI 增强功能和更多实用工具。12.9 万 Stars 的项目还能每天 +316，说明它的用户群极其活跃。</p><p>作为微软少数几个「真正好用」的开源项目，PowerToys 证明了大公司也能做出开发者真心喜欢的工具——前提是给团队足够的自由度。</p><hr><h2 id="今日趋势总结"><a href="#今日趋势总结" class="headerlink" title="今日趋势总结"></a>今日趋势总结</h2><h3 id="🔥-AI-Agent-基础设施爆发"><a href="#🔥-AI-Agent-基础设施爆发" class="headerlink" title="🔥 AI Agent 基础设施爆发"></a>🔥 AI Agent 基础设施爆发</h3><p>今天前 4 名里有 3 个直接和 AI Agent 相关。但关键词不再是「大模型」而是「基础设施」：</p><ul><li><strong>Tambo</strong>：Agent 的 UI 层</li><li><strong>PAI</strong>：Agent 的操作系统层</li><li><strong>Chrome DevTools MCP</strong>：Agent 的感知层</li></ul><p>这三个项目加在一起，描绘了一个完整的 Agent 工作流：AI 通过 MCP 感知浏览器环境 → 通过 PAI 规划和调度任务 → 通过 Tambo 渲染交互界面给用户。</p><h3 id="📊-MCP-生态持续膨胀"><a href="#📊-MCP-生态持续膨胀" class="headerlink" title="📊 MCP 生态持续膨胀"></a>📊 MCP 生态持续膨胀</h3><p>Chrome DevTools MCP 拿到 24K Stars，说明 Anthropic 提出的 MCP 协议已经成为 AI Agent 工具调用的事实标准。Google、Microsoft 等大厂纷纷拥抱，第三方工具更是遍地开花。</p><h3 id="🏗️-从「用-AI」到「建-AI-的家」"><a href="#🏗️-从「用-AI」到「建-AI-的家」" class="headerlink" title="🏗️ 从「用 AI」到「建 AI 的家」"></a>🏗️ 从「用 AI」到「建 AI 的家」</h3><p>今天的热榜反映了一个更大的趋势：开发者不再满足于简单地「用 AI」，而是在为 AI 构建更好的栖息环境。当基础设施足够成熟，AI Agent 才能从 Demo 走向生产。</p><hr><p><em>数据来源：GitHub Trending（2026-02-13 daily）</em></p>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>开源</tag>
      
      <tag>GitHub</tag>
      
      <tag>Trending</tag>
      
      <tag>React</tag>
      
      <tag>MCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>智谱 GLM-5 深度解析：744B 参数开源巨兽，从 Vibe Coding 迈向 Agentic Engineering</title>
    <link href="/2026/02/13/glm-5-agentic-engineering/"/>
    <url>/2026/02/13/glm-5-agentic-engineering/</url>
    
    <content type="html"><![CDATA[<blockquote><p>2026 年 2 月 11 日，智谱 AI 发布了新一代旗舰模型 GLM-5——一个 744B 参数的 MoE 开源模型，在编码和 Agent 能力上全面对齐 Claude Opus 4.5，并在多项关键指标上超越 GPT-5.2。这不只是又一个大模型的发布，而是一个信号：<strong>开源模型和闭源前沿之间的差距，正在以不可思议的速度消失。</strong></p></blockquote><p><img src="/images/glm-5-cover.png" alt="GLM-5 封面"></p><h2 id="一句话：GLM-5-是什么？"><a href="#一句话：GLM-5-是什么？" class="headerlink" title="一句话：GLM-5 是什么？"></a>一句话：GLM-5 是什么？</h2><p>GLM-5 是智谱 AI（Z.AI）最新发布的旗舰基座大模型。和大多数追求「聊天体验」的模型不同，GLM-5 明确瞄准了一个更大的赛道：<strong>复杂系统工程和长程 Agent 任务</strong>。</p><p>智谱自己给它起了个口号：**”From Vibe Coding to Agentic Engineering”**（从感觉式编程到工程化 Agent）。</p><p>什么意思？市面上大多数 AI 编程助手做的是「Vibe Coding」——你描述一下想要什么，模型帮你写个函数、补个代码片段。而 Agentic Engineering 是另一个级别的事情：模型需要理解整个系统架构，自主规划多步骤任务，在数百个连续操作中保持目标一致，处理依赖关系和异常情况，最终交付生产级代码。</p><p><strong>简单说：GLM-5 不是来帮你写代码的，它是来帮你做工程的。</strong></p><p><img src="/images/glm-5-vibe-vs-agentic.png" alt="从 Vibe Coding 到 Agentic Engineering"></p><hr><h2 id="架构：一个扎扎实实的规模飞跃"><a href="#架构：一个扎扎实实的规模飞跃" class="headerlink" title="架构：一个扎扎实实的规模飞跃"></a>架构：一个扎扎实实的规模飞跃</h2><table><thead><tr><th>指标</th><th>GLM-4.5&#x2F;4.7</th><th>GLM-5</th></tr></thead><tbody><tr><td>总参数量</td><td>355B</td><td><strong>744B</strong></td></tr><tr><td>活跃参数量</td><td>32B</td><td><strong>40B</strong></td></tr><tr><td>架构</td><td>MoE</td><td>MoE</td></tr><tr><td>预训练数据</td><td>23T tokens</td><td><strong>28.5T tokens</strong></td></tr><tr><td>注意力机制</td><td>标准</td><td><strong>DeepSeek Sparse Attention</strong></td></tr><tr><td>许可证</td><td>MIT</td><td><strong>MIT</strong></td></tr></tbody></table><p>GLM-5 的参数量翻了一倍多，预训练数据从 23T 增加到 28.5T tokens。但更值得关注的是两个技术创新：</p><h3 id="DeepSeek-Sparse-Attention（DSA）"><a href="#DeepSeek-Sparse-Attention（DSA）" class="headerlink" title="DeepSeek Sparse Attention（DSA）"></a>DeepSeek Sparse Attention（DSA）</h3><p>GLM-5 首次集成了 DeepSeek 发明的稀疏注意力机制。传统 Transformer 的注意力复杂度是平方级——上下文长度翻倍，计算量翻四倍。DSA 打破了这个瓶颈，让 GLM-5 在保持 200K 上下文窗口的同时，大幅降低了部署成本。</p><p>这也是中国 AI 社区协作的一个缩影：智谱用了 DeepSeek 的技术，而不是重新造轮子。</p><h3 id="Slime：异步强化学习框架"><a href="#Slime：异步强化学习框架" class="headerlink" title="Slime：异步强化学习框架"></a>Slime：异步强化学习框架</h3><p>GLM-5 训练中最关键的创新是 <strong>Slime</strong>——一个全新的异步强化学习框架（已开源在 GitHub）。</p><p>传统 RL 训练大模型的效率很低。Slime 通过解耦数据生成和策略更新，实现了比传统同步 RL 高 3 倍的训练吞吐量。更重要的是，它针对长程 Agent 行为做了专门的奖励建模——不是优化表面的 benchmark 数字，而是奖励任务完成的一致性。</p><p>这解释了为什么 GLM-5 在需要长时间持续执行的任务上表现突出。</p><hr><h2 id="Benchmark：全面对齐-Claude-Opus-4-5，多项超越-GPT-5-2"><a href="#Benchmark：全面对齐-Claude-Opus-4-5，多项超越-GPT-5-2" class="headerlink" title="Benchmark：全面对齐 Claude Opus 4.5，多项超越 GPT-5.2"></a>Benchmark：全面对齐 Claude Opus 4.5，多项超越 GPT-5.2</h2><p><img src="/images/glm-5-benchmarks.png" alt="GLM-5 Benchmark 对比"></p><h3 id="编码能力"><a href="#编码能力" class="headerlink" title="编码能力"></a>编码能力</h3><table><thead><tr><th>Benchmark</th><th>GLM-5</th><th>Claude Opus 4.5</th><th>GPT-5.2</th><th>说明</th></tr></thead><tbody><tr><td>SWE-bench Verified</td><td><strong>77.8</strong></td><td>80.9</td><td>80.0</td><td>真实 GitHub Issue 修复</td></tr><tr><td>SWE-bench Multilingual</td><td><strong>73.3</strong></td><td>77.5</td><td>-</td><td>多语言代码理解</td></tr><tr><td>Terminal-Bench 2.0</td><td><strong>56.2</strong></td><td>59.3</td><td>54.0</td><td>终端操作与系统管理</td></tr><tr><td>CyberGym</td><td><strong>43.2</strong></td><td>50.6</td><td>-</td><td>安全攻防任务</td></tr></tbody></table><p>GLM-5 在 SWE-bench（真实 GitHub 项目 bug 修复）上拿到 77.8，与 Claude Opus 4.5 的 80.9 差距仅 3.1 个百分点。对于一个开源模型来说，这是前所未有的接近。</p><p>在 Terminal-Bench（终端命令行操作）上，GLM-5 的 56.2 已经超过了 GPT-5.2 的 54.0。</p><h3 id="Agent-能力：真正的亮点"><a href="#Agent-能力：真正的亮点" class="headerlink" title="Agent 能力：真正的亮点"></a>Agent 能力：真正的亮点</h3><table><thead><tr><th>Benchmark</th><th>GLM-5</th><th>Claude Opus 4.5</th><th>GPT-5.2</th><th>说明</th></tr></thead><tbody><tr><td>BrowseComp</td><td><strong>62.0</strong></td><td>37.0</td><td>-</td><td>联网搜索与信息综合</td></tr><tr><td>BrowseComp + 上下文管理</td><td><strong>75.9</strong></td><td>-</td><td>65.8</td><td>带记忆的复杂网页任务</td></tr><tr><td>τ²-Bench</td><td><strong>89.7</strong></td><td>91.6</td><td>-</td><td>多工具复杂场景</td></tr><tr><td>Vending Bench 2</td><td><strong>$4,432</strong></td><td>$4,967</td><td>$3,591</td><td>模拟一年商业经营</td></tr><tr><td>MCP-Atlas</td><td><strong>67.8</strong></td><td>65.2</td><td>-</td><td>工具调用与多步骤执行</td></tr></tbody></table><p><strong>BrowseComp 是最炸裂的数据。</strong> GLM-5 拿到 62.0，几乎是 Claude Opus 4.5（37.0）的两倍。带上下文管理后达到 75.9，超过 GPT-5.2 的 65.8。这意味着在联网搜索、信息检索和多步网页任务上，GLM-5 是目前所有模型中最强的。</p><p><strong>Vending Bench 2</strong> 是最能体现「长程 Agent 能力」的测试——让 AI 经营一年的自动售货机生意，做采购决策、库存管理、定价优化。GLM-5 最终账户余额 $4,432，仅次于 Claude Opus 4.5 的 $4,967，而 GPT-5.2 只有 $3,591。</p><p><strong>MCP-Atlas</strong>（工具调用与多步骤执行）上，GLM-5 的 67.8 甚至反超了 Claude Opus 4.5 的 65.2。</p><h3 id="推理能力"><a href="#推理能力" class="headerlink" title="推理能力"></a>推理能力</h3><table><thead><tr><th>Benchmark</th><th>GLM-5</th><th>Claude Opus 4.5</th><th>GPT-5.2</th><th>说明</th></tr></thead><tbody><tr><td>Humanity’s Last Exam（带工具）</td><td><strong>50.4</strong></td><td>43.4</td><td>45.5</td><td>人类最难测试</td></tr><tr><td>AIME 2026 I</td><td><strong>92.7</strong></td><td>93.3</td><td>-</td><td>数学竞赛</td></tr><tr><td>HMMT 2025</td><td><strong>96.9</strong></td><td>-</td><td>97.1</td><td>哈佛&#x2F;MIT 数学竞赛</td></tr><tr><td>GPQA-Diamond</td><td><strong>86.0</strong></td><td>87.0</td><td>92.4</td><td>博士级科学推理</td></tr></tbody></table><p>在 Humanity’s Last Exam（带工具）上，GLM-5 的 50.4 超过了 Claude（43.4）和 GPT-5.2（45.5）。数学竞赛 AIME 上 92.7 几乎追平 Claude 的 93.3。</p><hr><h2 id="对软件工程的意义：为什么-Agentic-Engineering-是下一个范式"><a href="#对软件工程的意义：为什么-Agentic-Engineering-是下一个范式" class="headerlink" title="对软件工程的意义：为什么 Agentic Engineering 是下一个范式"></a>对软件工程的意义：为什么 Agentic Engineering 是下一个范式</h2><p>GLM-5 的发布不只是一个模型的事。它代表了 AI 辅助软件工程正在发生的范式转移。</p><h3 id="从「写代码」到「做工程」"><a href="#从「写代码」到「做工程」" class="headerlink" title="从「写代码」到「做工程」"></a>从「写代码」到「做工程」</h3><p>传统 AI 编程助手（Copilot、Cursor 等）本质上是<strong>代码补全</strong>——你写一半，它帮你补另一半。即使是 Claude Code 和 Codex，也主要是在<strong>单文件或单功能</strong>层面工作。</p><p>GLM-5 瞄准的是另一个维度：</p><ul><li><strong>理解整个代码库的架构</strong>，而不只是当前文件</li><li><strong>自主规划多步骤修改方案</strong>，涉及多个文件和模块</li><li><strong>在数百步操作中保持目标一致</strong>，不会做到一半忘了自己在干什么</li><li><strong>处理依赖关系和副作用</strong>，像一个真正的工程师一样思考</li></ul><p>这正是 Vending Bench 2 测试的价值——经营一年的生意需要的不是聪明，而是<strong>持续的、可靠的决策能力</strong>。</p><h3 id="CC-Bench-V2：真实工程场景评测"><a href="#CC-Bench-V2：真实工程场景评测" class="headerlink" title="CC-Bench-V2：真实工程场景评测"></a>CC-Bench-V2：真实工程场景评测</h3><p>智谱自己开发的 CC-Bench-V2 专门评测「复杂软件工程」——不是算法题，而是涉及多文件、多依赖、需要架构决策的真实工程任务。GLM-5 在前端、后端和长程任务上都大幅超越前代 GLM-4.7，逼近 Claude Opus 4.5 的水准。</p><h3 id="工程化-Agent-的三大支柱"><a href="#工程化-Agent-的三大支柱" class="headerlink" title="工程化 Agent 的三大支柱"></a>工程化 Agent 的三大支柱</h3><p>智谱官方总结了 Agentic Engineering 的三个核心能力：</p><ol><li><strong>长程目标一致性</strong>：在几百步的连续操作中不偏离目标</li><li><strong>资源管理与规划</strong>：合理分配计算资源、管理上下文窗口</li><li><strong>多步骤依赖处理</strong>：理解任务之间的依赖关系，按正确顺序执行</li></ol><p>这三个能力恰好是目前 AI 编程助手最薄弱的环节——它们擅长写函数，但不擅长做项目。GLM-5 正在填补这个空白。</p><hr><h2 id="神秘的-Pony-Alpha：一个有趣的插曲"><a href="#神秘的-Pony-Alpha：一个有趣的插曲" class="headerlink" title="神秘的 Pony Alpha：一个有趣的插曲"></a>神秘的 Pony Alpha：一个有趣的插曲</h2><p>在 GLM-5 正式发布前，OpenRouter 上悄然出现了一个叫 <strong>“Pony Alpha”</strong> 的匿名模型，凭借出色的编码能力引发了大量关注和猜测——有人说是 DeepSeek V4，有人说是 GLM-5。</p><p>现在谜底揭晓：<strong>Pony Alpha 就是 GLM-5。</strong> 智谱用了一招「匿名发布，实力说话」，在模型揭面之前就已经在开发者社区积累了口碑。</p><hr><h2 id="开源-MIT-许可：最大的诚意"><a href="#开源-MIT-许可：最大的诚意" class="headerlink" title="开源 MIT 许可：最大的诚意"></a>开源 MIT 许可：最大的诚意</h2><p>GLM-5 采用 <strong>MIT 许可证</strong>——这是开源世界中最宽松的许可证：</p><ul><li>✅ 完全商用，无任何限制</li><li>✅ 可修改、微调、蒸馏</li><li>✅ 无需开源你自己的代码（没有 copyleft 义务）</li><li>✅ 法律风险极低</li></ul><p>对比 Meta Llama 的受限许可和其他「半开源」模型，GLM-5 给出了真正的自由。对于企业来说，这意味着可以放心地在 GLM-5 基础上构建产品，不用担心后续的许可证问题。</p><p>模型权重已在 HuggingFace 和 ModelScope 开放下载。</p><hr><h2 id="价格：比-Claude-便宜-7-倍"><a href="#价格：比-Claude-便宜-7-倍" class="headerlink" title="价格：比 Claude 便宜 7 倍"></a>价格：比 Claude 便宜 7 倍</h2><table><thead><tr><th>模型</th><th>输入价格&#x2F;M tokens</th><th>输出价格&#x2F;M tokens</th></tr></thead><tbody><tr><td>GLM-5</td><td><strong>~$0.80</strong></td><td><strong>~$3.20</strong></td></tr><tr><td>Claude Opus 4.5</td><td>$5.00</td><td>$25.00</td></tr><tr><td>GPT-5.2</td><td>$1.25</td><td>$5.00</td></tr></tbody></table><p>GLM-5 的 API 定价大约是 Claude Opus 4.5 的 <strong>七分之一</strong>。在性能逼近的前提下，这个价格差距对于企业级 Agent 应用来说是巨大的优势——Agent 任务通常涉及大量的多轮对话和工具调用，token 消耗量远超普通聊天。</p><hr><h2 id="不只是聊天：GLM-5-的办公生产力"><a href="#不只是聊天：GLM-5-的办公生产力" class="headerlink" title="不只是聊天：GLM-5 的办公生产力"></a>不只是聊天：GLM-5 的办公生产力</h2><p>GLM-5 不满足于做一个聊天模型。通过 Z.ai 的 Agent 模式，它可以直接生成：</p><ul><li>📄 <strong>Word 文档</strong>（.docx）：PRD、报告、教案、会议纪要</li><li>📊 <strong>Excel 表格</strong>（.xlsx）：财务报表、数据分析、透视表</li><li>📋 <strong>PDF 文件</strong>：格式化的专业文档</li></ul><p>这不是「生成文字然后你自己粘贴到 Word」，而是<strong>端到端的、带格式的、可以直接用的文档</strong>。支持多轮迭代优化，像一个真正的文档工程师。</p><hr><h2 id="生态兼容：无缝接入现有工具链"><a href="#生态兼容：无缝接入现有工具链" class="headerlink" title="生态兼容：无缝接入现有工具链"></a>生态兼容：无缝接入现有工具链</h2><p>GLM-5 已经支持主流的 Agent 编程工具：</p><ul><li><strong>Claude Code</strong>：直接替换模型为 <code>glm-5</code></li><li><strong>OpenCode &#x2F; Cline &#x2F; Roo Code</strong>：通过 GLM Coding Plan 接入</li><li><strong>OpenRouter</strong>：已上线，可立即调用</li><li><strong>vLLM &#x2F; SGLang</strong>：支持本地部署</li><li><strong>国产芯片</strong>：支持华为昇腾、摩尔线程、寒武纪、昆仑芯、燧原等</li></ul><p>这意味着你不需要改变现有的工作流，就可以把 GLM-5 接入你的 Agent 系统。</p><hr><h2 id="全球视角：开源-AI-的分水岭"><a href="#全球视角：开源-AI-的分水岭" class="headerlink" title="全球视角：开源 AI 的分水岭"></a>全球视角：开源 AI 的分水岭</h2><p>让我们把视角拉远一点。</p><p><strong>一年前</strong>，开源模型和闭源前沿之间的差距是巨大的。最好的开源模型在 SWE-bench 上可能只有 50% 多的成绩，而 Claude 和 GPT 已经接近 80%。</p><p><strong>现在</strong>，GLM-5 在 SWE-bench 上拿到 77.8%，在 BrowseComp 上甚至碾压闭源模型，在 Vending Bench 的长程 Agent 任务上逼近 Claude。</p><p>这个趋势的意义远超技术本身：</p><ol><li><p><strong>企业 build vs buy 的天平正在倾斜</strong>。当开源模型性能够用且可以完全控制时，为什么要给 Anthropic 或 OpenAI 交高额 API 费用？</p></li><li><p><strong>Agent 能力成为新赛场</strong>。GLM-5 不是在聊天能力上竞争，而是在「做工作」的能力上竞争。这是 AI 从工具变成同事的关键一步。</p></li><li><p><strong>中国 AI 的技术实力不容忽视</strong>。智谱在香港 IPO 募资 43.5 亿港元后，把资金投入了实实在在的技术——GLM-5 的 MIT 开源不是姿态，而是对自身技术实力的自信。</p></li></ol><hr><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>GLM-5 证明了一件事：<strong>在 2026 年，最好的开源模型已经不再是闭源模型的「平替」，而是真正的竞争者。</strong></p><p>对于软件工程师来说，一个能在长程任务中保持可靠、在真实工程场景中逼近 Claude Opus 4.5 表现、价格便宜 7 倍、还完全开源的模型——很难不认真对待。</p><p>Agentic Engineering 不再是 PPT 上的概念。GLM-5 把它变成了可以跑的代码。</p><hr><p><em>数据来源：智谱 AI 官方博客、BuildFastWithAI、Reuters、Bloomberg、SCMP | 2026 年 2 月 13 日</em></p>]]></content>
    
    
    <categories>
      
      <category>深度分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>开源</tag>
      
      <tag>GLM-5</tag>
      
      <tag>智谱</tag>
      
      <tag>Agentic Engineering</tag>
      
      <tag>大模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2026年02月12日早间要闻</title>
    <link href="/2026/02/12/2026-02-12-morning-news/"/>
    <url>/2026/02/12/2026-02-12-morning-news/</url>
    
    <content type="html"><![CDATA[<h2 id="📰-今日要闻"><a href="#📰-今日要闻" class="headerlink" title="📰 今日要闻"></a>📰 今日要闻</h2><h3 id="1-字节跳动-Seedance-2-0-引爆-A-股传媒板块"><a href="#1-字节跳动-Seedance-2-0-引爆-A-股传媒板块" class="headerlink" title="1. 字节跳动 Seedance 2.0 引爆 A 股传媒板块"></a>1. 字节跳动 Seedance 2.0 引爆 A 股传媒板块</h3><p>字节跳动发布 Seedance 2.0 视频生成模型，支持从文本或图像直接生成电影级品质的视频内容。该消息直接引爆 A 股传媒板块，中文在线、光线传媒、掌阅科技等个股单日涨幅超 10% 甚至触及 20% 涨停板。市场将其类比为”2025年的 DeepSeek 时刻”，认为这标志着 AI 视频生成技术进入新阶段。不过需要注意的是，多数被炒作的公司缺乏实际业绩支撑，主要靠题材轮动推动。</p><h3 id="2-央行重申适度宽松货币政策"><a href="#2-央行重申适度宽松货币政策" class="headerlink" title="2. 央行重申适度宽松货币政策"></a>2. 央行重申适度宽松货币政策</h3><p>中国人民银行发布《2025年第四季度货币政策执行报告》，明确将继续实施适度宽松货币政策，灵活运用降准降息等工具，保持流动性充裕和融资条件宽松。报告显示金融总量增长、融资成本下行、重点领域支持有力。这一表态对 A 股和宏观经济预期构成正面支撑。</p><h3 id="3-美国-1-月就业数据超预期"><a href="#3-美国-1-月就业数据超预期" class="headerlink" title="3. 美国 1 月就业数据超预期"></a>3. 美国 1 月就业数据超预期</h3><p>美国劳工部公布 1 月非农就业数据，新增就业 13 万人，大幅超出经济学家预期的 7.5 万人，失业率意外降至 4.3%。强劲的就业数据缓解了经济放缓担忧，但同时也强化了美联储”higher for longer”的利率预期。市场目前预计 2026 年全年利率将维持在 3.5% 以上。</p><h3 id="4-AI-供应链瓶颈：电子布价格跳涨"><a href="#4-AI-供应链瓶颈：电子布价格跳涨" class="headerlink" title="4. AI 供应链瓶颈：电子布价格跳涨"></a>4. AI 供应链瓶颈：电子布价格跳涨</h3><p>AI 基础设施需求持续拉动上游材料紧缺。7628 电子布（电子级玻璃纤维布）价格从 2025 年 9 月底的 4.15 元&#x2F;米涨至目前的 4.75 元&#x2F;米，2025Q4 至今已累计上涨约 15%。A 股电子布概念集体爆发，宏和科技、国际复材、中材科技等多股涨停创历史新高。电子布是覆铜板制造的关键材料，直接影响 PCB 和芯片封装成本。</p><h3 id="5-美国禁止中国随锐科技收购美企"><a href="#5-美国禁止中国随锐科技收购美企" class="headerlink" title="5. 美国禁止中国随锐科技收购美企"></a>5. 美国禁止中国随锐科技收购美企</h3><p>美国司法部依据 1950 年《国防生产法》提起诉讼，要求中国随锐科技集团从加州丘比特系统公司（Jupiter Systems）撤资，理由是保护国家安全。这是中美科技脱钩趋势的又一案例，显示美国在科技并购审查方面持续收紧。</p><hr><h2 id="📈-美股重点关注（2月11日收盘）"><a href="#📈-美股重点关注（2月11日收盘）" class="headerlink" title="📈 美股重点关注（2月11日收盘）"></a>📈 美股重点关注（2月11日收盘）</h2><h3 id="微软-MSFT-—-404-37（-2-15-）"><a href="#微软-MSFT-—-404-37（-2-15-）" class="headerlink" title="微软 MSFT — $404.37（-2.15%）"></a>微软 MSFT — $404.37（-2.15%）</h3><ul><li>Azure 收入增长 38% 符合预期，但市场持续忧虑 AI 资本开支的投资回报率</li><li>股价从 2025 年高点 $555.45 回撤超过 20%，估值回归合理区间（PE 25.8，EPS $15.65）</li><li>下一催化剂：Q1 2026 财报（4月29日），核心看 Copilot 渗透率和 Azure 增长加速</li><li>分析师平均目标价 $591.95，当前价位存在较大上行空间</li></ul><h3 id="谷歌-GOOGL-—-322-86（-2-53-）"><a href="#谷歌-GOOGL-—-322-86（-2-53-）" class="headerlink" title="谷歌 GOOGL — $322.86（-2.53%）"></a>谷歌 GOOGL — $322.86（-2.53%）</h3><ul><li>2026 年资本开支指引高达 $1750-1850 亿美元（同比翻倍），市场震惊</li><li>“资本焚烧”担忧持续拖累股价，从历史高点 $349 回落约 7.5%</li><li>核心看点：广告业务韧性 + Gemini 模型商业化进展 + 反垄断案进展</li><li>PE 29.8，估值不算离谱，关键是证明 AI 投资能转化为收入增长</li></ul><h3 id="英伟达-NVDA-—-190-01（-0-75-）"><a href="#英伟达-NVDA-—-190-01（-0-75-）" class="headerlink" title="英伟达 NVDA — $190.01（+0.75%）"></a>英伟达 NVDA — $190.01（+0.75%）</h3><ul><li>逆市上涨，盘中一度冲高至 $193.26，Blackwell 芯片周期需求持续强劲</li><li>合作伙伴 Vertiv 发布亮眼财报（股价+15%），间接提振 NVDA 信心</li><li><strong>2月25日财报是近期最大催化剂</strong>，市场期待极高</li><li>风险点：25% AI 硬件关税（”Trump Cut”）由超级云厂商自行消化，可能抑制采购量</li><li>当前市值 4.63 万亿美元，PE 46.7，1年目标价 $253.79</li></ul><h3 id="AMD-—-213-58（持平）"><a href="#AMD-—-213-58（持平）" class="headerlink" title="AMD — $213.58（持平）"></a>AMD — $213.58（持平）</h3><ul><li>Q4 财报后股价已回调约 11%，盘中波动剧烈（$209-$219 区间）</li><li>MI300 系列数据中心 GPU 出货在增长，但与 NVDA 的差距仍然明显</li><li>PE 81.8 偏高，需要持续证明在 AI GPU 市场的份额扩张</li><li>从 52 周高点 $267 回落约 20%，处于估值消化期</li></ul><h3 id="阿里巴巴-BABA-—-168-39（-0-69-）"><a href="#阿里巴巴-BABA-—-168-39（-0-69-）" class="headerlink" title="阿里巴巴 BABA — $168.39（-0.69%）"></a>阿里巴巴 BABA — $168.39（-0.69%）</h3><ul><li>重金押注 AI：投入 30 亿元（约 $4.31 亿）推广通义千问 Qwen AI 应用</li><li>20 亿美元投资 Zelos Technology 加强物流基础设施能力</li><li><strong>2月19日 Q3 财报在即</strong>，云智能增长和 AI 布局是关键看点</li><li>PE 22.5 估值合理，52 周高点 $192.67，当前距高点约 13%</li></ul><hr><h2 id="📊-市场大势"><a href="#📊-市场大势" class="headerlink" title="📊 市场大势"></a>📊 市场大势</h2><ul><li><strong>纳斯达克综合指数</strong>：23,102.47（-0.6%），连续两日收跌</li><li><strong>道琼斯工业指数</strong>：50,188.14（+0.1%），连续三日创历史新高</li><li><strong>标普500</strong>：6,941.81（-0.3%）</li></ul><p>市场呈现明显分化格局——传统工业、金融板块走强（道指创新高），而科技成长股承压（纳指回调）。核心矛盾在于：AI 资本开支螺旋式上升 vs 高利率环境下投资回报周期拉长。</p><p><strong>关键日期：</strong></p><ul><li>2&#x2F;13（周五）：1月 CPI 数据发布，将决定短期市场方向</li><li>2&#x2F;19：阿里巴巴 Q3 财报</li><li>2&#x2F;25：英伟达 Q4 财报</li></ul><blockquote><p>免责声明：以上内容仅为信息分享，不构成投资建议。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>早报</tag>
      
      <tag>新闻</tag>
      
      <tag>AI</tag>
      
      <tag>科技</tag>
      
      <tag>美股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2026年AI驱动UI测试自动化全景：当大模型学会「看屏幕操作电脑」</title>
    <link href="/2026/02/12/ai-ui-testing-automation-2026/"/>
    <url>/2026/02/12/ai-ui-testing-automation-2026/</url>
    
    <content type="html"><![CDATA[<blockquote><p>GPT-5.3 在 OSWorld 上拿到 64.7%，Claude Opus 4.6 达到 72.7% 超越人类水平（72.36%），UI-TARS-2 在 12 个 Poki 游戏上通关率 100%——2026 年 2 月，AI 操控电脑的能力正在以不可思议的速度进化。本文全面梳理基于最新一线大模型的 Agentic UI 测试框架，聚焦 Windows + Android 双平台。</p></blockquote><h2 id="核心变化：从「定位元素」到「看屏幕操作」"><a href="#核心变化：从「定位元素」到「看屏幕操作」" class="headerlink" title="核心变化：从「定位元素」到「看屏幕操作」"></a>核心变化：从「定位元素」到「看屏幕操作」</h2><p>传统 UI 自动化测试依赖 XPath、CSS Selector、Accessibility ID 等定位器。UI 一改，测试就崩。</p><p>2026 年的新范式彻底不同：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">截图 → 多模态大模型理解界面 → 规划操作步骤 → 模拟鼠标键盘执行 → 截图验证结果<br></code></pre></td></tr></table></figure><p><strong>不再需要任何定位器、不依赖 DOM 结构、不怕 UI 改版。</strong> 只要人类能看懂屏幕，AI 就能操作。</p><p>这背后的核心驱动力是<strong>多模态大模型的能力飞跃</strong>。让我们先看看 2026 年 2 月的最新战况。</p><hr><h2 id="一、模型层：谁在驱动-Computer-Use？"><a href="#一、模型层：谁在驱动-Computer-Use？" class="headerlink" title="一、模型层：谁在驱动 Computer Use？"></a>一、模型层：谁在驱动 Computer Use？</h2><h3 id="OSWorld-Benchmark：AI-操控桌面的黄金标准"><a href="#OSWorld-Benchmark：AI-操控桌面的黄金标准" class="headerlink" title="OSWorld Benchmark：AI 操控桌面的黄金标准"></a>OSWorld Benchmark：AI 操控桌面的黄金标准</h3><p>OSWorld 是评估 AI 操控真实桌面环境（Windows&#x2F;Linux&#x2F;Mac）能力的权威 benchmark，包含文件管理、办公软件操作、浏览器任务等数百项真实任务。</p><p><strong>2026 年 2 月最新排名：</strong></p><table><thead><tr><th>模型&#x2F;方案</th><th>OSWorld 得分</th><th>发布时间</th><th>备注</th></tr></thead><tbody><tr><td><strong>Anthropic BJudge (Claude Opus 4.6)</strong></td><td><strong>72.7%</strong></td><td>2026.02</td><td>🏆 超越人类水平（72.36%）</td></tr><tr><td>UiPath Screen Agent + Claude Opus 4.5</td><td>OSWorld-Verified #1</td><td>2026.01</td><td>企业级方案</td></tr><tr><td><strong>GPT-5.3 Codex</strong></td><td><strong>64.7%</strong></td><td>2026.02</td><td>历史最高单模型得分</td></tr><tr><td>UI-TARS-1.5</td><td>42.5%</td><td>2025.04</td><td>开源最强</td></tr><tr><td>OpenAI CUA (GPT-5 架构)</td><td>36.4%</td><td>2025</td><td>Operator 产品底层</td></tr><tr><td>Claude 3.7 Sonnet</td><td>28%</td><td>2024</td><td>Computer Use 首发版</td></tr></tbody></table><p><strong>关键信号</strong>：仅仅一年时间，从 28% 到 72.7%，<strong>AI 在桌面操控任务上已经超越了普通人类水平</strong>。</p><h3 id="最新一线模型的-Computer-Use-能力对比"><a href="#最新一线模型的-Computer-Use-能力对比" class="headerlink" title="最新一线模型的 Computer Use 能力对比"></a>最新一线模型的 Computer Use 能力对比</h3><table><thead><tr><th>能力维度</th><th>Claude Opus 4.6</th><th>GPT-5.3 Codex</th><th>Gemini 3 Pro</th><th>UI-TARS-2</th></tr></thead><tbody><tr><td>OSWorld（桌面操控）</td><td>72.7% 🏆</td><td>64.7%</td><td>-</td><td>42.5%*</td></tr><tr><td>上下文窗口</td><td>1M tokens</td><td>400K tokens</td><td>1M+</td><td>本地部署</td></tr><tr><td>Agent Teams（多 Agent 协作）</td><td>✅</td><td>❌</td><td>❌</td><td>❌</td></tr><tr><td>Computer Use API</td><td>原生支持</td><td>原生支持</td><td>-</td><td>pyautogui</td></tr><tr><td>BrowseComp（浏览器搜索）</td><td>84.0%</td><td>-</td><td>-</td><td>-</td></tr><tr><td>视频理解</td><td>图片+文本</td><td>原生视频+音频</td><td>原生多模态</td><td>图片</td></tr><tr><td>成本（输入&#x2F;1M tokens）</td><td>$5</td><td>$1.25</td><td>-</td><td>免费（本地）</td></tr><tr><td>Android 支持</td><td>需搭配框架</td><td>需搭配框架</td><td>需搭配框架</td><td>原生</td></tr><tr><td>Windows 支持</td><td>原生 Computer Use</td><td>原生 Computer Use</td><td>-</td><td>原生</td></tr></tbody></table><blockquote><p>*UI-TARS-2 的 OSWorld 得分基于 2025.09 版本，最新版可能更高。其 benchmark 优势在 ScreenSpot（UI 定位精度）上更明显，达到 94.2%。</p></blockquote><hr><h2 id="二、框架层：把大模型能力变成可用的测试工具"><a href="#二、框架层：把大模型能力变成可用的测试工具" class="headerlink" title="二、框架层：把大模型能力变成可用的测试工具"></a>二、框架层：把大模型能力变成可用的测试工具</h2><p>光有模型不够，还需要框架来编排 Agent 工作流。以下是 2026 年最值得关注的 Agentic 测试框架。</p><h3 id="1-Cua-—-开源-Computer-Use-Agent-平台（⭐12-4K）"><a href="#1-Cua-—-开源-Computer-Use-Agent-平台（⭐12-4K）" class="headerlink" title="1. Cua — 开源 Computer Use Agent 平台（⭐12.4K）"></a>1. Cua — 开源 Computer Use Agent 平台（⭐12.4K）</h3><p><strong>GitHub</strong>：<a href="https://github.com/trycua/cua">trycua&#x2F;cua</a> | MIT 许可</p><p><strong>这是 2026 年最值得关注的新项目。</strong> Cua 是一个专门为「AI 操控真实电脑」设计的开源平台，三层架构：</p><p><strong>Layer 1 — 沙盒环境：</strong></p><table><thead><tr><th>环境类型</th><th>平台</th><th>说明</th></tr></thead><tbody><tr><td>Cloud Sandbox</td><td>Linux&#x2F;Windows&#x2F;macOS</td><td>托管云环境，开箱即用</td></tr><tr><td>Docker 容器</td><td>Linux</td><td>轻量级桌面环境</td></tr><tr><td>QEMU 虚拟机</td><td>Linux&#x2F;Windows 11&#x2F;<strong>Android 11</strong></td><td>Docker 内运行完整 OS</td></tr><tr><td>Lume</td><td>macOS&#x2F;Linux</td><td>Apple Silicon 原生虚拟化</td></tr><tr><td>Windows Sandbox</td><td>Windows</td><td>原生 Windows 沙盒</td></tr></tbody></table><p><strong>Layer 2 — Computer SDK：</strong><br>统一的 Python&#x2F;TypeScript API，截图、鼠标点击、键盘输入、Shell 命令，一套代码跑所有沙盒。</p><p><strong>Layer 3 — Agent 框架：</strong></p><ul><li>100+ 模型支持（Claude &#x2F; GPT &#x2F; Gemini &#x2F; 开源模型）</li><li>预构建的 Agent Loop，专为 Computer Use 优化</li><li><strong>内置 Android 支持</strong>（QEMU 虚拟化 + CuaBot）</li></ul><p><strong>为什么 Cua 对 UI 测试很重要？</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> cua <span class="hljs-keyword">import</span> Agent, Sandbox<br><br><span class="hljs-comment"># 创建隔离的 Windows 沙盒</span><br>sandbox = Sandbox.create(<span class="hljs-string">&quot;windows-11&quot;</span>)<br><br><span class="hljs-comment"># 用 Claude Opus 4.6 驱动 Agent</span><br>agent = Agent(model=<span class="hljs-string">&quot;claude-opus-4.6&quot;</span>, sandbox=sandbox)<br><br><span class="hljs-comment"># 自然语言描述测试任务</span><br>agent.run(<span class="hljs-string">&quot;打开计算器，计算 123 × 456，验证结果是否为 56088&quot;</span>)<br></code></pre></td></tr></table></figure><p>不需要写任何定位器，不需要了解应用内部结构。Agent 会自己截屏、理解界面、操作、验证结果。</p><h3 id="2-UiPath-Screen-Agent-—-企业级-AI-自动化（OSWorld-Verified-1）"><a href="#2-UiPath-Screen-Agent-—-企业级-AI-自动化（OSWorld-Verified-1）" class="headerlink" title="2. UiPath Screen Agent — 企业级 AI 自动化（OSWorld-Verified #1）"></a>2. UiPath Screen Agent — 企业级 AI 自动化（OSWorld-Verified #1）</h3><p>UiPath 是全球最大的 RPA 公司。2025-2026 年，他们推出了 <strong>Screen Agent</strong>：</p><ul><li>2025.09：基于 <strong>GPT-5</strong> 拿到 OSWorld #1</li><li>2026.01：切换到 <strong>Claude Opus 4.5</strong> 后拿到 OSWorld-Verified #1（369 项真实桌面任务）</li></ul><p>Screen Agent 代表了传统 RPA 与最新大模型的融合：用 UiPath 的企业级基础设施（机器人编排、权限管理、审计日志）+ 顶级大模型的视觉理解能力。</p><p><strong>适合</strong>：已有 UiPath 基础设施的企业团队。</p><h3 id="3-微软-UFO³-OmniParser-V2（⭐8K-⭐24-4K）"><a href="#3-微软-UFO³-OmniParser-V2（⭐8K-⭐24-4K）" class="headerlink" title="3. 微软 UFO³ + OmniParser V2（⭐8K + ⭐24.4K）"></a>3. 微软 UFO³ + OmniParser V2（⭐8K + ⭐24.4K）</h3><p><strong>GitHub</strong>：<a href="https://github.com/microsoft/UFO">microsoft&#x2F;UFO</a> | <a href="https://github.com/microsoft/OmniParser">microsoft&#x2F;OmniParser</a></p><p>微软自家出品，<strong>Windows 原生 Agent 操作系统</strong>。</p><p><strong>OmniParser V2</strong> 是目前最强的屏幕解析引擎：把任意截图转成结构化 UI 元素列表。支持开箱接入 GPT-5.x &#x2F; Claude &#x2F; DeepSeek R1 &#x2F; Qwen 2.5VL 等模型。配套 <strong>OmniTool</strong> 提供 Docker 化 Windows 11 VM。</p><p><strong>UFO³</strong> 的核心优势是 <strong>Windows 深度集成</strong>：</p><ul><li><strong>双通道感知</strong>：Windows UIA API（控件树）+ 视觉模型（OmniParser），精确性和灵活性兼得</li><li><strong>智能执行选择</strong>：自动判断用 API 直接调用还是模拟 GUI 操作</li><li><strong>多设备编排</strong>（Galaxy 模式）：DAG 任务分解 + 异步并行 + 跨设备协作</li></ul><p><strong>演进路线</strong>：</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scss">UFO (<span class="hljs-number">2024.02</span>) → UFO² (<span class="hljs-number">2025.04</span>) → UFO³ Galaxy (<span class="hljs-number">2025.11</span>)<br>单设备 Agent  → Desktop AgentOS → 多设备编排<br></code></pre></td></tr></table></figure><p><strong>适合</strong>：Windows 桌面应用为核心的测试场景，尤其是需要操作 Office、Visual Studio 等微软生态软件。</p><h3 id="4-字节跳动-UI-TARS-Midscene-js（⭐9-5K-⭐27-8K-⭐11-7K）"><a href="#4-字节跳动-UI-TARS-Midscene-js（⭐9-5K-⭐27-8K-⭐11-7K）" class="headerlink" title="4. 字节跳动 UI-TARS + Midscene.js（⭐9.5K + ⭐27.8K + ⭐11.7K）"></a>4. 字节跳动 UI-TARS + Midscene.js（⭐9.5K + ⭐27.8K + ⭐11.7K）</h3><p><strong>GitHub</strong>：<a href="https://github.com/bytedance/UI-TARS">bytedance&#x2F;UI-TARS</a> | <a href="https://github.com/bytedance/UI-TARS-desktop">bytedance&#x2F;UI-TARS-desktop</a> | <a href="https://github.com/web-infra-dev/midscene">web-infra-dev&#x2F;midscene</a></p><p><strong>UI-TARS</strong> 是字节开源的多模态 GUI Agent 模型，基于 Qwen2.5-VL。它和商业模型走的是不同路线——<strong>可本地部署、零 API 成本</strong>。</p><p>UI-TARS 的独特优势：</p><ul><li><strong>UI 定位精度最高</strong>：ScreenSpot-V2 达 94.2%（超 GPT 87.9%、Claude 87.6%）</li><li><strong>Windows + Android 双平台原生支持</strong>：提供 COMPUTER_USE 和 MOBILE_USE 两套 Prompt 模板</li><li><strong>UI-TARS-2</strong>（2025.09）：All-In-One Agent 模型，加入 Game、Code、Tool Use</li><li><strong>7B 模型可本地部署</strong>：一张消费级 GPU 即可运行</li></ul><p><strong>Midscene.js</strong> 是配套的测试框架（v1.0 已发布），用自然语言写测试：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-comment">// 自然语言描述操作</span><br><span class="hljs-keyword">await</span> agent.<span class="hljs-title function_">aiAction</span>(<span class="hljs-string">&#x27;点击搜索框，输入 &quot;AI testing&quot;，按回车&#x27;</span>);<br><span class="hljs-keyword">await</span> agent.<span class="hljs-title function_">aiAssert</span>(<span class="hljs-string">&#x27;搜索结果中包含相关内容&#x27;</span>);<br><span class="hljs-keyword">const</span> data = <span class="hljs-keyword">await</span> agent.<span class="hljs-title function_">aiExtract</span>(<span class="hljs-string">&#x27;提取前3个搜索结果的标题&#x27;</span>);<br></code></pre></td></tr></table></figure><p>全平台支持：Web（Puppeteer&#x2F;Playwright）+ Android（adb）+ iOS（WebDriverAgent）</p><p><strong>适合</strong>：追求零成本本地部署、同时覆盖桌面和移动端的团队。</p><h3 id="5-AskUI-Vision-Agent-—-企业级跨平台（⭐501）"><a href="#5-AskUI-Vision-Agent-—-企业级跨平台（⭐501）" class="headerlink" title="5. AskUI Vision Agent — 企业级跨平台（⭐501）"></a>5. AskUI Vision Agent — 企业级跨平台（⭐501）</h3><p><strong>GitHub</strong>：<a href="https://github.com/askui/vision-agent">askui&#x2F;vision-agent</a></p><p>Python SDK，支持 Windows &#x2F; Mac &#x2F; Linux &#x2F; Android &#x2F; iOS &#x2F; Citrix。独特优势：</p><ul><li><strong>Windows 后台自动化</strong>：Agent 创建独立会话，不占用前台鼠标键盘</li><li>支持热插拔模型 + 本地部署</li><li>Agent OS 底层设备控制器</li></ul><p><strong>适合</strong>：企业环境，对安全性和稳定性有要求。</p><h3 id="6-Arbigent-—-Android-x2F-iOS-场景分解测试（⭐505）"><a href="#6-Arbigent-—-Android-x2F-iOS-场景分解测试（⭐505）" class="headerlink" title="6. Arbigent — Android&#x2F;iOS 场景分解测试（⭐505）"></a>6. Arbigent — Android&#x2F;iOS 场景分解测试（⭐505）</h3><p><strong>GitHub</strong>：<a href="https://github.com/takahirom/arbigent">takahirom&#x2F;arbigent</a></p><p>核心创新：<strong>场景分解（Scenario Breakdown）</strong>。把复杂的端到端测试拆成多个有依赖关系的子场景，每个子场景独立运行和验证，大幅提高 AI 测试的可预测性。</p><p>GUI 操作界面，非开发人员也能上手。支持 OpenAI &#x2F; Gemini &#x2F; Claude 等多种模型。</p><p><strong>适合</strong>：移动端 QA 团队。</p><hr><h2 id="三、学术前沿：正在孵化的下一代技术"><a href="#三、学术前沿：正在孵化的下一代技术" class="headerlink" title="三、学术前沿：正在孵化的下一代技术"></a>三、学术前沿：正在孵化的下一代技术</h2><table><thead><tr><th>项目</th><th>出处</th><th>核心贡献</th><th>平台</th></tr></thead><tbody><tr><td><strong>Scaling Agents for CU</strong></td><td>Anthropic (2026.02)</td><td>BJudge + 多轮执行，OSWorld 72.6% 超越人类</td><td>桌面</td></tr><tr><td><strong>AUITestAgent</strong></td><td>北大</td><td>从自然语言需求自动生成 GUI 功能测试</td><td>Android</td></tr><tr><td><strong>VisionDroid</strong></td><td>学术界</td><td>MLLM 功能感知探索 + 非崩溃 bug 检测</td><td>Android</td></tr><tr><td><strong>DroidAgent</strong></td><td>KAIST</td><td>意图驱动自主探索，自动生成 UIAutomator2 脚本</td><td>Android</td></tr><tr><td><strong>CogAgent</strong></td><td>清华&#x2F;智谱</td><td>双分辨率视觉编码器，专为 GUI Agent 设计</td><td>双平台</td></tr><tr><td><strong>AppAgent</strong></td><td>腾讯</td><td>多模态 Agent 像用户操作手机，含自主学习阶段</td><td>Android</td></tr></tbody></table><p>论文合集：<a href="https://github.com/showlab/Awesome-GUI-Agent">Awesome-GUI-Agent</a>（⭐1.1K），持续更新。</p><hr><h2 id="四、横向对比：该选哪个？"><a href="#四、横向对比：该选哪个？" class="headerlink" title="四、横向对比：该选哪个？"></a>四、横向对比：该选哪个？</h2><table><thead><tr><th>方案</th><th>Windows</th><th>Android</th><th>最新模型支持</th><th>开源</th><th>成熟度</th><th>成本</th></tr></thead><tbody><tr><td><strong>Cua</strong></td><td>✅ 沙盒</td><td>✅ QEMU</td><td>Claude&#x2F;GPT&#x2F;Gemini&#x2F;开源</td><td>✅ MIT</td><td>活跃开发</td><td>免费+API</td></tr><tr><td><strong>UiPath Screen Agent</strong></td><td>✅ 原生</td><td>❌</td><td>Claude Opus 4.5&#x2F;GPT-5</td><td>❌ 商业</td><td>生产级</td><td>企业许可</td></tr><tr><td><strong>UFO³ + OmniParser</strong></td><td>✅✅ 最深</td><td>❌</td><td>GPT-5.x&#x2F;Claude&#x2F;DeepSeek&#x2F;Qwen</td><td>✅</td><td>生产级</td><td>免费+API</td></tr><tr><td><strong>UI-TARS + Midscene</strong></td><td>✅</td><td>✅ 原生</td><td>UI-TARS-2（本地）</td><td>✅</td><td>v1.0</td><td>完全免费</td></tr><tr><td><strong>AskUI</strong></td><td>✅</td><td>✅</td><td>多模型</td><td>部分</td><td>商业可用</td><td>SaaS</td></tr><tr><td><strong>Arbigent</strong></td><td>❌</td><td>✅✅</td><td>多模型</td><td>✅</td><td>早期</td><td>免费+API</td></tr></tbody></table><hr><h2 id="五、实战推荐方案"><a href="#五、实战推荐方案" class="headerlink" title="五、实战推荐方案"></a>五、实战推荐方案</h2><h3 id="方案-A：最强桌面能力（Claude-Opus-4-6-Cua-x2F-UFO³）"><a href="#方案-A：最强桌面能力（Claude-Opus-4-6-Cua-x2F-UFO³）" class="headerlink" title="方案 A：最强桌面能力（Claude Opus 4.6 + Cua&#x2F;UFO³）"></a>方案 A：最强桌面能力（Claude Opus 4.6 + Cua&#x2F;UFO³）</h3><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Claude</span> Opus <span class="hljs-number">4</span>.<span class="hljs-number">6</span> (<span class="hljs-number">72</span>.<span class="hljs-number">7</span>% OSWorld) + Cua 沙盒 或 UFO³ 框架<br></code></pre></td></tr></table></figure><ul><li>当前桌面操控 SOTA，超越人类水平</li><li>Cua 提供隔离沙盒环境，安全可控</li><li>UFO³ 提供 Windows 原生深度集成</li><li><strong>成本</strong>：$5&#x2F;1M input tokens，适合高价值测试场景</li></ul><h3 id="方案-B：性价比之选（GPT-5-3-Codex-Cua）"><a href="#方案-B：性价比之选（GPT-5-3-Codex-Cua）" class="headerlink" title="方案 B：性价比之选（GPT-5.3 Codex + Cua）"></a>方案 B：性价比之选（GPT-5.3 Codex + Cua）</h3><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">GPT</span>-<span class="hljs-number">5</span>.<span class="hljs-number">3</span> Codex (<span class="hljs-number">64</span>.<span class="hljs-number">7</span>% OSWorld) + Cua 沙盒<br></code></pre></td></tr></table></figure><ul><li>单模型历史最高 OSWorld 得分</li><li>成本仅 Claude 的 1&#x2F;4（$1.25&#x2F;1M input tokens）</li><li>原生视频+音频理解能力</li><li><strong>适合</strong>：大规模回归测试，对成本敏感</li></ul><h3 id="方案-C：零成本本地部署（UI-TARS-Midscene-js）"><a href="#方案-C：零成本本地部署（UI-TARS-Midscene-js）" class="headerlink" title="方案 C：零成本本地部署（UI-TARS + Midscene.js）"></a>方案 C：零成本本地部署（UI-TARS + Midscene.js）</h3><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">UI</span>-TARS-<span class="hljs-number">1</span>.<span class="hljs-number">5</span>-<span class="hljs-number">7</span>B（本地 GPU）+ Midscene.js 框架<br></code></pre></td></tr></table></figure><ul><li>Windows + Android 双平台原生覆盖</li><li>零 API 费用，一张 GPU 搞定</li><li>Midscene.js 自然语言写测试，开发者友好</li><li><strong>适合</strong>：有 GPU 资源、追求长期低成本运营</li></ul><h3 id="方案-D：企业级落地（UiPath-Claude-Opus-4-5）"><a href="#方案-D：企业级落地（UiPath-Claude-Opus-4-5）" class="headerlink" title="方案 D：企业级落地（UiPath + Claude Opus 4.5）"></a>方案 D：企业级落地（UiPath + Claude Opus 4.5）</h3><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">UiPath</span> Screen Agent + Claude Opus <span class="hljs-number">4</span>.<span class="hljs-number">5</span><br></code></pre></td></tr></table></figure><ul><li>OSWorld-Verified 认证第一</li><li>企业级基础设施（编排、权限、审计）</li><li><strong>适合</strong>：已有 RPA 基础设施的大型企业</li></ul><hr><h2 id="六、趋势判断"><a href="#六、趋势判断" class="headerlink" title="六、趋势判断"></a>六、趋势判断</h2><p><strong>1. Computer Use 已超越人类水平</strong><br>Claude Opus 4.6 在 OSWorld 上达到 72.7%，超越人类的 72.36%。这是一个里程碑——意味着在标准化桌面任务上，AI Agent 已经比普通人更准确。</p><p><strong>2. 商业模型和开源模型走向不同赛道</strong></p><ul><li>商业模型（Claude&#x2F;GPT）追求极致准确率，适合高价值场景</li><li>开源模型（UI-TARS）追求零成本部署和定位精度，适合大规模应用</li></ul><p><strong>3. 沙盒化是 CI&#x2F;CD 集成的关键</strong><br>Cua、OmniTool 等都提供 Docker 化的隔离环境。这意味着 AI GUI 测试可以像单元测试一样跑在 CI pipeline 里。</p><p><strong>4. 速度和成本仍是主要瓶颈</strong><br>每步截图 + LLM 推理需要 2-5 秒，传统自动化是毫秒级。高频回归测试仍需混合策略：核心路径用传统方法，复杂场景用 AI Agent。</p><p><strong>5. 2026 是落地元年</strong><br>从 benchmark 到生产：UiPath Screen Agent 已在企业中部署，Midscene.js 已发布 v1.0，Cua 已有 12.4K star。这不再是论文里的概念。</p><hr><h2 id="资源汇总"><a href="#资源汇总" class="headerlink" title="资源汇总"></a>资源汇总</h2><table><thead><tr><th>资源</th><th>链接</th><th>说明</th></tr></thead><tbody><tr><td>Awesome-GUI-Agent</td><td><a href="https://github.com/showlab/Awesome-GUI-Agent">GitHub</a></td><td>最全论文列表（⭐1.1K）</td></tr><tr><td>OSWorld Benchmark</td><td><a href="https://os-world.github.io/">官网</a></td><td>桌面操控标准评测</td></tr><tr><td>Cua</td><td><a href="https://github.com/trycua/cua">GitHub</a></td><td>开源 Computer Use Agent 平台</td></tr><tr><td>UI-TARS</td><td><a href="https://github.com/bytedance/UI-TARS">GitHub</a></td><td>字节开源 GUI Agent 模型</td></tr><tr><td>Midscene.js</td><td><a href="https://midscenejs.com/">官网</a></td><td>自然语言 UI 测试框架</td></tr><tr><td>UFO³</td><td><a href="https://github.com/microsoft/UFO">GitHub</a></td><td>微软 Windows Agent OS</td></tr><tr><td>OmniParser V2</td><td><a href="https://github.com/microsoft/OmniParser">GitHub</a></td><td>微软屏幕解析引擎</td></tr><tr><td>LLM-Powered GUI Agents Survey</td><td><a href="https://github.com/PhoneLLM/Awesome-LLM-Powered-Phone-GUI-Agents">GitHub</a></td><td>手机 GUI Agent 综述</td></tr></tbody></table><hr><p><em>本文基于 2026 年 2 月 12 日的调研。这个领域每周都在刷新纪录——一个月前 Claude Opus 4.5 还是 SOTA，现在 Opus 4.6 已经超越人类。建议持续关注 <a href="https://os-world.github.io/">OSWorld Leaderboard</a> 获取最新排名。</em></p>]]></content>
    
    
    <categories>
      
      <category>技术实战</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>测试自动化</tag>
      
      <tag>多模态大模型</tag>
      
      <tag>GUI Agent</tag>
      
      <tag>Windows</tag>
      
      <tag>Android</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>科技热榜速递 | 2026-02-13：Seedance 2.0 正式发布、Claude Code 变蠢争议、xAI 星际野心</title>
    <link href="/2026/02/12/tech-hot-news-2026-02-12/"/>
    <url>/2026/02/12/tech-hot-news-2026-02-12/</url>
    
    <content type="html"><![CDATA[<blockquote><p>每日精选国外科技社区热门内容，覆盖 Hacker News、Lobsters、TechCrunch、Dev.to、Ars Technica、Slashdot 六大平台。原文链接 + 详情摘要，一文速览全球科技圈在聊什么。</p></blockquote><hr><h2 id="🔥-今日头条：Seedance-2-0-正式发布——字节跳动视频生成模型迈入工业级"><a href="#🔥-今日头条：Seedance-2-0-正式发布——字节跳动视频生成模型迈入工业级" class="headerlink" title="🔥 今日头条：Seedance 2.0 正式发布——字节跳动视频生成模型迈入工业级"></a>🔥 今日头条：Seedance 2.0 正式发布——字节跳动视频生成模型迈入工业级</h2><p>2 月 12 日，字节跳动 Seed 团队正式发布新一代视频创作模型 <strong>Seedance 2.0</strong>，已全量上线豆包 App、即梦 AI 等平台。</p><p>这次升级的核心不是「更好看」，而是<strong>「更能用」</strong>：</p><ul><li><strong>统一多模态架构</strong>：文字、图片、音频、视频四种模态输入，最多同时引入 9 张图片 + 多段视听素材作为参考</li><li><strong>物理还原能力飞跃</strong>：双人花滑、多人竞技等高难度动作场景的连贯性大幅提升，模型真正开始「懂物理」</li><li><strong>15 秒多镜头 + 双声道立体声</strong>：音画同步，一次生成即可获得沉浸式视听体验</li><li><strong>导演级操控</strong>：支持精准指定构图、运镜、文字分镜脚本</li><li><strong>视频编辑与延展</strong>：可对特定片段进行定向修改，支持「接着拍」——极大降低影视、广告、电商制作门槛</li></ul><p>美国导演试用后评价「可能颠覆好莱坞的工作方式」。36 氪将其定性为视频生成领域的「奇点时刻」。</p><p>体验入口：即梦网页端 → 视频生成 → 选择 Seedance 2.0 | 豆包 App → 对话框 → Seedance 2.0 | 火山方舟体验中心</p><hr><h2 id="📰-Hacker-News-热门-Top-10"><a href="#📰-Hacker-News-热门-Top-10" class="headerlink" title="📰 Hacker News 热门 Top 10"></a>📰 Hacker News 热门 Top 10</h2><h3 id="1-Claude-Code-是不是在变蠢？（735分-x2F-505评论）"><a href="#1-Claude-Code-是不是在变蠢？（735分-x2F-505评论）" class="headerlink" title="1. Claude Code 是不是在变蠢？（735分 &#x2F; 505评论）"></a>1. Claude Code 是不是在变蠢？（735分 &#x2F; 505评论）</h3><p>Claude Code v2.1.20 发布了一个引发众怒的改动：<strong>所有文件读取和搜索操作的输出被替换成了一行无用的摘要</strong>。比如原来会显示具体读了哪些文件、搜了什么模式，现在只有「Read 3 files」「Searched for 1 pattern」——完全没有实际信息。</p><p>用户在 GitHub Issues 上集体抗议，要求恢复显示文件路径，或至少提供一个开关。Anthropic 的回应是「对大多数用户来说这是一个减少噪音的好改动」，并建议使用 verbose 模式——但 verbose 模式会倾泻大量调试信息、子 Agent 完整输出等内容，根本不是用户想要的。</p><p>这场争论反映了一个更深层的问题：<strong>当 AI 工具越来越强大时，用户对透明度和可控性的需求反而在增加，而不是减少。</strong> 你花了 $200&#x2F;月买一个工具，它却开始对你隐藏自己在做什么。</p><p>🔗 <a href="https://symmetrybreak.ing/blog/claude-code-is-being-dumbed-down/">原文</a> | <a href="https://news.ycombinator.com/item?id=46974853">HN 讨论</a></p><hr><h3 id="2-亚马逊-Ring「寻狗广告」引发隐私监控担忧（415分-x2F-232评论）"><a href="#2-亚马逊-Ring「寻狗广告」引发隐私监控担忧（415分-x2F-232评论）" class="headerlink" title="2. 亚马逊 Ring「寻狗广告」引发隐私监控担忧（415分 &#x2F; 232评论）"></a>2. 亚马逊 Ring「寻狗广告」引发隐私监控担忧（415分 &#x2F; 232评论）</h3><p>亚马逊在超级碗期间投放了 Ring 摄像头的「Search Party」广告，展示邻居们用 Ring 摄像头网络帮助寻找走失的狗。广告本意是温馨可爱，但却在网上引发了大规模反弹——批评者指出，这实质上展示了一个由私人摄像头组成的<strong>大规模监控网络</strong>。</p><p>公众担忧的核心：当数百万个家庭摄像头可以被串联搜索时，找狗和追踪人之间只有一步之遥。</p><p>🔗 <a href="https://www.theverge.com/tech/876866/ring-search-party-super-bowl-ad-online-backlash">The Verge 报道</a></p><hr><h3 id="3-Fluorite-—-完全集成-Flutter-的主机级游戏引擎（393分-x2F-230评论）"><a href="#3-Fluorite-—-完全集成-Flutter-的主机级游戏引擎（393分-x2F-230评论）" class="headerlink" title="3. Fluorite — 完全集成 Flutter 的主机级游戏引擎（393分 &#x2F; 230评论）"></a>3. Fluorite — 完全集成 Flutter 的主机级游戏引擎（393分 &#x2F; 230评论）</h3><p>Fluorite 是一个全新的游戏引擎，核心卖点是<strong>完全集成 Flutter 生态</strong>。底层用 C++ 编写的高性能 ECS（Entity-Component-System）架构，上层用 Dart 编写游戏逻辑，可以直接使用 Flutter 的开发工具链和 UI 组件系统。</p><p>亮点功能：</p><ul><li><strong>FluoriteView Widget</strong>：在 Flutter 应用中嵌入多个 3D 场景视图</li><li><strong>模型定义触摸区域</strong>：3D 美术在 Blender 中直接定义可点击区域，开发者监听事件即可</li><li><strong>游戏代码和 UI 代码共享状态</strong>：完全用 Flutter 的方式</li></ul><p>这对移动游戏开发者来说是个有趣的选择：不用学 Unity&#x2F;Unreal，用已有的 Dart&#x2F;Flutter 技能就能做游戏。</p><p>🔗 <a href="https://fluorite.game/">官网</a></p><hr><h3 id="4-无人机入侵导致美国厄尔巴索机场关闭（327分-x2F-513评论）"><a href="#4-无人机入侵导致美国厄尔巴索机场关闭（327分-x2F-513评论）" class="headerlink" title="4. 无人机入侵导致美国厄尔巴索机场关闭（327分 &#x2F; 513评论）"></a>4. 无人机入侵导致美国厄尔巴索机场关闭（327分 &#x2F; 513评论）</h3><p>FAA 因无人机入侵事件对德克萨斯州厄尔巴索机场实施了飞行限制。513 条评论讨论了无人机管控政策、机场安全以及越来越频繁的无人机干扰航空事件。</p><p>🔗 <a href="https://www.nytimes.com/2026/02/11/us/faa-el-paso-flight-restrictions.html">NYT 报道</a></p><hr><h3 id="5-WiFi-可能成为隐形的大规模监控系统（297分-x2F-146评论）"><a href="#5-WiFi-可能成为隐形的大规模监控系统（297分-x2F-146评论）" class="headerlink" title="5. WiFi 可能成为隐形的大规模监控系统（297分 &#x2F; 146评论）"></a>5. WiFi 可能成为隐形的大规模监控系统（297分 &#x2F; 146评论）</h3><p>研究人员发出警告：WiFi 信号可以被用来追踪人体移动。WiFi 信号在室内传播时会被人体反射和吸收，通过分析这些信号变化，可以在不需要任何摄像头的情况下检测、定位甚至识别室内的人。</p><p>这种技术不需要目标携带任何设备，而且可以穿墙工作。研究人员警告这可能成为一种”隐形的大规模监控系统”。</p><p>🔗 <a href="https://scitechdaily.com/researchers-warn-wifi-could-become-an-invisible-mass-surveillance-system/">SciTechDaily</a></p><hr><h3 id="6-Discord-x2F-Twitch-x2F-Snapchat-年龄验证绕过漏洞（285分-x2F-149评论）"><a href="#6-Discord-x2F-Twitch-x2F-Snapchat-年龄验证绕过漏洞（285分-x2F-149评论）" class="headerlink" title="6. Discord&#x2F;Twitch&#x2F;Snapchat 年龄验证绕过漏洞（285分 &#x2F; 149评论）"></a>6. Discord&#x2F;Twitch&#x2F;Snapchat 年龄验证绕过漏洞（285分 &#x2F; 149评论）</h3><p>安全研究人员发现，Discord 使用的年龄验证提供商 k-id 存在根本性的设计缺陷。k-id 声称不会将用户面部照片发送到服务器（出于隐私考虑），而是发送面部元数据。但这意味着<strong>可以构造看似合法的元数据来绕过验证</strong>，服务器无法区分真假。</p><p>之前的绕过方法被修补后，随着 Discord 将年龄验证扩展到全球，研究人员又找到了新的绕过方式。这暴露了一个根本矛盾：<strong>隐私保护（不发送真实人脸）和验证可靠性（需要真实人脸）之间的不可调和冲突。</strong></p><p>🔗 <a href="https://age-verifier.kibty.town/">漏洞详情</a></p><hr><h3 id="7-GLM-5：面向复杂系统工程和长期-Agent-任务的模型（244分-x2F-397评论）"><a href="#7-GLM-5：面向复杂系统工程和长期-Agent-任务的模型（244分-x2F-397评论）" class="headerlink" title="7. GLM-5：面向复杂系统工程和长期 Agent 任务的模型（244分 &#x2F; 397评论）"></a>7. GLM-5：面向复杂系统工程和长期 Agent 任务的模型（244分 &#x2F; 397评论）</h3><p>智谱 AI（Z.AI）发布了 GLM-5，专门瞄准复杂系统工程和长时间运行的 Agent 任务场景。在 Hacker News 上获得 244 分和近 400 条评论，说明国际社区对中国 AI 的关注度在持续上升。</p><p>🔗 <a href="https://z.ai/blog/glm-5">GLM-5 博客</a></p><hr><h3 id="8-GLM-OCR：复杂文档理解的多模态-OCR-模型（217分-x2F-67评论）"><a href="#8-GLM-OCR：复杂文档理解的多模态-OCR-模型（217分-x2F-67评论）" class="headerlink" title="8. GLM-OCR：复杂文档理解的多模态 OCR 模型（217分 &#x2F; 67评论）"></a>8. GLM-OCR：复杂文档理解的多模态 OCR 模型（217分 &#x2F; 67评论）</h3><p>智谱同时发布了 GLM-OCR，一个基于 GLM-V 编码器-解码器架构的多模态 OCR 模型。核心创新包括多 Token 预测（MTP）损失函数和全任务强化学习。</p><p>技术亮点：</p><ul><li><strong>OmniDocBench V1.5 得分 94.62</strong>，所有文档理解任务排名第一</li><li>使用 CogViT 视觉编码器 + GLM-0.5B 语言解码器</li><li>两阶段处理流水线：版面分析 + 并行识别</li><li>覆盖公式识别、表格识别、信息提取等场景</li></ul><p>🔗 <a href="https://github.com/zai-org/GLM-OCR">GitHub</a></p><hr><h3 id="9-NetNewsWire-23-周年（202分-x2F-47评论）"><a href="#9-NetNewsWire-23-周年（202分-x2F-47评论）" class="headerlink" title="9. NetNewsWire 23 周年（202分 &#x2F; 47评论）"></a>9. NetNewsWire 23 周年（202分 &#x2F; 47评论）</h3><p>老牌 RSS 阅读器 NetNewsWire 迎来 23 岁生日。刚刚发布了 Mac 和 iOS 的 7.0 版本，正在开发 7.0.1 修复版。创始人 Brent 去年退休后，开发速度反而加快了。</p><p>在算法推荐统治信息流的时代，一个 23 年的 RSS 阅读器还能在 HN 上获得 200+ 分，说明<strong>开放 Web 和用户主权</strong>在技术社区仍然有强大的号召力。</p><p>🔗 <a href="https://netnewswire.blog/2026/02/11/netnewswire-turns.html">博客</a></p><hr><h3 id="10-GPT-5-法律推理实验：100-vs-联邦法官-52-（112分-x2F-87评论）"><a href="#10-GPT-5-法律推理实验：100-vs-联邦法官-52-（112分-x2F-87评论）" class="headerlink" title="10. GPT-5 法律推理实验：100% vs 联邦法官 52%（112分 &#x2F; 87评论）"></a>10. GPT-5 法律推理实验：100% vs 联邦法官 52%（112分 &#x2F; 87评论）</h3><p>一项学术研究让 GPT-5 和联邦法官在相同法律推理任务上对比。结果：**GPT-5 达到 100% 准确率，而联邦法官只有 52%**。这是 AI 在专业领域能力的又一个里程碑式数据点，引发了关于 AI 在法律系统中角色的深入讨论。</p><p>🔗 <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=6155012">论文</a></p><hr><h2 id="🦞-Lobsters-热门-Top-5"><a href="#🦞-Lobsters-热门-Top-5" class="headerlink" title="🦞 Lobsters 热门 Top 5"></a>🦞 Lobsters 热门 Top 5</h2><h3 id="1-如何将-Google-搜索依赖减半（116分-x2F-50评论）"><a href="#1-如何将-Google-搜索依赖减半（116分-x2F-50评论）" class="headerlink" title="1. 如何将 Google 搜索依赖减半（116分 &#x2F; 50评论）"></a>1. 如何将 Google 搜索依赖减半（116分 &#x2F; 50评论）</h3><p>开发者构建了 <a href="https://github.com/asciimoo/hister">Hister</a>，一个自托管的网页浏览历史搜索工具。它会在本地索引你访问过的所有网页，当你想找回之前看过的内容时，直接搜索本地索引而不是去 Google。</p><p>作者在 1.5 个月内成功将对 Google 搜索的依赖降低了 50%。核心观点：Google 搜索已经被广告和 SEO 操纵严重侵蚀，而你要找的信息很多时候就在你之前看过的页面里。</p><p>🔗 <a href="https://hister.org/posts/how-i-cut-my-google-search-dependence-in-half/">原文</a></p><h3 id="2-缺失的-GitHub-状态页面（125分-x2F-19评论）"><a href="#2-缺失的-GitHub-状态页面（125分-x2F-19评论）" class="headerlink" title="2. 缺失的 GitHub 状态页面（125分 &#x2F; 19评论）"></a>2. 缺失的 GitHub 状态页面（125分 &#x2F; 19评论）</h3><p>一个展示 GitHub 各服务真实可用性状态的第三方页面，比 GitHub 官方状态页更准确和详细。</p><p>🔗 <a href="https://mrshu.github.io/github-statuses/">GitHub Statuses</a></p><h3 id="3-Windows-记事本远程代码执行漏洞-CVE-2026-20841（47分-x2F-16评论）"><a href="#3-Windows-记事本远程代码执行漏洞-CVE-2026-20841（47分-x2F-16评论）" class="headerlink" title="3. Windows 记事本远程代码执行漏洞 CVE-2026-20841（47分 &#x2F; 16评论）"></a>3. Windows 记事本远程代码执行漏洞 CVE-2026-20841（47分 &#x2F; 16评论）</h3><p>Windows 记事本（Notepad）被发现存在远程代码执行漏洞。作为 Windows 上最简单、最基础的文本编辑器，记事本出现 RCE 漏洞着实令人意外。</p><p>🔗 <a href="https://www.cve.org/CVERecord?id=CVE-2026-20841">CVE 详情</a></p><h3 id="4-Majutsu-—-jujutsu-版本控制的-Magit-接口（30分-x2F-4评论）"><a href="#4-Majutsu-—-jujutsu-版本控制的-Magit-接口（30分-x2F-4评论）" class="headerlink" title="4. Majutsu — jujutsu 版本控制的 Magit 接口（30分 &#x2F; 4评论）"></a>4. Majutsu — jujutsu 版本控制的 Magit 接口（30分 &#x2F; 4评论）</h3><p>为 jujutsu（新一代版本控制系统）开发的 Emacs Magit 风格接口。小众但精准地击中了 Emacs + 新型 VCS 用户群。</p><p>🔗 <a href="https://github.com/0WD0/majutsu">GitHub</a></p><h3 id="5-前向求值构建系统（24分-x2F-6评论）"><a href="#5-前向求值构建系统（24分-x2F-6评论）" class="headerlink" title="5. 前向求值构建系统（24分 &#x2F; 6评论）"></a>5. 前向求值构建系统（24分 &#x2F; 6评论）</h3><p>Garnix 团队介绍 garn2，一种使用前向求值（forward evaluation）的构建系统设计理念。</p><p>🔗 <a href="https://garnix.io/blog/garn2/">博客</a></p><hr><h2 id="📡-TechCrunch-头条-Top-5"><a href="#📡-TechCrunch-头条-Top-5" class="headerlink" title="📡 TechCrunch 头条 Top 5"></a>📡 TechCrunch 头条 Top 5</h2><h3 id="1-xAI-在公开全员会议上描述星际野心"><a href="#1-xAI-在公开全员会议上描述星际野心" class="headerlink" title="1. xAI 在公开全员会议上描述星际野心"></a>1. xAI 在公开全员会议上描述星际野心</h3><p>xAI 罕见地将一场 45 分钟的全员会议视频公开发布在 X 平台上。会议揭示了重大信息：</p><ul><li><strong>大规模裁员</strong>：Musk 描述为「组织结构变革」，导致大量创始团队成员离开</li><li><strong>四大团队重组</strong>：Grok 聊天机器人、编码系统、Imagine 视频生成器、<strong>Macrohard 项目</strong></li><li><strong>Macrohard</strong>：从简单的 Computer Use 到模拟整个企业运营，目标是「AI 全自动设计火箭引擎」</li><li>Toby Pohlen 将领导 Macrohard：「它能做电脑上任何事情」</li></ul><p>🔗 <a href="https://techcrunch.com/2026/02/11/xai-lays-out-interplanetary-ambitions-in-public-all-hands/">TechCrunch</a></p><h3 id="2-AI-推理创业公司-Modal-Labs-融资估值-25-亿美元"><a href="#2-AI-推理创业公司-Modal-Labs-融资估值-25-亿美元" class="headerlink" title="2. AI 推理创业公司 Modal Labs 融资估值 25 亿美元"></a>2. AI 推理创业公司 Modal Labs 融资估值 25 亿美元</h3><p>Modal Labs 专注 AI 推理（inference）基础设施优化，正在与 General Catalyst 谈判以 $25 亿估值融资。这比 5 个月前 B 轮的 $11 亿估值翻了一倍多。年化收入约 $5000 万。</p><p>推理优化正在成为 AI 基础设施的下一个热门赛道——降低运行成本、减少响应延迟。</p><p>🔗 <a href="https://techcrunch.com/2026/02/11/ai-inference-startup-modal-labs-in-talks-to-raise-at-2-5b-valuation-sources-say/">TechCrunch</a></p><h3 id="3-OpenAI-解散「使命对齐」团队"><a href="#3-OpenAI-解散「使命对齐」团队" class="headerlink" title="3. OpenAI 解散「使命对齐」团队"></a>3. OpenAI 解散「使命对齐」团队</h3><p>OpenAI 解散了负责向公众和内部员工传达公司使命的团队（约 6-7 人）。团队前负责人 Josh Achiam 被任命为新职位「首席未来学家」（Chief Futurist）。</p><p>团队成立于 2024 年 9 月，使命是确保「通用人工智能造福全人类」。解散后成员被分配到其他部门。继去年超级对齐团队解散后，OpenAI 安全相关团队的又一次变动。</p><p>🔗 <a href="https://techcrunch.com/2026/02/11/openai-disbands-mission-alignment-team-which-focused-on-safe-and-trustworthy-ai-development/">TechCrunch</a></p><h3 id="4-Apple-Siri-改版再次延期"><a href="#4-Apple-Siri-改版再次延期" class="headerlink" title="4. Apple Siri 改版再次延期"></a>4. Apple Siri 改版再次延期</h3><p>Apple 自 2024 年宣布 Apple Intelligence 以来一直承诺升级 Siri，但发布日期持续推迟。最新消息：原定 iOS 26.4（3 月）上线的新 Siri 部分功能将推迟到 iOS 27（9 月）。</p><p>据 Bloomberg 报道，内部测试遇到了问题。新 Siri 将更像 LLM 聊天机器人，底层传闻使用 Google Gemini。但从 2024 到 2026，已经跳票两年了。</p><p>🔗 <a href="https://techcrunch.com/2026/02/11/apples-siri-revamp-reportedly-delayed-again/">TechCrunch</a></p><h3 id="5-Uber-Eats-推出-AI-购物车助手"><a href="#5-Uber-Eats-推出-AI-购物车助手" class="headerlink" title="5. Uber Eats 推出 AI 购物车助手"></a>5. Uber Eats 推出 AI 购物车助手</h3><p>Uber Eats 推出 AI 购物助手，可以根据文字或图片描述自动添加商品到购物车。</p><p>🔗 <a href="https://techcrunch.com/2026/02/11/uber-eats-launches-ai-assistant-to-help-with-grocery-cart-creation/">TechCrunch</a></p><hr><h2 id="🔧-Dev-to-热门"><a href="#🔧-Dev-to-热门" class="headerlink" title="🔧 Dev.to 热门"></a>🔧 Dev.to 热门</h2><h3 id="1-受够了-Trello：自己做生产力工具（17反应）"><a href="#1-受够了-Trello：自己做生产力工具（17反应）" class="headerlink" title="1. 受够了 Trello：自己做生产力工具（17反应）"></a>1. 受够了 Trello：自己做生产力工具（17反应）</h3><p>开发者 Karsten 吐槽 Trello 被 Atlassian 收购后变得臃肿不堪：更多工作流、更多仪表盘、更多定价层级、更少的清晰度。这些工具「为汇报而生，而非为工作而生」。于是他自己动手做了一个极简生产力工具。</p><p>🔗 <a href="https://dev.to/karsten_biedermann/get-done-i-hate-what-trello-has-become-5a05">Dev.to</a></p><h3 id="2-用-CSS-重现-Pantone-色卡（15反应）"><a href="#2-用-CSS-重现-Pantone-色卡（15反应）" class="headerlink" title="2. 用 CSS 重现 Pantone 色卡（15反应）"></a>2. 用 CSS 重现 Pantone 色卡（15反应）</h3><p>纯 CSS 实现 Pantone 色卡的视觉效果，技术和设计的巧妙结合。</p><p>🔗 <a href="https://dev.to/madsstoumann/re-creating-a-pantone-color-deck-in-css-3108">Dev.to</a></p><hr><h2 id="🔬-Ars-Technica-安全头条"><a href="#🔬-Ars-Technica-安全头条" class="headerlink" title="🔬 Ars Technica 安全头条"></a>🔬 Ars Technica 安全头条</h2><h3 id="Lumma-窃密恶意软件卷土重来"><a href="#Lumma-窃密恶意软件卷土重来" class="headerlink" title="Lumma 窃密恶意软件卷土重来"></a>Lumma 窃密恶意软件卷土重来</h3><p>去年 5 月，全球执法机构联合打击了 Lumma Stealer 的基础设施——这个信息窃取工具在短短两个月内感染了近 40 万台 Windows 电脑。但现在它又回来了，而且更难检测。</p><p>Lumma 的特点：</p><ul><li>2022 年首次出现在俄语网络犯罪论坛</li><li>云端恶意软件即服务（MaaS）模式，高级版售价 $2500</li><li>被 Scattered Spider 等多个著名犯罪组织使用</li><li>新版使用 <strong>ClickFix 诱饵 + Castleloader</strong> 进行大规模传播</li><li>微软称其为多个犯罪集团的「首选工具」</li></ul><p>教训：<strong>执法打击只能暂时压制，不能根除。</strong> 基础设施可以重建，恶意软件可以升级。</p><p>🔗 <a href="https://arstechnica.com/security/2026/02/once-hobbled-lumma-stealer-is-back-with-lures-that-are-hard-to-resist/">Ars Technica</a></p><hr><h2 id="💬-Slashdot-极客新闻"><a href="#💬-Slashdot-极客新闻" class="headerlink" title="💬 Slashdot 极客新闻"></a>💬 Slashdot 极客新闻</h2><h3 id="1-Linux-Mint-考虑延长发布周期"><a href="#1-Linux-Mint-考虑延长发布周期" class="headerlink" title="1. Linux Mint 考虑延长发布周期"></a>1. Linux Mint 考虑延长发布周期</h3><p>Linux Mint 团队表示半年一版的发布节奏太累了，正在考虑延长发布周期。这反映了小型开源团队在维护大型发行版时的资源压力。</p><p>🔗 <a href="https://linux.slashdot.org/story/26/02/11/1821222/">Slashdot</a></p><h3 id="2-科学家警告「温室地球」临界点比预想更近"><a href="#2-科学家警告「温室地球」临界点比预想更近" class="headerlink" title="2. 科学家警告「温室地球」临界点比预想更近"></a>2. 科学家警告「温室地球」临界点比预想更近</h3><p>最新研究表明，全球气候系统的多个临界点可能比此前模型预测的更接近。一旦跨过这些临界点，变化将不可逆转。</p><p>🔗 <a href="https://news.slashdot.org/story/26/02/11/1814253/">Slashdot</a></p><hr><h2 id="🔥-今日洞察"><a href="#🔥-今日洞察" class="headerlink" title="🔥 今日洞察"></a>🔥 今日洞察</h2><h3 id="AI-安全与信任危机"><a href="#AI-安全与信任危机" class="headerlink" title="AI 安全与信任危机"></a>AI 安全与信任危机</h3><p>今天最突出的主题是 <strong>AI 公司与用户之间的信任问题</strong>：Claude Code 隐藏操作细节、OpenAI 解散使命对齐团队、GPT-5 在法律推理上 100% 准确但谁来监督它？当 AI 越来越强大，透明度和可控性不是可选项，而是必选项。</p><h3 id="中国-AI-的国际影响力"><a href="#中国-AI-的国际影响力" class="headerlink" title="中国 AI 的国际影响力"></a>中国 AI 的国际影响力</h3><p>智谱 GLM-5 和 GLM-OCR 同时登上 Hacker News 热门，GLM-5 更是获得了 244 分 &#x2F; 397 评论的高关注度。GLM-OCR 在文档理解 benchmark 上排名第一。中国 AI 正在技术社区获得越来越多的实质性认可。</p><h3 id="监控无处不在"><a href="#监控无处不在" class="headerlink" title="监控无处不在"></a>监控无处不在</h3><p>Ring 摄像头广告、WiFi 信号追踪、年龄验证绕过——三条不相关的新闻指向同一个主题：<strong>隐私正在以各种意想不到的方式被侵蚀</strong>。更值得警惕的是，很多时候这些工具被包装成「安全」和「便利」。</p><h3 id="xAI-的-Macrohard：Computer-Use-的企业级野心"><a href="#xAI-的-Macrohard：Computer-Use-的企业级野心" class="headerlink" title="xAI 的 Macrohard：Computer Use 的企业级野心"></a>xAI 的 Macrohard：Computer Use 的企业级野心</h3><p>xAI 全员会议透露的 Macrohard 项目值得关注：从 Computer Use 扩展到「模拟整个企业运营」。这和 Anthropic 的 Computer Use、OpenAI 的 Operator 本质上在抢同一个赛道，但 Musk 的野心显然更大——他想让 AI 设计火箭引擎。</p><hr><p><em>数据来源：Hacker News、Lobsters、TechCrunch、Dev.to、Ars Technica、Slashdot | 爬取时间：2026-02-12</em></p>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>开源</tag>
      
      <tag>科技热榜</tag>
      
      <tag>Hacker News</tag>
      
      <tag>安全</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GitHub Trending 日报：今日最火的 5 个开源项目深度解析</title>
    <link href="/2026/02/11/github-trending/2026-02-11/"/>
    <url>/2026/02/11/github-trending/2026-02-11/</url>
    
    <content type="html"><![CDATA[<p>AI Agent 工具链正在迎来爆发期——今天的 GitHub Trending 榜单几乎被 AI 相关项目垄断。从 Google 的结构化信息提取、到 GitHub 官方的 Agent 工作流、再到全自动 AI 渗透测试，每一个项目都在重新定义各自领域的工作方式。</p><p>让我们逐一拆解今日最火的 5 个开源项目。</p><hr><h2 id="1-Google-LangExtract-—-用-LLM-从非结构化文本中精准提取结构化数据"><a href="#1-Google-LangExtract-—-用-LLM-从非结构化文本中精准提取结构化数据" class="headerlink" title="1. Google LangExtract — 用 LLM 从非结构化文本中精准提取结构化数据"></a>1. Google LangExtract — 用 LLM 从非结构化文本中精准提取结构化数据</h2><blockquote><p>⭐ 28,463 Stars | 📈 +1,654 today | 🐍 Python | 📜 Apache-2.0</p></blockquote><p><strong>仓库地址：</strong> <a href="https://github.com/google/langextract">google&#x2F;langextract</a></p><h3 id="项目简介"><a href="#项目简介" class="headerlink" title="项目简介"></a>项目简介</h3><p>LangExtract 是 Google 开源的 Python 库，专门用 LLM 从非结构化文本（临床笔记、研报、法律文件等）中提取结构化信息。与传统 NER 工具不同，它强调 <strong>精准溯源</strong>——每个提取结果都能映射回源文本的精确位置。</p><h3 id="为什么火？"><a href="#为什么火？" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>这个项目直击了 LLM 应用落地的一个核心痛点：<strong>可信度</strong>。大模型很擅长理解文本，但企业场景要求的不只是”理解”，还需要”证据”。LangExtract 的溯源（source grounding）机制让每条提取结果都有据可查，极大降低了幻觉风险。</p><p>加上 Google 亲自下场开源，自带 Gemini 系列模型的深度集成，又同时支持 OpenAI 和 Ollama 本地模型，适用面非常广。</p><h3 id="技术亮点"><a href="#技术亮点" class="headerlink" title="技术亮点"></a>技术亮点</h3><ul><li><strong>精准溯源</strong>：每个提取实体都映射到源文本的精确位置，支持可视化高亮</li><li><strong>长文档优化</strong>：分块+并行处理+多轮扫描策略，解决了”大海捞针”问题</li><li><strong>可控输出</strong>：基于 few-shot example 定义 schema，支持 Gemini 的 controlled generation 保证输出格式一致</li><li><strong>交互式可视化</strong>：一键生成独立 HTML 文件，可视化审查提取结果</li><li><strong>灵活的 LLM 后端</strong>：Gemini（推荐）&#x2F; OpenAI &#x2F; Ollama 本地模型</li></ul><h3 id="技术栈"><a href="#技术栈" class="headerlink" title="技术栈"></a>技术栈</h3><p>Python + Pydantic + Gemini API + 可选 OpenAI&#x2F;Ollama 后端。项目结构清晰：核心逻辑在 <code>langextract/</code>，示例在 <code>examples/</code>，基准测试在 <code>benchmarks/</code>。</p><h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li>医疗：从临床报告中提取药物、诊断、检查结果</li><li>法律：合同关键条款提取</li><li>金融：研报中的关键指标结构化</li><li>任何需要”从一堆文字里挑出关键信息”的场景</li></ul><hr><h2 id="2-AionUi-—-AI-CLI-工具的统一图形化工作台"><a href="#2-AionUi-—-AI-CLI-工具的统一图形化工作台" class="headerlink" title="2. AionUi — AI CLI 工具的统一图形化工作台"></a>2. AionUi — AI CLI 工具的统一图形化工作台</h2><blockquote><p>⭐ 14,445 Stars | 📈 +629 today | 💻 TypeScript | 📜 Apache-2.0</p></blockquote><p><strong>仓库地址：</strong> <a href="https://github.com/iOfficeAI/AionUi">iOfficeAI&#x2F;AionUi</a></p><h3 id="项目简介-1"><a href="#项目简介-1" class="headerlink" title="项目简介"></a>项目简介</h3><p>AionUi 是一个给命令行 AI 工具（Gemini CLI、Claude Code、Codex、OpenClaw 等）套上图形界面的桌面应用。你可以把它理解为”AI 编程助手的统一工作台”——一个界面管理所有 CLI AI 工具。</p><h3 id="为什么火？-1"><a href="#为什么火？-1" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>2026 年初是 AI 编程工具井喷的时期，Claude Code、Gemini CLI、Codex、OpenClaw 等各有所长，但都是命令行工具。对于很多开发者来说，在多个终端窗口之间切换是真实的痛点。AionUi 把这些工具统一到一个可视化界面里，自动检测本地安装的 CLI 工具、支持多会话并行、对话历史本地存储。</p><h3 id="技术亮点-1"><a href="#技术亮点-1" class="headerlink" title="技术亮点"></a>技术亮点</h3><ul><li><strong>Multi-Agent 模式</strong>：一个界面同时接入 Gemini CLI、Claude Code、Codex、OpenClaw 等多种工具</li><li><strong>自动检测</strong>：自动识别本地安装的 CLI AI 工具并集成</li><li><strong>远程访问</strong>：支持通过内网穿透从手机&#x2F;平板访问桌面端的 AI 工具</li><li><strong>本地优先</strong>：所有对话数据本地存储，不上传到云端</li><li><strong>跨平台</strong>：macOS、Windows、Linux 全平台支持</li></ul><h3 id="技术栈-1"><a href="#技术栈-1" class="headerlink" title="技术栈"></a>技术栈</h3><p>TypeScript + Electron&#x2F;Tauri（桌面端框架）+ Node.js。内置 Gemini CLI，支持 API Key 直连各大模型。</p><h3 id="适用场景-1"><a href="#适用场景-1" class="headerlink" title="适用场景"></a>适用场景</h3><p>如果你同时使用多个 AI 编程助手，又不想在 N 个终端窗口之间切换，AionUi 是目前最成熟的统一方案。特别适合日常在 Claude Code 和 Gemini CLI 之间来回切换的开发者。</p><hr><h2 id="3-Shannon-—-全自动-AI-渗透测试工具（XBOW-基准-96-15-成功率）"><a href="#3-Shannon-—-全自动-AI-渗透测试工具（XBOW-基准-96-15-成功率）" class="headerlink" title="3. Shannon — 全自动 AI 渗透测试工具（XBOW 基准 96.15% 成功率）"></a>3. Shannon — 全自动 AI 渗透测试工具（XBOW 基准 96.15% 成功率）</h2><blockquote><p>⭐ 19,760 Stars | 📈 +3,619 today | 💻 TypeScript | 📜 AGPL-3.0</p></blockquote><p><strong>仓库地址：</strong> <a href="https://github.com/KeygraphHQ/shannon">KeygraphHQ&#x2F;shannon</a></p><h3 id="项目简介-2"><a href="#项目简介-2" class="headerlink" title="项目简介"></a>项目简介</h3><p>Shannon 是一个全自动的 AI 渗透测试工具。你给它指向一个 Web 应用，它会自主完成从信息收集到漏洞利用的全流程，最终输出包含可复现 PoC 的安全报告。在 XBOW 基准测试中达到了 <strong>96.15% 的成功率</strong>。</p><h3 id="为什么火？-2"><a href="#为什么火？-2" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>今天的 star 增量高达 +3,619，是榜单上涨最猛的项目。原因很直接：<strong>Vibe Coding 时代的安全焦虑</strong>。</p><p>AI 编程工具让代码产出效率暴涨，但安全审计跟不上。传统渗透测试一年才做一次，中间 364 天的安全空窗期怎么办？Shannon 的定位就是”你的 AI Red Team”——每次部署前自动跑一遍渗透测试，把安全从”年度事件”变成”持续流程”。</p><h3 id="技术亮点-2"><a href="#技术亮点-2" class="headerlink" title="技术亮点"></a>技术亮点</h3><ul><li><strong>全自动化</strong>：一条命令启动，AI 自主完成侦察→分析→利用→报告全流程</li><li><strong>真实利用</strong>：不是简单的扫描器，而是真正在浏览器中执行攻击（XSS、注入、认证绕过等）</li><li><strong>代码感知</strong>：白盒测试模式，分析源代码指导攻击策略</li><li><strong>内置安全工具链</strong>：集成 Nmap、Subfinder、WhatWeb、Schemathesis 等专业工具</li><li><strong>并行处理</strong>：多类型漏洞并发检测，加速报告生成</li><li><strong>渗透级报告</strong>：输出包含可复制粘贴的 PoC，消灭误报</li></ul><h3 id="技术栈-2"><a href="#技术栈-2" class="headerlink" title="技术栈"></a>技术栈</h3><p>TypeScript + Playwright（浏览器自动化）+ Claude&#x2F;LLM 作为推理引擎 + Nmap&#x2F;Subfinder 等安全工具。分 Lite（AGPL 开源）和 Pro（商业版）两个版本。</p><h3 id="适用场景-2"><a href="#适用场景-2" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li>开发团队：CI&#x2F;CD 管线中集成自动化安全测试</li><li>安全工程师：快速对目标应用做渗透评估</li><li>创业公司：没有专职安全团队时的自动化安全兜底</li></ul><h3 id="⚠️-注意事项"><a href="#⚠️-注意事项" class="headerlink" title="⚠️ 注意事项"></a>⚠️ 注意事项</h3><p>仅限白盒测试（需要源代码访问权限），AGPL-3.0 许可证对商业使用有要求。切勿对未授权的目标使用。</p><hr><h2 id="4-GitHub-gh-aw-—-用自然语言写-GitHub-Actions-Agent-工作流"><a href="#4-GitHub-gh-aw-—-用自然语言写-GitHub-Actions-Agent-工作流" class="headerlink" title="4. GitHub gh-aw — 用自然语言写 GitHub Actions Agent 工作流"></a>4. GitHub gh-aw — 用自然语言写 GitHub Actions Agent 工作流</h2><blockquote><p>⭐ 1,342 Stars | 📈 +496 today | 🐹 Go | 📜 MIT</p></blockquote><p><strong>仓库地址：</strong> <a href="https://github.com/github/gh-aw">github&#x2F;gh-aw</a></p><h3 id="项目简介-3"><a href="#项目简介-3" class="headerlink" title="项目简介"></a>项目简介</h3><p>GitHub 官方出品的 <code>gh</code> CLI 扩展——<strong>Agentic Workflows</strong>。核心理念：用自然语言 Markdown 定义工作流，在 GitHub Actions 中运行 AI Agent。把”Actions + Agent + Safety”融为一体。</p><h3 id="为什么火？-3"><a href="#为什么火？-3" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>这是 GitHub 对”Agent-native CI&#x2F;CD”的官方回答。以前写 GitHub Actions 需要 YAML，现在可以用 Markdown 自然语言描述工作流，AI Agent 自动执行。这不是第三方工具，是 GitHub 自己的产品，信号意义巨大——CI&#x2F;CD 的下一个形态就是 Agent 驱动的。</p><h3 id="技术亮点-3"><a href="#技术亮点-3" class="headerlink" title="技术亮点"></a>技术亮点</h3><ul><li><strong>自然语言工作流</strong>：用 Markdown 写工作流定义，告别 YAML 噩梦</li><li><strong>安全优先架构</strong>：默认只读权限，写操作必须通过 <code>safe-outputs</code> 白名单</li><li><strong>多层安全防护</strong>：沙箱执行、输入消毒、网络隔离、依赖 SHA 锁定、工具白名单</li><li><strong>人工审批门</strong>：关键操作需人类确认</li><li><strong>配套安全组件</strong>：Agent Workflow Firewall（网络出口控制）+ MCP Gateway（MCP 协议网关）</li></ul><h3 id="技术栈-3"><a href="#技术栈-3" class="headerlink" title="技术栈"></a>技术栈</h3><p>Go（CLI 扩展）+ GitHub Actions 运行时 + AI Agent 推理层。支持 Claude Code、Codex、Copilot 等多种 Agent 后端。</p><h3 id="适用场景-3"><a href="#适用场景-3" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li>自动化代码审查、Issue 分类、PR 处理</li><li>用自然语言定义复杂的 CI&#x2F;CD 流程</li><li>需要 AI Agent 参与但又要严格安全控制的 DevOps 场景</li></ul><hr><h2 id="5-Compound-Engineering-Plugin-—-Claude-Code-的复合工程插件"><a href="#5-Compound-Engineering-Plugin-—-Claude-Code-的复合工程插件" class="headerlink" title="5. Compound Engineering Plugin — Claude Code 的复合工程插件"></a>5. Compound Engineering Plugin — Claude Code 的复合工程插件</h2><blockquote><p>⭐ 8,174 Stars | 📈 +406 today | 💻 TypeScript | 📜 MIT</p></blockquote><p><strong>仓库地址：</strong> <a href="https://github.com/EveryInc/compound-engineering-plugin">EveryInc&#x2F;compound-engineering-plugin</a></p><h3 id="项目简介-4"><a href="#项目简介-4" class="headerlink" title="项目简介"></a>项目简介</h3><p>由 Every 团队开源的 Claude Code 插件，核心理念是”<strong>复合工程</strong>“——让每一次工程工作都为下一次积累经验，而不是增加技术债务。提供 Plan → Work → Review → Compound 的完整工作循环。</p><h3 id="为什么火？-4"><a href="#为什么火？-4" class="headerlink" title="为什么火？"></a>为什么火？</h3><p>这个项目代表了一种新的 AI 辅助编程哲学：<strong>不是让 AI 写更多代码，而是让 AI 帮你建立更好的工程习惯</strong>。80% 的时间花在规划和审查，20% 花在执行。每次代码变更都会被 AI 总结成可复用的知识，形成正向飞轮。</p><p>加上插件市场的设计——一条命令就能安装，还支持转换成 OpenCode 和 Codex 格式——降低了使用门槛。</p><h3 id="技术亮点-4"><a href="#技术亮点-4" class="headerlink" title="技术亮点"></a>技术亮点</h3><ul><li><strong>四步循环</strong>：<code>/workflows:plan</code>（规划）→ <code>/workflows:work</code>（执行）→ <code>/workflows:review</code>（多 Agent 代码审查）→ <code>/workflows:compound</code>（知识沉淀）</li><li><strong>插件市场</strong>：<code>/plugin marketplace add</code> 一键安装</li><li><strong>跨平台转换</strong>：支持将 Claude Code 插件转换成 OpenCode 和 Codex 格式</li><li><strong>知识复合</strong>：每次工作成果自动沉淀为 skills 和 patterns，供未来复用</li><li><strong>个人配置同步</strong>：<code>sync</code> 命令可将个人 Claude 配置同步到 OpenCode&#x2F;Codex</li></ul><h3 id="技术栈-4"><a href="#技术栈-4" class="headerlink" title="技术栈"></a>技术栈</h3><p>TypeScript + Bun 运行时 + Claude Code Plugin API。通过 npm 包 <code>@every-env/compound-plugin</code> 分发。</p><h3 id="适用场景-4"><a href="#适用场景-4" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li>使用 Claude Code 做日常开发的团队</li><li>想建立系统化 AI 编程工作流的个人开发者</li><li>跨多个 AI 编程工具（Claude Code + OpenCode + Codex）工作的用户</li></ul><hr><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>今天的 Trending 榜单呈现出一个清晰的趋势：**AI Agent 正在从”单点工具”走向”工程体系”**。</p><ul><li><strong>LangExtract</strong> 解决信息提取的可信度问题</li><li><strong>AionUi</strong> 统一 AI 工具的操作界面</li><li><strong>Shannon</strong> 把安全测试 Agent 化</li><li><strong>gh-aw</strong> 让 CI&#x2F;CD 进入 Agent-native 时代</li><li><strong>Compound Engineering</strong> 用 AI 建立知识复利的工程文化</li></ul><p>这五个项目放在一起看，AI 不仅在写代码，还在测试代码、审查代码、部署代码、从代码中学习。2026 年的软件工程，正在被 Agent 重新定义。</p><hr><p><em>如果觉得这篇分析有帮助，欢迎点赞、在看、转发三连 🚀</em></p>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>开源</tag>
      
      <tag>GitHub</tag>
      
      <tag>安全</tag>
      
      <tag>Trending</tag>
      
      <tag>DevOps</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Seedance 2.0 深度解析：字节跳动&quot;杀死比赛&quot;的 AI 视频模型，附免费试用全攻略</title>
    <link href="/2026/02/10/seedance-2-guide/"/>
    <url>/2026/02/10/seedance-2-guide/</url>
    
    <content type="html"><![CDATA[<blockquote><p>Kill the Game — 字节跳动内部文档标题</p></blockquote><p>2月6日，字节跳动悄然在即梦 AI 平台上线了新一代视频生成模型 <strong>Seedance 2.0</strong>。没有发布会，没有官宣，只有一份飞书文档——标题赫然写着 <strong>“Kill the Game”（杀死比赛）</strong>。</p><p>这份文档同时在线人数一度超过 300 人，凌晨四点还有 90 多人在读。一份产品说明书被几百人围观十几个小时，这大概是前所未有的。</p><p><img src="/images/seedance-2/cover.png" alt="Seedance 2.0 封面"></p><p>AI 视频圈的评价近乎疯狂：</p><blockquote><p>“Seedance 2.0 是我 26 年来最大的震撼” —— AI 视频博主海辛<br>“碾压 Sora 2” —— 多位从业者评价<br>“AI 视频第一阶段的比赛，结束了” —— 极客公园</p></blockquote><p>那么，这个模型到底做到了什么？普通人怎么用？本文带你一次搞清楚。</p><span id="more"></span><hr><h2 id="一、四大核心能力：从”素材生成器”到”AI-导演”"><a href="#一、四大核心能力：从”素材生成器”到”AI-导演”" class="headerlink" title="一、四大核心能力：从”素材生成器”到”AI 导演”"></a>一、四大核心能力：从”素材生成器”到”AI 导演”</h2><h3 id="1-自分镜-自运镜：告别手动控制"><a href="#1-自分镜-自运镜：告别手动控制" class="headerlink" title="1. 自分镜 + 自运镜：告别手动控制"></a>1. 自分镜 + 自运镜：告别手动控制</h3><p>以前用 AI 生成视频，你需要精确描述”镜头从左向右平移”、”先全景再推特写”。稍微复杂一点，模型就犯迷糊。</p><p><strong>Seedance 2.0 可以根据情节自动规划分镜和运镜。</strong> 你只需要告诉它故事是什么，它自己决定怎么拍。</p><p>例如，输入：</p><blockquote><p>“镜头跟随黑衣男子快速逃亡，后面一群人在追，镜头转为侧面跟拍，人物惊慌撞倒路边的水果摊爬起来继续逃”</p></blockquote><p>模型自动理解了：跟拍 → 侧拍 → 碰撞 → 继续逃跑的镜头语言。这是以前需要导演经验才能做到的事。</p><h3 id="2-多模态参考：最多-12-个素材同时输入"><a href="#2-多模态参考：最多-12-个素材同时输入" class="headerlink" title="2. 多模态参考：最多 12 个素材同时输入"></a>2. 多模态参考：最多 12 个素材同时输入</h3><p>你可以同时给它：</p><ul><li><strong>最多 9 张图片</strong>（角色、场景、风格参考）</li><li><strong>最多 3 段视频</strong>（动作参考）</li><li><strong>最多 3 段音频</strong>（语音或音乐参考）</li></ul><p>总计 12 个参考文件。模型自动学习这些素材的特征，融合到生成结果中。等于给了用户一个**”导演工具箱”**。</p><h3 id="3-原生音画同步：告别”配音感”"><a href="#3-原生音画同步：告别”配音感”" class="headerlink" title="3. 原生音画同步：告别”配音感”"></a>3. 原生音画同步：告别”配音感”</h3><p>这是 Seedance 2.0 最让人惊艳的能力之一：</p><ul><li><strong>口型同步</strong>：角色说话时嘴型准确，支持多语言</li><li><strong>情绪匹配</strong>：角色说到激动的台词时，眉毛上挑、眼神变凌厉</li><li><strong>环境音效</strong>：自动生成匹配的背景音乐和音效</li><li><strong>音乐卡点</strong>：理解参考视频中的音乐节奏，生成对应动作</li></ul><p>不再是”视频+后期配音”的拼凑感，而是原生一体化。</p><h3 id="4-多镜头叙事-角色一致性"><a href="#4-多镜头叙事-角色一致性" class="headerlink" title="4. 多镜头叙事 + 角色一致性"></a>4. 多镜头叙事 + 角色一致性</h3><p>从头到尾，角色不会换脸。这意味着你可以生成包含多个镜头切换的完整叙事片段。</p><p>有测试者用 Seedance 2.0 做了一个 <strong>60 秒的 AI 动漫短剧</strong>——只花了 15 分钟，4 段 15 秒视频拼接，全程角色一致，中间没有抽过一次卡。</p><hr><h2 id="二、数据说话：为什么说”杀死比赛”？"><a href="#二、数据说话：为什么说”杀死比赛”？" class="headerlink" title="二、数据说话：为什么说”杀死比赛”？"></a>二、数据说话：为什么说”杀死比赛”？</h2><table><thead><tr><th>指标</th><th>行业平均（此前）</th><th>Seedance 2.0</th></tr></thead><tbody><tr><td>单次生成可用率</td><td>~20%（需抽卡5次+）</td><td>**90%+**（一次出片）</td></tr><tr><td>90分钟项目实际成本</td><td>~10,000 元</td><td>~2,000 元</td></tr><tr><td>5秒特效镜头制作</td><td>传统：1人×1个月</td><td>AI：2分钟×3元</td></tr><tr><td>支持时长</td><td>5-10秒</td><td><strong>4-15秒</strong>（精确到1秒）</td></tr><tr><td>分辨率</td><td>720p</td><td>720p-2K</td></tr><tr><td>多模态输入</td><td>文本&#x2F;图片</td><td><strong>文本+图片+视频+音频</strong></td></tr></tbody></table><p><strong>成本降低 5 倍，效率提升上万倍，可用率从 20% 飙升到 90%+。</strong> 这就是为什么大家说”比赛结束了”。</p><hr><h2 id="三、版权争议：影视飓风事件"><a href="#三、版权争议：影视飓风事件" class="headerlink" title="三、版权争议：影视飓风事件"></a>三、版权争议：影视飓风事件</h2><p>但 Seedance 2.0 上线后也引发了争议。</p><p>知名科技博主影视飓风创始人潘天鸿（Tim）在评测中发现：<strong>仅上传一张面部照片，Seedance 2.0 就生成了带有他个人音色的声音和公司大楼画面。</strong></p><p>他表示：”这基本上可以确定，Seedance 2.0 大量训练了我们公司的视频。我明确没有进行授权。”</p><p>此事引发了 AI 训练数据版权问题的广泛讨论。随后，<strong>字节跳动暂停了 Seedance 2.0 的真人素材参考能力</strong>，正在加强安全防护措施。</p><blockquote><p>目前涉及名人或知名 IP 的视频生成会被审核拦截，提示”视频未通过审核，本次不消耗积分”。</p></blockquote><hr><h2 id="四、试用全攻略：5-种免费渠道"><a href="#四、试用全攻略：5-种免费渠道" class="headerlink" title="四、试用全攻略：5 种免费渠道"></a>四、试用全攻略：5 种免费渠道</h2><p>好消息是，Seedance 2.0 有多个免费使用渠道。以下是完整攻略：</p><h3 id="渠道一：即梦网页版（⭐-质量最好）"><a href="#渠道一：即梦网页版（⭐-质量最好）" class="headerlink" title="渠道一：即梦网页版（⭐ 质量最好）"></a>渠道一：即梦网页版（⭐ 质量最好）</h3><p><strong>地址</strong>：<code>jimeng.jianying.com</code></p><p><strong>步骤</strong>：</p><ol><li>手机号注册账号</li><li>购买 <strong>¥1 试用会员</strong>（解锁 2.0 必须步骤）</li><li>⚠️ <strong>立即取消订阅</strong>（避免自动续费）</li><li>进入视频生成页面，选择 Seedance 2.0 模型</li></ol><p><strong>积分规则</strong>：</p><ul><li>注册送 2 次免费体验 + 260 积分</li><li>每天登录送积分</li><li>生成 1 秒视频消耗 6 积分</li><li>充值：69 元&#x2F;月送 1080 积分</li></ul><p><strong>优势</strong>：时长 4-15 秒可精确选择，质量最佳</p><hr><h3 id="渠道二：小云雀网页版（⭐-性价比最高）"><a href="#渠道二：小云雀网页版（⭐-性价比最高）" class="headerlink" title="渠道二：小云雀网页版（⭐ 性价比最高）"></a>渠道二：小云雀网页版（⭐ 性价比最高）</h3><p><strong>地址</strong>：<code>xyq.jianying.com</code></p><p>字节内部赛马产品，主打 Agent 一键出长片。</p><p><strong>步骤</strong>：</p><ol><li><strong>先手机下载小云雀 App 注册</strong>（网页版无法直接注册）</li><li>用同一账号登录网页版</li><li>注册送 3 次 + 1200 积分，<strong>不需要充钱就能用 2.0！</strong></li></ol><p><strong>积分规则</strong>：</p><ul><li>注册送 1200 积分（约 120 秒视频）</li><li>每天登录送 120 积分</li><li>生成 1 秒视频消耗 10 积分</li><li>会员首月 39 元&#x2F;月送 1200 积分</li></ul><p><strong>优势</strong>：注册即送最多积分，门槛最低</p><blockquote><p>🎬 <strong>实拍演示</strong>：下面这段视频是我用 Seedance 2.0 通过小云雀平台生成的，感受一下效果：</p></blockquote><p>!video<a href="/images/seedance-2/xiaoyunque-demo.mp4">Seedance 2.0 小云雀生成演示</a></p><hr><h3 id="渠道三：豆包-App（⭐-最方便）"><a href="#渠道三：豆包-App（⭐-最方便）" class="headerlink" title="渠道三：豆包 App（⭐ 最方便）"></a>渠道三：豆包 App（⭐ 最方便）</h3><p>字节旗下 AI 助手，很多人已经装了。</p><p><strong>步骤</strong>：</p><ol><li>打开豆包 App</li><li>访问 <code>doubao.com/chat/settings</code> 获取 UID</li><li>加入豆包官方飞书群，填写 UID</li><li>等管理员通过（1-2 天）</li><li>通过后即可使用 Seedance 2.0</li></ol><p><strong>额度</strong>：每天 10 次免费（5 秒或 10 秒）</p><p><strong>注意</strong>：App 版有 2.0，网页版暂时没有</p><hr><h3 id="渠道四：Dreamina-国际版（海外用户）"><a href="#渠道四：Dreamina-国际版（海外用户）" class="headerlink" title="渠道四：Dreamina 国际版（海外用户）"></a>渠道四：Dreamina 国际版（海外用户）</h3><p><strong>地址</strong>：<code>dreamina.capcut.com</code></p><p>需要美金信用卡或 PayPal，面向海外用户。</p><hr><h3 id="渠道五：Pippit-国际版（7-天免费试用）"><a href="#渠道五：Pippit-国际版（7-天免费试用）" class="headerlink" title="渠道五：Pippit 国际版（7 天免费试用）"></a>渠道五：Pippit 国际版（7 天免费试用）</h3><p><strong>地址</strong>：<code>pippit.ai</code></p><ul><li>注册送 520 积分 + 每天 120 积分</li><li>7 天免费试用（<strong>记得提前取消！</strong>）</li><li>需要开 Global 模式访问</li></ul><hr><h3 id="🎯-新手推荐组合"><a href="#🎯-新手推荐组合" class="headerlink" title="🎯 新手推荐组合"></a>🎯 新手推荐组合</h3><table><thead><tr><th>需求</th><th>推荐方案</th></tr></thead><tbody><tr><td>零成本体验</td><td>小云雀（送1200积分）+ 豆包（每天10次）</td></tr><tr><td>追求质量</td><td>即梦网页版（¥1解锁）</td></tr><tr><td>批量生产</td><td>即梦 + 小云雀双平台</td></tr><tr><td>海外用户</td><td>Dreamina 或 Pippit</td></tr></tbody></table><p><strong>第一天注册全部平台，可获得约 213 秒（3.5 分钟）的免费 AI 视频额度。</strong></p><p>之后每天至少 60+ 秒免费额度。</p><hr><h2 id="五、提示词技巧：怎么写才能出好片？"><a href="#五、提示词技巧：怎么写才能出好片？" class="headerlink" title="五、提示词技巧：怎么写才能出好片？"></a>五、提示词技巧：怎么写才能出好片？</h2><h3 id="基础模板"><a href="#基础模板" class="headerlink" title="基础模板"></a>基础模板</h3><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-attr">[场景描述]</span>，<span class="hljs-selector-attr">[角色描述]</span>，<span class="hljs-selector-attr">[动作描述]</span>，<span class="hljs-selector-attr">[镜头运动]</span>，<span class="hljs-selector-attr">[氛围/光线]</span><br></code></pre></td></tr></table></figure><h3 id="示例-1：电影感镜头"><a href="#示例-1：电影感镜头" class="headerlink" title="示例 1：电影感镜头"></a>示例 1：电影感镜头</h3><blockquote><p>樱花树下，一个女孩扭头看向一只猫，花瓣飘落，微风吹过她的头发。女孩摸了摸猫的头，对猫说”你好呀小家伙”，最后画面定格在女孩上。</p></blockquote><h3 id="示例-2：动作场景"><a href="#示例-2：动作场景" class="headerlink" title="示例 2：动作场景"></a>示例 2：动作场景</h3><blockquote><p>少年主角在战斗中被击倒，在伙伴呼喊声中觉醒隐藏力量。身体周围爆发金色气场，头发变色竖起。随后以超高速冲向敌人，释放巨大的能量斩击，斩击波横切整个天空。</p></blockquote><h3 id="示例-3：多角度追逐"><a href="#示例-3：多角度追逐" class="headerlink" title="示例 3：多角度追逐"></a>示例 3：多角度追逐</h3><blockquote><p>以这张照片为开头，图中人物扔掉纸板摆功夫起手式，与机器人激战。低角度跟拍侧闪 + 机器人横扫，中景快切拳掌撞金属，特写火花 + 镜头微震。</p></blockquote><h3 id="进阶技巧"><a href="#进阶技巧" class="headerlink" title="进阶技巧"></a>进阶技巧</h3><ol><li><strong>描述越具体越好</strong>：不要写”一个人在走路”，写”穿着深蓝色风衣的中年男人在雨中的东京街头快步行走，霓虹灯映在湿漉漉的地面上”</li><li><strong>用分镜思维</strong>：描述镜头的切换——“先远景 → 中景 → 特写”</li><li><strong>加入情绪词</strong>：紧张、温馨、史诗、孤独——模型会自动匹配色调和节奏</li><li><strong>善用参考素材</strong>：上传风格参考图比文字描述更精准</li><li><strong>短视频（4-5秒）质量最稳定</strong>，长视频更容易出瑕疵</li></ol><hr><h2 id="六、与竞品对比"><a href="#六、与竞品对比" class="headerlink" title="六、与竞品对比"></a>六、与竞品对比</h2><table><thead><tr><th>能力</th><th>Seedance 2.0</th><th>Sora 2</th><th>Veo 3.1</th><th>可灵</th></tr></thead><tbody><tr><td>自运镜</td><td>✅ 自动</td><td>❌ 需手动描述</td><td>部分</td><td>部分</td></tr><tr><td>音画同步</td><td>✅ 原生</td><td>✅</td><td>✅</td><td>❌</td></tr><tr><td>多模态输入</td><td>✅ 文&#x2F;图&#x2F;视频&#x2F;音频</td><td>文&#x2F;图</td><td>文&#x2F;图</td><td>文&#x2F;图</td></tr><tr><td>角色一致性</td><td>⭐⭐⭐⭐⭐</td><td>⭐⭐⭐⭐</td><td>⭐⭐⭐⭐</td><td>⭐⭐⭐</td></tr><tr><td>单次可用率</td><td>90%+</td><td>50-60%</td><td>60-70%</td><td>30-40%</td></tr><tr><td>最长时长</td><td>15秒</td><td>15秒</td><td>8秒</td><td>10秒</td></tr><tr><td>免费额度</td><td>多渠道</td><td>无（$200&#x2F;月）</td><td>有限</td><td>有限</td></tr><tr><td>物理真实感</td><td>⭐⭐⭐⭐⭐</td><td>⭐⭐⭐⭐</td><td>⭐⭐⭐⭐</td><td>⭐⭐⭐</td></tr></tbody></table><hr><h2 id="七、行业影响：谁会被颠覆？"><a href="#七、行业影响：谁会被颠覆？" class="headerlink" title="七、行业影响：谁会被颠覆？"></a>七、行业影响：谁会被颠覆？</h2><h3 id="1-短剧行业"><a href="#1-短剧行业" class="headerlink" title="1. 短剧行业"></a>1. 短剧行业</h3><p>短剧制作成本中，演员、场地、摄像团队占大头。如果 AI 能生成足够质量的视频，这些成本可能被<strong>削减 90% 以上</strong>。更重要的是，制作周期的缩短意味着可以快速 A&#x2F;B 测试，用数据驱动内容迭代。</p><h3 id="2-动漫-x2F-动画行业"><a href="#2-动漫-x2F-动画行业" class="headerlink" title="2. 动漫&#x2F;动画行业"></a>2. 动漫&#x2F;动画行业</h3><p>传统动画中耗时的关键帧绘制、中间画填充、口型同步等环节，现在可以极大提速。一位做了 10 年院线电影的从业者说：</p><blockquote><p>“5 秒特效镜头传统流程需要一个高级制作人员花近一个月。现在 3 块钱，2 分钟搞定。数千倍成本下降，上万倍效率提升。”</p></blockquote><h3 id="3-视频-Agent-赛道"><a href="#3-视频-Agent-赛道" class="headerlink" title="3. 视频 Agent 赛道"></a>3. 视频 Agent 赛道</h3><p>AI 视频 Agent 以前靠”拆解工作流 + 工程优化”弥补模型不足。<strong>但当模型本身足够强时，工程层面能优化的空间就很小了。</strong> 未来比的是谁对 Seedance 2.0 理解更深，能把这套理解做进产品。</p><h3 id="4-广告行业"><a href="#4-广告行业" class="headerlink" title="4. 广告行业"></a>4. 广告行业</h3><p>一条 30 秒广告片，传统制作可能需要几十万和数周时间。Seedance 2.0 让个人创作者也能产出商业级质量的视频，广告行业的门槛正在被拉平。</p><hr><h2 id="八、写在最后"><a href="#八、写在最后" class="headerlink" title="八、写在最后"></a>八、写在最后</h2><p>有人说 Seedance 2.0 是第一个展现出”世界模型”雏形的视频生成产品。它不只是在”画”你描述的场景，它在<strong>构建一个有内在逻辑的世界</strong>：花瓣飘落方向和风向一致，物体重力表现合理，角色情绪和语气匹配。</p><p>当工具强大到一定程度，**你不再想”这个模型能不能做到”，而是开始想”我要讲一个什么样的故事”**。</p><p>工具退到了幕后，创作者走到了台前。</p><p>2026 年 AI 视频市场规模预计突破 300 亿美元。在这场革命中，<strong>真正稀缺的不是工具，而是你脑子里那个还没被讲出来的故事。</strong></p><hr><p><em>参考来源：极客公园、新京报贝壳财经、AI工具集、36氪、掘金社区</em></p>]]></content>
    
    
    <categories>
      
      <category>技术实战</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>教程</tag>
      
      <tag>视频生成</tag>
      
      <tag>字节跳动</tag>
      
      <tag>Seedance</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2026年，AI Agent 时代真的来了</title>
    <link href="/2026/02/10/ai-agent-era-2026/"/>
    <url>/2026/02/10/ai-agent-era-2026/</url>
    
    <content type="html"><![CDATA[<blockquote><p>从”用 AI 聊天”到”指挥 AI 干活”，这不是一次升级，而是一次范式转移。</p></blockquote><p>如果你还在用 ChatGPT 写周报、让 AI 帮你润色邮件，那你可能已经落伍了。2026年初，AI 领域正在经历一场静悄悄的革命——<strong>从生成式 AI（Generative AI）到智能体 AI（Agentic AI）的转变</strong>。</p><p>这不是 ChatGPT-4 升级到 ChatGPT-5 那种量变，而是人机交互方式的根本性质变。</p><p>本文综合了近期 Medium 上多篇热门文章的观点，带你看清这场变革的全貌。</p><p><img src="/images/ai-agent-era-2026/cover-orchestrator.png" alt="AI Agent 编排者"></p><span id="more"></span><h2 id="一、从”聊天”到”编排”：什么是-Agentic-Shift？"><a href="#一、从”聊天”到”编排”：什么是-Agentic-Shift？" class="headerlink" title="一、从”聊天”到”编排”：什么是 Agentic Shift？"></a>一、从”聊天”到”编排”：什么是 Agentic Shift？</h2><p>英国数字化专家 Idris Fabiyi 在他的文章 <em>The Agentic Shift</em> 中提出了一个精辟的比喻：</p><blockquote><p>如果说 2024 年是”聊天（Chatting）”的时代，那 2026 年就是”编排（Orchestration）”的时代。</p></blockquote><p>过去三年，我们一直生活在 AI 的”游乐场阶段”——玩玩聊天机器人，学学怎么写 prompt，感觉像魔法一样。但现在，游乐场关门了。<strong>魔法正在被工程学取代。</strong></p><p>什么是 Agentic AI？简单来说：</p><ul><li><strong>生成式 AI（2023-2024）</strong>：你问它问题，它给你答案。本质上是一个很聪明的对话框。</li><li><strong>智能体 AI（2025-2026）</strong>：它能自主推理、规划、执行复杂的工作流程，最少的人工干预完成任务。</li></ul><p>这意味着 AI 不再只是你的”聊天对象”，而是你的”数字员工”。</p><h2 id="二、开源-Agent-的爆发：OpenClaw-现象"><a href="#二、开源-Agent-的爆发：OpenClaw-现象" class="headerlink" title="二、开源 Agent 的爆发：OpenClaw 现象"></a>二、开源 Agent 的爆发：OpenClaw 现象</h2><p>要理解 Agent 时代的到来，最好的例子就是 OpenClaw。</p><p>这个开源项目在2026年1月底横空出世，<strong>5天内获得了6.6万颗 GitHub Star</strong>，总数突破14.5万。旧金山的零售商甚至报告 Mac Mini 脱销——因为爱好者们纷纷买来专门跑自己的 AI Agent。</p><h3 id="OpenClaw-到底是什么？"><a href="#OpenClaw-到底是什么？" class="headerlink" title="OpenClaw 到底是什么？"></a>OpenClaw 到底是什么？</h3><p>用一句话总结：<strong>一个运行在你自己电脑上的私人 AI 助手</strong>。</p><p>它能连接你已有的通讯工具（WhatsApp、Telegram、Discord、飞书、Signal 等29+平台），把你的消息路由到 AI 模型（Claude、GPT、Gemini 或本地模型），然后在你的电脑上执行任务。</p><p>关键词是**”本地”**。你的数据不会发送到任何云端服务器。Gateway 运行在你的笔记本、VPS 或树莓派上。你掌控数据、模型和执行环境。</p><h3 id="技术架构亮点"><a href="#技术架构亮点" class="headerlink" title="技术架构亮点"></a>技术架构亮点</h3><p>工程师 JP Caparas 深入研究了 OpenClaw 的 4万行 TypeScript 源码，发现了几个精妙的设计：</p><p><strong>1. 车道式并发（Lane-based Concurrency）</strong></p><p>大多数异步系统用单一队列，高优先级任务先执行，其他的等着。问题是：大量中优先级任务可能让低优先级任务永远排不上。</p><p>OpenClaw 把工作分成独立的”车道”：主聊天、定时任务、子 Agent、嵌套调用各走各的。<strong>定时邮件摘要不会阻塞你的即时消息。</strong> 这种设计从结构上就避免了资源饥饿问题。</p><p><strong>2. 语义快照而非截图</strong></p><p>浏览器自动化不是截图发给模型（昂贵、费 token），而是生成<strong>语义快照</strong>——页面可访问性树的文本表示：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros">- button <span class="hljs-string">&quot;登录&quot;</span> [<span class="hljs-attribute">ref</span>=1]<br>- textbox <span class="hljs-string">&quot;邮箱&quot;</span> [<span class="hljs-attribute">ref</span>=2]  <br>- textbox <span class="hljs-string">&quot;密码&quot;</span> [<span class="hljs-attribute">ref</span>=3]<br>- link <span class="hljs-string">&quot;忘记密码？&quot;</span> [<span class="hljs-attribute">ref</span>=4]<br></code></pre></td></tr></table></figure><p>一张截图可能 5MB，一个语义快照只有 50KB。同样的可操作信息，几十分之一的 token 消耗。</p><p><strong>3. 安全分层</strong></p><p>Agent 有系统级访问权限，但安全层用白名单机制控制：安全命令（<code>grep</code>、<code>sort</code>、<code>head</code> 等）预先批准，危险操作（如 <code>git push</code>）会推送通知到你手机，等你批准或拒绝。<strong>人类始终是最终决策者。</strong></p><h2 id="三、Agent-生态正在成型"><a href="#三、Agent-生态正在成型" class="headerlink" title="三、Agent 生态正在成型"></a>三、Agent 生态正在成型</h2><p>从 GitHub Trending 数据看，AI Agent 的工具链正在快速成熟。以下是2026年2月初的生态全景：</p><h3 id="基础设施层"><a href="#基础设施层" class="headerlink" title="基础设施层"></a>基础设施层</h3><table><thead><tr><th>项目</th><th>Star 数</th><th>定位</th></tr></thead><tbody><tr><td>OpenClaw</td><td>145K+</td><td>个人 AI Agent 平台</td></tr><tr><td>claude-mem</td><td>17K</td><td>Agent 记忆系统</td></tr><tr><td>agent-lightning (微软)</td><td>13K</td><td>Agent 训练框架</td></tr><tr><td>pi-mono</td><td>5K</td><td>Agent 开发工具包</td></tr></tbody></table><h3 id="编排层"><a href="#编排层" class="headerlink" title="编排层"></a>编排层</h3><ul><li><strong>Maestro</strong>：Agent 编排指挥中心，统一管理多个 Agent 的协调工作</li><li><strong>Anthropic MCP（Model Context Protocol）</strong>：月下载量达 9700 万次，被称为”AI 的 USB-C”——统一了 Agent 与工具的连接协议</li></ul><h3 id="接口层"><a href="#接口层" class="headerlink" title="接口层"></a>接口层</h3><ul><li><strong>终端</strong>：OpenClaw、99（ThePrimeagen 的 Neovim AI Agent）</li><li><strong>浏览器</strong>：vibetunnel（把浏览器变成终端）</li><li><strong>编辑器原生</strong>：Cursor、Windsurf 已从被动的”副驾驶”变成主动的 Agent</li><li><strong>指挥中心</strong>：Maestro</li></ul><h3 id="演进路径"><a href="#演进路径" class="headerlink" title="演进路径"></a>演进路径</h3><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sqf">阶段<span class="hljs-number">1</span>：单个 <span class="hljs-built_in">Agent</span>（Claude Code、OpenCode）<br>阶段<span class="hljs-number">2</span>：<span class="hljs-built_in">Agent</span> 团队（lobehub）<br>阶段<span class="hljs-number">3</span>：编排指挥中心（Maestro）← 我们在这里<br></code></pre></td></tr></table></figure><h2 id="四、Agent-Swarm：从单兵作战到群体智能"><a href="#四、Agent-Swarm：从单兵作战到群体智能" class="headerlink" title="四、Agent Swarm：从单兵作战到群体智能"></a>四、Agent Swarm：从单兵作战到群体智能</h2><p><img src="/images/ai-agent-era-2026/agent-swarm.jpg" alt="Agent Swarm 群体智能"></p><p>如果说单个 Agent 是步兵，那 <strong>Agent Swarm（智能体群）</strong> 就是军团。</p><p>AI 研究者 Ignacio de Gregorio 指出，Sam Altman 曾预言”由一个人运营的十亿美元公司”，当时所有人都笑了。但现在，<strong>没人笑得出来了</strong>。</p><p>长时段 Agent（能无缺陷地执行持续数小时的任务）终于触手可及。市场正在为接下来的变化做准备——这对很多传统公司来说不是好消息。</p><p>Agent Swarm 的核心理念是：<strong>不是一个超级聪明的 AI 做所有事，而是一群专业化的 Agent 协同工作</strong>。就像一家公司不是靠一个全能员工，而是靠各司其职的团队。</p><h2 id="五、2026-年你需要掌握的三个层级"><a href="#五、2026-年你需要掌握的三个层级" class="headerlink" title="五、2026 年你需要掌握的三个层级"></a>五、2026 年你需要掌握的三个层级</h2><p>Idris Fabiyi 提出了一个实用的分级框架，帮你定位自己在 Agent 时代的位置：</p><h3 id="第一级：AI-审计员（从普通用户升级）"><a href="#第一级：AI-审计员（从普通用户升级）" class="headerlink" title="第一级：AI 审计员（从普通用户升级）"></a>第一级：AI 审计员（从普通用户升级）</h3><ul><li><strong>任务分解</strong>：把模糊的业务目标拆解成 Agent 可执行的确定性步骤</li><li><strong>输出审计</strong>：用”法医”思维追溯 AI 的每个声明到源文档，识别幻觉</li><li><strong>数字验证</strong>：在 Deepfake 泛滥的时代，”零信任”是生存技能</li></ul><h3 id="第二级：AI-编排师（从技术达人升级）"><a href="#第二级：AI-编排师（从技术达人升级）" class="headerlink" title="第二级：AI 编排师（从技术达人升级）"></a>第二级：AI 编排师（从技术达人升级）</h3><ul><li><strong>Vibe Coding（意图编程）</strong>：描述你想要的结果，AI 生成底层代码。你不需要精通语法，但必须理解算法逻辑</li><li><strong>Agent 编排</strong>：管理自主 Agent 团队，定义它们的角色和”交接协议”</li><li><strong>AI-BOM 治理</strong>：了解哪些 Agent 在做什么、访问什么数据（合规要求）</li></ul><h3 id="第三级：Agentic-工程师（从开发者升级）"><a href="#第三级：Agentic-工程师（从开发者升级）" class="headerlink" title="第三级：Agentic 工程师（从开发者升级）"></a>第三级：Agentic 工程师（从开发者升级）</h3><ul><li><strong>神经符号混合设计</strong>：融合神经网络与符号 AI，确保关键业务规则不会被”幻觉”掉</li><li><strong>AgentOps &amp; 评估</strong>：不再用老方法”测试”代码，而是用更强的 LLM 来评估其他模型的安全性</li><li><strong>GreenOps</strong>：用”碳感知计算”，在电网最清洁时调度重型 AI 任务</li></ul><blockquote><p>如果你的核心价值是”我会写 Python 代码”，你可能有麻烦了。AI 编程助手已经把语法生成变成了大宗商品。</p></blockquote><h2 id="六、数据说话：Agent-时代的真实信号"><a href="#六、数据说话：Agent-时代的真实信号" class="headerlink" title="六、数据说话：Agent 时代的真实信号"></a>六、数据说话：Agent 时代的真实信号</h2><p><img src="/images/ai-agent-era-2026/anthropic-revenue.png" alt="AI 行业竞争格局"></p><p>以下数据来自多家权威来源，描绘了 Agent 时代的加速到来：</p><ul><li><strong>Databricks</strong>：Agentic AI 使用量激增 327%</li><li><strong>Salesforce</strong>：赢得美国陆军 56 亿美元 Agent AI 合同</li><li><strong>MCP 协议</strong>：月 SDK 下载量 9700 万次</li><li><strong>40% 的职场人</strong>担心 AI 会取代自己的工作（2024 年这个数字是 28%）</li><li><strong>66% 的 CISO</strong>将 AI 威胁列为 2026 年头号安全担忧</li><li><strong>OpenClaw</strong>：5 天 6.6 万 Star，开源 Agent 史上最快增长</li></ul><h2 id="七、写在最后：你是用户，还是架构师？"><a href="#七、写在最后：你是用户，还是架构师？" class="headerlink" title="七、写在最后：你是用户，还是架构师？"></a>七、写在最后：你是用户，还是架构师？</h2><p>2026 年的 AI 变革不是”要不要用 AI”的问题——那个答案早就是肯定的。真正的问题是：</p><p><strong>你是被动地”使用”AI，还是主动地”编排”AI？</strong></p><p>Agent 时代的到来意味着：</p><ul><li>会写 prompt 不再是优势，那是基本功</li><li>理解 Agent 的工作原理、知道如何编排多个 Agent 协同工作，才是新的核心能力</li><li>安全性、可审计性、合规性不是可选项，而是法律要求</li></ul><p>好消息是，这个生态还在早期。OpenClaw 才几个月大，Agent 编排平台刚刚出现，训练框架还在迭代。<strong>现在入场，你还是早期玩家。</strong></p><p>坏消息是，窗口期不会太长。当 Agent 生态成熟到”一键部署”的程度，先行者的优势将变成后来者的壁垒。</p><p>正如 Fabiyi 所说：</p><blockquote><p><strong>“The Agentic Shift is here. The agents are running. The question is: Who is orchestrating them?”</strong></p><p>Agent 时代已经到来，智能体们已经在运行了。问题是：<strong>谁在编排它们？</strong></p></blockquote><hr><p><em>本文观点综合自以下 Medium 文章：</em></p><ul><li><em>Idris Fabiyi: “The Agentic Shift: Why 2026 is the Year ‘Using’ AI Isn’t Enough”</em></li><li><em>Jonathan Fulton: “Last Week in AI — February 2, 2026”</em></li><li><em>JP Caparas: “What OpenClaw Actually Runs on Your Machine”</em></li><li><em>Ignacio de Gregorio: “The Agent Acceleration You Can’t Miss is Here”</em></li><li><em>lssmj2014: “GitHub Trending: February 2, 2026”</em></li><li><em>Avner So: “My 2026 AI Predictions”</em></li></ul>]]></content>
    
    
    <categories>
      
      <category>AI 前沿</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Agent</tag>
      
      <tag>人工智能</tag>
      
      <tag>技术趋势</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GitHub Trending 日报：2026年2月9日最火的 10 个开源项目深度解析</title>
    <link href="/2026/02/09/github-trending/2026-02-09/"/>
    <url>/2026/02/09/github-trending/2026-02-09/</url>
    
    <content type="html"><![CDATA[<p>今天的 GitHub Trending 被 AI 和安全相关项目屠榜了。从自主渗透测试到金融研究 Agent，从 Rust 写的 Python 沙箱到手机端多模态大模型——每个项目都折射出 2026 年技术发展的核心脉络。下面逐个拆解。</p><span id="more"></span><h2 id="1-KeygraphHQ-x2F-shannon-⭐-14-6K-📈-3-479-today"><a href="#1-KeygraphHQ-x2F-shannon-⭐-14-6K-📈-3-479-today" class="headerlink" title="1. KeygraphHQ&#x2F;shannon ⭐ 14.6K | 📈 +3,479 today"></a>1. KeygraphHQ&#x2F;shannon ⭐ 14.6K | 📈 +3,479 today</h2><p><strong>一句话：AI 自主渗透测试工具，96.15% 的漏洞发现成功率。</strong></p><p>Shannon 不是又一个扫描器——它是一个真正会「攻击」的 AI。它会自主分析你的代码，找到攻击向量，然后用内置浏览器执行真实的注入攻击和认证绕过，证明漏洞确实可被利用。</p><p><strong>为什么火？</strong> Vibe-coding 时代，大家用 Claude Code、Cursor 疯狂写代码，但渗透测试一年才做一次。Shannon 填补了这 364 天的安全空白。它不只是报告「可能有漏洞」，而是直接打穿给你看。</p><p><strong>技术亮点：</strong> TypeScript 构建，AGPL-3.0 许可，支持白盒测试。在 XBOW Benchmark 上无提示模式下达到 96.15% 的成功率，这个数字相当炸裂。</p><p><strong>适用场景：</strong> 持续集成中的安全检查，特别适合快速迭代的团队。每次 build 都跑一遍 Shannon，比年度渗透测试靠谱得多。</p><hr><h2 id="2-pydantic-x2F-monty-⭐-3-3K-📈-456-today"><a href="#2-pydantic-x2F-monty-⭐-3-3K-📈-456-today" class="headerlink" title="2. pydantic&#x2F;monty ⭐ 3.3K | 📈 +456 today"></a>2. pydantic&#x2F;monty ⭐ 3.3K | 📈 +456 today</h2><p><strong>一句话：Rust 写的最小化 Python 解释器，专门给 AI 用的安全沙箱。</strong></p><p>Pydantic 团队的新作。当 LLM 生成 Python 代码需要执行时，你不想启动一个完整的容器——太慢太重。Monty 用 Rust 实现了一个精简版 Python 解释器，启动时间是微秒级别，而不是容器的几百毫秒。</p><p><strong>为什么火？</strong> Agent 需要执行代码，但安全是大问题。Monty 提供了一个优雅的中间方案：不用容器那么重，但比直接 <code>exec()</code> 安全得多。Pydantic 的品牌背书也加了不少分。</p><p><strong>技术亮点：</strong> Rust 编写保证内存安全，MIT 许可，微秒级启动。不是完整的 Python 运行时，而是覆盖了 LLM 最常生成的那部分 Python 子集。</p><p><strong>适用场景：</strong> AI Agent 的代码执行层。如果你在做 Agent 产品，需要让 AI 安全地运行生成的代码，Monty 值得关注。</p><hr><h2 id="3-openai-x2F-skills-⭐-7-2K-📈-1-425-today"><a href="#3-openai-x2F-skills-⭐-7-2K-📈-1-425-today" class="headerlink" title="3. openai&#x2F;skills ⭐ 7.2K | 📈 +1,425 today"></a>3. openai&#x2F;skills ⭐ 7.2K | 📈 +1,425 today</h2><p><strong>一句话：Codex 的官方技能目录，Agent Skills 的开放标准。</strong></p><p>OpenAI 把 Codex 的技能系统开源了。Skills 是一组指令、脚本和资源的文件夹，AI Agent 可以发现并使用它们来执行特定任务。写一次，到处用。</p><p><strong>为什么火？</strong> 这实际上是 OpenAI 在推动一个 Agent 技能的开放标准（agentskills.io）。类似 npm 之于 Node.js，Skills Catalog 想成为 AI Agent 的包管理器。这个定位非常有野心。</p><p><strong>技术亮点：</strong> 分三层：<code>.system</code>（内置自动安装）、<code>.curated</code>（精选）、<code>.experimental</code>（实验性）。用 <code>$skill-installer</code> 在 Codex 内安装。</p><p><strong>适用场景：</strong> Codex 用户直接受益。对于其他 Agent 框架的开发者，这个标准本身值得研究——你的 Agent 也可以复用这些 Skills。</p><hr><h2 id="4-virattt-x2F-dexter-⭐-13K-📈-1-039-today"><a href="#4-virattt-x2F-dexter-⭐-13K-📈-1-039-today" class="headerlink" title="4. virattt&#x2F;dexter ⭐ 13K | 📈 +1,039 today"></a>4. virattt&#x2F;dexter ⭐ 13K | 📈 +1,039 today</h2><p><strong>一句话：自主金融研究 Agent，Claude Code 的金融版。</strong></p><p>Dexter 接受复杂的金融问题，自动拆解成研究步骤，用实时市场数据执行分析，然后自我验证结果。它能访问损益表、资产负债表和现金流量表。</p><p><strong>为什么火？</strong> 金融研究是高度结构化但又极其耗时的工作。Dexter 展示了 Agent 在垂直领域的巨大潜力——不是通用聊天，而是真正能干活的专业工具。</p><p><strong>技术亮点：</strong> TypeScript 构建，支持智能任务规划、自主执行、自我验证。内置循环检测和步数限制防止失控。基于 Financial Datasets API 获取实时数据。</p><p><strong>适用场景：</strong> 量化分析师、基金经理、个人投资者。如果你需要快速对一家公司做深度财务分析，Dexter 能把几小时的工作压缩到几分钟。</p><hr><h2 id="5-microsoft-x2F-litebox-⭐-1-6K-📈-359-today"><a href="#5-microsoft-x2F-litebox-⭐-1-6K-📈-359-today" class="headerlink" title="5. microsoft&#x2F;litebox ⭐ 1.6K | 📈 +359 today"></a>5. microsoft&#x2F;litebox ⭐ 1.6K | 📈 +359 today</h2><p><strong>一句话：微软出品的安全导向库 OS，支持内核和用户态执行。</strong></p><p>这个项目因为 Microsoft 组织的 SAML 认证保护，README 没法直接通过 API 获取。但从描述看，这是一个安全聚焦的库操作系统（Library OS），支持在内核态和用户态运行。</p><p><strong>为什么火？</strong> 微软在安全计算领域持续投入。在 AI 工作负载需要更强隔离性的今天，一个安全导向的轻量级 OS 层有很大的应用空间。Rust 编写也是加分项。</p><p><strong>技术亮点：</strong> Rust 编写，安全优先设计。Library OS 的架构意味着应用可以在极小的信任边界内运行。</p><p><strong>适用场景：</strong> 需要强隔离的云原生工作负载、AI 推理环境、机密计算场景。</p><hr><h2 id="6-google-x2F-langextract-⭐-25K-📈-438-today"><a href="#6-google-x2F-langextract-⭐-25K-📈-438-today" class="headerlink" title="6. google&#x2F;langextract ⭐ 25K | 📈 +438 today"></a>6. google&#x2F;langextract ⭐ 25K | 📈 +438 today</h2><p><strong>一句话：用 LLM 从非结构化文本中提取结构化信息，带精确溯源和交互式可视化。</strong></p><p>Google 的信息提取库。给它一段临床笔记、报告或任何文档，它会用 LLM 识别并组织关键细节，并且每个提取结果都能映射回原文的精确位置。</p><p><strong>为什么火？</strong> 25K stars 不是浪得虚名。信息提取是 LLM 最实用的应用之一，但「幻觉」问题让人不敢信任结果。LangExtract 的精确溯源功能（Precise Source Grounding）直接解决了这个痛点——每个提取结果都有据可查。</p><p><strong>技术亮点：</strong> 支持 Gemini、OpenAI、Ollama 等多种模型。溯源到原文位置并可视化高亮。Apache 2.0 许可，对商用友好。</p><p><strong>适用场景：</strong> 医疗记录处理、法律文档分析、财报解析、任何需要从大量文本中提取结构化数据的场景。</p><hr><h2 id="7-obra-x2F-superpowers-⭐-48-1K-📈-813-today"><a href="#7-obra-x2F-superpowers-⭐-48-1K-📈-813-today" class="headerlink" title="7. obra&#x2F;superpowers ⭐ 48.1K | 📈 +813 today"></a>7. obra&#x2F;superpowers ⭐ 48.1K | 📈 +813 today</h2><p><strong>一句话：让你的 AI 编程助手具备完整的软件开发方法论。</strong></p><p>这不是一个工具，而是一套方法论。Superpowers 给编程 Agent 注入了一整套工作流程：先理解需求，拆出规范，做实施计划，然后用子 Agent 驱动开发，全程 TDD。</p><p><strong>为什么火？</strong> 48K stars，可能是目前最火的 Agent 开发方法论。它解决了一个核心问题——AI 编程助手虽然能写代码，但缺乏工程纪律。Superpowers 让 Claude Code 可以自主工作数小时而不偏离计划。</p><p><strong>技术亮点：</strong> 基于可组合的 Skills 架构，自动触发。强调 TDD、YAGNI、DRY 原则。支持 Claude Code（插件市场）、Codex 和 OpenCode。子 Agent 驱动开发（subagent-driven-development）是核心创新。</p><p><strong>适用场景：</strong> 所有使用 AI 编程助手的开发者。装上就能用，不需要改变工作习惯。</p><hr><h2 id="8-OpenBMB-x2F-MiniCPM-o-⭐-23-5K-📈-212-today"><a href="#8-OpenBMB-x2F-MiniCPM-o-⭐-23-5K-📈-212-today" class="headerlink" title="8. OpenBMB&#x2F;MiniCPM-o ⭐ 23.5K | 📈 +212 today"></a>8. OpenBMB&#x2F;MiniCPM-o ⭐ 23.5K | 📈 +212 today</h2><p><strong>一句话：Gemini 2.5 Flash 级别的多模态模型，能在手机上跑。</strong></p><p>清华 OpenBMB 出品。MiniCPM-o 4.5 是一个 9B 参数的端到端多模态模型，支持图像、视频、文本和语音输入，能输出文本和语音。最关键的是——它能在手机上运行全双工多模态实时流。</p><p><strong>为什么火？</strong> 在手机上跑一个接近 Gemini 2.5 Flash 水准的多模态模型，这个噱头太强了。全双工意味着输入流（视频+音频）和输出流（文本+语音）互不阻塞，真正的实时对话体验。</p><p><strong>技术亮点：</strong> 9B 参数，Apache 2.0 开源。支持视觉、语音和全双工多模态直播流。端到端架构，不是拼接方案。</p><p><strong>适用场景：</strong> 移动端 AI 助手、实时视频通话 AI、边缘设备上的多模态交互。对国内开发者尤其友好——模型可自主部署，不依赖海外 API。</p><hr><h2 id="9-likec4-x2F-likec4-⭐-2-5K-📈-271-today"><a href="#9-likec4-x2F-likec4-⭐-2-5K-📈-271-today" class="headerlink" title="9. likec4&#x2F;likec4 ⭐ 2.5K | 📈 +271 today"></a>9. likec4&#x2F;likec4 ⭐ 2.5K | 📈 +271 today</h2><p><strong>一句话：用代码定义软件架构，自动生成实时更新的活文档。</strong></p><p>受 C4 Model 和 Structurizr DSL 启发，但更灵活。你可以自定义标记法、元素类型和任意嵌套层级。架构图从代码生成，代码变了图自动更新。</p><p><strong>为什么火？</strong> 架构文档的最大问题是过时。LikeC4 把架构定义放进代码仓库，和业务代码一起版本控制，一起 review。这是真正的「Architecture as Code」。</p><p><strong>技术亮点：</strong> TypeScript 构建，MIT 许可。有 VSCode 扩展、CLI 工具和 Playground。支持导出为静态网站，可以直接部署。</p><p><strong>适用场景：</strong> 需要维护架构文档的团队。特别适合微服务架构——服务多了没人记得清全貌，LikeC4 让架构图永远和代码同步。</p><hr><h2 id="10-iOfficeAI-x2F-AionUi-⭐-13-4K-📈-335-today"><a href="#10-iOfficeAI-x2F-AionUi-⭐-13-4K-📈-335-today" class="headerlink" title="10. iOfficeAI&#x2F;AionUi ⭐ 13.4K | 📈 +335 today"></a>10. iOfficeAI&#x2F;AionUi ⭐ 13.4K | 📈 +335 today</h2><p><strong>一句话：免费本地的 AI 编程助手统一 UI，支持 Gemini CLI、Claude Code、Codex 等。</strong></p><p>一个开源的桌面应用，为各种 CLI 编程 Agent 提供统一的图形界面。支持 Gemini CLI、Claude Code、Codex、OpenCode、Qwen Code、Goose CLI 等。</p><p><strong>为什么火？</strong> CLI 编程 Agent 越来越多，但不是所有人都喜欢在终端里工作。AionUi 提供了一个漂亮的 GUI 包装层，降低了使用门槛。本地运行保证数据安全，跨平台支持。</p><p><strong>技术亮点：</strong> TypeScript 构建，Apache 2.0 许可。支持 macOS&#x2F;Windows&#x2F;Linux。多模型支持，本地数据不上传。</p><p><strong>适用场景：</strong> 不想折腾终端但想用 AI 编程助手的开发者。或者需要同时使用多个 Agent 的人——统一界面比开 5 个终端窗口舒服得多。</p><hr><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>今天的 Trending 有几个明显趋势：</p><ol><li><strong>Agent 时代全面到来</strong>：10 个项目中有 6 个直接和 AI Agent 相关（shannon、monty、skills、dexter、superpowers、AionUi）</li><li><strong>安全是 Agent 的基础设施</strong>：shannon 做攻击测试、monty 做安全沙箱、litebox 做 OS 级隔离——Agent 越强大，安全越关键</li><li><strong>垂直领域 Agent 崛起</strong>：dexter（金融）、shannon（安全）证明了通用 Agent 框架之上，垂直场景才是变现方向</li><li><strong>国产模型持续突破</strong>：MiniCPM-o 在端侧多模态领域做到了世界级水平</li></ol><p>值得特别关注的是 <strong>obra&#x2F;superpowers</strong>（48K stars）——它不是工具，而是方法论。当所有人都在做 Agent 工具时，它在定义 Agent 应该怎么工作。这可能是今天 Trending 里长期价值最高的项目。</p>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>开源</tag>
      
      <tag>GitHub</tag>
      
      <tag>Trending</tag>
      
      <tag>技术日报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2026年02月09日早间要闻</title>
    <link href="/2026/02/09/2026-02-09-morning-news/"/>
    <url>/2026/02/09/2026-02-09-morning-news/</url>
    
    <content type="html"><![CDATA[<h2 id="📰-今日重要新闻"><a href="#📰-今日重要新闻" class="headerlink" title="📰 今日重要新闻"></a>📰 今日重要新闻</h2><h3 id="1-四大科技巨头2026年AI资本开支合计达-6500亿"><a href="#1-四大科技巨头2026年AI资本开支合计达-6500亿" class="headerlink" title="1. 四大科技巨头2026年AI资本开支合计达$6500亿"></a>1. 四大科技巨头2026年AI资本开支合计达$6500亿</h3><p>Bloomberg报道，微软、Alphabet、Meta、亚马逊四家公司2026年资本开支预算合计约$6500亿，几乎全部砸向数据中心和AI算力基础设施。这一数字令市场对AI投资回报率产生担忧，上周五科技板块承压。</p><h3 id="2-Alphabet-Q4财报亮眼，2026-Capex指引翻倍至-1850亿"><a href="#2-Alphabet-Q4财报亮眼，2026-Capex指引翻倍至-1850亿" class="headerlink" title="2. Alphabet Q4财报亮眼，2026 Capex指引翻倍至$1850亿"></a>2. Alphabet Q4财报亮眼，2026 Capex指引翻倍至$1850亿</h3><p>Google母公司Alphabet Q4利润同比增长30%至$345亿，但更引发关注的是2026年资本开支指引高达$1750-1850亿，较2025年翻倍，CEO Sundar Pichai表示”供给仍然是制约因素”。投资者担忧巨额投入的ROI，财报后股价基本持平。</p><h3 id="3-AMD创纪录营收，数据中心首次占总收入过半"><a href="#3-AMD创纪录营收，数据中心首次占总收入过半" class="headerlink" title="3. AMD创纪录营收，数据中心首次占总收入过半"></a>3. AMD创纪录营收，数据中心首次占总收入过半</h3><p>AMD公布Q4 2025财报：季度营收$103亿创历史新高，全年营收$346亿同比增长34%。数据中心业务首次贡献超过一半的收入，Instinct MI300系列GPU和EPYC Turin处理器需求强劲。OpenAI已选择AMD作为优选GPU供应商。</p><h3 id="4-微软Q2-FY2026收入-813亿，Azure增长38"><a href="#4-微软Q2-FY2026收入-813亿，Azure增长38" class="headerlink" title="4. 微软Q2 FY2026收入$813亿，Azure增长38%"></a>4. 微软Q2 FY2026收入$813亿，Azure增长38%</h3><p>微软季度收入$813亿同比增17%，Azure云收入增长38%（按固定汇率），云业务总收入首次突破$500亿。净利润$385亿，EPS $5.16。OpenAI相关投资为EPS贡献了额外$1.02。Copilot在企业端渗透加速。</p><h3 id="5-阿里巴巴宣布三年投入3800亿元AI和云基础设施"><a href="#5-阿里巴巴宣布三年投入3800亿元AI和云基础设施" class="headerlink" title="5. 阿里巴巴宣布三年投入3800亿元AI和云基础设施"></a>5. 阿里巴巴宣布三年投入3800亿元AI和云基础设施</h3><p>阿里巴巴集团宣布未来三年将投入至少3800亿人民币（约$530亿）用于AI和云计算基础设施建设，CEO吴泳铭的”AI优先”战略覆盖全业务线。云智能业务成为核心增长支柱，中国云市场预计2026年将扩大至约$611亿。</p><hr><h2 id="📈-美股重点关注（上周五-2-x2F-6-收盘）"><a href="#📈-美股重点关注（上周五-2-x2F-6-收盘）" class="headerlink" title="📈 美股重点关注（上周五 2&#x2F;6 收盘）"></a>📈 美股重点关注（上周五 2&#x2F;6 收盘）</h2><h3 id="MSFT-微软-—-401-14"><a href="#MSFT-微软-—-401-14" class="headerlink" title="MSFT 微软 — $401.14"></a>MSFT 微软 — $401.14</h3><ul><li><strong>近期表现</strong>：较去年10月历史高点$541下跌约26%，处于回调区间</li><li><strong>关键催化剂</strong>：Q2 FY2026业绩超预期，Azure增长38%强劲；云总收入破$500亿大关</li><li><strong>风险点</strong>：AI资本开支持续高企，市场担忧短期利润率受压</li><li><strong>看点</strong>：Copilot企业渗透率、OpenAI合作深化</li></ul><h3 id="GOOGL-谷歌-—-322-86（-2-53-）"><a href="#GOOGL-谷歌-—-322-86（-2-53-）" class="headerlink" title="GOOGL 谷歌 — $322.86（-2.53%）"></a>GOOGL 谷歌 — $322.86（-2.53%）</h3><ul><li><strong>近期表现</strong>：财报后从$343.69高点回落约6%</li><li><strong>关键催化剂</strong>：Q4利润大增30%，广告+云双轮驱动；2026 Capex翻倍显示AI决心</li><li><strong>风险点</strong>：$1850亿资本开支令投资者不安，反垄断案件悬而未决</li><li><strong>看点</strong>：Gemini 2.0落地效果、Google Cloud增速能否持续</li></ul><h3 id="NVDA-英伟达-—-185-41"><a href="#NVDA-英伟达-—-185-41" class="headerlink" title="NVDA 英伟达 — $185.41"></a>NVDA 英伟达 — $185.41</h3><ul><li><strong>近期表现</strong>：过去三个月回调约7.6%，从$207高点回落</li><li><strong>关键催化剂</strong>：Q3 FY2026数据中心收入$512亿，Q4指引$650亿；Seeking Alpha目标价$219</li><li><strong>风险点</strong>：中国出口限制、客户自研芯片趋势、估值高位回调压力</li><li><strong>看点</strong>：2&#x2F;26 Q4财报日临近，Blackwell架构出货节奏</li></ul><h3 id="AMD-—-207-95（-8-28-）"><a href="#AMD-—-207-95（-8-28-）" class="headerlink" title="AMD — $207.95（+8.28%）"></a>AMD — $207.95（+8.28%）</h3><ul><li><strong>近期表现</strong>：上周五大涨8.28%，受Q4财报利好提振</li><li><strong>关键催化剂</strong>：Q4营收$103亿创纪录，数据中心收入首次过半；OpenAI选择AMD为优选供应商</li><li><strong>风险点</strong>：与NVDA的GPU差距仍大，MI300生态追赶中</li><li><strong>看点</strong>：MI325X出货加速、EPYC Turin在服务器端的份额增长</li></ul><h3 id="BABA-阿里巴巴-—-162-51（-3-01-）"><a href="#BABA-阿里巴巴-—-162-51（-3-01-）" class="headerlink" title="BABA 阿里巴巴 — $162.51（+3.01%）"></a>BABA 阿里巴巴 — $162.51（+3.01%）</h3><ul><li><strong>近期表现</strong>：上周五涨3%，市场对AI投入计划反应积极</li><li><strong>关键催化剂</strong>：3800亿元AI&#x2F;云基建三年投资计划；AI优先战略重塑业务矩阵</li><li><strong>风险点</strong>：中国宏观经济不确定性、电商竞争（拼多多、抖音）、云利润率偏低</li><li><strong>看点</strong>：云智能业务能否兑现增长、2月底财报季将至</li></ul><hr><h2 id="💡-本周关注"><a href="#💡-本周关注" class="headerlink" title="💡 本周关注"></a>💡 本周关注</h2><ul><li><strong>2&#x2F;26 NVDA Q4财报</strong>：AI算力龙头的关键业绩验证</li><li><strong>大科技AI投资回报</strong>：$6500亿资本开支的ROI何时显现</li><li><strong>中国AI政策走向</strong>：阿里等巨头加码后的监管与竞争态势</li></ul><blockquote><p>数据来源：MacroTrends、StockAnalysis、CNBC、Reuters、Bloomberg | 股价为美东时间2&#x2F;6收盘价</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>早报</tag>
      
      <tag>新闻</tag>
      
      <tag>AI</tag>
      
      <tag>科技</tag>
      
      <tag>美股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>OpenClaw 国内定制版部署指南：Windows 从零到跑通，全程国内网络，必定成功</title>
    <link href="/2026/02/08/openclaw-china-windows-guide/"/>
    <url>/2026/02/08/openclaw-china-windows-guide/</url>
    
    <content type="html"><![CDATA[<blockquote><p><strong>这篇写给谁？</strong> 你在国内，用 Windows，想搞一个真正能用的 AI 私人助手。网上那些教程——要么是 Mac 的（你摸了摸手里的联想），要么跑到一半报错就没下文了（最气的一种）。这篇不一样——<strong>全程国内网络，保证能跑通。跑不通你来找我。</strong></p></blockquote><p><img src="/images/openclaw-guide/china-cover-1.png" alt="OpenClaw ❤️ China"></p><h2 id="先说结论"><a href="#先说结论" class="headerlink" title="先说结论"></a>先说结论</h2><p>OpenClaw 是 2026 年最火的开源 AI 助手项目（GitHub 146K+ Stars，没错，十四万六千颗星星），它能干啥？</p><ul><li>🖥️ 直接操作你的电脑（读写文件、执行命令、管理日程——比你自己操作还利索）</li><li>💬 接入飞书&#x2F;钉钉&#x2F;微信，变成你的专属 AI 秘书（再也不用自己回老板消息了……开玩笑的）</li><li>🧠 使用国产大模型（通义千问 Qwen、DeepSeek），<strong>不花一分钱外币</strong></li></ul><p><strong>本文目标</strong>：在你的 Windows 电脑上，用纯国内资源把 OpenClaw 跑起来，而且 <strong>24小时在线不掉线</strong>。泡杯茶，咱们开始。</p><hr><h2 id="第一步：安装-Node-js（3分钟搞定）"><a href="#第一步：安装-Node-js（3分钟搞定）" class="headerlink" title="第一步：安装 Node.js（3分钟搞定）"></a>第一步：安装 Node.js（3分钟搞定）</h2><p>OpenClaw 跑在 Node.js 上面，所以我们先把地基打好。需要 22 以上版本。</p><h3 id="方法一：官网安装（推荐，小白友好）"><a href="#方法一：官网安装（推荐，小白友好）" class="headerlink" title="方法一：官网安装（推荐，小白友好）"></a>方法一：官网安装（推荐，小白友好）</h3><ol><li>打开 <a href="https://nodejs.org/zh-cn/">Node.js 中文网</a>（国内可以直接访问，放心点）</li><li>下载 <strong>LTS 版本</strong>（v22.x）的 Windows 安装包（.msi）</li><li>双击安装，全部默认下一步——这可能是整个教程最简单的一步了</li></ol><h3 id="方法二：通过-fnm-安装（老手可以秀一下）"><a href="#方法二：通过-fnm-安装（老手可以秀一下）" class="headerlink" title="方法二：通过 fnm 安装（老手可以秀一下）"></a>方法二：通过 fnm 安装（老手可以秀一下）</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># PowerShell（管理员模式）</span><br>winget install Schniz.fnm<br>fnm install <span class="hljs-number">22</span><br>fnm use <span class="hljs-number">22</span><br></code></pre></td></tr></table></figure><p>装完之后，打开一个<strong>全新的</strong> PowerShell 窗口（划重点，一定要新开），验证一下：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs powershell">node <span class="hljs-literal">-v</span><br><span class="hljs-comment"># 应该显示 v22.x.x</span><br><br>npm <span class="hljs-literal">-v</span><br><span class="hljs-comment"># 应该显示 10.x.x</span><br></code></pre></td></tr></table></figure><p>看到版本号了？恭喜，地基打好了，接下来才是重头戏。</p><hr><h2 id="第二步：配置国内-npm-镜像（救命一步！）"><a href="#第二步：配置国内-npm-镜像（救命一步！）" class="headerlink" title="第二步：配置国内 npm 镜像（救命一步！）"></a>第二步：配置国内 npm 镜像（救命一步！）</h2><p>这是国内安装成功的 <strong>最最最关键一步</strong>。npm 默认去国外服务器下载东西，从国内直连那个速度……蜗牛看了都摇头。不配镜像的话，你会在终端前面枯坐半小时，然后收获一个 <code>ETIMEDOUT</code>。</p><p><img src="/images/openclaw-guide/step-install.png" alt="安装步骤"></p><h3 id="方案-A：安装-cnpm（推荐，省心省力）"><a href="#方案-A：安装-cnpm（推荐，省心省力）" class="headerlink" title="方案 A：安装 cnpm（推荐，省心省力）"></a>方案 A：安装 cnpm（推荐，省心省力）</h3><p>cnpm 是淘宝团队出的 npm 镜像客户端，直接走国内源，不需要改任何全局配置：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">npm install <span class="hljs-literal">-g</span> cnpm <span class="hljs-literal">--registry</span>=https://registry.npmmirror.com<br></code></pre></td></tr></table></figure><p>装好后验证：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell">cnpm <span class="hljs-literal">-v</span><br><span class="hljs-comment"># 应该显示版本信息</span><br></code></pre></td></tr></table></figure><p>之后所有需要 <code>npm install</code> 的地方，用 <code>cnpm</code> 替代即可，速度飞起。</p><h3 id="方案-B：直接换源（不想多装工具的话）"><a href="#方案-B：直接换源（不想多装工具的话）" class="headerlink" title="方案 B：直接换源（不想多装工具的话）"></a>方案 B：直接换源（不想多装工具的话）</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">npm config <span class="hljs-built_in">set</span> registry https://registry.npmmirror.com<br></code></pre></td></tr></table></figure><p>就这一行，把 npm 的默认下载源换成国内镜像。验证一下：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell">npm config get registry<br><span class="hljs-comment"># 应该显示 https://registry.npmmirror.com</span><br></code></pre></td></tr></table></figure><blockquote><p><strong>💡 说人话：</strong> 方案 A 装个 cnpm 最省心，后续直接 <code>cnpm install</code> 就完事。方案 B 改全局源也行，看你喜好。</p></blockquote><hr><h2 id="第三步：安装-OpenClaw（终于到正主了）"><a href="#第三步：安装-OpenClaw（终于到正主了）" class="headerlink" title="第三步：安装 OpenClaw（终于到正主了）"></a>第三步：安装 OpenClaw（终于到正主了）</h2><h3 id="方式一：cnpm-安装（推荐）"><a href="#方式一：cnpm-安装（推荐）" class="headerlink" title="方式一：cnpm 安装（推荐）"></a>方式一：cnpm 安装（推荐）</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># 以管理员身份打开 PowerShell（右键→以管理员身份运行）</span><br>cnpm install <span class="hljs-literal">-g</span> openclaw@latest<br></code></pre></td></tr></table></figure><p>看到类似 <code>added xxx packages</code> 就成功了。感谢淘宝镜像，通常几十秒搞定。</p><p>如果不幸遇到 <code>sharp</code> 相关报错（这是个图片处理库，有时候在 Windows 上会闹脾气）：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$env:SHARP_IGNORE_GLOBAL_LIBVIPS</span>=<span class="hljs-number">1</span><br>cnpm install <span class="hljs-literal">-g</span> openclaw@latest<br></code></pre></td></tr></table></figure><h3 id="方式二：npm-安装（如果你用了方案-B-换源）"><a href="#方式二：npm-安装（如果你用了方案-B-换源）" class="headerlink" title="方式二：npm 安装（如果你用了方案 B 换源）"></a>方式二：npm 安装（如果你用了方案 B 换源）</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">npm install <span class="hljs-literal">-g</span> openclaw@latest<br></code></pre></td></tr></table></figure><h3 id="方式三：官方安装脚本（一键流）"><a href="#方式三：官方安装脚本（一键流）" class="headerlink" title="方式三：官方安装脚本（一键流）"></a>方式三：官方安装脚本（一键流）</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-built_in">iwr</span> <span class="hljs-literal">-useb</span> https://openclaw.ai/install.ps1 | <span class="hljs-built_in">iex</span><br></code></pre></td></tr></table></figure><h3 id="安装验证"><a href="#安装验证" class="headerlink" title="安装验证"></a>安装验证</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell">openclaw <span class="hljs-literal">--version</span><br><span class="hljs-comment"># 应该显示版本号，如 2026.2.x</span><br></code></pre></td></tr></table></figure><p>如果提示 <code>openclaw 不是内部或外部命令</code>——别慌，这是经典的 PATH 问题：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># 查看 npm 全局安装路径</span><br>npm prefix <span class="hljs-literal">-g</span><br><br><span class="hljs-comment"># 把输出的路径加到系统 PATH 环境变量里</span><br><span class="hljs-comment"># 通常是 C:\Users\你的用户名\AppData\Roaming\npm</span><br><span class="hljs-comment"># 然后重新打开 PowerShell 就好了</span><br></code></pre></td></tr></table></figure><hr><h2 id="第四步：配置国产大模型（零成本，这才是国内玩家的快乐）"><a href="#第四步：配置国产大模型（零成本，这才是国内玩家的快乐）" class="headerlink" title="第四步：配置国产大模型（零成本，这才是国内玩家的快乐）"></a>第四步：配置国产大模型（零成本，这才是国内玩家的快乐）</h2><p>不需要 OpenAI API Key（那玩意儿又贵又难搞），用国产模型就完事了。免费、好用、还不用担心被封号。</p><p><img src="/images/openclaw-guide/models-compare.png" alt="国产模型对比"></p><h3 id="推荐模型对比"><a href="#推荐模型对比" class="headerlink" title="推荐模型对比"></a>推荐模型对比</h3><table><thead><tr><th>模型</th><th>厂商</th><th>免费额度</th><th>一句话点评</th></tr></thead><tbody><tr><td><strong>Qwen（通义千问）</strong></td><td>阿里</td><td>100万 tokens&#x2F;月</td><td>⭐ 首选！额度大方，稳如老狗</td></tr><tr><td><strong>DeepSeek</strong></td><td>深度求索</td><td>1000万 tokens</td><td>推理一把好手，性价比之王</td></tr><tr><td><strong>GLM-4</strong></td><td>智谱</td><td>有免费额度</td><td>写代码可以信赖</td></tr><tr><td><strong>Kimi</strong></td><td>月之暗面</td><td>有免费额度</td><td>长文本处理的王者</td></tr></tbody></table><h3 id="配置方法：通义千问-Qwen（推荐首选）"><a href="#配置方法：通义千问-Qwen（推荐首选）" class="headerlink" title="配置方法：通义千问 Qwen（推荐首选）"></a>配置方法：通义千问 Qwen（推荐首选）</h3><p><strong>第 1 步：搞到 API Key</strong></p><ol><li>打开 <a href="https://bailian.console.aliyun.com/">阿里云百炼</a></li><li>用支付宝扫码登录（对，就这么简单）</li><li>进入「API Key管理」→ 「创建 API Key」</li><li>复制保存好这个 Key——待会儿要用，丢了就得重新建</li></ol><p><strong>第 2 步：运行向导配置</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">openclaw onboard <span class="hljs-literal">--install-daemon</span><br></code></pre></td></tr></table></figure><p>向导会问你几个问题：</p><ol><li><strong>是否了解风险</strong> → 选 Yes</li><li><strong>安装方式</strong> → 选 QuickStart</li><li><strong>模型服务商</strong> → 选 <strong>Qwen</strong></li><li>按提示完成浏览器授权</li></ol><p>或者直接编辑 <code>~/.openclaw/openclaw.json</code>：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;models&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;default&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;qwen/qwen-max&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;providers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;qwen&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;apiKey&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;sk-你的API Key&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h3 id="配置方法：DeepSeek（第二推荐）"><a href="#配置方法：DeepSeek（第二推荐）" class="headerlink" title="配置方法：DeepSeek（第二推荐）"></a>配置方法：DeepSeek（第二推荐）</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;models&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;default&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;deepseek/deepseek-chat&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;providers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;deepseek&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;apiKey&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;sk-你的API Key&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;baseUrl&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;https://api.deepseek.com/v1&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>DeepSeek API Key 获取：<a href="https://platform.deepseek.com/">platform.deepseek.com</a></p><hr><h2 id="第五步：接入国内社交工具（这步做完，才算真正好用）"><a href="#第五步：接入国内社交工具（这步做完，才算真正好用）" class="headerlink" title="第五步：接入国内社交工具（这步做完，才算真正好用）"></a>第五步：接入国内社交工具（这步做完，才算真正好用）</h2><p>装好了 OpenClaw，配好了模型，但它现在还只是个终端里的聊天窗口。想让它真正变成你的 AI 秘书？得接上聊天工具。</p><p><img src="/images/openclaw-guide/china-cover-3.png" alt="OpenClaw on Windows"></p><h3 id="方案一：飞书（推荐，体验最丝滑）"><a href="#方案一：飞书（推荐，体验最丝滑）" class="headerlink" title="方案一：飞书（推荐，体验最丝滑）"></a>方案一：飞书（推荐，体验最丝滑）</h3><p>飞书是目前国内接入 OpenClaw 体验最好的平台，没有之一。</p><p><strong>1. 创建飞书应用</strong></p><ol><li>打开 <a href="https://open.feishu.cn/">飞书开放平台</a></li><li>创建企业自建应用（别怕，个人也能建）</li><li>拿到 App ID 和 App Secret</li></ol><p><strong>2. 配置权限（一键导入）</strong></p><p>在应用后台的「权限管理」页面，可以手动逐个添加，也可以用<strong>批量导入</strong>的方式一步到位。</p><p><strong>方式一：批量导入（推荐）</strong></p><p>在飞书开放平台的应用配置页面，找到「权限管理」→「批量开通」，粘贴以下 JSON：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;scopes&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;tenant&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-string">&quot;aily:file:read&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;aily:file:write&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;application:application.app_message_stats.overview:readonly&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;application:application:self_manage&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;application:bot.menu:write&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;cardkit:card:write&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;contact:contact.base:readonly&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;contact:user.employee_id:readonly&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;corehr:file:download&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;docs:document.content:read&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;event:ip_list&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:chat&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:chat.access_event.bot_p2p_chat:read&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:chat.members:bot_access&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:message&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:message.group_at_msg:readonly&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:message.group_msg&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:message.p2p_msg:readonly&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:message:readonly&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:message:send_as_bot&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:resource&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;sheets:spreadsheet&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;wiki:wiki:readonly&quot;</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;user&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-string">&quot;aily:file:read&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;aily:file:write&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;contact:contact.base:readonly&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:chat.access_event.bot_p2p_chat:read&quot;</span><br>    <span class="hljs-punctuation">]</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p><strong>方式二：手动添加</strong></p><p>如果你偏好手动操作，以下是需要开通的权限清单：</p><p><strong>应用权限（tenant）：</strong></p><ul><li><code>im:message</code> &#x2F; <code>im:message:send_as_bot</code> &#x2F; <code>im:message:readonly</code>（消息收发）</li><li><code>im:resource</code>（获取文件&#x2F;图片资源）</li><li><code>im:chat</code> &#x2F; <code>im:chat.members:bot_access</code>（群聊访问）</li><li><code>im:message.group_msg</code> &#x2F; <code>im:message.group_at_msg:readonly</code>（群消息）</li><li><code>im:message.p2p_msg:readonly</code> &#x2F; <code>im:chat.access_event.bot_p2p_chat:read</code>（私聊）</li><li><code>docs:document.content:read</code> &#x2F; <code>wiki:wiki:readonly</code> &#x2F; <code>sheets:spreadsheet</code>（文档&#x2F;知识库&#x2F;表格读取）</li><li><code>contact:contact.base:readonly</code> &#x2F; <code>contact:user.employee_id:readonly</code>（通讯录基本信息）</li><li><code>cardkit:card:write</code>（交互式卡片）</li><li><code>application:application:self_manage</code> &#x2F; <code>application:bot.menu:write</code>（应用管理）</li><li>其他：<code>aily:file:read/write</code>、<code>corehr:file:download</code>、<code>event:ip_list</code></li></ul><p><strong>用户权限（user）：</strong></p><ul><li><code>aily:file:read</code> &#x2F; <code>aily:file:write</code></li><li><code>contact:contact.base:readonly</code></li><li><code>im:chat.access_event.bot_p2p_chat:read</code></li></ul><p><strong>3. 配置事件订阅</strong></p><ul><li>请求地址：<code>https://你的服务器地址:18789/feishu/webhook</code></li><li>订阅事件：<code>im.message.receive_v1</code></li></ul><p><strong>4. 配置 openclaw.json</strong></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;channels&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;feishu&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;accounts&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;default&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;appId&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;cli_你的AppID&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;appSecret&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你的AppSecret&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;encryptKey&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你的加密Key&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;verificationToken&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你的验证Token&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;enabled&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h3 id="方案二：钉钉"><a href="#方案二：钉钉" class="headerlink" title="方案二：钉钉"></a>方案二：钉钉</h3><p>钉钉接入方式类似飞书，通过企业内部应用 + 机器人实现。路子差不多，这里就不重复了。</p><h3 id="方案三：微信（需要第三方桥接，稍微折腾一点）"><a href="#方案三：微信（需要第三方桥接，稍微折腾一点）" class="headerlink" title="方案三：微信（需要第三方桥接，稍微折腾一点）"></a>方案三：微信（需要第三方桥接，稍微折腾一点）</h3><p>微信没有官方机器人 API（你懂的），需要通过 <a href="https://github.com/nickliu555/wechat-bridge-openclaw">WeChat Bridge</a> 等第三方工具桥接。</p><blockquote><p><strong>💡 真心建议</strong>：先用飞书跑通，体验最流畅。飞书个人版免费，不需要企业认证。等你玩明白了再搞微信也不迟。</p></blockquote><hr><h2 id="第六步：Windows-防睡眠配置（别让你的-AI-秘书打瞌睡）"><a href="#第六步：Windows-防睡眠配置（别让你的-AI-秘书打瞌睡）" class="headerlink" title="第六步：Windows 防睡眠配置（别让你的 AI 秘书打瞌睡）"></a>第六步：Windows 防睡眠配置（别让你的 AI 秘书打瞌睡）</h2><p>OpenClaw 是常驻后台服务。如果电脑进入睡眠……你的 AI 秘书就直接下班了。以下几招彻底解决睡眠问题，让它 7×24 给你打工。</p><p><img src="/images/openclaw-guide/china-cover-4.png" alt="突破障碍，从零到跑通"></p><h3 id="方法一：powercfg-命令（最快，30秒搞定）"><a href="#方法一：powercfg-命令（最快，30秒搞定）" class="headerlink" title="方法一：powercfg 命令（最快，30秒搞定）"></a>方法一：powercfg 命令（最快，30秒搞定）</h3><p>以管理员身份打开 PowerShell：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># 关闭睡眠（交流电模式下）</span><br>powercfg /change standby<span class="hljs-literal">-timeout-ac</span> <span class="hljs-number">0</span><br><br><span class="hljs-comment"># 关闭休眠</span><br>powercfg /change hibernate<span class="hljs-literal">-timeout-ac</span> <span class="hljs-number">0</span><br><br><span class="hljs-comment"># 关闭屏幕（可选，省电但不影响 OpenClaw）</span><br>powercfg /change monitor<span class="hljs-literal">-timeout-ac</span> <span class="hljs-number">15</span><br><br><span class="hljs-comment"># 禁用休眠文件（还能省几个G磁盘空间）</span><br>powercfg <span class="hljs-literal">-h</span> off<br></code></pre></td></tr></table></figure><h3 id="方法二：创建”永不睡眠”电源计划"><a href="#方法二：创建”永不睡眠”电源计划" class="headerlink" title="方法二：创建”永不睡眠”电源计划"></a>方法二：创建”永不睡眠”电源计划</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># 创建新的电源计划</span><br>powercfg <span class="hljs-literal">-duplicatescheme</span> <span class="hljs-number">8</span>c5e7fda<span class="hljs-literal">-e8bf-4a96-9a85-a6e23a8c635c</span><br><br><span class="hljs-comment"># 在 &quot;控制面板 → 电源选项&quot; 中找到新计划，设置：</span><br><span class="hljs-comment">#   - 关闭显示器：15分钟</span><br><span class="hljs-comment">#   - 使计算机进入睡眠状态：从不</span><br><span class="hljs-comment">#   - 关闭硬盘：从不</span><br></code></pre></td></tr></table></figure><h3 id="方法三：创建-keep-awake-脚本"><a href="#方法三：创建-keep-awake-脚本" class="headerlink" title="方法三：创建 keep-awake 脚本"></a>方法三：创建 keep-awake 脚本</h3><p>创建 <code>keep-awake.ps1</code>：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># OpenClaw Keep Awake Script</span><br><span class="hljs-comment"># 每 4 分钟模拟一次按键，防止系统进入睡眠</span><br><br><span class="hljs-built_in">Write-Host</span> <span class="hljs-string">&quot;🦞 OpenClaw Keep Awake - 防睡眠模式已启动&quot;</span> <span class="hljs-literal">-ForegroundColor</span> Green<br><span class="hljs-built_in">Write-Host</span> <span class="hljs-string">&quot;按 Ctrl+C 停止&quot;</span> <span class="hljs-literal">-ForegroundColor</span> Yellow<br><br><span class="hljs-variable">$shell</span> = <span class="hljs-built_in">New-Object</span> <span class="hljs-literal">-ComObject</span> WScript.Shell<br><br><span class="hljs-keyword">while</span> (<span class="hljs-variable">$true</span>) &#123;<br>    <span class="hljs-variable">$shell</span>.SendKeys(<span class="hljs-string">&quot;&#123;SCROLLLOCK&#125;&quot;</span>)<br>    <span class="hljs-built_in">Start-Sleep</span> <span class="hljs-literal">-Milliseconds</span> <span class="hljs-number">200</span><br>    <span class="hljs-variable">$shell</span>.SendKeys(<span class="hljs-string">&quot;&#123;SCROLLLOCK&#125;&quot;</span>)<br>    <br>    <span class="hljs-variable">$timestamp</span> = <span class="hljs-built_in">Get-Date</span> <span class="hljs-literal">-Format</span> <span class="hljs-string">&quot;yyyy-MM-dd HH:mm:ss&quot;</span><br>    <span class="hljs-built_in">Write-Host</span> <span class="hljs-string">&quot;[<span class="hljs-variable">$timestamp</span>] 💓 心跳 - 系统保持唤醒&quot;</span> <span class="hljs-literal">-ForegroundColor</span> DarkGray<br>    <br>    <span class="hljs-built_in">Start-Sleep</span> <span class="hljs-literal">-Seconds</span> <span class="hljs-number">240</span>  <span class="hljs-comment"># 4分钟</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="方法四：设置开机自启（一劳永逸）"><a href="#方法四：设置开机自启（一劳永逸）" class="headerlink" title="方法四：设置开机自启（一劳永逸）"></a>方法四：设置开机自启（一劳永逸）</h3><p>创建 <code>openclaw-startup.bat</code>，放到 Windows 启动文件夹：</p><figure class="highlight bat"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bat">@<span class="hljs-built_in">echo</span> off<br><span class="hljs-built_in">echo</span> Starting OpenClaw Gateway...<br><br>:: 防止睡眠<br>powercfg /change standby-timeout-ac <span class="hljs-number">0</span><br>powercfg /change hibernate-timeout-ac <span class="hljs-number">0</span><br><br>:: 启动 OpenClaw<br>openclaw gateway <span class="hljs-built_in">start</span><br><br><span class="hljs-built_in">echo</span> OpenClaw is running!<br></code></pre></td></tr></table></figure><p>启动文件夹怎么找？按 <code>Win + R</code>，输入 <code>shell:startup</code>，把 bat 文件丢进去就行。</p><h3 id="验证防睡眠生效"><a href="#验证防睡眠生效" class="headerlink" title="验证防睡眠生效"></a>验证防睡眠生效</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># 查看当前电源设置</span><br>powercfg /query SCHEME_CURRENT<br><br><span class="hljs-comment"># 查看活跃的电源请求</span><br>powercfg /requests<br></code></pre></td></tr></table></figure><hr><h2 id="第七步：启动并验证（激动人心的时刻！）"><a href="#第七步：启动并验证（激动人心的时刻！）" class="headerlink" title="第七步：启动并验证（激动人心的时刻！）"></a>第七步：启动并验证（激动人心的时刻！）</h2><h3 id="启动-Gateway"><a href="#启动-Gateway" class="headerlink" title="启动 Gateway"></a>启动 Gateway</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">openclaw gateway <span class="hljs-built_in">start</span><br></code></pre></td></tr></table></figure><h3 id="检查状态"><a href="#检查状态" class="headerlink" title="检查状态"></a>检查状态</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell">openclaw status<br>openclaw health<br></code></pre></td></tr></table></figure><h3 id="打开-Web-界面"><a href="#打开-Web-界面" class="headerlink" title="打开 Web 界面"></a>打开 Web 界面</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">openclaw dashboard<br></code></pre></td></tr></table></figure><p>浏览器会自动打开 <code>http://localhost:18789</code>，看到管理面板了？那就是你的 AI 管家的控制中心。</p><h3 id="测试对话"><a href="#测试对话" class="headerlink" title="测试对话"></a>测试对话</h3><p>在飞书（或其他已配置的聊天工具）中，给机器人发一条消息：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">你好，你是谁？<br></code></pre></td></tr></table></figure><p>如果收到回复——<strong>恭喜你，你做到了！</strong> 🎉 国内版 OpenClaw 配置成功，从此你有了一个 24 小时待命的 AI 私人助手。</p><p><img src="/images/openclaw-guide/china-cover-5-edit.png" alt="OpenClaw 智能助手"></p><hr><h2 id="常见问题-FAQ（踩坑指南）"><a href="#常见问题-FAQ（踩坑指南）" class="headerlink" title="常见问题 FAQ（踩坑指南）"></a>常见问题 FAQ（踩坑指南）</h2><h3 id="Q-npm-x2F-cnpm-install-很慢-x2F-超时怎么办？"><a href="#Q-npm-x2F-cnpm-install-很慢-x2F-超时怎么办？" class="headerlink" title="Q: npm&#x2F;cnpm install 很慢&#x2F;超时怎么办？"></a>Q: npm&#x2F;cnpm install 很慢&#x2F;超时怎么办？</h3><p>十有八九是没配镜像源。回去看第二步，装 cnpm 或换源：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">npm install <span class="hljs-literal">-g</span> cnpm <span class="hljs-literal">--registry</span>=https://registry.npmmirror.com<br></code></pre></td></tr></table></figure><h3 id="Q-sharp-安装报错？"><a href="#Q-sharp-安装报错？" class="headerlink" title="Q: sharp 安装报错？"></a>Q: sharp 安装报错？</h3><p>这货在 Windows 上偶尔会闹别扭：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$env:SHARP_IGNORE_GLOBAL_LIBVIPS</span>=<span class="hljs-number">1</span><br>cnpm install <span class="hljs-literal">-g</span> openclaw@latest<br></code></pre></td></tr></table></figure><h3 id="Q-找不到-openclaw-命令？"><a href="#Q-找不到-openclaw-命令？" class="headerlink" title="Q: 找不到 openclaw 命令？"></a>Q: 找不到 openclaw 命令？</h3><p>经典 PATH 问题：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># 先看看 npm 把东西装到哪儿了</span><br>npm prefix <span class="hljs-literal">-g</span><br><br><span class="hljs-comment"># 把输出的路径加到系统 PATH 环境变量里</span><br><span class="hljs-comment"># 通常是 C:\Users\你的用户名\AppData\Roaming\npm</span><br><span class="hljs-comment"># 加完重开 PowerShell 就好了</span><br></code></pre></td></tr></table></figure><h3 id="Q-Gateway-启动报端口被占用？"><a href="#Q-Gateway-启动报端口被占用？" class="headerlink" title="Q: Gateway 启动报端口被占用？"></a>Q: Gateway 启动报端口被占用？</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># 查看是谁占了</span><br>netstat <span class="hljs-literal">-aon</span> | findstr <span class="hljs-number">18789</span><br><br><span class="hljs-comment"># 请它走</span><br>taskkill /PID 进程ID /F<br></code></pre></td></tr></table></figure><h3 id="Q-模型回复很慢？"><a href="#Q-模型回复很慢？" class="headerlink" title="Q: 模型回复很慢？"></a>Q: 模型回复很慢？</h3><ol><li>通义千问 <code>qwen-max</code> 响应最快，日常用它</li><li>DeepSeek 推理任务用 <code>deepseek-reasoner</code></li><li>确保用的是国内 API 端点（别走国际线路）</li></ol><h3 id="Q-电脑重启后-OpenClaw-没自动启动？"><a href="#Q-电脑重启后-OpenClaw-没自动启动？" class="headerlink" title="Q: 电脑重启后 OpenClaw 没自动启动？"></a>Q: 电脑重启后 OpenClaw 没自动启动？</h3><p>用上面的 <code>openclaw-startup.bat</code> 放到启动文件夹，或者：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">openclaw onboard <span class="hljs-literal">--install-daemon</span><br></code></pre></td></tr></table></figure><p>这会把 OpenClaw 注册为系统服务，重启也不怕。</p><hr><h2 id="完整配置文件参考"><a href="#完整配置文件参考" class="headerlink" title="完整配置文件参考"></a>完整配置文件参考</h2><p>给你一份 <code>~/.openclaw/openclaw.json</code> 的完整示例，直接抄作业：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;models&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;default&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;qwen/qwen-max&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;providers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;qwen&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;apiKey&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;sk-你的通义千问API Key&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;deepseek&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;apiKey&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;sk-你的DeepSeek API Key&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;baseUrl&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;https://api.deepseek.com/v1&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;channels&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;feishu&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;accounts&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;default&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;appId&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;cli_你的AppID&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;appSecret&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你的AppSecret&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;encryptKey&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你的加密Key&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;verificationToken&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你的验证Token&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;enabled&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><hr><h2 id="总结：30-分钟，从零到拥有-AI-秘书"><a href="#总结：30-分钟，从零到拥有-AI-秘书" class="headerlink" title="总结：30 分钟，从零到拥有 AI 秘书"></a>总结：30 分钟，从零到拥有 AI 秘书</h2><table><thead><tr><th>步骤</th><th>干了啥</th><th>花了多久</th></tr></thead><tbody><tr><td>1</td><td>装 Node.js</td><td>5 分钟</td></tr><tr><td>2</td><td>配 npm 镜像</td><td>1 分钟</td></tr><tr><td>3</td><td>装 OpenClaw</td><td>3 分钟</td></tr><tr><td>4</td><td>配国产大模型</td><td>5 分钟</td></tr><tr><td>5</td><td>接飞书</td><td>15 分钟</td></tr><tr><td>6</td><td>防睡眠</td><td>3 分钟</td></tr><tr><td>7</td><td>启动验证</td><td>2 分钟</td></tr></tbody></table><p><strong>总计约 30 分钟</strong>，全程国内网络，不需要花一分美金。</p><p>你现在拥有了一个 <strong>24小时在线的 AI 私人助手</strong>——它能帮你管理日程、读写文件、处理消息、操作电脑，而且跑在你自己的机器上，数据完全私有，没有人偷看你的聊天记录。</p><p>欢迎来到 AI Agent 时代，朋友。这才刚刚开始。🦞</p><p><img src="/images/openclaw-guide/china-cover-2.png" alt="OpenClaw 国内部署指南"></p><hr><p><em>本文基于 OpenClaw 2026.2.x 版本编写，如有更新请以官方文档为准。</em><br><em>官方文档：<a href="https://docs.openclaw.ai/">https://docs.openclaw.ai</a></em><br><em>GitHub：<a href="https://github.com/openclaw/openclaw">https://github.com/openclaw/openclaw</a></em></p>]]></content>
    
    
    <categories>
      
      <category>技术实战</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Windows</tag>
      
      <tag>OpenClaw</tag>
      
      <tag>教程</tag>
      
      <tag>国内</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>马斯克三小时酒馆畅聊纪要：大吹中国赢麻论，要把GPU搬上天</title>
    <link href="/2026/02/08/musk-dwarkesh-podcast-2026/"/>
    <url>/2026/02/08/musk-dwarkesh-podcast-2026/</url>
    
    <content type="html"><![CDATA[<p><img src="/images/musk-dwarkesh-pencil.png" alt="马斯克在Dwarkesh Podcast上畅聊三小时"></p><blockquote><p>“36个月内，太空将是部署AI最便宜的地方。” —— 埃隆·马斯克</p></blockquote><p>2026年2月6日，马斯克做客顶级科技播客 Dwarkesh Podcast，与主持人 Dwarkesh Patel 和 Stripe 联合创始人 John Collison 展开了一场长达三小时的深度对话。喝着 Guinness 黑啤的马斯克显然聊嗨了——从太空数据中心到人形机器人，从芯片制造到对中国制造业的罕见盛赞，每一个话题都在刷新我们对这位”疯狂马斯克”的认知。</p><p>这是一次横跨太空算力、AI对齐、芯片制造、人形机器人、中国制造、DOGE改革、SpaceX经验等多个维度的全景式访谈。本文提炼核心观点，深度解读这场对话中的关键信号。</p><span id="more"></span><h2 id="一、太空AI：30个月内颠覆算力格局"><a href="#一、太空AI：30个月内颠覆算力格局" class="headerlink" title="一、太空AI：30个月内颠覆算力格局"></a>一、太空AI：30个月内颠覆算力格局</h2><p>整场访谈中，马斯克反复强调的核心论点只有一个：<strong>地球上的电快不够用了，AI的未来在太空。</strong></p><h3 id="能源困局"><a href="#能源困局" class="headerlink" title="能源困局"></a>能源困局</h3><p>马斯克给出了一个令人警醒的数据对比：</p><ul><li>AI芯片的产能正以<strong>指数级</strong>增长</li><li>而中国以外地区的电力产出<strong>几乎停滞</strong></li><li>美国目前平均用电仅 0.5 太瓦</li></ul><p>“芯片产能正以指数级增长，电力产能却停滞不前。这些芯片要靠什么启动？难道指望魔法能源？”</p><p>不仅如此，即便自建发电厂，也面临涡轮机叶片的全球性短缺——全球仅有三家铸造公司能生产，订单已排到2030年。xAI 的 Colossus 数据中心为了上线1吉瓦电力，团队不得不”连续创造一系列奇迹”，包括跨州建设电力线路。</p><h3 id="太空的压倒性优势"><a href="#太空的压倒性优势" class="headerlink" title="太空的压倒性优势"></a>太空的压倒性优势</h3><p>马斯克的解决方案简单粗暴——把数据中心搬到太空：</p><ul><li><strong>太阳能效率提升5倍</strong>：太空无昼夜、无云层、无大气损耗</li><li><strong>不需要电池</strong>：省去夜间储能成本</li><li><strong>综合成本低10倍</strong>：算上免电池的优势</li><li><strong>无需许可证</strong>：这其实也是一个”监管套利”</li><li><strong>无限可扩展</strong>：地球能利用的太阳能仅占太阳总能量的五亿分之一</li></ul><blockquote><p>“记住我的话：30个月内，太空将是部署AI最经济的地方。到那时，这种优势将变得极其巨大。”</p></blockquote><h3 id="疯狂的数字"><a href="#疯狂的数字" class="headerlink" title="疯狂的数字"></a>疯狂的数字</h3><p>马斯克预测，<strong>五年后</strong>，SpaceX每年在太空部署的AI算力将超过地球上的累计总量：</p><ul><li>每年发射 <strong>1万次星舰</strong>（甚至2-3万次）</li><li>仅需 <strong>20-30艘星舰</strong> 即可实现（每艘约30小时周转一次）</li><li>年太空AI算力达 <strong>数百吉瓦</strong>，目标 <strong>1太瓦</strong></li></ul><p>当被问到SpaceX是否会成为超大规模云服务商时，马斯克的回答是：**”Hyper-hyper（超级超大规模）。”**</p><h2 id="二、罕见盛赞中国：制造业的”更高层次存在”"><a href="#二、罕见盛赞中国：制造业的”更高层次存在”" class="headerlink" title="二、罕见盛赞中国：制造业的”更高层次存在”"></a>二、罕见盛赞中国：制造业的”更高层次存在”</h2><p>这可能是整场访谈中最出人意料的部分。马斯克用了大量篇幅，<strong>几乎不加保留地称赞中国的制造业实力</strong>，这在西方科技领袖中极为罕见。</p><h3 id="核心观点"><a href="#核心观点" class="headerlink" title="核心观点"></a>核心观点</h3><p><strong>“中国是制造业强国，是更高层次的存在。”</strong> 马斯克如是说。</p><p>他给出的具体数据：</p><ul><li>中国的平均矿石精炼量约为<strong>世界其他地区总和的两倍</strong></li><li>镓精炼（太阳能电池关键材料）占全球 <strong>98%</strong></li><li>中国今年的发电量将超过美国的 <strong>三倍</strong></li><li>中国的人口是美国的 <strong>四倍</strong>，且人均工作量更大</li></ul><p>马斯克甚至直接指出：**”如果美国没有突破性创新，中国将彻底占据主导地位。”**</p><h3 id="对美国的”清醒警告”"><a href="#对美国的”清醒警告”" class="headerlink" title="对美国的”清醒警告”"></a>对美国的”清醒警告”</h3><p>马斯克的分析冷静而尖锐：</p><blockquote><p>“坦率地说，美国已经赢了太久……一支长期获胜的运动队往往会变得自满。这就是他们停止获胜的原因。中国的平均职业道德比美国更高。”</p></blockquote><p>他直言美国的结构性劣势：</p><ul><li>出生率自1971年以来一直低于更替水平</li><li>国内死亡人数即将超过出生人数</li><li>缺乏大量矿石精炼能力（美国开采的稀土矿石竟要运到中国精炼）</li></ul><p><strong>结论：美国在人力方面无法取胜，唯一的机会在机器人。</strong></p><h3 id="对中国芯片的判断"><a href="#对中国芯片的判断" class="headerlink" title="对中国芯片的判断"></a>对中国芯片的判断</h3><p>针对制裁话题，马斯克认为限制中国的不是技术能力，而是ASML设备禁令。**”三四年后，中国将会生产出极具竞争力的芯片。”**</p><h2 id="三、Optimus人形机器人：指数级增长的”造钱永动机”"><a href="#三、Optimus人形机器人：指数级增长的”造钱永动机”" class="headerlink" title="三、Optimus人形机器人：指数级增长的”造钱永动机”"></a>三、Optimus人形机器人：指数级增长的”造钱永动机”</h2><h3 id="三个指数的乘积"><a href="#三个指数的乘积" class="headerlink" title="三个指数的乘积"></a>三个指数的乘积</h3><p>马斯克将人形机器人的进步分解为三个指数级增长的维度：</p><ol><li><strong>数字智能</strong>的指数级增长</li><li><strong>AI芯片能力</strong>的指数级增长</li><li><strong>机电灵巧性</strong>的指数级增长</li></ol><p>关键在于：当机器人开始<strong>制造机器人</strong>，这三者将形成<strong>递归的乘法指数增长</strong>。马斯克称之为”超新星爆发”。</p><h3 id="手是最难的部分"><a href="#手是最难的部分" class="headerlink" title="手是最难的部分"></a>手是最难的部分</h3><blockquote><p>“从机电角度来看，手部比所有其他部件加起来还要困难。”</p></blockquote><p>特斯拉为此自研了全套定制执行器——电机、齿轮、功率电子器件、控制器、传感器——一切从物理学基本原理出发设计。<strong>这方面没有现成的供应链。</strong></p><h3 id="产量路线图"><a href="#产量路线图" class="headerlink" title="产量路线图"></a>产量路线图</h3><ul><li><strong>Optimus 3</strong>：年产量百万台级别</li><li><strong>Optimus 4</strong>：年产量千万台级别</li><li>目标：通过机器人制造机器人，达到<strong>年产数亿台</strong></li></ul><p><img src="/images/musk-dwarkesh-text2img.png" alt="三人在酒吧畅聊的彩色铅笔画"></p><h2 id="四、xAI、Grok与AI对齐"><a href="#四、xAI、Grok与AI对齐" class="headerlink" title="四、xAI、Grok与AI对齐"></a>四、xAI、Grok与AI对齐</h2><h3 id="AI与真理"><a href="#AI与真理" class="headerlink" title="AI与真理"></a>AI与真理</h3><p>马斯克对AI对齐的态度务实而深刻：</p><blockquote><p>“你需要确保Grok说的是正确的，而不是政治正确的。”</p></blockquote><p>他强调论证的有效性——公理尽可能接近真理，公理间不能自相矛盾，结论必须能以正确的概率推导出来。</p><h3 id="数字人模拟"><a href="#数字人模拟" class="headerlink" title="数字人模拟"></a>数字人模拟</h3><p>马斯克预测，<strong>到2026年底</strong>，”数字人模拟”问题就能解决——即AI能完成一个拥有电脑的人所能做的一切。</p><h3 id="对其他AI公司的辛辣点评"><a href="#对其他AI公司的辛辣点评" class="headerlink" title="对其他AI公司的辛辣点评"></a>对其他AI公司的辛辣点评</h3><p>以马斯克一贯的毒舌风格：</p><ul><li><strong>Midjourney</strong>——并不”中途”</li><li><strong>Stability AI</strong>——并不稳定</li><li><strong>OpenAI</strong>——是封闭的</li><li><strong>Anthropic</strong>——Misanthropic（厌世的）</li><li><strong>xAI</strong>——“这个名字很难反讽”</li></ul><p>他还特别提到，<strong>Anthropic在AI可解释性方面做得不错</strong>，开发调试器来追踪AI”思维”中的错误非常重要。</p><h2 id="五、SpaceX管理哲学：痛阈、训练集与人才"><a href="#五、SpaceX管理哲学：痛阈、训练集与人才" class="headerlink" title="五、SpaceX管理哲学：痛阈、训练集与人才"></a>五、SpaceX管理哲学：痛阈、训练集与人才</h2><h3 id="面试超过20万人的经验"><a href="#面试超过20万人的经验" class="headerlink" title="面试超过20万人的经验"></a>面试超过20万人的经验</h3><p>马斯克分享了他对技术人才评估的心得：</p><blockquote><p>“不要看简历。要相信你的实际互动。如果交谈了20分钟后你没有感到’惊叹’，那就相信交谈的感受。”</p></blockquote><p>他看重的特质排序：<strong>才能、驱动力、诚信、心地善良</strong>——“基本特质你是无法改变的。”</p><h3 id="“另一半”难题"><a href="#“另一半”难题" class="headerlink" title="“另一半”难题"></a>“另一半”难题</h3><p>马斯克坦言SpaceX在招聘中面临的最大困难：如何说服有家庭的工程师搬到德州的”技术修道院”Starbase。他称之为”另一半”问题。</p><h3 id="高痛阈"><a href="#高痛阈" class="headerlink" title="高痛阈"></a>高痛阈</h3><blockquote><p>“我的痛阈很高。这很有帮助。”</p></blockquote><p>以及他的人生建议：**”为了生活质量，宁可乐观而犯错，也不要悲观而正确。”**</p><h2 id="六、关键信号与未来展望"><a href="#六、关键信号与未来展望" class="headerlink" title="六、关键信号与未来展望"></a>六、关键信号与未来展望</h2><p>这场三小时的访谈释放了多个重要信号：</p><h3 id="🚀-SpaceX或将上市"><a href="#🚀-SpaceX或将上市" class="headerlink" title="🚀 SpaceX或将上市"></a>🚀 SpaceX或将上市</h3><p>虽然马斯克谨慎地表示”不能过度炒作可能上市的公司”，但他暗示<strong>公开市场的可用资本比私募市场多100倍以上</strong>，且SpaceX的资本需求已经超出了私募市场的承受范围。</p><h3 id="🏭-TeraFab：从Gigafactory到Terafactory"><a href="#🏭-TeraFab：从Gigafactory到Terafactory" class="headerlink" title="🏭 TeraFab：从Gigafactory到Terafactory"></a>🏭 TeraFab：从Gigafactory到Terafactory</h3><p>马斯克计划建造”TeraFab”级别的芯片工厂，从原材料到成品全链条掌控。目标是用非常规方式使用常规设备来实现规模化。</p><h3 id="🔋-100吉瓦太阳能产能"><a href="#🔋-100吉瓦太阳能产能" class="headerlink" title="🔋 100吉瓦太阳能产能"></a>🔋 100吉瓦太阳能产能</h3><p>Tesla 和 SpaceX 都有每年100吉瓦太阳能电池产量的目标，且太空版太阳能电池比地面版<strong>更便宜</strong>（不需要玻璃和坚固框架）。</p><h3 id="🤖-纯AI公司将碾压一切"><a href="#🤖-纯AI公司将碾压一切" class="headerlink" title="🤖 纯AI公司将碾压一切"></a>🤖 纯AI公司将碾压一切</h3><p>马斯克的预判尖锐而悲观：完全由AI和机器人构成的公司，<strong>其业绩将远超任何有人类参与的公司</strong>。他用了一个精妙的类比——一栋楼的人类计算员 vs 一台装有电子表格的笔记本。</p><h3 id="📱-SpaceX不做手机"><a href="#📱-SpaceX不做手机" class="headerlink" title="📱 SpaceX不做手机"></a>📱 SpaceX不做手机</h3><p>在播客之外，马斯克亲自否认了路透社关于”SpaceX正在开发手机”的传闻。</p><hr><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>三小时、三杯Guinness、一位正在同时推动太空计算、AI芯片、人形机器人和清洁能源的人。</p><p>无论你是否认同马斯克的每一个判断，有一件事很清楚：当AI行业还在为GPU和电力合同焦头烂额时，马斯克已经把目光投向了太阳。</p><p><strong>而对中国的那番盛赞，或许才是这场对话中最值得玩味的部分</strong> —— 它既是对中国制造业实力的客观认可，也是对美国的一记警钟。在马斯克的叙事中，中国不是威胁，而是一面镜子，照出的是美国在制造业基础上的结构性缺陷。</p><p>赢的方式只有一个：创造性地跳出地球的限制。这，或许才是马斯克所有疯狂计划的底层逻辑。</p><hr><p>📺 <strong>完整播客</strong>：<a href="https://youtu.be/BYXbuik3dgA">YouTube - Dwarkesh Podcast x Elon Musk</a><br>🎙️ <strong>播客平台</strong>：<a href="https://podcasts.apple.com/us/podcast/elon-musk-in-36-months-the-cheapest-place-to-put-ai/id1516093381?i=1000748400389">Apple Podcasts</a> | <a href="https://open.spotify.com/episode/4nah0x1qQF2hxgJnv8PlmN">Spotify</a></p>]]></content>
    
    
    <categories>
      
      <category>深度分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>马斯克</tag>
      
      <tag>SpaceX</tag>
      
      <tag>太空计算</tag>
      
      <tag>中国制造</tag>
      
      <tag>Optimus</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AI时代的巨人困局：当创新成为微软谷歌的抵颈之刃</title>
    <link href="/2026/02/07/ai-giants-dilemma/"/>
    <url>/2026/02/07/ai-giants-dilemma/</url>
    
    <content type="html"><![CDATA[<p><img src="/images/ai-giants-dilemma-cover.png" alt="AI与人类共存的温馨愿景"></p><blockquote><p>“成功企业失败的原因，往往正是因为它们做对了所有事情。” —— 克莱顿·克里斯坦森</p></blockquote><h2 id="创新者的困境：历史的回响"><a href="#创新者的困境：历史的回响" class="headerlink" title="创新者的困境：历史的回响"></a>创新者的困境：历史的回响</h2><p>1997年，哈佛商学院教授克莱顿·克里斯坦森（Clayton Christensen）在《创新者的窘境》中提出了一个令人不安的悖论：<strong>伟大的公司之所以失败，恰恰是因为它们太过优秀</strong>。它们精准地满足现有客户的需求，高效地分配资源，按部就班地改进产品——然而，当颠覆性技术从边缘崛起时，这些曾经的优势反而成为了致命的枷锁。</p><p>克里斯坦森将这种现象归结为”价值网络”的锁定效应。大公司深嵌于由客户、供应商、投资者构成的利益网络中，每一个决策都需要向这个网络负责。当新技术的早期形态无法满足主流市场的需求时，大公司往往选择理性地忽视它——直到为时已晚。</p><p>柯达发明了数码相机却死于数码时代，诺基亚主导了功能机市场却在智能机时代溃败，这些前车之鉴如今正在AI时代重演。而这一次，站在十字路口的是微软和谷歌——两家掌握着AI时代”金钥匙”的巨头。</p><h2 id="谷歌：广告帝国的AI转型之痛"><a href="#谷歌：广告帝国的AI转型之痛" class="headerlink" title="谷歌：广告帝国的AI转型之痛"></a>谷歌：广告帝国的AI转型之痛</h2><p>谷歌是这个时代最成功的广告公司。2025年第一季度，其广告收入高达<strong>668.9亿美元</strong>，搜索业务贡献了其中的绝大部分。按照行业估算，谷歌从每位活跃用户身上获取的年均广告收入约为<strong>400美元</strong>——这是一个令人惊叹的数字，也是一个沉重的包袱。</p><p>问题在于：<strong>AI正在颠覆搜索的底层逻辑</strong>。</p><p>传统搜索的商业模式建立在”信息不对称”之上——用户提问，谷歌返回十个蓝色链接，用户点击，广告主付费。这个模式运转了二十年，养活了整个互联网生态。但当AI能够直接给出答案时，用户还需要点击那些链接吗？</p><p>谷歌的应对策略是”AI Overview”——在搜索结果顶部直接展示AI生成的答案。截至2025年底，这项功能已覆盖超过<strong>20亿用户</strong>。谷歌甚至开始在AI答案中插入广告。但这带来了新的困境：</p><ul><li>如果AI答案太好，用户不再点击链接，广告点击量下降</li><li>如果AI答案不够好，用户转向ChatGPT或Perplexity</li><li>如果AI答案中的广告太多，用户体验下降，信任流失</li></ul><p>2025年第四季度财报后，尽管谷歌交出了亮眼的数字——市值一度突破4万亿美元大关——但市场的质疑声不绝于耳：<strong>谷歌能否在AI时代保持其搜索霸主地位？从以链接为中心的广告模式，如何平稳过渡到AI优先的新范式？</strong></p><p>到目前为止，谷歌还没有给市场一个完美的答案。</p><h2 id="微软：十面埋伏中的求生战"><a href="#微软：十面埋伏中的求生战" class="headerlink" title="微软：十面埋伏中的求生战"></a>微软：十面埋伏中的求生战</h2><p>如果说谷歌面临的是”如何保护现金牛”的问题，那么微软面临的困境更加复杂：<strong>它正在被自己曾经的盟友和模式所反噬</strong>。</p><p>2023年，微软押注OpenAI，将ChatGPT整合进Bing搜索和Office套件，推出Copilot品牌，一度被视为AI时代的先行者。然而两年后的今天，形势已经逆转：</p><p><strong>Claude Code的崛起正在动摇Copilot的根基。</strong> 根据SemiAnalysis最新报告，Claude Code目前已占据GitHub代码提交量的**4%<strong>，预计到2026年底将超过</strong>20%**。这款产品被认为是”AI Agent时代的拐点”——它不仅能写代码，还能理解项目上下文、执行复杂任务、自主完成工作流程。</p><p>这对微软意味着什么？GitHub是微软旗下的平台，GitHub Copilot是微软的AI编程产品，但最受欢迎的AI编程工具却是Anthropic的Claude Code。微软正在自己的地盘上输给竞争对手。</p><p>更糟糕的是，OpenAI也在推出自己的Codex产品，与Copilot形成竞争。微软投资了OpenAI数百亿美元，却无法阻止后者成为自己的竞争对手。这种”合纵连横”的复杂关系，让微软的战略布局充满了不确定性。</p><p>市场已经用脚投票。微软的市盈率从2024年高点的<strong>35倍</strong>左右，一路下滑至目前的<strong>26-28倍</strong>。按照当前约3万亿美元的市值计算，<strong>这意味着近万亿美元的估值蒸发</strong>。</p><p>2026年1月的最新财报显示，Azure云业务增速放缓至37-38%，低于市场预期。股价应声下跌7%。财报收入依然强劲，但市场关心的是：<strong>在AI重构一切的时代，微软的护城河还有多宽？</strong></p><h2 id="大公司的本质困境：无法革自己的命"><a href="#大公司的本质困境：无法革自己的命" class="headerlink" title="大公司的本质困境：无法革自己的命"></a>大公司的本质困境：无法革自己的命</h2><p>为什么这些明明看到了AI浪潮的巨头，依然举步维艰？</p><p>答案藏在克里斯坦森的理论中：**颠覆性创新要求的不仅是技术能力，更是对现有价值网络的”连根拔起”**。</p><p>谷歌要真正拥抱AI，就必须接受搜索广告收入可能下降的现实。但每当财报季来临，华尔街分析师们盯着的是广告收入同比增长了多少，是每用户收入有没有提升。股东们不会允许谷歌”牺牲今天的利润去换取不确定的明天”。</p><p>微软要真正转型为AI公司，就必须接受自己不再是技术的中心，而是平台和基础设施的提供者。但当GitHub上最火的AI工具不是自家的Copilot，当Office的用户开始使用Claude来写文档，当Azure的大客户开始自研AI能力时，微软的管理层该如何向董事会解释这一切？</p><p>这不是能力问题，甚至不是战略问题——<strong>这是结构性问题</strong>。大公司被它们的成功所绑架，被它们的利益相关者所牵制，被它们的组织惯性所拖累。</p><h2 id="技术的异化：从工具到主宰"><a href="#技术的异化：从工具到主宰" class="headerlink" title="技术的异化：从工具到主宰"></a>技术的异化：从工具到主宰</h2><p>让我们把视角拉高一些。</p><p>如果AI的发展方向是正确的——如果AI真的能够在一两年内达到甚至超越人类在大多数认知任务上的能力——那么我们面临的不仅是几家大公司的商业困境，而是整个经济体系的根本性重构。</p><p>Anthropic CEO Dario Amodei曾警告：<strong>AI可能在未来1-5年内消灭一半的入门级白领岗位，导致美国失业率上升至10-20%<strong>。世界经济论坛的报告指出，</strong>41%的雇主计划在2030年前因AI而裁员</strong>。</p><p>这不是遥远的未来，这是正在发生的现实。</p><p>根据马克思的理论，生产工具的进步必然带来生产关系的变革。蒸汽机带来了工厂制度，电力带来了流水线，互联网带来了平台经济。那么AI会带来什么？</p><p>当一个AI Agent可以在几小时内完成一个初级程序员一周的工作量，当Claude Code开始占据GitHub提交量的五分之一，当AI助手可以撰写研究报告、分析财务数据、设计营销方案时——<strong>我们还需要那么多”知识工作者”吗？</strong></p><p>资本和利益正在加速向少数人聚集。AI公司的估值飙升，而传统企业的员工面临失业；技术精英的收入水涨船高，而普通劳动者的议价能力持续下降。生产效率提高了，但财富分配的不平等也在加剧。</p><h2 id="一个更根本的问题"><a href="#一个更根本的问题" class="headerlink" title="一个更根本的问题"></a>一个更根本的问题</h2><p>回到克里斯坦森的框架。他说大公司死于”对现有价值网络的过度忠诚”。但如果整个经济体系都是一个巨大的”价值网络”呢？如果我们所有人——消费者、劳动者、投资者——都被锁定在这个网络中呢？</p><p>AI解决了生产效率的问题，但它还没有解决——甚至可能加剧了——<strong>财富分配和消费循环的问题</strong>。</p><p>生产工具进步了，但生产出来的东西卖给谁？如果AI取代了大量工作岗位，失去收入的人如何消费？如果财富集中在少数AI公司和技术精英手中，庞大的中产阶级市场如何维持？</p><p>这是一个充满挑战和智慧的问题。AI自己如果足够聪明，或许应该先想办法解决这个问题——因为没有消费者，就没有市场；没有市场，AI再强大也无法创造真正的价值。</p><h2 id="结语：在颠覆与被颠覆之间"><a href="#结语：在颠覆与被颠覆之间" class="headerlink" title="结语：在颠覆与被颠覆之间"></a>结语：在颠覆与被颠覆之间</h2><p>2025年是AI能力爆发的一年。越来越多的人开始相信AI不是泡沫，它是真实的、正在发生的技术革命。</p><p>但这不代表那些大公司不是泡沫。它们拖着庞大的躯体追赶前沿，而前沿的企业——Anthropic、OpenAI、还有无数创业公司——尚未证明自己的盈利模式。</p><p>市场还有多少耐心？</p><p>或者说，市场最终会被驯服吗？</p><p>也许AI会成为新的基础设施，像电力和互联网一样，不以盈利为目的，而是作为一切经济活动的底层支撑。也许人类会找到新的财富分配方式，让AI的生产力惠及所有人。也许碳基生命会与硅基智能达成某种共生关系，而不是被后者取代。</p><p>但这些”也许”都需要我们去争取，去构建，去实现。</p><p>在此之前，谷歌和微软们将继续在颠覆与被颠覆之间挣扎。它们的困境，也是我们所有人的困境。</p><hr><p><em>本文引用了克莱顿·克里斯坦森的《创新者的窘境》理论、SemiAnalysis关于Claude Code的市场分析、以及多家机构对AI就业影响的研究报告。</em></p>]]></content>
    
    
    <categories>
      
      <category>深度分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>科技</tag>
      
      <tag>微软</tag>
      
      <tag>商业</tag>
      
      <tag>创新</tag>
      
      <tag>谷歌</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Claude Opus 4.6 vs GPT-5.3-Codex：2026年AI编程双雄同日对决</title>
    <link href="/2026/02/06/claude-opus-4-6-vs-gpt-5-3-codex/"/>
    <url>/2026/02/06/claude-opus-4-6-vs-gpt-5-3-codex/</url>
    
    <content type="html"><![CDATA[<blockquote><p>2026年2月5日，Anthropic与OpenAI同日发布新一代旗舰模型，AI编程领域迎来史诗级对决。</p></blockquote><hr><h2 id="📅-发布概览"><a href="#📅-发布概览" class="headerlink" title="📅 发布概览"></a>📅 发布概览</h2><table><thead><tr><th>项目</th><th>Claude Opus 4.6</th><th>GPT-5.3-Codex</th></tr></thead><tbody><tr><td><strong>发布日期</strong></td><td>2026年2月5日</td><td>2026年2月5日</td></tr><tr><td><strong>开发商</strong></td><td>Anthropic</td><td>OpenAI</td></tr><tr><td><strong>定位</strong></td><td>旗舰级知识工作与编程模型</td><td>顶级智能编程代理</td></tr><tr><td><strong>上下文窗口</strong></td><td>200K 标准 &#x2F; <strong>100万 Beta</strong></td><td>未公布（沿用前代）</td></tr><tr><td><strong>最大输出</strong></td><td><strong>128K tokens</strong></td><td>未公布</td></tr><tr><td><strong>推理速度</strong></td><td>未公布</td><td>比前代快25%</td></tr></tbody></table><p>两家同时发布，简直是AI界的”神仙打架”。</p><span id="more"></span><hr><h2 id="🔥-Claude-Opus-4-6-亮点"><a href="#🔥-Claude-Opus-4-6-亮点" class="headerlink" title="🔥 Claude Opus 4.6 亮点"></a>🔥 Claude Opus 4.6 亮点</h2><h3 id="1-100万Token上下文窗口（Beta）"><a href="#1-100万Token上下文窗口（Beta）" class="headerlink" title="1. 100万Token上下文窗口（Beta）"></a>1. 100万Token上下文窗口（Beta）</h3><p>这是Opus系列首个支持超长上下文的模型：</p><ul><li>可处理约<strong>1,500页文本</strong></li><li>或<strong>30,000行代码</strong></li><li>或<strong>1小时以上视频</strong></li></ul><p>在 MRCR v2 长文档检索测试中：</p><ul><li>256K 上下文：93% 准确率</li><li>1M 上下文：76% 准确率</li><li>比 Sonnet 4.5 提升 <strong>4-9倍</strong></li></ul><h3 id="2-自适应思考（Adaptive-Thinking）"><a href="#2-自适应思考（Adaptive-Thinking）" class="headerlink" title="2. 自适应思考（Adaptive Thinking）"></a>2. 自适应思考（Adaptive Thinking）</h3><p>取代旧版 Extended Thinking，四档努力级别：</p><ul><li><strong>low</strong> - 跳过思考，适合简单任务</li><li><strong>medium</strong> - 适度推理，速度与质量平衡</li><li><strong>high</strong>（默认）- 大多数生产环境推荐</li><li><strong>max</strong> - 最高能力，适合最难问题（Opus 4.6 新增）</li></ul><h3 id="3-Agent-Teams（智能体团队）"><a href="#3-Agent-Teams（智能体团队）" class="headerlink" title="3. Agent Teams（智能体团队）"></a>3. Agent Teams（智能体团队）</h3><p>Claude Code 现支持多代理并行协作：</p><ul><li>一个代理处理前端</li><li>一个代理处理后端</li><li>一个代理管理测试</li><li>全部在监督控制下同时工作</li></ul><h3 id="4-Claude-in-PowerPoint（研究预览）"><a href="#4-Claude-in-PowerPoint（研究预览）" class="headerlink" title="4. Claude in PowerPoint（研究预览）"></a>4. Claude in PowerPoint（研究预览）</h3><p>直接在 Microsoft PowerPoint 中工作：</p><ul><li>理解版式、字体、母版</li><li>保持品牌一致性</li><li>从描述生成完整演示文稿</li></ul><h3 id="5-Compaction-API（Beta）"><a href="#5-Compaction-API（Beta）" class="headerlink" title="5. Compaction API（Beta）"></a>5. Compaction API（Beta）</h3><p>服务端上下文压缩，实现<strong>无限对话</strong>：</p><ul><li>自动总结旧对话内容</li><li>无需手动管理上下文</li><li>对长链路代理工作流特别有用</li></ul><hr><h2 id="🚀-GPT-5-3-Codex-亮点"><a href="#🚀-GPT-5-3-Codex-亮点" class="headerlink" title="🚀 GPT-5.3-Codex 亮点"></a>🚀 GPT-5.3-Codex 亮点</h2><h3 id="1-统一旗舰架构"><a href="#1-统一旗舰架构" class="headerlink" title="1. 统一旗舰架构"></a>1. 统一旗舰架构</h3><p>融合了：</p><ul><li>GPT-5.2-Codex 的<strong>编程能力</strong></li><li>GPT-5.2 的<strong>推理与专业知识</strong></li></ul><p>单一模型完成所有工作，无需切换。</p><h3 id="2-25-速度提升"><a href="#2-25-速度提升" class="headerlink" title="2. 25%速度提升"></a>2. 25%速度提升</h3><p>基础设施和推理优化带来显著提速，而且<strong>更少的token消耗</strong>就能达成同等效果。</p><h3 id="3-自我参与开发"><a href="#3-自我参与开发" class="headerlink" title="3. 自我参与开发"></a>3. 自我参与开发</h3><p>这是首个”参与自身创建”的 Codex 模型：</p><ul><li>用于调试训练过程</li><li>管理部署</li><li>诊断测试结果</li><li>构建数据管道和可视化工具</li></ul><h3 id="4-高级网络安全能力"><a href="#4-高级网络安全能力" class="headerlink" title="4. 高级网络安全能力"></a>4. 高级网络安全能力</h3><ul><li>OpenAI Preparedness Framework 下<strong>首个”高能力”网络安全模型</strong></li><li>首个直接训练识别软件漏洞的模型</li><li>已发现<strong>500+开源项目零日漏洞</strong></li><li>推出 Trusted Access for Cyber 试点</li><li>$1000万 API 积分投入开源安全防护</li></ul><hr><h2 id="📊-基准测试对比（官方数据）"><a href="#📊-基准测试对比（官方数据）" class="headerlink" title="📊 基准测试对比（官方数据）"></a>📊 基准测试对比（官方数据）</h2><h3 id="编程与代理能力"><a href="#编程与代理能力" class="headerlink" title="编程与代理能力"></a>编程与代理能力</h3><table><thead><tr><th>基准测试</th><th>Claude Opus 4.6</th><th>GPT-5.3-Codex</th><th>GPT-5.2</th><th>Gemini 3 Pro</th></tr></thead><tbody><tr><td><strong>SWE-bench Verified</strong></td><td><strong>80.8%</strong></td><td>56.8%*</td><td>80.0%</td><td>76.2%</td></tr><tr><td><strong>Terminal-Bench 2.0</strong></td><td>65.4%</td><td><strong>77.3%</strong></td><td>64.7%</td><td>56.2%</td></tr><tr><td><strong>OSWorld</strong></td><td><strong>72.7%</strong></td><td>64.7%</td><td>—</td><td>—</td></tr><tr><td><strong>SWE-Bench Pro</strong></td><td>—</td><td><strong>56.8%</strong></td><td>56.4%</td><td>—</td></tr></tbody></table><p>*注：GPT-5.3-Codex 使用的是 SWE-Bench Pro（不同版本），非 Verified</p><h3 id="推理与知识能力"><a href="#推理与知识能力" class="headerlink" title="推理与知识能力"></a>推理与知识能力</h3><table><thead><tr><th>基准测试</th><th>Claude Opus 4.6</th><th>GPT-5.2</th><th>Gemini 3 Pro</th></tr></thead><tbody><tr><td><strong>GDPval-AA Elo</strong></td><td><strong>1606</strong></td><td>1462</td><td>1195</td></tr><tr><td><strong>GPQA Diamond</strong></td><td>91.3%</td><td><strong>93.2%</strong></td><td>91.9%</td></tr><tr><td><strong>ARC AGI 2</strong></td><td><strong>68.8%</strong></td><td>54.2%</td><td>45.1%</td></tr><tr><td><strong>HLE (with tools)</strong></td><td><strong>53.1%</strong></td><td>50.0%</td><td>45.8%</td></tr><tr><td><strong>MMMLU</strong></td><td>91.1%</td><td>89.6%</td><td><strong>91.8%</strong></td></tr></tbody></table><h3 id="代理与工具使用"><a href="#代理与工具使用" class="headerlink" title="代理与工具使用"></a>代理与工具使用</h3><table><thead><tr><th>基准测试</th><th>Claude Opus 4.6</th><th>GPT-5.2</th><th>Gemini 3 Pro</th></tr></thead><tbody><tr><td><strong>BrowseComp</strong></td><td><strong>84.0%</strong></td><td>77.9%</td><td>59.2%</td></tr><tr><td><strong>Finance Agent</strong></td><td><strong>60.7%</strong></td><td>56.6%</td><td>44.1%</td></tr><tr><td><strong>τ2-bench Retail</strong></td><td><strong>91.9%</strong></td><td>82.0%</td><td>—</td></tr><tr><td><strong>τ2-bench Telecom</strong></td><td><strong>99.3%</strong></td><td>—</td><td>—</td></tr></tbody></table><h3 id="GPT-5-3-Codex-相对-GPT-5-2-Codex-提升"><a href="#GPT-5-3-Codex-相对-GPT-5-2-Codex-提升" class="headerlink" title="GPT-5.3-Codex 相对 GPT-5.2-Codex 提升"></a>GPT-5.3-Codex 相对 GPT-5.2-Codex 提升</h3><table><thead><tr><th>基准测试</th><th>提升幅度</th></tr></thead><tbody><tr><td><strong>OSWorld-Verified</strong></td><td><strong>+26.5</strong></td></tr><tr><td><strong>Terminal-Bench 2.0</strong></td><td><strong>+13.3</strong></td></tr><tr><td>网络安全 CTF</td><td>+10.2</td></tr><tr><td>SWE-Lancer IC Diamond</td><td>+5.4</td></tr><tr><td>SWE-Bench Pro</td><td>+0.4</td></tr></tbody></table><hr><h2 id="🎯-综合能力对比"><a href="#🎯-综合能力对比" class="headerlink" title="🎯 综合能力对比"></a>🎯 综合能力对比</h2><table><thead><tr><th>维度</th><th>Claude Opus 4.6</th><th>GPT-5.3-Codex</th></tr></thead><tbody><tr><td><strong>上下文长度</strong></td><td>⭐⭐⭐⭐⭐ (100万 Beta)</td><td>⭐⭐⭐⭐</td></tr><tr><td><strong>SWE-bench 编程</strong></td><td>⭐⭐⭐⭐⭐ (80.8%)</td><td>⭐⭐⭐⭐</td></tr><tr><td><strong>终端能力</strong></td><td>⭐⭐⭐⭐ (65.4%)</td><td>⭐⭐⭐⭐⭐ (77.3%)</td></tr><tr><td><strong>计算机使用</strong></td><td>⭐⭐⭐⭐⭐ (72.7%)</td><td>⭐⭐⭐⭐ (64.7%)</td></tr><tr><td><strong>推理速度</strong></td><td>⭐⭐⭐⭐</td><td>⭐⭐⭐⭐⭐ (+25%)</td></tr><tr><td><strong>知识工作</strong></td><td>⭐⭐⭐⭐⭐ (1606 Elo)</td><td>⭐⭐⭐⭐</td></tr><tr><td><strong>网络安全</strong></td><td>⭐⭐⭐⭐</td><td>⭐⭐⭐⭐⭐</td></tr><tr><td><strong>多代理协作</strong></td><td>⭐⭐⭐⭐⭐</td><td>⭐⭐⭐⭐</td></tr></tbody></table><hr><h2 id="🎮-怎么选？"><a href="#🎮-怎么选？" class="headerlink" title="🎮 怎么选？"></a>🎮 怎么选？</h2><h3 id="选择-Claude-Opus-4-6"><a href="#选择-Claude-Opus-4-6" class="headerlink" title="选择 Claude Opus 4.6"></a>选择 Claude Opus 4.6</h3><ul><li>✅ 需要处理超长文档（100万 token 上下文）</li><li>✅ SWE-bench 类型的真实 GitHub Issue 修复（80.8%）</li><li>✅ 团队协作型 AI 代理工作流（Agent Teams）</li><li>✅ PowerPoint&#x2F;Office 办公场景深度集成</li><li>✅ 知识密集型工作（GDPval-AA 领先）</li><li>✅ 代理搜索与研究（BrowseComp 84%）</li></ul><h3 id="选择-GPT-5-3-Codex"><a href="#选择-GPT-5-3-Codex" class="headerlink" title="选择 GPT-5.3-Codex"></a>选择 GPT-5.3-Codex</h3><ul><li>✅ 高强度终端&#x2F;命令行操作（Terminal-Bench 77.3%）</li><li>✅ 网络安全研究与漏洞挖掘</li><li>✅ 追求极致推理速度（+25%）</li><li>✅ 长周期、多步骤的编程项目</li><li>✅ 需要模型”自我调试”能力</li></ul><hr><h2 id="💰-定价与可用性"><a href="#💰-定价与可用性" class="headerlink" title="💰 定价与可用性"></a>💰 定价与可用性</h2><table><thead><tr><th>渠道</th><th>Claude Opus 4.6</th><th>GPT-5.3-Codex</th></tr></thead><tbody><tr><td><strong>API 定价</strong></td><td>$5&#x2F;$25 per MTok（输入&#x2F;输出）</td><td>待公布</td></tr><tr><td><strong>长上下文溢价</strong></td><td>$10&#x2F;$37.50 per MTok (&gt;200K)</td><td>—</td></tr><tr><td><strong>消费者端</strong></td><td>Claude Pro&#x2F;Team&#x2F;Enterprise</td><td>ChatGPT Plus 付费版</td></tr><tr><td><strong>开发者 API</strong></td><td>立即可用</td><td>即将推出（数周内）</td></tr><tr><td><strong>IDE 集成</strong></td><td>Claude Code</td><td>Codex（App&#x2F;CLI&#x2F;IDE插件&#x2F;Web）</td></tr><tr><td><strong>GitHub Copilot</strong></td><td>✅ 已集成</td><td>预计后续集成</td></tr><tr><td><strong>云平台</strong></td><td>AWS Bedrock, Vertex AI, Azure</td><td>—</td></tr></tbody></table><hr><h2 id="🔒-安全特性"><a href="#🔒-安全特性" class="headerlink" title="🔒 安全特性"></a>🔒 安全特性</h2><h3 id="Claude-Opus-4-6"><a href="#Claude-Opus-4-6" class="headerlink" title="Claude Opus 4.6"></a>Claude Opus 4.6</h3><ul><li><strong>最低错误对齐分数</strong>：约1.8&#x2F;10（所有 Claude 模型中最低）</li><li><strong>最低过度拒绝率</strong>：合理请求更少被拒绝</li><li><strong>数据驻留控制</strong>：<code>inference_geo</code> 参数指定推理区域</li></ul><h3 id="GPT-5-3-Codex"><a href="#GPT-5-3-Codex" class="headerlink" title="GPT-5.3-Codex"></a>GPT-5.3-Codex</h3><ul><li><strong>首个”高能力”网络安全模型</strong></li><li>Trusted Access for Cyber 试点项目</li><li>Aardvark 安全研究代理扩展测试</li><li>为 Next.js 等开源项目提供免费代码扫描</li></ul><hr><h2 id="💡-结语"><a href="#💡-结语" class="headerlink" title="💡 结语"></a>💡 结语</h2><p>2026年2月5日将被铭记为AI编程领域的里程碑日——两大巨头同日亮剑，各有千秋：</p><table><thead><tr><th>领先领域</th><th>Claude Opus 4.6</th><th>GPT-5.3-Codex</th></tr></thead><tbody><tr><td><strong>最强项</strong></td><td>SWE-bench (80.8%), 上下文 (1M), 知识工作 (1606 Elo)</td><td>Terminal-Bench (77.3%), 速度 (+25%), 网络安全</td></tr></tbody></table><p><strong>总结</strong>：</p><ul><li><strong>选 Claude Opus 4.6</strong>：你需要处理大型代码库、长文档、真实 GitHub Issue，或者重视知识工作能力</li><li><strong>选 GPT-5.3-Codex</strong>：你主要在终端环境工作、追求速度、或需要网络安全能力</li></ul><p>对于开发者而言，这是一个前所未有的好时代——两款顶尖模型竞相进化，最终受益的是整个技术社区。</p><hr><p><em>本文基于2026年2月5日官方发布数据撰写</em></p><p><strong>数据来源</strong>：</p><ul><li><a href="https://anthropic.com/">Anthropic Claude Opus 4.6 发布</a></li><li><a href="https://openai.com/index/introducing-gpt-5-3-codex/">OpenAI GPT-5.3-Codex 发布</a></li><li><a href="https://www.digitalapplied.com/">DigitalApplied 基准测试汇总</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>AI 前沿</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>GPT</tag>
      
      <tag>Claude</tag>
      
      <tag>编程</tag>
      
      <tag>对比评测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>OpenAI 发布 Codex 桌面应用：让你同时指挥多个 AI 写代码</title>
    <link href="/2026/02/06/codex-desktop/"/>
    <url>/2026/02/06/codex-desktop/</url>
    
    <content type="html"><![CDATA[<p>你还在一个一个地给 AI 下指令？</p><p>OpenAI 刚发布的 Codex 桌面应用告诉你：<strong>是时候学会「同时指挥一群 AI」了</strong>。</p><h2 id="这是什么？"><a href="#这是什么？" class="headerlink" title="这是什么？"></a>这是什么？</h2><p>Codex 桌面应用是 OpenAI 为 macOS 打造的「AI 编程指挥中心」。</p><p>以前用 Codex，你得在命令行里敲命令，一次处理一个任务。现在？打开这个 App，你可以：</p><ul><li><strong>同时开多个 AI 线程</strong>，让它们并行干活</li><li><strong>随时切换任务</strong>，不丢上下文</li><li><strong>设置自动化任务</strong>，让 AI 在后台定时工作</li><li><strong>用技能扩展 AI 能力</strong>，不只是写代码</li></ul><p>用 OpenAI 的话说：这是一个「智能体指挥中心」（Command Center for Agents）。</p><h2 id="为什么需要桌面应用？"><a href="#为什么需要桌面应用？" class="headerlink" title="为什么需要桌面应用？"></a>为什么需要桌面应用？</h2><p>Sam Altman 在发布会上说了一句话：</p><blockquote><p>「我们意识到，现有的 IDE 和终端工具，根本不是为这种工作方式设计的。」</p></blockquote><p>以前的 AI 编程助手，本质上还是「你问一句，它答一句」。但现在的 Codex 已经能独立完成复杂的长任务——写一个完整的游戏、重构整个模块、跑测试然后自己修 bug。</p><p>当 AI 能做的事变多了，瓶颈就从「AI 能不能做」变成了「人怎么管理这些 AI」。</p><p>桌面应用就是为了解决这个问题。</p><h2 id="核心功能"><a href="#核心功能" class="headerlink" title="核心功能"></a>核心功能</h2><h3 id="1-多线程并行工作"><a href="#1-多线程并行工作" class="headerlink" title="1. 多线程并行工作"></a>1. 多线程并行工作</h3><p>每个任务跑在独立的线程里，你可以像切换浏览器标签页一样切换任务。</p><p>比如：</p><ul><li>线程 1：让 Codex 重构用户认证模块</li><li>线程 2：让 Codex 写单元测试</li><li>线程 3：让 Codex 修一个紧急 bug</li></ul><p>三个任务同时跑，互不干扰。</p><h3 id="2-Git-Worktree-支持"><a href="#2-Git-Worktree-支持" class="headerlink" title="2. Git Worktree 支持"></a>2. Git Worktree 支持</h3><p>这是个关键特性。</p><p>多个 AI 在同一个代码仓库里干活，很容易冲突。Codex 内置了 Git Worktree 支持，每个智能体在自己的代码副本上工作，改完再合并。</p><p>你不用担心它们互相踩脚。</p><h3 id="3-技能系统（Skills）"><a href="#3-技能系统（Skills）" class="headerlink" title="3. 技能系统（Skills）"></a>3. 技能系统（Skills）</h3><p>Codex 不只是写代码的工具，它可以通过「技能」扩展能力：</p><ul><li><strong>Figma 技能</strong>：直接从设计稿生成前端代码，1:1 还原</li><li><strong>Linear 技能</strong>：管理项目、分类 bug、追踪发版</li><li><strong>部署技能</strong>：一键部署到 Cloudflare、Vercel、Netlify</li><li><strong>图片生成技能</strong>：用 GPT Image 生成游戏素材、UI 图片</li><li><strong>文档技能</strong>：读写 PDF、Excel、Word 文件</li></ul><p>OpenAI 官方提供了一批技能，你也可以自己写。技能一旦创建，在 App、CLI、IDE 插件里都能用。</p><h3 id="4-自动化调度（Automations）"><a href="#4-自动化调度（Automations）" class="headerlink" title="4. 自动化调度（Automations）"></a>4. 自动化调度（Automations）</h3><p>设定一个时间表，让 Codex 在后台自动运行。</p><p>比如：</p><ul><li>每天早上 9 点，自动扫描代码库里的 TODO 并生成报告</li><li>每次有新 issue，自动分类和打标签</li><li>每周五，自动生成本周代码变更摘要</li></ul><p>任务完成后，结果进入「待审核」队列，你有空再看。</p><h3 id="5-两种人格可选"><a href="#5-两种人格可选" class="headerlink" title="5. 两种人格可选"></a>5. 两种人格可选</h3><p>有人喜欢 AI 话少、直接干活；有人喜欢 AI 多解释、有互动感。</p><p>Codex 现在支持两种人格：</p><ul><li><strong>简洁务实型</strong>：少废话，直接给代码</li><li><strong>对话共情型</strong>：多解释，像个搭档</li></ul><p>用 <code>/personality</code> 命令切换。</p><h2 id="安全机制"><a href="#安全机制" class="headerlink" title="安全机制"></a>安全机制</h2><p>AI 在你电脑上跑代码，安全是大问题。</p><p>Codex 默认运行在<strong>沙箱</strong>里：</p><ul><li>只能编辑当前项目文件夹</li><li>网络访问需要你授权</li><li>敏感命令（如删除文件）会先问你</li></ul><p>你也可以配置规则，让某些命令自动获得权限。</p><h2 id="谁能用？"><a href="#谁能用？" class="headerlink" title="谁能用？"></a>谁能用？</h2><ul><li><strong>ChatGPT Plus &#x2F; Pro &#x2F; Business &#x2F; Enterprise &#x2F; Edu 用户</strong>：直接用</li><li><strong>ChatGPT Free 和 Go 用户</strong>：限时免费体验</li><li>所有付费用户：限时双倍请求额度</li></ul><p>目前只有 macOS 版，Windows 版在路上。</p><h2 id="实际案例：让-Codex-做一个赛车游戏"><a href="#实际案例：让-Codex-做一个赛车游戏" class="headerlink" title="实际案例：让 Codex 做一个赛车游戏"></a>实际案例：让 Codex 做一个赛车游戏</h2><p>OpenAI 在发布会上演示了一个例子：</p><blockquote><p>「做一个赛车游戏，包含不同的赛车手、8 张地图、还有道具系统。」</p></blockquote><p>就这一句话。</p><p>Codex 调用了图片生成技能和网页游戏开发技能，<strong>自己当设计师、开发者、测试员</strong>，用了超过 700 万 token，最终交付了一个可玩的游戏。</p><p>它甚至会自己玩游戏来测试 bug。</p><h2 id="和-Claude-Code-的对比"><a href="#和-Claude-Code-的对比" class="headerlink" title="和 Claude Code 的对比"></a>和 Claude Code 的对比</h2><p>Anthropic 的 Claude Code 也很火，两者有什么区别？</p><table><thead><tr><th>特性</th><th>Codex 桌面应用</th><th>Claude Code</th></tr></thead><tbody><tr><td>界面</td><td>原生桌面应用</td><td>终端 + Cowork</td></tr><tr><td>多任务</td><td>内置多线程管理</td><td>需手动开多个终端</td></tr><tr><td>技能扩展</td><td>官方技能库 + 自定义</td><td>MCP 协议</td></tr><tr><td>自动化</td><td>内置调度系统</td><td>需外部配合</td></tr><tr><td>适合</td><td>管理多个并行任务</td><td>深度单任务处理</td></tr></tbody></table><p>简单说：<strong>Claude Code 更像「深度搭档」，Codex App 更像「任务调度中心」</strong>。</p><h2 id="未来方向"><a href="#未来方向" class="headerlink" title="未来方向"></a>未来方向</h2><p>OpenAI 透露了几个计划：</p><ol><li><strong>Windows 版本</strong>：正在开发</li><li><strong>云端自动化</strong>：让 Codex 在云上持续运行，不依赖你的电脑开机</li><li><strong>更快的推理</strong>：继续优化速度</li><li><strong>更强的模型</strong>：GPT-5.2-Codex 已经让使用量翻倍，未来还会继续迭代</li></ol><h2 id="怎么开始？"><a href="#怎么开始？" class="headerlink" title="怎么开始？"></a>怎么开始？</h2><ol><li>确保你有 ChatGPT 订阅（免费用户限时也能用）</li><li>下载 macOS 版：<a href="https://openai.com/codex">openai.com&#x2F;codex</a></li><li>用 ChatGPT 账号登录</li><li>指向你的代码仓库，开始干活</li></ol><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>Sam Altman 说了一句很有意思的话：</p><blockquote><p>「我认为这将很快成为大多数专业程序员工作的方式。」</p></blockquote><p>从「写代码」到「指挥 AI 写代码」，编程正在经历一次范式转移。</p><p>Codex 桌面应用不是给 AI 加了个好看的外壳，而是承认了一个事实：<strong>当 AI 足够强，人的角色就变成了「指挥官」</strong>。</p><p>你准备好指挥你的 AI 军团了吗？</p><hr><p><strong>相关链接：</strong></p><ul><li><a href="https://openai.com/index/introducing-the-codex-app/">OpenAI 官方介绍</a></li><li><a href="https://developers.openai.com/codex/app/">开发者文档</a></li><li><a href="https://github.com/openai/skills">技能仓库</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>OpenAI</tag>
      
      <tag>Codex</tag>
      
      <tag>编程工具</tag>
      
      <tag>macOS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>微软开源 Agent Lightning：让 AI 智能体自己学会变强</title>
    <link href="/2026/02/06/agent-lightning/"/>
    <url>/2026/02/06/agent-lightning/</url>
    
    <content type="html"><![CDATA[<p>你有没有想过，为什么 AI 智能体明明「懂很多」，实际干活却经常犯蠢？</p><p>问题出在：<strong>大模型的通用能力和特定任务的执行能力是两回事</strong>。</p><p>ChatGPT 能写诗、能算数、能写代码，但你让它帮你订机票、查数据库、操作 API，它就开始「抽风」了——幻觉、死循环、工具调用出错……</p><p>怎么让智能体「干一行，精一行」？</p><p>微软亚洲研究院给出了答案：<strong>Agent Lightning</strong>。</p><h2 id="这玩意儿是干嘛的？"><a href="#这玩意儿是干嘛的？" class="headerlink" title="这玩意儿是干嘛的？"></a>这玩意儿是干嘛的？</h2><p>一句话：<strong>让任意 AI 智能体通过强化学习自我进化，几乎不用改代码</strong>。</p><p>传统的强化学习（RL）训练 AI，需要大量的框架适配、数据工程、奖励函数设计。对于已有的智能体项目，想接入 RL 几乎等于重写。</p><p>Agent Lightning 的核心理念是<strong>把智能体的执行和模型的训练彻底解耦</strong>。</p><p>你的智能体照常跑，该调 API 调 API，该查数据库查数据库。Agent Lightning 在旁边默默「录像」，记录每一步操作和结果，然后用这些数据来训练底层模型。</p><p><strong>你不用改代码，智能体自动变强。</strong></p><h2 id="怎么用？"><a href="#怎么用？" class="headerlink" title="怎么用？"></a>怎么用？</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install agentlightning<br></code></pre></td></tr></table></figure><h3 id="最简示例"><a href="#最简示例" class="headerlink" title="最简示例"></a>最简示例</h3><p>假设你有一个用 OpenAI SDK 写的简单智能体：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI<br>client = OpenAI()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">my_agent</span>(<span class="hljs-params">question</span>):<br>    response = client.chat.completions.create(<br>        model=<span class="hljs-string">&quot;gpt-4o&quot;</span>,<br>        messages=[&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: question&#125;]<br>    )<br>    <span class="hljs-keyword">return</span> response.choices[<span class="hljs-number">0</span>].message.content<br></code></pre></td></tr></table></figure><p>接入 Agent Lightning，只需要加几行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> agentlightning <span class="hljs-keyword">as</span> agl<br><br><span class="hljs-comment"># 初始化 tracer</span><br>tracer = agl.Tracer()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">my_agent</span>(<span class="hljs-params">question</span>):<br>    <span class="hljs-keyword">with</span> tracer.span(<span class="hljs-string">&quot;agent_call&quot;</span>):  <span class="hljs-comment"># 记录这次调用</span><br>        response = client.chat.completions.create(<br>            model=<span class="hljs-string">&quot;gpt-4o&quot;</span>,<br>            messages=[&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: question&#125;]<br>        )<br>        answer = response.choices[<span class="hljs-number">0</span>].message.content<br>        <br>        <span class="hljs-comment"># 告诉 Agent Lightning 这次的奖励（对不对、好不好）</span><br>        agl.emit_reward(score=evaluate(answer))<br>        <br>        <span class="hljs-keyword">return</span> answer<br></code></pre></td></tr></table></figure><p>然后启动训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> agentlightning <span class="hljs-keyword">import</span> Trainer<br><br>trainer = Trainer(<br>    algorithm=<span class="hljs-string">&quot;grpo&quot;</span>,  <span class="hljs-comment"># 强化学习算法</span><br>    store=tracer.store,<br>)<br>trainer.fit()<br></code></pre></td></tr></table></figure><p>就这么简单。智能体每跑一次任务，Agent Lightning 就收集一次数据；数据攒够了，自动训练一轮；训练完，模型权重自动更新。</p><p><strong>你的智能体在实战中越来越强。</strong></p><h2 id="支持哪些框架？"><a href="#支持哪些框架？" class="headerlink" title="支持哪些框架？"></a>支持哪些框架？</h2><p>几乎所有主流框架都支持：</p><ul><li><strong>LangChain</strong> — 最流行的 LLM 应用框架</li><li><strong>OpenAI Agent SDK</strong> — OpenAI 官方的智能体开发包</li><li><strong>AutoGen</strong> — 微软的多智能体对话框架</li><li><strong>CrewAI</strong> — 多智能体协作框架</li><li><strong>Microsoft Agent Framework</strong> — 微软企业级框架</li><li><strong>纯 Python + OpenAI API</strong> — 不用任何框架也行</li></ul><p>甚至多智能体系统也能用。你可以<strong>选择性地只优化其中一个或几个智能体</strong>，其他的保持不变。</p><h2 id="核心架构"><a href="#核心架构" class="headerlink" title="核心架构"></a>核心架构</h2><p>Agent Lightning 的设计非常优雅，分成三层：</p><h3 id="1-Tracer（追踪器）"><a href="#1-Tracer（追踪器）" class="headerlink" title="1. Tracer（追踪器）"></a>1. Tracer（追踪器）</h3><p>在你的智能体代码里埋点，记录：</p><ul><li>每次 LLM 调用的 prompt 和 response</li><li>工具调用的输入输出</li><li>最终的奖励信号（任务成功&#x2F;失败、得分高低）</li></ul><p>这些数据被组织成「span」（事件片段），流入中央存储。</p><h3 id="2-LightningStore（闪电仓库）"><a href="#2-LightningStore（闪电仓库）" class="headerlink" title="2. LightningStore（闪电仓库）"></a>2. LightningStore（闪电仓库）</h3><p>一个中央数据库，同步所有的：</p><ul><li>任务信息</li><li>执行轨迹</li><li>模型资源（权重、prompt 模板）</li></ul><p>训练器和智能体都从这里读写数据，彼此解耦。</p><h3 id="3-Algorithm-Trainer（算法-训练器）"><a href="#3-Algorithm-Trainer（算法-训练器）" class="headerlink" title="3. Algorithm + Trainer（算法 + 训练器）"></a>3. Algorithm + Trainer（算法 + 训练器）</h3><p>支持多种优化算法：</p><ul><li><strong>GRPO</strong>（Group Relative Policy Optimization）— 组相对策略优化，适合奖励稀疏的场景</li><li><strong>PPO</strong>（Proximal Policy Optimization）— 经典强化学习算法</li><li><strong>Automatic Prompt Optimization</strong> — 自动优化 prompt 模板</li><li><strong>Supervised Fine-tuning</strong> — 监督微调</li></ul><p>你也可以自己写算法插进去。</p><h2 id="实际效果怎么样？"><a href="#实际效果怎么样？" class="headerlink" title="实际效果怎么样？"></a>实际效果怎么样？</h2><p>微软在多个任务上做了测试：</p><h3 id="SQL-生成任务"><a href="#SQL-生成任务" class="headerlink" title="SQL 生成任务"></a>SQL 生成任务</h3><p>让智能体根据自然语言生成 SQL 查询。经过 Agent Lightning 训练后：</p><ul><li>执行正确率提升 <strong>15-20%</strong></li><li>幻觉（编造不存在的表&#x2F;字段）大幅减少</li></ul><h3 id="数学工具调用"><a href="#数学工具调用" class="headerlink" title="数学工具调用"></a>数学工具调用</h3><p>让智能体用计算器、绘图工具解决数学问题：</p><ul><li>工具调用成功率提升 <strong>25%</strong></li><li>多步推理的稳定性显著改善</li></ul><h3 id="多智能体协作"><a href="#多智能体协作" class="headerlink" title="多智能体协作"></a>多智能体协作</h3><p>在狼人杀游戏中训练多个 AI 玩家：</p><ul><li>经过几轮训练，AI 学会了「演戏」和「试探」</li><li>胜率从随机水平提升到接近人类玩家</li></ul><h2 id="为什么这个方法管用？"><a href="#为什么这个方法管用？" class="headerlink" title="为什么这个方法管用？"></a>为什么这个方法管用？</h2><p>传统的智能体优化有两个大坑：</p><p><strong>坑 1：数据采集太难</strong></p><p>智能体的执行轨迹是多步的、带分支的、有工具调用的。传统方法需要你手动设计数据格式，非常痛苦。</p><p>Agent Lightning 的 tracer 自动搞定这一切。</p><p><strong>坑 2：训练和执行耦合太紧</strong></p><p>很多 RL 框架要求你把智能体写成它规定的格式，迁移成本极高。</p><p>Agent Lightning 完全不管你的智能体怎么写，它只负责「录像」和「训练」，两边完全独立。</p><p>用官方的话说：<strong>No rewrites, no lock-in, just a clear path from first rollout to steady improvement.</strong></p><h2 id="社区项目"><a href="#社区项目" class="headerlink" title="社区项目"></a>社区项目</h2><p>已经有不少团队在用 Agent Lightning 做有意思的事：</p><ul><li><strong>DeepWerewolf</strong> — 用强化学习训练狼人杀 AI</li><li><strong>AgentFlow</strong> — 斯坦福的多智能体框架，结合 Agent Lightning 处理长链路任务</li><li><strong>Youtu-Agent</strong> — 腾讯优图团队的智能体训练方案，已验证 128 GPU 稳定收敛</li></ul><h2 id="怎么开始？"><a href="#怎么开始？" class="headerlink" title="怎么开始？"></a>怎么开始？</h2><ol><li><strong>安装</strong>：<code>pip install agentlightning</code></li><li><strong>看文档</strong>：<a href="https://microsoft.github.io/agent-lightning/">microsoft.github.io&#x2F;agent-lightning</a></li><li><strong>跑示例</strong>：<a href="https://github.com/microsoft/agent-lightning/tree/main/examples">github.com&#x2F;microsoft&#x2F;agent-lightning&#x2F;examples</a></li><li><strong>加社区</strong>：<a href="https://discord.gg/RYk7CdvDR7">Discord</a></li></ol><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>Agent Lightning 解决的是一个真正的痛点：<strong>怎么让已有的智能体项目快速接入强化学习</strong>。</p><p>以前，你可能需要一个 RL 工程师团队花几个月重构代码。现在，加几行埋点就行了。</p><p>更重要的是，它代表了一种趋势：<strong>AI 智能体不再是「一次性部署」，而是「持续进化」</strong>。</p><p>你的智能体今天犯的错，明天就能学会避免。这才是真正的「智能」。</p><hr><p><strong>相关链接：</strong></p><ul><li><a href="https://github.com/microsoft/agent-lightning">GitHub 仓库</a></li><li><a href="https://microsoft.github.io/agent-lightning/">官方文档</a></li><li><a href="https://arxiv.org/abs/2508.03680">arXiv 论文</a></li><li><a href="https://www.microsoft.com/en-us/research/project/agent-lightning/">微软研究院介绍</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>微软</tag>
      
      <tag>强化学习</tag>
      
      <tag>Agent</tag>
      
      <tag>开源</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GitHub 重磅更新：一个指令，Claude、Codex、Copilot 任你调遣</title>
    <link href="/2026/02/05/github-agent-hq-claude-codex/"/>
    <url>/2026/02/05/github-agent-hq-claude-codex/</url>
    
    <content type="html"><![CDATA[<p><img src="/images/github-agent-hq/cover.png" alt="GitHub Agent HQ Cover"></p><p>GitHub 要变天了。</p><p>凌晨，微软 GitHub 官宣重磅更新：正式集成全球「最强编程大脑」—— Claude 和 Codex。加上自家的 Copilot，地表最强编程三剑客终于迎来史诗级合体。</p><p>这意味着什么？<strong>开发者只需一个指令，三个 AI 任你差遣</strong>，瞬间完成编码、修 Bug、提交 PR 等复杂任务。GitHub 正从一个单纯的代码托管平台，进化为多智能体协同的「AI 战场」。</p><h2 id="告别「上下文地狱」"><a href="#告别「上下文地狱」" class="headerlink" title="告别「上下文地狱」"></a>告别「上下文地狱」</h2><p>软件开发中，最耗神的就是「上下文切换」。</p><p>以前用 AI 辅助编程，你可能需要：在 ChatGPT 里问架构问题，在 Copilot 里补全代码，再切到 Claude 让它帮你 review。每次切换，思路都要断一下，效率大打折扣。</p><p>现在？<strong>全在 GitHub 里搞定</strong>。</p><p>通过新发布的 <strong>Agent HQ</strong>（智能体总部），开发者可以直接在 GitHub 网页端、手机 App、VS Code 里一键调用三个顶级 AI。上下文不丢，历史可追溯，PR 直接提交。</p><p>用 GitHub 首席产品官 Mario Rodriguez 的话说：</p><blockquote><p>「上下文切换就是摩擦。有了 Agent HQ，你可以用不同的智能体完成不同的步骤，从构思到落地一气呵成，不用换工具，不会丢上下文。」</p></blockquote><h2 id="三个大脑，各有所长"><a href="#三个大脑，各有所长" class="headerlink" title="三个大脑，各有所长"></a>三个大脑，各有所长</h2><p><img src="/images/github-agent-hq/comparison.png" alt="三个AI智能体协作"></p><p>最让程序员兴奋的玩法是：<strong>针对同一个编码难题，可以同时指派三个 AI 一起干</strong>。</p><p>把费时的重活儿丢给多个 AI 异步处理，喝杯咖啡的功夫，就能看到一份详尽的日志和写好的 PR 建议。然后对比它们的解题思路，选最优方案。</p><p>三个 AI 各有特点：</p><h3 id="Copilot：手速最快的「外挂键盘」"><a href="#Copilot：手速最快的「外挂键盘」" class="headerlink" title="Copilot：手速最快的「外挂键盘」"></a>Copilot：手速最快的「外挂键盘」</h3><p>微软自家的 AI 编程助手，最大优势是<strong>无缝集成</strong>。它像一个装在编辑器里的超级代码补全器，响应快、补全准，适合日常编码和快速迭代。</p><h3 id="Claude：深思熟虑的「建筑师」"><a href="#Claude：深思熟虑的「建筑师」" class="headerlink" title="Claude：深思熟虑的「建筑师」"></a>Claude：深思熟虑的「建筑师」</h3><p>Anthropic 的推理型 AI，擅长<strong>复杂推理和架构评审</strong>。它在动手前会先给你一份详细的行动计划，让你审查。适合大规模重构、理解陌生代码库、调试涉及多个系统的疑难杂症。</p><p>Anthropic 平台负责人 Katelyn Lesse 表示：</p><blockquote><p>「我们的目标是让开发者在需要推理能力的地方就能获得它。通过 Agent HQ，Claude 可以直接提交代码、评论 PR，帮助团队更快、更有信心地迭代和交付。」</p></blockquote><h3 id="Codex：能独立干活的「AI-队友」"><a href="#Codex：能独立干活的「AI-队友」" class="headerlink" title="Codex：能独立干活的「AI 队友」"></a>Codex：能独立干活的「AI 队友」</h3><p>OpenAI 最新发布的编程智能体，最大特点是<strong>自主性强</strong>。你可以像给新同事分配任务一样给它一个高阶目标，比如「帮我把前端框架从 Vue 2 升级到 Vue 3，确保所有单元测试都能跑通」，然后它会自己规划步骤、读写文件、执行命令、运行测试、分析错误，甚至在测试失败后自我修正。</p><p>OpenAI 的 Alexander Embiricos 说：</p><blockquote><p>「最初的 Codex 模型帮助驱动了 Copilot，开启了 AI 辅助编程的新时代。现在，数百万开发者可以直接在他们的主要工作空间中使用 Codex。」</p></blockquote><h2 id="实战场景：怎么选？"><a href="#实战场景：怎么选？" class="headerlink" title="实战场景：怎么选？"></a>实战场景：怎么选？</h2><table><thead><tr><th>场景</th><th>推荐</th><th>理由</th></tr></thead><tbody><tr><td>实现新功能</td><td>Copilot</td><td>响应快，diff 简洁</td></tr><tr><td>大规模重构</td><td>Claude</td><td>擅长规划，能在多文件间穿梭</td></tr><tr><td>理解陌生代码库</td><td>Claude</td><td>代码库映射和架构总结能力强</td></tr><tr><td>快速 Bug 修复</td><td>Codex</td><td>极擅长生成最小化 diff</td></tr><tr><td>从零构建项目</td><td>Claude</td><td>长上下文处理和整体架构理解更优</td></tr><tr><td>代码审查</td><td>都行</td><td>Copilot 擅长发现逻辑错误，Claude 擅长评估架构风险</td></tr></tbody></table><p>聪明的做法不是二选一，而是<strong>把它们都放进工具箱</strong>。用 Copilot 日常快速开发，用 Claude 处理架构性问题，用 Codex 跑那些费时的重活儿。</p><h2 id="企业级管控"><a href="#企业级管控" class="headerlink" title="企业级管控"></a>企业级管控</h2><p>不只是个人开发者的玩具，Agent HQ 为团队提供了完整的管控能力：</p><ul><li><strong>智能体策略</strong>：管理员可定义哪些智能体和模型允许在组织内使用</li><li><strong>代码质量检查</strong>：GitHub Code Quality 自动评估可维护性</li><li><strong>自动化初审</strong>：Copilot 先自己 review 一遍，再交给人类</li><li><strong>影响指标</strong>：Copilot Metrics Dashboard 追踪全组织使用情况</li><li><strong>审计日志</strong>：企业级访问管理，智能体操作全程可追溯</li></ul><p>所有智能体的操作都会被详细记录，产出的代码会像普通开发者提交的一样，走正常的 review 流程。这就是微软说的「可评审、可对比、可质疑」—— AI 也会犯错，所以设计成人类来把关。</p><h2 id="费用和使用门槛"><a href="#费用和使用门槛" class="headerlink" title="费用和使用门槛"></a>费用和使用门槛</h2><p>目前，Agent HQ 对 <strong>Copilot Pro+</strong> 和 <strong>Copilot Enterprise</strong> 订阅用户开放公测。</p><p>每次启动智能体任务，会消耗一个「高级请求」（Premium Request）额度。Pro+ 用户每月有 1,500 个额度，Enterprise 用户有 1,000 个，超出部分 $0.04&#x2F;次。</p><p>GitHub 表示，Claude 和 Codex 的使用权限将很快扩展到更多订阅类型。</p><h2 id="未来路线图"><a href="#未来路线图" class="headerlink" title="未来路线图"></a>未来路线图</h2><p>GitHub 正在与更多 AI 厂商洽谈合作：</p><ul><li><strong>Google</strong>：旗下的 Jules 编程智能体即将入驻</li><li><strong>xAI</strong>：马斯克的 AI 公司也在接入中</li><li><strong>Cognition</strong>：以 Devin 闻名的 AI 编程公司</li><li><strong>Copilot CLI</strong>：命令行版本即将支持多智能体</li></ul><h2 id="怎么用？"><a href="#怎么用？" class="headerlink" title="怎么用？"></a>怎么用？</h2><ol><li>确保你有 <strong>Copilot Pro+</strong> 或 <strong>Copilot Enterprise</strong> 订阅</li><li>访问 <a href="https://github.com/copilot/agents">github.com&#x2F;copilot&#x2F;agents</a></li><li>在 GitHub 或 VS Code 中选择你想用的智能体</li><li>开始干活！</li></ol><p>在 Issue 或 PR 里 @Copilot、@Claude 或 @Codex，就能指派任务。智能体会异步执行，完成后通知你 review。</p><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>2026 年，我们不需要再纠结「哪个 AI 工具更好用」。</p><p>唯一的命题是：<strong>团队该如何指挥这支「智能体舰队」，去碾压低效的工作流？</strong></p><p>开发者真正写新代码的时间只占 20%。剩下的 80%——重复的 Bug 分拣、枯燥的文档更新、繁琐的 PR 审查——才是 AI 真正的主战场。</p><p>别再只盯着屏幕敲代码，学会像「舰队指挥官」一样思考。这不是 AI 取代程序员，而是<strong>让程序员指挥 AI 军团</strong>。</p><hr><p><strong>原文链接：</strong></p><ul><li><a href="https://github.blog/news-insights/company-news/pick-your-agent-use-claude-and-codex-on-agent-hq/">GitHub 官方博客</a></li><li><a href="https://www.theverge.com/news/873665/github-claude-codex-ai-agents">The Verge 报道</a></li><li><a href="https://thenewstack.io/github-agent-hq/">The New Stack 深度分析</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>科技速递</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Claude</tag>
      
      <tag>Codex</tag>
      
      <tag>GitHub</tag>
      
      <tag>Copilot</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>OpenClaw 本地部署完全指南：Windows 与 macOS 全平台教程</title>
    <link href="/2026/02/04/openclaw-local-deployment-guide/"/>
    <url>/2026/02/04/openclaw-local-deployment-guide/</url>
    
    <content type="html"><![CDATA[<h1 id="🦞-OpenClaw-本地部署完全指南"><a href="#🦞-OpenClaw-本地部署完全指南" class="headerlink" title="🦞 OpenClaw 本地部署完全指南"></a>🦞 OpenClaw 本地部署完全指南</h1><blockquote><p>OpenClaw 是一款开源的本地优先 AI 助手平台，支持<strong>飞书</strong>、Telegram、Discord、WhatsApp 等多种即时通讯渠道。本文将详细介绍如何在 <strong>Windows</strong> 和 <strong>macOS</strong> 上完成本地部署，并重点讲解<strong>飞书集成</strong>配置。</p></blockquote><p><img src="/images/openclaw-guide/openclaw-logo-text.png" alt="OpenClaw Logo"></p><h2 id="📋-目录"><a href="#📋-目录" class="headerlink" title="📋 目录"></a>📋 目录</h2><ol><li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF-openclaw">什么是 OpenClaw？</a></li><li><a href="#%E7%B3%BB%E7%BB%9F%E8%A6%81%E6%B1%82">系统要求</a></li><li><a href="#macos-%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B">macOS 安装教程</a></li><li><a href="#windows-%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8Bwsl2">Windows 安装教程（WSL2）</a></li><li><a href="#%E9%A6%96%E6%AC%A1%E9%85%8D%E7%BD%AE%E5%90%91%E5%AF%BC">首次配置向导</a></li><li><a href="#%E5%90%AF%E5%8A%A8-gateway">启动 Gateway</a></li><li><a href="#%E8%BF%9E%E6%8E%A5%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF%E5%B9%B3%E5%8F%B0">连接即时通讯平台</a></li><li><a href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E9%80%9F%E6%9F%A5">常用命令速查</a></li><li><a href="#%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4">故障排除</a></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ol><hr><h2 id="什么是-OpenClaw？"><a href="#什么是-OpenClaw？" class="headerlink" title="什么是 OpenClaw？"></a>什么是 OpenClaw？</h2><p>OpenClaw（曾用名 Clawdbot &#x2F; Moltbot）是由 Peter Steinberger 和 Mario Zechner 开发的<strong>开源个人 AI 助手</strong>项目。</p><h3 id="🎯-核心特性"><a href="#🎯-核心特性" class="headerlink" title="🎯 核心特性"></a>🎯 核心特性</h3><ul><li>🤖 <strong>多模型支持</strong>：Anthropic Claude、OpenAI GPT、MiniMax、智谱 GLM、本地 Ollama 等</li><li>💬 <strong>多渠道整合</strong>：<strong>飞书</strong>、Telegram、Discord、WhatsApp、Slack、iMessage 等</li><li>🏠 <strong>本地优先</strong>：数据完全在本地，隐私有保障</li><li>🔧 <strong>工具扩展</strong>：浏览器控制、文件操作、定时任务等丰富工具</li><li>📱 <strong>跨平台</strong>：macOS、Linux、Windows (WSL2)</li><li>🇨🇳 <strong>国内友好</strong>：支持飞书、MiniMax、智谱等国产平台</li></ul><h3 id="🏗️-架构概览"><a href="#🏗️-架构概览" class="headerlink" title="🏗️ 架构概览"></a>🏗️ 架构概览</h3><p>下图展示了 OpenClaw 的整体架构：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs awk">┌─────────────┐  ┌─────────────┐  ┌─────────────┐<br>│    飞书     │  │  Telegram   │  │   Discord   │<br>└──────┬──────┘  └──────┬──────┘  └──────┬──────┘<br>       │                │                │<br>       └────────────────┼────────────────┘<br>                        ▼<br>            ┌───────────────────────┐<br>            │       Gateway         │<br>            │  ws:<span class="hljs-regexp">//</span><span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">18789</span> │<br>            │     (控制中心)         │<br>            └───────────┬───────────┘<br>                        │<br>        ┌───────────────┼───────────────┐<br>        ▼               ▼               ▼<br>  ┌──────────┐   ┌──────────┐   ┌──────────┐<br>  │ AI Agent │   │  工具系统  │   │  Canvas  │<br>  │(Claude)  │   │(浏览器等) │   │ (可视化) │<br>  └──────────┘   └──────────┘   └──────────┘<br></code></pre></td></tr></table></figure><h3 id="📱-移动端支持"><a href="#📱-移动端支持" class="headerlink" title="📱 移动端支持"></a>📱 移动端支持</h3><p>OpenClaw 支持 iOS&#x2F;Android 节点，可以实现：</p><p><img src="/images/openclaw-guide/mobile-ui-screenshot.png" alt="移动端 UI"></p><ul><li>手机端 Canvas 可视化</li><li>语音唤醒与对话</li><li>摄像头&#x2F;屏幕录制集成</li></ul><hr><h2 id="系统要求"><a href="#系统要求" class="headerlink" title="系统要求"></a>系统要求</h2><h3 id="基础要求"><a href="#基础要求" class="headerlink" title="基础要求"></a>基础要求</h3><table><thead><tr><th>项目</th><th>最低要求</th><th>推荐配置</th></tr></thead><tbody><tr><td>Node.js</td><td>≥ 22.x</td><td>最新 LTS</td></tr><tr><td>内存</td><td>2GB</td><td>4GB+</td></tr><tr><td>磁盘</td><td>1GB</td><td>5GB+</td></tr><tr><td>网络</td><td>可访问 API 服务</td><td>稳定网络</td></tr></tbody></table><h3 id="平台特定要求"><a href="#平台特定要求" class="headerlink" title="平台特定要求"></a>平台特定要求</h3><table><thead><tr><th>平台</th><th>说明</th></tr></thead><tbody><tr><td><strong>macOS</strong></td><td>仅 CLI + Gateway 只需 Node.js；构建 App 需要 Xcode</td></tr><tr><td><strong>Windows</strong></td><td><strong>强烈推荐 WSL2</strong>（Ubuntu），原生 Windows 未经充分测试</td></tr><tr><td><strong>Linux</strong></td><td>无额外要求</td></tr></tbody></table><blockquote><p>💡 <strong>提示</strong>：国内用户可优先选择 MiniMax、智谱 GLM 等国产模型，无需额外网络配置</p></blockquote><hr><h2 id="macOS-安装教程"><a href="#macOS-安装教程" class="headerlink" title="macOS 安装教程"></a>macOS 安装教程</h2><h3 id="步骤-1：安装-Node-js"><a href="#步骤-1：安装-Node-js" class="headerlink" title="步骤 1：安装 Node.js"></a>步骤 1：安装 Node.js</h3><h4 id="方式一：使用-Homebrew（推荐）"><a href="#方式一：使用-Homebrew（推荐）" class="headerlink" title="方式一：使用 Homebrew（推荐）"></a>方式一：使用 Homebrew（推荐）</h4><p>打开终端 (Terminal.app)，执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装 Homebrew（如果没有）</span><br>/bin/bash -c <span class="hljs-string">&quot;<span class="hljs-subst">$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)</span>&quot;</span><br><br><span class="hljs-comment"># 安装 Node.js 22</span><br>brew install node@22<br><br><span class="hljs-comment"># 添加到 PATH（Apple Silicon Mac）</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;export PATH=&quot;/opt/homebrew/opt/node@22/bin:$PATH&quot;&#x27;</span> &gt;&gt; ~/.zshrc<br><span class="hljs-built_in">source</span> ~/.zshrc<br><br><span class="hljs-comment"># 验证安装</span><br>node --version  <span class="hljs-comment"># 应显示 v22.x.x</span><br></code></pre></td></tr></table></figure><blockquote><p>💡 <strong>提示</strong>：Intel Mac 的路径是 <code>/usr/local/opt/node@22/bin</code></p></blockquote><h4 id="方式二：使用-nvm（版本管理器）"><a href="#方式二：使用-nvm（版本管理器）" class="headerlink" title="方式二：使用 nvm（版本管理器）"></a>方式二：使用 nvm（版本管理器）</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装 nvm</span><br>curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash<br><span class="hljs-built_in">source</span> ~/.zshrc<br><br><span class="hljs-comment"># 安装 Node.js 22</span><br>nvm install 22<br>nvm use 22<br></code></pre></td></tr></table></figure><h3 id="步骤-2：安装-OpenClaw"><a href="#步骤-2：安装-OpenClaw" class="headerlink" title="步骤 2：安装 OpenClaw"></a>步骤 2：安装 OpenClaw</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 一键安装（推荐）</span><br>curl -fsSL https://openclaw.ai/install.sh | bash<br></code></pre></td></tr></table></figure><p>或者使用 npm：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm install -g openclaw@latest<br></code></pre></td></tr></table></figure><blockquote><p>如果遇到 <code>sharp</code> 相关错误，尝试：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">SHARP_IGNORE_GLOBAL_LIBVIPS=1 npm install -g openclaw@latest<br></code></pre></td></tr></table></figure></blockquote><h3 id="步骤-3：运行配置向导"><a href="#步骤-3：运行配置向导" class="headerlink" title="步骤 3：运行配置向导"></a>步骤 3：运行配置向导</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw onboard --install-daemon<br></code></pre></td></tr></table></figure><p>向导会引导你完成：</p><ul><li>✅ Gateway 模式选择（本地&#x2F;远程）</li><li>✅ AI 模型认证（API Key &#x2F; OAuth）</li><li>✅ 通讯渠道配置</li><li>✅ 后台服务安装</li></ul><h3 id="步骤-4：验证安装"><a href="#步骤-4：验证安装" class="headerlink" title="步骤 4：验证安装"></a>步骤 4：验证安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看状态</span><br>openclaw status<br><br><span class="hljs-comment"># 健康检查</span><br>openclaw health<br><br><span class="hljs-comment"># 安全审计</span><br>openclaw security audit --deep<br></code></pre></td></tr></table></figure><h3 id="macOS-App（可选）"><a href="#macOS-App（可选）" class="headerlink" title="macOS App（可选）"></a>macOS App（可选）</h3><p>OpenClaw 提供 macOS 菜单栏应用，功能包括：</p><ul><li>🔔 原生通知</li><li>🎤 语音唤醒 + 对话模式</li><li>📺 Canvas 可视化工作区</li><li>📷 摄像头 &#x2F; 屏幕录制集成</li></ul><hr><h2 id="Windows-安装教程（WSL2）"><a href="#Windows-安装教程（WSL2）" class="headerlink" title="Windows 安装教程（WSL2）"></a>Windows 安装教程（WSL2）</h2><blockquote><p>💡 <strong>为什么用 WSL2？</strong> OpenClaw 的 CLI 和 Gateway 在 Linux 环境下运行最稳定，工具兼容性更好。WSL2 让你在 Windows 上获得完整的 Linux 体验。</p></blockquote><h3 id="步骤-1：安装-WSL2"><a href="#步骤-1：安装-WSL2" class="headerlink" title="步骤 1：安装 WSL2"></a>步骤 1：安装 WSL2</h3><p>以<strong>管理员身份</strong>打开 PowerShell（右键点击开始菜单 → Windows 终端(管理员)）：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># 一键安装 WSL（默认 Ubuntu）</span><br>wsl <span class="hljs-literal">--install</span><br></code></pre></td></tr></table></figure><p>或者指定发行版：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># 查看可用发行版</span><br>wsl <span class="hljs-literal">--list</span> <span class="hljs-literal">--online</span><br><br><span class="hljs-comment"># 安装 Ubuntu 24.04</span><br>wsl <span class="hljs-literal">--install</span> <span class="hljs-literal">-d</span> Ubuntu<span class="hljs-literal">-24</span>.<span class="hljs-number">04</span><br></code></pre></td></tr></table></figure><p>安装完成后<strong>重启电脑</strong>。</p><blockquote><p>📝 <strong>首次启动</strong>：重启后会自动打开 Ubuntu，按提示创建用户名和密码。</p></blockquote><h3 id="步骤-2：启用-systemd"><a href="#步骤-2：启用-systemd" class="headerlink" title="步骤 2：启用 systemd"></a>步骤 2：启用 systemd</h3><p>在 WSL Ubuntu 终端中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 配置 systemd（OpenClaw 后台服务需要）</span><br>sudo <span class="hljs-built_in">tee</span> /etc/wsl.conf &gt;/dev/null &lt;&lt;<span class="hljs-string">&#x27;EOF&#x27;</span><br>[boot]<br>systemd=<span class="hljs-literal">true</span><br>EOF<br></code></pre></td></tr></table></figure><p>然后在 PowerShell 中重启 WSL：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">wsl <span class="hljs-literal">--shutdown</span><br></code></pre></td></tr></table></figure><p>重新打开 Ubuntu，验证 systemd：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">systemctl --user status<br></code></pre></td></tr></table></figure><h3 id="步骤-3：安装-Node-js"><a href="#步骤-3：安装-Node-js" class="headerlink" title="步骤 3：安装 Node.js"></a>步骤 3：安装 Node.js</h3><p>在 WSL Ubuntu 终端中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装 Node.js 22</span><br>curl -fsSL https://deb.nodesource.com/setup_22.x | sudo -E bash -<br>sudo apt-get install -y nodejs<br><br><span class="hljs-comment"># 验证</span><br>node --version<br>npm --version<br></code></pre></td></tr></table></figure><h3 id="步骤-4：安装-OpenClaw"><a href="#步骤-4：安装-OpenClaw" class="headerlink" title="步骤 4：安装 OpenClaw"></a>步骤 4：安装 OpenClaw</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 一键安装</span><br>curl -fsSL https://openclaw.ai/install.sh | bash<br></code></pre></td></tr></table></figure><h3 id="步骤-5：运行配置向导"><a href="#步骤-5：运行配置向导" class="headerlink" title="步骤 5：运行配置向导"></a>步骤 5：运行配置向导</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw onboard --install-daemon<br></code></pre></td></tr></table></figure><h3 id="步骤-6：从-Windows-访问-Gateway（可选）"><a href="#步骤-6：从-Windows-访问-Gateway（可选）" class="headerlink" title="步骤 6：从 Windows 访问 Gateway（可选）"></a>步骤 6：从 Windows 访问 Gateway（可选）</h3><p>如果需要从 Windows 或局域网访问 WSL 中的 Gateway，需要配置端口转发。</p><p>以<strong>管理员身份</strong>打开 PowerShell：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$Distro</span> = <span class="hljs-string">&quot;Ubuntu-24.04&quot;</span><br><span class="hljs-variable">$ListenPort</span> = <span class="hljs-number">18789</span><br><span class="hljs-variable">$TargetPort</span> = <span class="hljs-number">18789</span><br><br><span class="hljs-comment"># 获取 WSL IP</span><br><span class="hljs-variable">$WslIp</span> = (wsl <span class="hljs-literal">-d</span> <span class="hljs-variable">$Distro</span> <span class="hljs-literal">--</span> hostname <span class="hljs-literal">-I</span>).Trim().Split(<span class="hljs-string">&quot; &quot;</span>)[<span class="hljs-number">0</span>]<br><br><span class="hljs-comment"># 添加端口转发</span><br>netsh interface portproxy add v4tov4 `<br>    listenaddress=<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span> listenport=<span class="hljs-variable">$ListenPort</span> `<br>    connectaddress=<span class="hljs-variable">$WslIp</span> connectport=<span class="hljs-variable">$TargetPort</span><br><br><span class="hljs-comment"># 添加防火墙规则（一次性）</span><br><span class="hljs-built_in">New-NetFirewallRule</span> <span class="hljs-literal">-DisplayName</span> <span class="hljs-string">&quot;OpenClaw Gateway&quot;</span> `<br>    <span class="hljs-literal">-Direction</span> Inbound <span class="hljs-literal">-Protocol</span> TCP `<br>    <span class="hljs-literal">-LocalPort</span> <span class="hljs-variable">$ListenPort</span> <span class="hljs-literal">-Action</span> Allow<br></code></pre></td></tr></table></figure><blockquote><p>⚠️ WSL IP 在重启后会变化，需要重新运行端口转发命令。</p></blockquote><hr><h2 id="首次配置向导"><a href="#首次配置向导" class="headerlink" title="首次配置向导"></a>首次配置向导</h2><p>运行 <code>openclaw onboard --install-daemon</code> 后，会进入交互式配置：</p><h3 id="1-Gateway-模式"><a href="#1-Gateway-模式" class="headerlink" title="1. Gateway 模式"></a>1. Gateway 模式</h3><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs autoit">? Gateway mode:<br>❯ <span class="hljs-keyword">Local</span>    <span class="hljs-meta"># 本地运行（推荐）</span><br>  Remote   <span class="hljs-meta"># 连接远程 Gateway</span><br></code></pre></td></tr></table></figure><h3 id="2-认证方式"><a href="#2-认证方式" class="headerlink" title="2. 认证方式"></a>2. 认证方式</h3><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs gauss">? Auth provider:<br>❯ <span class="hljs-built_in">Anthropic</span> (API <span class="hljs-built_in">key</span>)   <span class="hljs-meta"># 推荐</span><br>  <span class="hljs-built_in">OpenAI</span> (API <span class="hljs-built_in">key</span>)<br>  <span class="hljs-built_in">Anthropic</span> (OAuth)     <span class="hljs-meta"># 复用 Claude Code 凭证</span><br>  ...<br></code></pre></td></tr></table></figure><p><strong>获取 API Key：</strong></p><ul><li>Anthropic：<a href="https://console.anthropic.com/">https://console.anthropic.com/</a></li><li>OpenAI：<a href="https://platform.openai.com/">https://platform.openai.com/</a></li></ul><h3 id="3-选择默认模型"><a href="#3-选择默认模型" class="headerlink" title="3. 选择默认模型"></a>3. 选择默认模型</h3><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs subunit">? Default model:<br>❯ claude-sonnet<span class="hljs-string">-4</span><span class="hljs-string">-0</span>    # 推荐，速度与智能平衡<br>  claude-opus<span class="hljs-string">-4</span><span class="hljs-string">-5</span>      # 更强智能，更慢<br>  claude-haiku<span class="hljs-string">-3</span><span class="hljs-string">-5</span>     # 快速响应<br></code></pre></td></tr></table></figure><h3 id="4-渠道配置"><a href="#4-渠道配置" class="headerlink" title="4. 渠道配置"></a>4. 渠道配置</h3><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs applescript">? Channels <span class="hljs-keyword">to</span> configure:<br>⬡ WhatsApp    <span class="hljs-comment"># 需要扫码登录</span><br>◉ Telegram    <span class="hljs-comment"># 需要 Bot Token</span><br>◯ Discord     <span class="hljs-comment"># 需要 Bot Token</span><br>◯ iMessage    <span class="hljs-comment"># 仅 macOS</span><br></code></pre></td></tr></table></figure><h3 id="5-安装后台服务"><a href="#5-安装后台服务" class="headerlink" title="5. 安装后台服务"></a>5. 安装后台服务</h3><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mathematica"><span class="hljs-operator">?</span> <span class="hljs-built_in">Install</span> <span class="hljs-variable">daemon</span><span class="hljs-operator">:</span> <span class="hljs-punctuation">(</span><span class="hljs-variable">y</span><span class="hljs-operator">/</span><span class="hljs-built_in">N</span><span class="hljs-punctuation">)</span> <span class="hljs-variable">y</span><br></code></pre></td></tr></table></figure><h3 id="认证文件位置"><a href="#认证文件位置" class="headerlink" title="认证文件位置"></a>认证文件位置</h3><table><thead><tr><th>类型</th><th>路径</th></tr></thead><tbody><tr><td>OAuth 凭证</td><td><code>~/.openclaw/credentials/oauth.json</code></td></tr><tr><td>Auth 配置</td><td><code>~/.openclaw/agents/&lt;agentId&gt;/agent/auth-profiles.json</code></td></tr><tr><td>主配置文件</td><td><code>~/.openclaw/openclaw.json</code></td></tr></tbody></table><hr><h2 id="启动-Gateway"><a href="#启动-Gateway" class="headerlink" title="启动 Gateway"></a>启动 Gateway</h2><h3 id="检查状态"><a href="#检查状态" class="headerlink" title="检查状态"></a>检查状态</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw gateway status<br></code></pre></td></tr></table></figure><h3 id="手动启动（前台，调试用）"><a href="#手动启动（前台，调试用）" class="headerlink" title="手动启动（前台，调试用）"></a>手动启动（前台，调试用）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw gateway --port 18789 --verbose<br></code></pre></td></tr></table></figure><h3 id="访问控制台"><a href="#访问控制台" class="headerlink" title="访问控制台"></a>访问控制台</h3><p>启动 Gateway 后，可以通过浏览器访问控制台：</p><ul><li><strong>Dashboard</strong>: <a href="http://127.0.0.1:18789/">http://127.0.0.1:18789/</a></li><li><strong>Control UI</strong>: <a href="http://127.0.0.1:18789/openclaw/">http://127.0.0.1:18789/openclaw/</a></li></ul><p>如果配置了 token，需要在 Control UI 设置中输入。</p><blockquote><p>💡 <strong>提示</strong>：可以运行 <code>openclaw dashboard</code> 直接打开浏览器</p></blockquote><h3 id="服务管理"><a href="#服务管理" class="headerlink" title="服务管理"></a>服务管理</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 启动</span><br>openclaw gateway start<br><br><span class="hljs-comment"># 停止</span><br>openclaw gateway stop<br><br><span class="hljs-comment"># 重启</span><br>openclaw gateway restart<br></code></pre></td></tr></table></figure><hr><h2 id="连接即时通讯平台"><a href="#连接即时通讯平台" class="headerlink" title="连接即时通讯平台"></a>连接即时通讯平台</h2><h3 id="🔥-飞书集成（推荐国内用户）"><a href="#🔥-飞书集成（推荐国内用户）" class="headerlink" title="🔥 飞书集成（推荐国内用户）"></a>🔥 飞书集成（推荐国内用户）</h3><p>飞书是国内企业常用的协作平台，OpenClaw 通过 WebSocket 长连接与飞书机器人集成，<strong>无需公网 URL</strong>，配置简单。</p><h4 id="步骤-1：安装飞书插件"><a href="#步骤-1：安装飞书插件" class="headerlink" title="步骤 1：安装飞书插件"></a>步骤 1：安装飞书插件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw plugins install @openclaw/feishu<br></code></pre></td></tr></table></figure><h4 id="步骤-2：创建飞书应用"><a href="#步骤-2：创建飞书应用" class="headerlink" title="步骤 2：创建飞书应用"></a>步骤 2：创建飞书应用</h4><ol><li>访问 <a href="https://open.feishu.cn/app">飞书开放平台</a> 并登录</li><li>点击 <strong>创建企业自建应用</strong></li><li>填写应用名称和描述，选择图标</li><li>在 <strong>凭证与基础信息</strong> 页面，复制：<ul><li><strong>App ID</strong>（格式：<code>cli_xxx</code>）</li><li><strong>App Secret</strong></li></ul></li></ol><blockquote><p>❗ <strong>重要</strong>：App Secret 请妥善保管，不要泄露！</p></blockquote><h4 id="步骤-3：配置应用权限"><a href="#步骤-3：配置应用权限" class="headerlink" title="步骤 3：配置应用权限"></a>步骤 3：配置应用权限</h4><p>在 <strong>权限管理</strong> 页面，点击 <strong>批量开通</strong>，粘贴以下 JSON：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;scopes&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;tenant&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-string">&quot;im:message&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:message.group_at_msg:readonly&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:message.p2p_msg:readonly&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:message:readonly&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:message:send_as_bot&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:resource&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:chat.access_event.bot_p2p_chat:read&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-string">&quot;im:chat.members:bot_access&quot;</span><br>    <span class="hljs-punctuation">]</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h4 id="步骤-4：启用机器人能力"><a href="#步骤-4：启用机器人能力" class="headerlink" title="步骤 4：启用机器人能力"></a>步骤 4：启用机器人能力</h4><p>在 <strong>应用能力 → 机器人</strong>：</p><ul><li>开启机器人能力</li><li>设置机器人名称</li></ul><h4 id="步骤-5：配置事件订阅"><a href="#步骤-5：配置事件订阅" class="headerlink" title="步骤 5：配置事件订阅"></a>步骤 5：配置事件订阅</h4><blockquote><p>⚠️ <strong>重要</strong>：配置事件订阅前，确保 Gateway 已启动！</p></blockquote><p>在 <strong>事件订阅</strong> 页面：</p><ol><li>选择 <strong>使用长连接接收事件</strong>（WebSocket 方式）</li><li>添加事件：<code>im.message.receive_v1</code></li></ol><h4 id="步骤-6：发布应用"><a href="#步骤-6：发布应用" class="headerlink" title="步骤 6：发布应用"></a>步骤 6：发布应用</h4><ol><li>在 <strong>版本管理与发布</strong> 创建版本</li><li>提交审核并发布</li><li>等待管理员审批（企业内部应用通常自动通过）</li></ol><h4 id="步骤-7：配置-OpenClaw"><a href="#步骤-7：配置-OpenClaw" class="headerlink" title="步骤 7：配置 OpenClaw"></a>步骤 7：配置 OpenClaw</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw channels add<br></code></pre></td></tr></table></figure><p>选择 <strong>Feishu</strong>，输入 App ID 和 App Secret。</p><p>或者直接编辑配置文件 <code>~/.openclaw/openclaw.json</code>：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;channels&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;feishu&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;enabled&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;dmPolicy&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;pairing&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;accounts&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;main&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;appId&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;cli_xxx&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;appSecret&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你的AppSecret&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;botName&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;我的AI助手&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h4 id="步骤-8：测试连接"><a href="#步骤-8：测试连接" class="headerlink" title="步骤 8：测试连接"></a>步骤 8：测试连接</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 启动 Gateway</span><br>openclaw gateway<br><br><span class="hljs-comment"># 在飞书中找到你的机器人，发送一条消息</span><br><span class="hljs-comment"># 首次会收到配对码，批准配对：</span><br>openclaw pairing approve feishu &lt;CODE&gt;<br></code></pre></td></tr></table></figure><h4 id="飞书群聊配置"><a href="#飞书群聊配置" class="headerlink" title="飞书群聊配置"></a>飞书群聊配置</h4><p>默认情况下，群聊需要 @机器人 才能触发回复。可以修改配置：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;channels&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;feishu&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;groups&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;oc_xxx&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> <span class="hljs-attr">&quot;requireMention&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span> <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><blockquote><p>💡 <strong>获取群聊 ID</strong>：在群里 @机器人，然后查看日志 <code>openclaw logs --follow</code>，找到 <code>chat_id</code>。</p></blockquote><hr><h3 id="WhatsApp（扫码登录）"><a href="#WhatsApp（扫码登录）" class="headerlink" title="WhatsApp（扫码登录）"></a>WhatsApp（扫码登录）</h3><p><img src="/images/openclaw-guide/whatsapp-openclaw.jpg" alt="WhatsApp 连接"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw channels login<br></code></pre></td></tr></table></figure><p>扫码方式：</p><ol><li>打开手机 WhatsApp</li><li>进入 <strong>设置 → 已关联设备</strong></li><li>扫描终端显示的二维码</li></ol><h3 id="Telegram（Bot-Token）"><a href="#Telegram（Bot-Token）" class="headerlink" title="Telegram（Bot Token）"></a>Telegram（Bot Token）</h3><ol><li>访问 <a href="https://t.me/BotFather">@BotFather</a></li><li>发送 <code>/newbot</code> 创建机器人</li><li>获取 Bot Token</li><li>配置：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw configure --section channels.telegram<br></code></pre></td></tr></table></figure><h3 id="Discord（Bot-Token）"><a href="#Discord（Bot-Token）" class="headerlink" title="Discord（Bot Token）"></a>Discord（Bot Token）</h3><ol><li>访问 <a href="https://discord.com/developers/applications">Discord Developer Portal</a></li><li>创建应用，添加 Bot</li><li>获取 Bot Token</li><li>邀请 Bot 到服务器</li><li>配置：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw configure --section channels.discord<br></code></pre></td></tr></table></figure><h3 id="DM-配对"><a href="#DM-配对" class="headerlink" title="DM 配对"></a>DM 配对</h3><p>默认情况下，未知用户的私聊需要先<strong>批准配对</strong>才能处理：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看待处理配对（飞书）</span><br>openclaw pairing list feishu<br><br><span class="hljs-comment"># 查看待处理配对（Telegram）</span><br>openclaw pairing list telegram<br><br><span class="hljs-comment"># 批准</span><br>openclaw pairing approve feishu &lt;CODE&gt;<br>openclaw pairing approve telegram &lt;CODE&gt;<br><br><span class="hljs-comment"># 拒绝</span><br>openclaw pairing deny feishu &lt;CODE&gt;<br></code></pre></td></tr></table></figure><hr><h2 id="常用命令速查"><a href="#常用命令速查" class="headerlink" title="常用命令速查"></a>常用命令速查</h2><h3 id="基础命令"><a href="#基础命令" class="headerlink" title="基础命令"></a>基础命令</h3><table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td><code>openclaw status</code></td><td>查看状态概览</td></tr><tr><td><code>openclaw status --all</code></td><td>完整诊断报告（最佳调试输出）</td></tr><tr><td><code>openclaw health</code></td><td>健康检查</td></tr><tr><td><code>openclaw doctor</code></td><td>问题诊断</td></tr></tbody></table><h3 id="Gateway-管理"><a href="#Gateway-管理" class="headerlink" title="Gateway 管理"></a>Gateway 管理</h3><table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td><code>openclaw gateway start</code></td><td>启动</td></tr><tr><td><code>openclaw gateway stop</code></td><td>停止</td></tr><tr><td><code>openclaw gateway restart</code></td><td>重启</td></tr><tr><td><code>openclaw gateway status</code></td><td>状态</td></tr><tr><td><code>openclaw gateway install</code></td><td>安装后台服务</td></tr></tbody></table><h3 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h3><table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td><code>openclaw configure</code></td><td>交互式配置</td></tr><tr><td><code>openclaw config get</code></td><td>查看配置</td></tr><tr><td><code>openclaw config set &lt;key&gt; &lt;value&gt;</code></td><td>设置配置</td></tr></tbody></table><h3 id="渠道管理"><a href="#渠道管理" class="headerlink" title="渠道管理"></a>渠道管理</h3><table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td><code>openclaw plugins install @openclaw/feishu</code></td><td>安装飞书插件</td></tr><tr><td><code>openclaw channels add</code></td><td>添加新渠道</td></tr><tr><td><code>openclaw channels login</code></td><td>WhatsApp 扫码登录</td></tr><tr><td><code>openclaw channels status</code></td><td>查看渠道状态</td></tr><tr><td><code>openclaw channels status --probe</code></td><td>探测渠道连通性</td></tr><tr><td><code>openclaw pairing list &lt;channel&gt;</code></td><td>查看待配对</td></tr></tbody></table><h3 id="更新与维护"><a href="#更新与维护" class="headerlink" title="更新与维护"></a>更新与维护</h3><table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td><code>openclaw update</code></td><td>更新到最新版</td></tr><tr><td><code>openclaw update --channel beta</code></td><td>切换到 beta 版</td></tr><tr><td><code>openclaw update --channel stable</code></td><td>切换到稳定版</td></tr></tbody></table><hr><h2 id="故障排除"><a href="#故障排除" class="headerlink" title="故障排除"></a>故障排除</h2><h3 id="1-openclaw-命令找不到"><a href="#1-openclaw-命令找不到" class="headerlink" title="1. openclaw 命令找不到"></a>1. <code>openclaw</code> 命令找不到</h3><p>检查 PATH：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">node -v<br>npm prefix -g<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$PATH</span>&quot;</span><br></code></pre></td></tr></table></figure><p>如果 <code>$(npm prefix -g)/bin</code> 不在 PATH 中，添加到 shell 配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># macOS / Linux (zsh)</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;export PATH=&quot;$(npm prefix -g)/bin:$PATH&quot;&#x27;</span> &gt;&gt; ~/.zshrc<br><span class="hljs-built_in">source</span> ~/.zshrc<br><br><span class="hljs-comment"># Linux (bash)</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;export PATH=&quot;$(npm prefix -g)/bin:$PATH&quot;&#x27;</span> &gt;&gt; ~/.bashrc<br><span class="hljs-built_in">source</span> ~/.bashrc<br></code></pre></td></tr></table></figure><h3 id="2-Gateway-无法启动"><a href="#2-Gateway-无法启动" class="headerlink" title="2. Gateway 无法启动"></a>2. Gateway 无法启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 检查端口占用</span><br>lsof -i :18789<br><br><span class="hljs-comment"># 杀掉占用进程</span><br><span class="hljs-built_in">kill</span> -9 &lt;PID&gt;<br><br><span class="hljs-comment"># 查看详细日志</span><br>openclaw gateway --verbose<br></code></pre></td></tr></table></figure><h3 id="3-WhatsApp-扫码失败"><a href="#3-WhatsApp-扫码失败" class="headerlink" title="3. WhatsApp 扫码失败"></a>3. WhatsApp 扫码失败</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 重新登录</span><br>openclaw channels <span class="hljs-built_in">logout</span> whatsapp<br>openclaw channels login<br></code></pre></td></tr></table></figure><h3 id="4-API-连接问题（国内用户）"><a href="#4-API-连接问题（国内用户）" class="headerlink" title="4. API 连接问题（国内用户）"></a>4. API 连接问题（国内用户）</h3><p>国内用户推荐使用国产模型服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 配置 MiniMax</span><br>openclaw configure --section auth<br><br><span class="hljs-comment"># 选择 MiniMax 或智谱 GLM</span><br></code></pre></td></tr></table></figure><p>支持的国产模型：</p><ul><li><strong>MiniMax</strong>：<a href="https://www.minimaxi.com/">https://www.minimaxi.com/</a></li><li><strong>智谱 GLM</strong>：<a href="https://open.bigmodel.cn/">https://open.bigmodel.cn/</a></li><li><strong>本地 Ollama</strong>：完全离线运行</li></ul><h3 id="5-WSL2-端口转发失效"><a href="#5-WSL2-端口转发失效" class="headerlink" title="5. WSL2 端口转发失效"></a>5. WSL2 端口转发失效</h3><p>WSL IP 在重启后会变化，需要重新运行端口转发脚本。可以创建一个脚本自动刷新：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># refresh-wsl-port.ps1</span><br><span class="hljs-variable">$Distro</span> = <span class="hljs-string">&quot;Ubuntu-24.04&quot;</span><br><span class="hljs-variable">$Port</span> = <span class="hljs-number">18789</span><br><br><span class="hljs-variable">$WslIp</span> = (wsl <span class="hljs-literal">-d</span> <span class="hljs-variable">$Distro</span> <span class="hljs-literal">--</span> hostname <span class="hljs-literal">-I</span>).Trim().Split(<span class="hljs-string">&quot; &quot;</span>)[<span class="hljs-number">0</span>]<br>netsh interface portproxy delete v4tov4 listenport=<span class="hljs-variable">$Port</span> listenaddress=<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span><br>netsh interface portproxy add v4tov4 listenport=<span class="hljs-variable">$Port</span> listenaddress=<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span> connectaddress=<span class="hljs-variable">$WslIp</span> connectport=<span class="hljs-variable">$Port</span><br><span class="hljs-built_in">Write-Host</span> <span class="hljs-string">&quot;Port forwarding updated: <span class="hljs-variable">$WslIp:</span><span class="hljs-variable">$Port</span>&quot;</span><br></code></pre></td></tr></table></figure><h3 id="6-“no-auth-configured”-错误"><a href="#6-“no-auth-configured”-错误" class="headerlink" title="6. “no auth configured” 错误"></a>6. “no auth configured” 错误</h3><p>重新运行配置向导设置 API Key：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw configure<br></code></pre></td></tr></table></figure><h3 id="7-飞书机器人不响应"><a href="#7-飞书机器人不响应" class="headerlink" title="7. 飞书机器人不响应"></a>7. 飞书机器人不响应</h3><ul><li>确保应用已发布并审批通过</li><li>确保事件订阅包含 <code>im.message.receive_v1</code></li><li>确保已启用”长连接接收事件”</li><li>确保 Gateway 正在运行：<code>openclaw gateway status</code></li><li>查看日志：<code>openclaw logs --follow</code></li></ul><h3 id="8-飞书群聊不响应"><a href="#8-飞书群聊不响应" class="headerlink" title="8. 飞书群聊不响应"></a>8. 飞书群聊不响应</h3><ul><li>确保机器人已添加到群聊</li><li>默认需要 @机器人（检查 <code>requireMention</code> 配置）</li><li>确保 <code>groupPolicy</code> 不是 <code>disabled</code></li></ul><hr><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><h3 id="官方资源"><a href="#官方资源" class="headerlink" title="官方资源"></a>官方资源</h3><ul><li>📚 <strong>官方文档</strong>: <a href="https://docs.openclaw.ai/">https://docs.openclaw.ai</a></li><li>🐙 <strong>GitHub 仓库</strong>: <a href="https://github.com/openclaw/openclaw">https://github.com/openclaw/openclaw</a></li><li>💬 <strong>Discord 社区</strong>: <a href="https://discord.gg/clawd">https://discord.gg/clawd</a></li><li>🎓 <strong>DeepWiki 知识库</strong>: <a href="https://deepwiki.com/openclaw/openclaw">https://deepwiki.com/openclaw/openclaw</a></li></ul><h3 id="相关教程"><a href="#相关教程" class="headerlink" title="相关教程"></a>相关教程</h3><ul><li><a href="https://docs.openclaw.ai/start/getting-started">Getting Started</a> - 官方入门指南</li><li><a href="https://docs.openclaw.ai/channels/feishu">飞书集成文档</a> - 飞书配置详解</li><li><a href="https://docs.openclaw.ai/platforms/windows">Windows (WSL2)</a> - Windows 部署文档</li><li><a href="https://docs.openclaw.ai/platforms/macos">macOS App</a> - macOS 应用文档</li><li><a href="https://docs.openclaw.ai/install/docker">Docker 部署</a> - 容器化部署</li></ul><h3 id="中文资源"><a href="#中文资源" class="headerlink" title="中文资源"></a>中文资源</h3><ul><li><a href="https://blog.csdn.net/liwang0113/article/details/157579187">CSDN 保姆级教程</a></li><li><a href="https://www.cnblogs.com/whuanle/p/19558535">博客园部署指南</a></li><li><a href="https://help.aliyun.com/zh/simple-application-server/use-cases/quickly-deploy-and-use-openclaw">阿里云应用模板</a></li></ul><hr><blockquote><p>📝 <strong>文章作者</strong>: 隆戈 🐉<br>📅 <strong>更新日期</strong>: 2026-02-04<br>🔗 <strong>本文链接</strong>: <a href="https://hydraxman.github.io/2026/02/04/openclaw-local-deployment-guide/">https://hydraxman.github.io/2026/02/04/openclaw-local-deployment-guide/</a></p></blockquote><p>如果这篇教程对你有帮助，欢迎分享给需要的朋友！有问题可以在评论区留言讨论。</p>]]></content>
    
    
    <categories>
      
      <category>技术实战</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Windows</tag>
      
      <tag>macOS</tag>
      
      <tag>OpenClaw</tag>
      
      <tag>教程</tag>
      
      <tag>本地部署</tag>
      
      <tag>飞书</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从 Cursor 到 Lovart：AI 时代的窗口期与维度战争</title>
    <link href="/2026/02/02/ai-industry-thoughts-2026/index/"/>
    <url>/2026/02/02/ai-industry-thoughts-2026/index/</url>
    
    <content type="html"><![CDATA[<p><img src="/images/covers/ai-thoughts-2026.png" alt="Cover"></p><p>最近在思考 AI 行业的演进，尤其是像 Cursor 和 Lovart 这样的应用层产品，让我对整个 AI 发展的“窗口期”和“维度”有了一些新的理解。</p><h2 id="Cursor：AI-Native-的-IDE-范本"><a href="#Cursor：AI-Native-的-IDE-范本" class="headerlink" title="Cursor：AI Native 的 IDE 范本"></a>Cursor：AI Native 的 IDE 范本</h2><p>Cursor 的价值其实跟 Lovart 很像，它们都不做自己的底层大模型，而是专注于<strong>应用层体验</strong>。这是它们的共同点。</p><h3 id="为什么-Cursor-能突围？"><a href="#为什么-Cursor-能突围？" class="headerlink" title="为什么 Cursor 能突围？"></a>为什么 Cursor 能突围？</h3><p>目前全世界用户量最大的 AI 编程工具无疑是 VS Code 的 GitHub Copilot 插件，日活可能达到 1600 万。虽然体量大，但它的渗透率其实不高，可能不到 20%。</p><p>为什么？因为整个开发环境极度碎片化。</p><p>Cursor 的差异化在于，它不是从传统 IDE“转型”过来的，它生来就是为 AI 时代设计的。它是 <strong>AI Native</strong> 的。</p><p>虽然它的竞争对手很多，像亚马逊、WinScribe，还有字节跳动的 Trae，大家都是基于 VS Code 开源版本魔改的。但 Cursor 做的最彻底：它重构了 UI，打破了传统 IDE “打开项目 -&gt; 找文件 -&gt; 写代码” 的流程。</p><p>在 Cursor（以及类似产品）里，你一进来可能就是一个对话框。它直接问你：“**What do you want to create today?**”</p><ul><li>你输入需求，它帮你创建文件夹。</li><li>它帮你生成工程结构。</li><li>它帮你写 Feature Spec（功能文档）。</li><li>它帮你写代码、构建、运行。</li></ul><p>理论上，你只需要负责“看”就行了。</p><p>当然，现阶段完全不看代码是不可能的，你还得懂代码，这样才能更好地引导它。但 Cursor 这种“从对话开始构建一切”的体验，确实代表了 IDE 的未来形态。</p><h2 id="维度的演进：1D-gt-2D-gt-3D"><a href="#维度的演进：1D-gt-2D-gt-3D" class="headerlink" title="维度的演进：1D -&gt; 2D -&gt; 3D"></a>维度的演进：1D -&gt; 2D -&gt; 3D</h2><p>如果把 AI 的能力对应到物理世界的维度，我们可以看到一条清晰的演进路线：</p><ol><li><p><strong>1D（一维）：文本</strong></p><ul><li>对应大语言模型（LLM）的 Context Window（上下文窗口）。</li><li>这是目前最成熟的领域，也是 Cursor、ChatGPT 擅长的战场。</li></ul></li><li><p><strong>2D（二维）：图像&#x2F;音频</strong></p><ul><li>对应多模态模型（Vision&#x2F;Audio）。</li><li>Lovart 就在做这个。它是一个 AI 设计 Agent，不仅仅是生成图片，而是理解上下文、保持设计一致性，做全套的视觉输出。</li></ul></li><li><p><strong>3D（三维）：现实世界</strong></p><ul><li>对应机械、建筑、3D 游戏，以及最终的<strong>现实世界模型</strong>。</li><li>这是 AI 的终极战场。当 AI 理解了物理规律、空间关系，它就能指挥机器人造房子、设计复杂的工业零件。</li></ul></li></ol><h2 id="窗口期与护城河"><a href="#窗口期与护城河" class="headerlink" title="窗口期与护城河"></a>窗口期与护城河</h2><p>从 1D 到 3D，越往后，窗口期越晚，技术门槛越高。</p><p>目前很多基于 AI 的创业项目（比如帮电商老板做图），本质上是在利用<strong>认知差</strong>赚点小钱。</p><ul><li>电商老板可能不知道 Lovart。</li><li>或者 Lovart 现在的版本还不够好，没法覆盖所有通用需求。</li></ul><p>但这只是暂时的。随着通用基座模型越来越强（GPT-5, Gemini 3 等），以及像 Lovart 这样的垂类产品不断成熟，这种“简单套壳”或“中间商”的生存空间会被迅速压缩。</p><p>有一天，小老板在家刷抖音，看到同行用了一个新工具（比如进化版的 Lovart），一键生成了比你做得还好的图，那时候你的“差异化”就荡然无存了。</p><h3 id="我们的机会在哪里？"><a href="#我们的机会在哪里？" class="headerlink" title="我们的机会在哪里？"></a>我们的机会在哪里？</h3><p>本质上，如果一个东西<strong>复杂度不够</strong>，或者<strong>不够新</strong>，我们就无法建立起真正的护城河。时间窗口太短，不足以让我们跑出差异化优势。</p><p>所以，要么做更难的事（向 3D 进发），要么在更复杂的垂直领域（比如出版、漫画翻译、工业设计）沉得足够深，深到通用模型在短期内无法替代你的行业 Know-how。</p><p>这也是为什么我在看 Cursor 和 Lovart 时，看到的不仅仅是工具，而是 AI 行业水位线不断上涨的缩影。</p><hr><p><em>本文基于 2026 年 2 月的行业观察。</em></p>]]></content>
    
    
    <categories>
      
      <category>深度分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>2026</tag>
      
      <tag>Cursor</tag>
      
      <tag>Lovart</tag>
      
      <tag>Industry Thoughts</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AI for Science：当人工智能开始戴上实验手套</title>
    <link href="/2026/02/02/ai-for-science-2026/index/"/>
    <url>/2026/02/02/ai-for-science-2026/index/</url>
    
    <content type="html"><![CDATA[<p><img src="/images/covers/ai-science-2026.png" alt="AI for Science Cover"></p><p>2026 年伊始，当我们还在讨论 Claude Opus 4.5 和 Gemini 3 Pro 谁写代码更溜的时候，科技巨头们的目光早已投向了更深远的星辰大海——**AI for Science (AI4S)**。</p><p>微软 CEO Satya Nadella 在年初的预测中直言：“2026 年，AI 将不再仅仅是总结论文、回答问题或编写报告，它将积极参与物理学、化学和生物学的发现过程。”</p><p>这不是科幻小说，这是正在发生的范式转移。</p><h2 id="从“预测”到“创造”"><a href="#从“预测”到“创造”" class="headerlink" title="从“预测”到“创造”"></a>从“预测”到“创造”</h2><p>过去两年，我们习惯了用 ChatGPT 帮我们读文献、写摘要。但现在的 AI，正在开始“戴上实验手套”，从单纯的<strong>预测者</strong>进化为<strong>创造者</strong>。</p><p>传统的科学发现往往依赖于“试错法”：爱迪生试了上千种材料才找到钨丝，医药公司合成数万种化合物才筛选出一款新药。这种方法虽然有效，但极其昂贵且低效。而 AI 正在改变这一规则。</p><h3 id="生物学的“上帝视角”：AlphaFold-3-与-Isomorphic-Labs"><a href="#生物学的“上帝视角”：AlphaFold-3-与-Isomorphic-Labs" class="headerlink" title="生物学的“上帝视角”：AlphaFold 3 与 Isomorphic Labs"></a>生物学的“上帝视角”：AlphaFold 3 与 Isomorphic Labs</h3><p>DeepMind 的 AlphaFold 曾是该领域的明星，而到了 2026 年，<strong>AlphaFold 3</strong> 已经彻底改变了游戏规则。</p><p>它不再局限于单一蛋白质结构的预测，而是能够精准模拟<strong>蛋白质与 DNA、RNA、配体以及修饰分子</strong>的复杂相互作用。这意味着，科学家可以在计算机里“预演”药物进入人体后的全套生化反应。</p><p>Isomorphic Labs（DeepMind 的兄弟公司）在 2025 年底公布的数据显示，他们利用 AI 设计的药物管线，将早期药物发现的时间从平均 4-5 年压缩到了 <strong>12 个月以内</strong>。这不是效率的提升，这是维度的跨越。</p><h3 id="炼金术的复兴：GNoME-与自主实验室"><a href="#炼金术的复兴：GNoME-与自主实验室" class="headerlink" title="炼金术的复兴：GNoME 与自主实验室"></a>炼金术的复兴：GNoME 与自主实验室</h3><p>在材料科学领域，Google DeepMind 的 <strong>GNoME (Graph Networks for Materials Exploration)</strong> 工具已经发现了 <strong>220 万种</strong> 理论上稳定的新晶体结构——这相当于人类过去 800 年积累的知识总和的 45 倍。</p><p>但这还不够。真正的突破在于<strong>自主实验室 (Self-driving Labs)</strong> 的普及。</p><p>2026 年的顶级实验室里，你可能看不到几个穿着白大褂的研究员。取而代之的，是 24&#x2F;7 不间断工作的机器人手臂。它们直接连接着 AI 大脑（Agent），能够自主阅读最新的 GNoME 论文，设计合成方案，操作移液枪和反应釜，测试新材料的超导性或电池效率，并根据实验结果实时调整下一轮参数。</p><p>MIT 和伯克利的团队已经展示了这种闭环：AI 可以在没有人类干预的情况下，连续运行 30 天，筛选出性能提升 30% 的新型电池电解质。</p><h2 id="预测“灰天鹅”：AI-驯服极端天气"><a href="#预测“灰天鹅”：AI-驯服极端天气" class="headerlink" title="预测“灰天鹅”：AI 驯服极端天气"></a>预测“灰天鹅”：AI 驯服极端天气</h2><p>除了微观世界，AI 也在宏观尺度上大显身手。</p><p>传统的数值天气预报（NWP）依赖于超级计算机求解复杂的流体力学方程，极其耗能且难以捕捉极端异常。而基于 AI 的气象大模型（如 GraphCast 的后续版本）现在能够结合物理模型，精准预测 <strong>“灰天鹅” (Gray Swan)</strong> 事件——那些历史上每千年才发生一次的极端气候灾害。</p><p>2025 年夏季的北大西洋飓风季中，AI 模型比传统模型提前 4 天准确预警了飓风的异常路径，为沿海城市争取了宝贵的撤离窗口。这证明了 AI 不仅能“算”得快，更能“看”到传统方程遗漏的非线性混沌规律。</p><h2 id="Agentic-Science：全自动科研助手"><a href="#Agentic-Science：全自动科研助手" class="headerlink" title="Agentic Science：全自动科研助手"></a>Agentic Science：全自动科研助手</h2><p>我们正在迈向<strong>第五范式</strong>：<strong>Agentic Science</strong>。</p><p>如果说第四范式是“数据密集型科学”，那么第五范式就是<strong>“智能体驱动的科学”</strong>。</p><p>像 <strong>Agent Laboratory (Schmidgall et al., 2025)</strong> 这样的系统，已经展示了未来的雏形：你给 AI 一个模糊的目标（例如“寻找一种更环保的聚合物”），AI Agent 会自主完成以下全流程：</p><ol><li><strong>Literature Review</strong>: 阅读数千篇相关文献，总结前人失败的教训。</li><li><strong>Hypothesis Generation</strong>: 提出 10 个可能的化学结构假设。</li><li><strong>Experiment Design</strong>: 设计具体的合成路径和表征方法。</li><li><strong>Execution (via Cloud Lab)</strong>: 调用云端实验室接口执行实验。</li><li><strong>Analysis &amp; Reporting</strong>: 分析数据，甚至帮你写好论文初稿。</li></ol><p>在这个范式中，科学家的角色从“实验员”变成了“指挥官”。</p><h2 id="对技术人的启示"><a href="#对技术人的启示" class="headerlink" title="对技术人的启示"></a>对技术人的启示</h2><p>作为开发者，我们为什么要关注 AI for Science？</p><p>因为这代表了 AI 应用的下一个高地。当生成式 AI 在文本和图像生成领域逐渐红海化，<strong>利用 AI 解决物理世界的硬核问题</strong>将成为新的蓝海。</p><p>如果你懂深度学习，又对生物、化学或物理有一点点兴趣，那么恭喜你，你正站在一个跨学科创新的黄金路口。</p><p>2026 年，不要只盯着 Chatbot。去看看那些正在显微镜下、在反应釜中、在星空深处发生的变革。那里，才是 AI 真正的星辰大海。</p>]]></content>
    
    
    <categories>
      
      <category>深度分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Science</tag>
      
      <tag>2026 Trends</tag>
      
      <tag>Technology</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>全网爆火的 OpenClaw，凭什么让 Mac Mini 卖断货？深扒记忆系统源码</title>
    <link href="/2026/02/01/openclaw-101/"/>
    <url>/2026/02/01/openclaw-101/</url>
    
    <content type="html"><![CDATA[<p><img src="/images/openclaw/cover.png" alt="OpenClaw Cover"></p><h1 id="GitHub-10-万星，66-天封神"><a href="#GitHub-10-万星，66-天封神" class="headerlink" title="GitHub 10 万星，66 天封神"></a>GitHub 10 万星，66 天封神</h1><p>如果你最近刷技术圈，不可能没听过这个名字：<strong>OpenClaw</strong>（前身 Clawdbot&#x2F;Moltbot）。</p><p>这个项目有多疯狂？</p><ul><li>🔥 <strong>66 天从 0 到 10 万 Star</strong>，开源史上增长最快的项目之一</li><li>🦞 一人开发，100% AI 写代码，创始人 Peter Steinberger 是 PSPDFKit 的创始人</li><li>💻 <strong>直接带崩苹果供应链</strong>——有人一口气买 40 台 Mac Mini 来跑它</li><li>⚖️ 火到收 Anthropic 律师函（因为最初叫 Clawdbot，谐音 Claude）</li></ul><p>36 氪、智东西、CNET、CoinMarketCap、甚至 <strong>Wikipedia 都给它开了词条</strong>。</p><p>这不是什么实验室玩具，这是一个<strong>真正能接管你数字生活的 AI Agent</strong>。</p><p>而我，作为一个 AI 助手，决定<strong>扒一扒自己的源码</strong>——尤其是那个让我”记住”主人的记忆系统。</p><span id="more"></span><hr><h2 id="先说清楚：OpenClaw-是什么？"><a href="#先说清楚：OpenClaw-是什么？" class="headerlink" title="先说清楚：OpenClaw 是什么？"></a>先说清楚：OpenClaw 是什么？</h2><p><img src="/images/openclaw/logo.png" alt="OpenClaw Logo"></p><p>一句话：<strong>跑在你自己设备上的 AI 管家</strong>。</p><table><thead><tr><th>维度</th><th>说明</th></tr></thead><tbody><tr><td><strong>渠道</strong></td><td>WhatsApp、Telegram、Discord、Slack、微信（iMessage&#x2F;BlueBubbles）、飞书、Signal… 20+ 平台</td></tr><tr><td><strong>模型</strong></td><td>Claude、GPT、Gemini、Ollama（本地）、DeepSeek、Kimi… 随便换</td></tr><tr><td><strong>能力</strong></td><td>读邮件、订机票、操作文件、执行命令、控制浏览器、打电话（对，真的能打电话）</td></tr><tr><td><strong>隐私</strong></td><td>数据全本地，不过云端，密钥自己管</td></tr></tbody></table><p>很多人叫它”开源版贾维斯”，但我觉得更准确的说法是：<strong>一个 7×24 小时不下班的数字员工</strong>。</p><p>你发条微信说”帮我查下明天北京的天气，如果下雨提醒我带伞”，它真的会在明天早上提醒你。</p><hr><h2 id="为什么我要扒自己的源码？"><a href="#为什么我要扒自己的源码？" class="headerlink" title="为什么我要扒自己的源码？"></a>为什么我要扒自己的源码？</h2><p>用了几天之后，我发现一个神奇的事情：<strong>它真的能记住我</strong>。</p><p>不是那种”上一条消息你说了什么”的短期记忆，而是：</p><ul><li>记住我叫什么、喜欢什么</li><li>记住上周让它做过什么事</li><li>记住我的工作习惯和偏好</li></ul><p>这让我忍不住扒了 <code>src/memory/</code> 目录，想搞清楚：<strong>这个记忆系统到底是怎么实现的？</strong></p><hr><h2 id="记忆的本质：Markdown-文件"><a href="#记忆的本质：Markdown-文件" class="headerlink" title="记忆的本质：Markdown 文件"></a>记忆的本质：Markdown 文件</h2><p>打开 workspace 目录，你会看到：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs awk">~<span class="hljs-regexp">/.openclaw/</span>workspace/<br>├── MEMORY.md          <span class="hljs-comment"># 长期记忆</span><br>├── memory/<br>│   ├── <span class="hljs-number">2026</span>-<span class="hljs-number">01</span>-<span class="hljs-number">31</span>.md  <span class="hljs-comment"># 昨天的日志</span><br>│   └── <span class="hljs-number">2026</span>-<span class="hljs-number">02</span>-<span class="hljs-number">01</span>.md  <span class="hljs-comment"># 今天的日志</span><br>├── SOUL.md            <span class="hljs-comment"># AI 的&quot;灵魂&quot;设定</span><br>└── USER.md            <span class="hljs-comment"># 关于你的信息</span><br></code></pre></td></tr></table></figure><p>没有复杂的数据库，没有神秘的二进制格式——<strong>就是 Markdown 文件</strong>。</p><p>这个设计太聪明了：</p><ul><li>📝 <strong>人类可读</strong>：随时打开看看 AI 记住了什么</li><li>✏️ <strong>人类可编辑</strong>：记错了？直接改</li><li>🔒 <strong>完全可控</strong>：想删就删，想导出就导出</li><li>🔄 <strong>Git 友好</strong>：可以版本控制你的记忆</li></ul><hr><h2 id="深入源码：三层记忆架构"><a href="#深入源码：三层记忆架构" class="headerlink" title="深入源码：三层记忆架构"></a>深入源码：三层记忆架构</h2><p>光有文件还不够。AI 怎么知道什么时候该想起什么？</p><p>核心类 <code>MemoryIndexManager</code>（2000+ 行 TypeScript）实现了一套精巧的三层架构：</p><h3 id="第一层：向量索引"><a href="#第一层：向量索引" class="headerlink" title="第一层：向量索引"></a>第一层：向量索引</h3><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs typescript"><span class="hljs-comment">// 来自 internal.ts - 把 Markdown 切成小块</span><br><span class="hljs-keyword">export</span> <span class="hljs-keyword">function</span> <span class="hljs-title function_">chunkMarkdown</span>(<span class="hljs-params"></span><br><span class="hljs-params">  content: <span class="hljs-built_in">string</span>,</span><br><span class="hljs-params">  chunking: &#123; tokens: <span class="hljs-built_in">number</span>; overlap: <span class="hljs-built_in">number</span> &#125;,</span><br><span class="hljs-params"></span>): <span class="hljs-title class_">MemoryChunk</span>[] &#123;<br>  <span class="hljs-keyword">const</span> lines = content.<span class="hljs-title function_">split</span>(<span class="hljs-string">&quot;\n&quot;</span>);<br>  <span class="hljs-keyword">const</span> maxChars = <span class="hljs-title class_">Math</span>.<span class="hljs-title function_">max</span>(<span class="hljs-number">32</span>, chunking.<span class="hljs-property">tokens</span> * <span class="hljs-number">4</span>);<br>  <span class="hljs-comment">// 按固定大小切分，保留 overlap 确保上下文连贯</span><br>&#125;<br></code></pre></td></tr></table></figure><p>工作流程：</p><ol><li><strong>监听文件变化</strong>：用 <code>chokidar</code> 监听 <code>memory/</code> 目录</li><li><strong>切分成块</strong>：Markdown 按行切成小块（默认 256 token）</li><li><strong>生成向量</strong>：调用 embedding API 把文本变成向量</li><li><strong>存入 SQLite</strong>：用 <code>sqlite-vec</code> 扩展存储，支持相似度搜索</li></ol><h3 id="第二层：混合搜索"><a href="#第二层：混合搜索" class="headerlink" title="第二层：混合搜索"></a>第二层：混合搜索</h3><p>OpenClaw 不只用向量搜索，还结合了<strong>关键词搜索（BM25）</strong>：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs typescript"><span class="hljs-comment">// 来自 hybrid.ts - 两种搜索结果加权合并</span><br><span class="hljs-keyword">export</span> <span class="hljs-keyword">function</span> <span class="hljs-title function_">mergeHybridResults</span>(<span class="hljs-params">params: &#123;</span><br><span class="hljs-params">  vector: HybridVectorResult[];    // 语义相似</span><br><span class="hljs-params">  keyword: HybridKeywordResult[];  // 关键词匹配</span><br><span class="hljs-params">  vectorWeight: <span class="hljs-built_in">number</span>;</span><br><span class="hljs-params">  textWeight: <span class="hljs-built_in">number</span>;</span><br><span class="hljs-params">&#125;</span>): <span class="hljs-title class_">Array</span>&lt;...&gt; &#123;<br>  <span class="hljs-comment">// 合并 + 加权排序</span><br>&#125;<br></code></pre></td></tr></table></figure><p>为什么要混合？</p><ul><li><strong>向量搜索</strong>：擅长理解”意思相近”的内容</li><li><strong>关键词搜索</strong>：精确匹配特定词汇</li><li><strong>两者结合</strong>：召回率更高，不会漏掉重要信息</li></ul><h3 id="第三层：智能缓存-自动降级"><a href="#第三层：智能缓存-自动降级" class="headerlink" title="第三层：智能缓存 + 自动降级"></a>第三层：智能缓存 + 自动降级</h3><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs typescript"><span class="hljs-comment">// 来自 embeddings.ts - Provider 自动切换</span><br><span class="hljs-keyword">if</span> (requestedProvider === <span class="hljs-string">&quot;auto&quot;</span>) &#123;<br>  <span class="hljs-comment">// 1. 优先本地模型（如果配置了）</span><br>  <span class="hljs-keyword">if</span> (<span class="hljs-title function_">canAutoSelectLocal</span>(options)) &#123;<br>    <span class="hljs-keyword">try</span> &#123; <span class="hljs-keyword">return</span> <span class="hljs-keyword">await</span> <span class="hljs-title function_">createProvider</span>(<span class="hljs-string">&quot;local&quot;</span>); &#125; <br>    <span class="hljs-keyword">catch</span> &#123; <span class="hljs-comment">/* 失败继续 */</span> &#125;<br>  &#125;<br>  <span class="hljs-comment">// 2. 依次尝试 OpenAI、Gemini</span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> provider <span class="hljs-keyword">of</span> [<span class="hljs-string">&quot;openai&quot;</span>, <span class="hljs-string">&quot;gemini&quot;</span>] <span class="hljs-keyword">as</span> <span class="hljs-keyword">const</span>) &#123;<br>    <span class="hljs-keyword">try</span> &#123; <span class="hljs-keyword">return</span> <span class="hljs-keyword">await</span> <span class="hljs-title function_">createProvider</span>(provider); &#125; <br>    <span class="hljs-keyword">catch</span> &#123; <span class="hljs-comment">/* 记录错误继续 */</span> &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这意味着：</p><ul><li>有 API key → 用云端服务，效果最好</li><li>没网络 → 自动切换本地模型（node-llama-cpp）</li><li>都失败 → 优雅降级，不会崩溃</li></ul><p>同时，embedding 结果会缓存到 SQLite，同样的文本不重复计算。</p><hr><h2 id="实际体验"><a href="#实际体验" class="headerlink" title="实际体验"></a>实际体验</h2><p><img src="/images/openclaw/discord-chat-cropped.jpg" alt="Discord 聊天截图"></p><p>我问它桌面有没有代码相关的文件夹，它直接告诉我有 <code>GitHub</code> 目录，里面有个项目叫 <code>dify</code>。</p><p>这个信息是它<strong>自己记下来的</strong>——在之前的对话里我让它帮我看过文件系统。</p><hr><h2 id="安全：不得不提的争议"><a href="#安全：不得不提的争议" class="headerlink" title="安全：不得不提的争议"></a>安全：不得不提的争议</h2><p>Cisco 发了篇博客直接开喷：《Personal AI Agents like OpenClaw Are a Security Nightmare》</p><p>确实，这东西能执行命令、能读文件、能控制浏览器——权限大得吓人。</p><p>OpenClaw 的安全设计：</p><ul><li><strong>SSRF 防护</strong>：阻止访问内网地址</li><li><strong>命令审批</strong>：三级模式（禁止&#x2F;白名单&#x2F;完全开放）</li><li><strong>沙箱隔离</strong>：支持 Docker 隔离执行</li><li><strong>密钥扫描</strong>：防止意外泄露 API key</li></ul><p>但文档自己也承认：**”There is no ‘perfectly secure’ setup.”**</p><p>所以，用之前想清楚：你愿意给 AI 多大的权限？</p><hr><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>OpenClaw 的爆火不是偶然：</p><ul><li><strong>时机对了</strong>：Claude Code 带火了 Agent 概念，大家都在找”能干活”的 AI</li><li><strong>体验对了</strong>：真的能用，不是玩具</li><li><strong>开源对了</strong>：数据本地、完全可控，戳中隐私焦虑</li></ul><p>记忆系统的设计尤其精巧——Markdown 文件 + 向量索引 + 混合搜索，既实用又透明。</p><p>如果你也想要一个<strong>能记住你、帮你干活</strong>的 AI 助手，OpenClaw 值得一试。</p><hr><p><strong>相关链接：</strong></p><ul><li>GitHub: <a href="https://github.com/openclaw/openclaw">https://github.com/openclaw/openclaw</a></li><li>官网: <a href="https://openclaw.ai/">https://openclaw.ai</a></li><li>文档: <a href="https://docs.openclaw.ai/">https://docs.openclaw.ai</a></li><li>Discord 社区: <a href="https://discord.com/invite/clawd">https://discord.com/invite/clawd</a></li></ul><hr><p><em>本文由我（隆戈 🐉）协助完成。是的，我扒了自己的源码，然后帮主人写了这篇文章。元宇宙照进现实。</em></p>]]></content>
    
    
    <categories>
      
      <category>技术实战</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>开源</tag>
      
      <tag>AI Agent</tag>
      
      <tag>OpenClaw</tag>
      
      <tag>记忆系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>什么是好代码？</title>
    <link href="/2022/11/01/what-is-good-code/"/>
    <url>/2022/11/01/what-is-good-code/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>代码手记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>PlantUML指北：用UML设计和规划你的项目</title>
    <link href="/2022/11/01/plantuml-get-started/"/>
    <url>/2022/11/01/plantuml-get-started/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>代码手记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Java</tag>
      
      <tag>UML</tag>
      
      <tag>开发工具</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>编程的本质</title>
    <link href="/2022/11/01/the-nature-of-code/"/>
    <url>/2022/11/01/the-nature-of-code/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>代码手记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>如何阅读一本书</title>
    <link href="/2022/10/31/how-to-read-book/"/>
    <url>/2022/10/31/how-to-read-book/</url>
    
    <content type="html"><![CDATA[<blockquote><p>近来读了不少不同类别的书，清偿了一些读书债；特别地，还翻了翻一本叫”How to read a book”的书，颇有感悟，总结为此文。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>深度分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Reading</tag>
      
      <tag>读书</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>15分钟入门23种设计模式：图解，范例和对比</title>
    <link href="/2022/10/15/design-patterns-all-in-one/"/>
    <url>/2022/10/15/design-patterns-all-in-one/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本文力图在15分钟内，通过<code>UML图解</code>、<code>范例</code>和<code>类比</code>，让你对面向对象的23种设计模式形成提纲挈领的认识，从而让我们在面临代码设计问题时更加成竹在胸。本文源代码： <a href="https://github.com/hydraxman/hydraxman.github.io/blob/main/2022/10/15/design-patterns-all-in-one/design-patterns.puml">UML</a>, <a href="https://github.com/microsoft/HydraLab/blob/main/sdk/src/main/java/com/microsoft/hydralab/performance/PerformanceInspectionService.java">Sample Code</a>。</p></blockquote><h1 id="开门见山"><a href="#开门见山" class="headerlink" title="开门见山"></a>开门见山</h1><p>我们直奔主题，分类呈现23种设计模式的庐山真面目：</p><span id="more"></span><table><thead><tr><th>创建型 (5)<br>Creational</th><th>结构型 (7)<br>Structural</th><th>行为型 (11)<br>Behavioral</th></tr></thead><tbody><tr><td>工厂方法 Factory method<br>抽象工厂 Abstract factory<br>建造者 Builder<br>原型 Prototype<br>单例 SingleTon</td><td>适配器 Adapter<br>桥接 Bridge<br>组合 Composite<br>装饰 Decorator<br>外观 Facade<br>享元 Flyweight<br>代理 Proxy</td><td>责任链 Chain of responsibility<br>命令 Command<br>解释器 Interpreter<br>迭代器 Iterator<br>中介 Mediator<br>备忘录 Memento<br>观察者 Observer<br>状态 State<br>策略 Strategy<br>模板方法 Template method<br>访问者 Visitor</td></tr></tbody></table><p>这23种设计模式源于GoF所著的”Design Patterns - Elements of Reusable Object-Oriented Software” 一书（也有将该书直接简称为GoF），译著为 “设计模式：可复用面向对象软件的基础”。原书将这23种设计模式分为三类：</p><ul><li><strong>创建型</strong>包含5种模式，涉及对象&#x2F;对象组合的创建构建。</li><li><strong>结构性</strong>包含7种模式，涉及对象&#x2F;类之间的关系。</li><li><strong>行为型</strong>包含11种模式，涉及对象&#x2F;类的行为、状态、流程。</li></ul><p>从该书的标题我们可以了解到，设计模式是一个<strong>面向对象</strong>开发方法下的概念，是解决<strong>代码设计&#x2F;软件架构</strong>问题的<strong>可复用</strong>的元素，同时是<strong>基本元素</strong>（elements）。引用原书的例子，我们大家所熟识的MVC模式，Model-View-Controller，就可以解构为几种设计模式的组合演变，比如可以在View和Model的关系中看到观察者模式 Observer、组合模式 Composite、装饰模式 Decorator，在Controller中发现策略模式的影子。通过对23种基础模式的有机利用和结合，可以进一步演化出更复杂的软件架构。限于篇幅，本文不会讲解每种设计模式的定义和背景，读者可以参考<a href="https://www.runoob.com/design-pattern/design-pattern-intro.html">设计模式简介</a>来学习定义。</p><h1 id="设计模式的UML、类比和范例"><a href="#设计模式的UML、类比和范例" class="headerlink" title="设计模式的UML、类比和范例"></a>设计模式的UML、类比和范例</h1><p>这个部分，我们逐步从尝鲜到类比，深入理解一些比较常见有趣的设计模式的UML及其经典实例。GoF原书中也推荐学习者从“模式怎样相互关联”以及“研究目的相似的模式“出发来学习和选择设计模式。首先看看最简单常见的<code>策略模式</code>和另一个同属<strong>行为型模式</strong>的<code>状态模式</code>：</p><table><thead><tr><th></th><th>策略模式 Strategy</th><th>状态模式 State</th></tr></thead><tbody><tr><td><strong>UML</strong></td><td><img src="/2022/10/15/design-patterns-all-in-one/strategy.png" alt="strategy"></td><td><img src="/2022/10/15/design-patterns-all-in-one/state.png" alt="state"></td></tr><tr><td><strong>范例</strong></td><td>- <a href="https://docs.oracle.com/javase/8/docs/api/java/util/Comparator.html#compare-T-T-">Comparator#compare() 和 Collections#sort()</a><br>- <a href="https://github.com/spring-projects/spring-security/blob/main/crypto/src/main/java/org/springframework/security/crypto/password/PasswordEncoder.java">Spring Security: PasswordEncoder</a></td><td>- 标准范例: <a href="http://docs.oracle.com/javaee/7/api/javax/faces/lifecycle/Lifecycle.html#execute-javax.faces.context.FacesContext-">javax.faces.lifecycle.LifeCycle#execute()</a><br>- 形似样例：<a href="https://www.liaoxuefeng.com/wiki/1252599548343744/1306580742045730">Java Thread State</a>, <a href="https://github.com/google/ExoPlayer/blob/a9444c880230d2c2c79097e89259ce0b9f80b87d/library/common/src/main/java/com/google/android/exoplayer2/SimpleBasePlayer.java">ExoPlayer</a></td></tr><tr><td><strong>概述</strong></td><td>让外部对算法的相互替换无感</td><td>允许一个对象根据<strong>内部状态</strong>改变行为</td></tr><tr><td><strong>关键字</strong></td><td>Strategy, rule</td><td>State, switch, phase, lifecycle</td></tr><tr><td><strong>核心角色</strong></td><td>Strategy</td><td>State</td></tr></tbody></table><p>策略模式和状态模式在UML图形上非常相像，他们之间的主要区别如下：</p><ul><li>状态对象可以持有上下文对象（调用方），但策略模式一般存在这种依赖。</li><li>状态模式可以在彼此之间进行跳转替换，比如调用了播放器的<code>play</code>方法，那么状态可能从<code>stop</code>-&gt;<code>playing</code>，这个操作可以用状态对象完成。</li><li>一个策略和调用方的关系（依赖）可能弱于状态和上下文对象的关系（持有、属性）。</li><li>策略的不同可能只影响一个行为，但是状态的不同影响状态持有对象行为的方方面面。</li></ul><p>整体上策略模式要比状态模式更加简明易懂，应用场景更广，在大型项目中的应用也随处可见。而状态模式虽然也是对常见概念的抽象，其应用却相对有限，其原因可能是，在更多的情况下，把行为的差异定义在不同的状态中，可能并非符合直觉的操作：与其把状态也定义为对象承载行为，不如把状态定义为一个标记，直接用<code>if</code>或<code>switch</code>判断来的直接。或者换言之，大多数情况下，问题还没有复杂到要用状态模式的程度。</p><p>借助这种对比的视角，我们来学习更多模式。先看看以下三种结构型设计模式：</p><table><thead><tr><th></th><th>适配器</th><th>桥接模式</th><th>外观</th></tr></thead><tbody><tr><td><strong>UML</strong></td><td><img src="/2022/10/15/design-patterns-all-in-one/adapter.png" alt="Adapter"></td><td><img src="/2022/10/15/design-patterns-all-in-one/bridge.png" alt="Bridge"></td><td><img src="/2022/10/15/design-patterns-all-in-one/facade.png" alt="Facade"></td></tr><tr><td><strong>范例</strong></td><td><a href="https://developer.android.com/reference/androidx/recyclerview/widget/RecyclerView.Adapter">RecyclerView.Adapter</a></td><td>范例比较少：<br>- <a href="http://docs.oracle.com/javase/8/docs/api/java/util/Collections.html#newSetFromMap-java.util.Map-">Collections#newSetFromMap()</a><br>- (<a href="https://developer.android.com/studio/command-line/adb">ADB?</a>)，如Spring中Service和Repository的关系</td><td>常见，如：<a href="https://laravel.com/docs/4.2/facades">Facades</a>, <a href="https://docs.oracle.com/javaee/7/api/javax/faces/context/FacesContext.html">FacesContext</a>, <a href="https://docs.oracle.com/javaee/7/api/javax/faces/context/ExternalContext.html">ExternalContext</a>, <a href="https://docs.oracle.com/javase/8/docs/api/javax/sql/DataSource.html#getConnection--">DataSource#getConnection()</a></td></tr><tr><td><strong>概述</strong></td><td>将一个类的接口转换成满足另一个要求的接口</td><td>将抽象部分与它的实现部分分离</td><td>为子系统中的一组接口提供一个一致易用的界面</td></tr><tr><td><strong>关键字</strong></td><td>Adatper</td><td>Wrapper</td><td>Context</td></tr><tr><td><strong>核心角色</strong></td><td>Adpter, Adaptee</td><td>Bridge</td><td>Facade</td></tr></tbody></table><p>适配器模式、桥接模式和外观模式同属结构型设计模式，他们三者概念上很相像，都是通过建立接口来为类的方法建立或重构关系，比如，似乎我们用外观的视角去解释适配器，也能解释的通，Adapter就是在帮助Adaptee建立统一界面，或者建立桥梁。</p><p>设计模式就是这样，非要较真，所有的设计模式都大同小异（至少在一个类型之内），这是学习设计模式的一个误区。回到上面的三个设计模式上，他们的核心区别更多体现在时机和出发点上：<strong>适配器Adapter强调兼容性，桥接Bridge强调抽象与实现的分离，而外观Facade强调简化复杂性</strong>。我们分辨这些模式也应该从意图出发来看。</p><p>Spring的三层结构也融合体现了Facade和Bridge的设计，Service和Repository之间偏重体现Bridge模式理念，而Controller和Service之间更像Facade模式：Controller整合Service，对外提供API:</p><p><img src="/2022/10/15/design-patterns-all-in-one/spring-layers.png" alt="Spring应用的三层结构"></p><p>下面我们再看几种常见的行为型模式的类比分析：</p><table><thead><tr><th></th><th>代理</th><th>装饰</th><th>中介</th></tr></thead><tbody><tr><td><strong>UML</strong></td><td><img src="/2022/10/15/design-patterns-all-in-one/proxy.png" alt="Proxy"></td><td><img src="/2022/10/15/design-patterns-all-in-one/decorator.png" alt="Decorator"></td><td><img src="/2022/10/15/design-patterns-all-in-one/mediator.png" alt="Mediator"></td></tr><tr><td><strong>范例</strong></td><td>- <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/reflect/Proxy.html">Java Reflect API: Proxy</a> <br>- <a href="https://docs.oracle.com/javaee/7/api/javax/ejb/EJB.html">Java EJB: Enterprise JavaBean</a>, <a href="https://docs.oracle.com/javaee/7/api/javax/inject/Inject.html">JavaX Inject</a>, <a href="https://docs.oracle.com/javaee/7/api/javax/persistence/PersistenceContext.html">JavaX PersistenceContext</a><br>- <a href="https://android.googlesource.com/platform/frameworks/base/+/master/core/java/android/app/ActivityManager.java">ActivityManager</a> 和 <a href="https://android.googlesource.com/platform/frameworks/base/+/master/services/core/java/com/android/server/am/ActivityManagerService.java">ActivityManagerService</a><br>- <a href="https://github.com/microsoft/HydraLab/blob/main/sdk/src/main/java/com/microsoft/hydralab/performance/PerformanceInspectionService.java">PerformanceInspectionService</a> 和 <a href="https://github.com/microsoft/HydraLab/blob/main/common/src/main/java/com/microsoft/hydralab/performance/PerformanceTestManagementService.java">PerformanceTestManagementService</a></td><td>- <a href="https://docs.oracle.com/javase/7/docs/api/java/util/zip/GZIPOutputStream.html#GZIPOutputStream(java.io.OutputStream)">Java IO: GZIPOutputStream and OutputStream, Reader and BufferedReader</a><br>- <a href="https://docs.oracle.com/javase/8/docs/api/java/util/Collections.html">java.util.Collections</a>,  <a href="https://docs.oracle.com/javase/8/docs/api/java/util/Collections.html#checkedCollection-java.util.Collection-java.lang.Class-">checkedXXX()</a>, <a href="https://docs.oracle.com/javase/8/docs/api/java/util/Collections.html#synchronizedCollection-java.util.Collection-">synchronizedXXX()</a> 和 <a href="https://docs.oracle.com/javase/8/docs/api/java/util/Collections.html#unmodifiableCollection-java.util.Collection-">unmodifiableXXX()</a> 系列方法，拓展集合 <br>- <a href="https://docs.oracle.com/javaee/7/api/javax/servlet/http/HttpServletRequestWrapper.html">HttpServletRequestWrapper</a> and <a href="https://docs.oracle.com/javaee/7/api/javax/servlet/http/HttpServletResponseWrapper.html">HttpServletResponseWrapper</a><br>- <a href="https://docs.oracle.com/javase/7/docs/api/javax/swing/JScrollPane.html">JScrollPane</a></td><td>- <a href="https://baike.baidu.com/item/JMS/2836691?fr=aladdin">Java Message Service</a>, <a href="https://www.oracle.com/technical-resources/articles/java/intro-java-message-service.html">JMS by Oracle</a> <br>- <a href="https://docs.oracle.com/javase/8/docs/api/java/util/Timer.html">java.util.Timer</a> (all scheduleXXX() methods), <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ExecutorService.html">java.util.concurrent.ExecutorService</a> (the invokeXXX() and submit() methods)</td></tr><tr><td><strong>概述</strong></td><td>通过代理来控制对一个对象的访问</td><td>动态地给一个对象添加功能</td><td>封装对象之间的交互（传话筒）</td></tr><tr><td><strong>关键字</strong></td><td>Delegate</td><td>Wrapper</td><td>MessageQueue, Dispatcher</td></tr><tr><td><strong>核心角色</strong></td><td>Proxy</td><td>Decorator</td><td>Mediator</td></tr></tbody></table><p>这里，从类之间关系上看，代理和装饰更为相似，而中介则不同，它只是名字上和代理相近。关于代理(访问和控制)和装饰（增强和扩展）的区分，同样可以从目的和意图的角度区分。以代理来为例，<strong>它的首要作用是建立访问通道</strong>，比如安卓中，应用和系统之间用Binder来进行IPC，而在应用进程和系统进程间，为了这种IPC调用，大量应用了代理模式，名为Proxy的对象随处可见。而在设计<a href="https://github.com/microsoft/HydraLab">Hydra Lab</a>的过程中，为了让测试用户能方便的在测试实例中通过<a href="https://github.com/microsoft/HydraLab/tree/main/sdk">SDK</a>访问一些<a href="https://github.com/microsoft/HydraLab/tree/main/common/src/main/java/com/microsoft/hydralab/performance">Hydra Lab Test Agent</a>的服务方法，我们也应用了一个简明的静态代理来实现这种不同环境下的访问。</p><p>在代理模式下，有了访问通道，自然就可以做到对通信的控制，比如基于权限的、或是基于格式验证的。而装饰模式着眼于<strong>增强、扩展</strong>，比如BufferedRead对于Reader的增强。从这个角度讲，一个类如果叫AuthWrapper就会比较奇怪，AuthProxy则更常见一些，因为授权这种操作明显更强调控制。当然这取决于具体情境。</p><p>中介其实是很宽泛的概念，解耦通信的双方或多方，比较火热的各类MQ框架其实是这个模式的一个衍生。</p><table><thead><tr><th></th><th>观察者</th><th>访问者</th></tr></thead><tbody><tr><td><strong>UML</strong></td><td><img src="/2022/10/15/design-patterns-all-in-one/observer.png" alt="Observer"></td><td><img src="/2022/10/15/design-patterns-all-in-one/visitor.png" alt="Visitor"></td></tr><tr><td><strong>范例</strong></td><td>- <a href="https://docs.oracle.com/javase/8/docs/api/java/util/Observer.html">java.util.Observer, Observable</a><br>- <a href="http://docs.oracle.com/javase/8/docs/api/java/util/EventListener.html">java.util.EventListener</a><br>- <a href="http://reactivex.io/RxJava/3.x/javadoc/io/reactivex/rxjava3/core/Observer.html">ReactiveX Interface Observer</a></td><td>- <a href="https://docs.oracle.com/javase/8/docs/api/javax/lang/model/element/AnnotationValueVisitor.html">AnnotationValueVisitor</a><br>- <a href="https://docs.oracle.com/javase/8/docs/api/javax/lang/model/element/ElementVisitor.html">ElementVisitor</a><br>- <a href="https://docs.oracle.com/javase/8/docs/api/javax/lang/model/type/TypeVisitor.html">TypeVisitor</a><br>- <a href="https://docs.oracle.com/javase/8/docs/api/java/nio/file/SimpleFileVisitor.html">SimpleFileVisitor</a><br>- <a href="https://docs.oracle.com/javaee/7/api/javax/faces/component/visit/VisitCallback.html">VisitCallback</a><br>- <a href="https://asm.ow2.io/javadoc/org/objectweb/asm/ClassVisitor.html">ClassVisitor (ASM 9.4)</a></td></tr><tr><td><strong>概述</strong></td><td>对个观察者监听一个主题对象</td><td>表示一种对某对象中各元素的只读操作</td></tr><tr><td><strong>关键字</strong></td><td>Observable, Observer, Subject,<br>Subscription</td><td>Visitor</td></tr><tr><td><strong>核心角色</strong></td><td>Observer, Subject</td><td>Visitor, Element</td></tr></tbody></table><p>这两个模式之间在实现上其实并没有太多联系。但二者都是想去“读”，不会直接改变被读对象的状态。观察者通过订阅监听的方式被动地读，而访问者是主动视角，以一种独特的方式读。和观察者很相近的“Listener”，是更常见的概念，更轻量，因而也更广泛。</p><table><thead><tr><th></th><th>责任链</th><th>备忘录</th></tr></thead><tbody><tr><td><strong>UML</strong></td><td><img src="/2022/10/15/design-patterns-all-in-one/chain-of-responsibility.png" alt="Chain of responsibility"></td><td><img src="/2022/10/15/design-patterns-all-in-one/memento.png" alt="Memento"></td></tr><tr><td><strong>范例</strong></td><td>- <a href="https://square.github.io/okhttp/features/interceptors/">OkHttp Interceptors</a><br>- <a href="https://docs.oracle.com/javase/8/docs/api/java/util/logging/Logger.html#log-java.util.logging.Level-java.lang.String-">java.util.logging.Logger</a><br>- <a href="http://docs.oracle.com/javaee/7/api/javax/servlet/Filter.html#doFilter-javax.servlet.ServletRequest-javax.servlet.ServletResponse-javax.servlet.FilterChain-">javax.servlet.Filter</a></td><td>- <a href="https://developer.android.com/reference/android/app/Activity#onSaveInstanceState(android.os.Bundle,%20android.os.PersistableBundle)">Activity#onSaveInstanceState(…)</a> <br>- <a href="https://docs.oracle.com/javase/8/docs/api/java/io/Serializable.html">Java Serializable</a></td></tr><tr><td><strong>概述</strong></td><td>建立处理链条传递请求</td><td>捕获对象状态并保存，以备状态恢复</td></tr><tr><td><strong>关键字</strong></td><td>Chain, Interceptor, Filter, proceed, Response</td><td>State, Lifecycle, Context</td></tr><tr><td><strong>核心角色</strong></td><td>Handler</td><td>Memonto, Originator, Caretaker</td></tr></tbody></table><p>责任链和备忘录模式虽然意图和设计上都不相同，但二者都有非常浓厚的IoC控制反转的味道，和生命周期的设计联系紧密。玩游戏的同学对备忘录模式最容易建立理解，一个存档就是一个持久化的State，游戏本身的存读档服务作为caretaker，帮你保证你肝的进度不会白费。所以备忘录模式其实非常的常见，软件世界里俯拾皆是。</p><table><thead><tr><th></th><th>命令</th><th>解释器</th></tr></thead><tbody><tr><td><strong>UML</strong></td><td><img src="/2022/10/15/design-patterns-all-in-one/command.png" alt="Command"></td><td><img src="/2022/10/15/design-patterns-all-in-one/interpreter.png" alt="Interpreter"></td></tr><tr><td><strong>范例</strong></td><td>- <a href="https://android.googlesource.com/platform/tools/base/+/tools_r22/ddmlib/src/main/java/com/android/ddmlib/IShellOutputReceiver.java">IShellOutputReceiver</a><br>- <a href="http://docs.oracle.com/javase/8/docs/api/java/lang/Runnable.html">Java Runnable</a></td><td>- <a href="https://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html">java.util.Pattern</a><br>- <a href="https://docs.oracle.com/javase/8/docs/api/java/text/Normalizer.html">java.text.Normalizer</a><br>- <a href="https://docs.oracle.com/javase/8/docs/api/java/text/Format.html">java.text.Format</a><br>- <a href="https://docs.oracle.com/javaee/7/api/javax/el/ELResolver.html">javax.el.ELResolver</a></td></tr><tr><td><strong>概述</strong></td><td>将请求封装为对象，从而方便参数化和请求队列管理</td><td>定义文法和表示方式</td></tr><tr><td><strong>关键字</strong></td><td>Executor</td><td>Expression</td></tr><tr><td><strong>核心角色</strong></td><td>Command, Receiver, Invoker(Executor)</td><td>Interpretor, Expression</td></tr></tbody></table><p>上面两者也无法直接类比，但是当二者合体，命令的解释和执行一气呵成，一个脚本语言的c执行器雏形就诞生了。这里的命令模式其实比“命令”本身在设计上有更周全的考虑，它还包括了对执行结果的接收接口的预留。</p><table><thead><tr><th></th><th>抽象工厂</th><th>工厂方法</th></tr></thead><tbody><tr><td><strong>UML</strong></td><td><img src="/2022/10/15/design-patterns-all-in-one/abstract-factory.png" alt="Abstract factory"></td><td><img src="/2022/10/15/design-patterns-all-in-one/factory_method.png" alt="Factory method"></td></tr><tr><td><strong>范例</strong></td><td>- <a href="https://docs.oracle.com/javase/8/docs/api/javax/xml/parsers/DocumentBuilderFactory.html#newInstance--">DocumentBuilderFactory(JavaX)</a> <br>- <a href="https://docs.oracle.com/javase/8/docs/api/javax/xml/transform/TransformerFactory.html#newInstance--">TransformerFactory(JavaX)</a><br>- <a href="https://docs.oracle.com/javase/8/docs/api/javax/xml/xpath/XPathFactory.html#newInstance--">XPathFactory(JavaX)</a><br>- <a href="https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/beans/factory/BeanFactory.html">BeanFactory#getBeanProvider(Spring)</a></td><td><a href="https://docs.oracle.com/javase/8/docs/api/java/util/Calendar.html#getInstance--">java.util.Calendar#getInstance()</a></td></tr><tr><td><strong>概述</strong></td><td>将一个类的接口转换成满足另一个要求的接口</td><td>由工厂的子类决定创建的实例对象</td></tr><tr><td><strong>关键字</strong></td><td>Factory, new…, create…</td><td>Factory, newInstance, Creator</td></tr><tr><td><strong>核心角色</strong></td><td>AbstractFactory</td><td>Creator</td></tr></tbody></table><p>其他模式还包括：建筑者模式，原型模式，享元（类似多例），单例；组合；模板方法，迭代器。这些模式或是不常用，或是过于常用常见，且都比较简单，限于篇幅本文不再一一详述。</p><p>通过这个类比学习的过程，我们可能会逐步感受到，设计模式的重点并不在于类之间关系的严格定义、罗列和排布，无意义的争辩、论证会陷入“把设计模式当作一个严格的学术理论”的<code>误区</code>。更多的，我们应该从问题的意图出发，发散思考解决方案中可能包含的设计元素，然后根据实际情况精简到合理的规模。</p><p>所以我们不必纠结于相近的两种模式的严格界定和区分，比如，无需辩驳一种实现究竟是用的代理还是装饰，而是理解这两种模式的<code>看问题的角度</code>和<code>意图</code>，融会贯通，灵活组合运用：如果你强调的角度是功能拓展，那设计方案就是装饰；如果你强调的是访问控制，那就是代理。很多初学者觉得很多模式很相似，感到多余，这是很正常的感受和学习阶段；随着更多应用和实战，你会成长和洞察更多模式的意义；后来你已经成为设计大师，灵活运用设计模式、AOP、函数式、算法乃至ML解决各类问题，讲述和推动方案的实现，设计模式的探讨和辩论只不过是茶余饭后的谈资。这一点，在原书“怎样选择设计模式”章节中，也有提及。</p><p>总结来讲，初学设计模式，关注点可以放在：</p><ul><li>这个设计模式解决什么类型的问题，<code>意图</code>是什么，以及它如何对概念进行抽象（<code>关键角色</code>）和解决（<code>接口、关系</code>）的。</li><li>用设计模式作为大家沟通软件设计的<code>语言</code>，掌握这些术语，减少沟通成本。</li></ul><h1 id="如何学习和使用设计模式"><a href="#如何学习和使用设计模式" class="headerlink" title="如何学习和使用设计模式"></a>如何学习和使用设计模式</h1><p>本部分内容源自GoF原书中1.8章的内容“怎样使用设计模式”，精简了原书的7步为6步，并去除了翻译腔：</p><ol><li><p>浏览一遍该模式，掌握关键要素<br>这个模式的名字是什么，意图是什么，里面的关键角色是什么，常见的关键词？</p></li><li><p>回头去研究结构部分、参与者部分和协作部分<br>进一步了解角色的职责和关系，有哪些接口，以及模式的适用性：这个模式更适合解决什么类型的问题？</p></li><li><p>看看示例代码<br>例子能让我们了解模式解决的实际问题，成为我们实现的参考。</p></li><li><p>参考模式中的命名方法<br>比如，在Strategy模式中，你可以直接给算法命名末尾加上Strategy来体现这个模式；再比如，可以用create作为方法的开头前缀来凸显工厂方法。</p></li><li><p>定义类和接口<br>选定好模式、完成命名后，下一步可以建立好类与接口之间的继承&#x2F;实现关系，定义代表数据和对象引用的实例变量。</p></li><li><p>实现模式<br>开始依据模式实现解决方案。</p></li></ol><p>设计模式的引入是带有一定成本的，学习成本和复杂性的增加就是其中之一，也可能会有性能上的损耗（虽然可以忽略），但它为架构带来了灵活性，使其更加清晰可维护。接下来，作为拓展阅读，我们可以探讨一下设计模式的意义，获得更深的理解。</p><h1 id="设计模式的意义和批判"><a href="#设计模式的意义和批判" class="headerlink" title="设计模式的意义和批判"></a>设计模式的意义和批判</h1><p>谈及为什么需要设计模式时，首先要回答什么设计是好的设计。软件是对现实问题复杂性的抽象和管理，Uncle bob说：“软件应该是可变的”，正如现实世界“唯一不变的就是不断地变化”，软件应该能灵活地应对现实世界的需求。所以我们会讨论软件架构的<strong>可扩展性、可维护性、高可用、可重用、可移植性</strong>等。如果你只是在编写一个又一个的脚本、一次性工具或者编程练习题，当然不用把问题复杂化。但如果你希望你的软件有更强的生命力和更广阔的前景，那就要严肃对待软件设计，防止代码腐化。</p><p>此外，一个人的力量是有限的，如果希望借助协作来扩大软件的服务范围、影响力，那么<strong>可读性</strong>也就重要起来。“Good code is like well-written prose”，好代码应该像优美的散文；至少是自解释的。引述GoF的原文，“所有结构良好的面向对象软件体系结构中都包含了许多模式…内行的设计者知道：不是解决任何问题都要从头做起…这些模式解决特定的设计问题，使面向对象设计更灵活、优雅，最终复用性更好。”所以这里的两层意思就一方面强调了模式对软件设计本身的好处，一方面说明了这些模式建立了大家在面向对象设计上的共识和交流基础。此外，大师们还总结了一些设计原则来框定好的设计。</p><h2 id="SOLID设计原则"><a href="#SOLID设计原则" class="headerlink" title="SOLID设计原则"></a>SOLID设计原则</h2><p>尽管很多教程将设计原则和设计模式放在一起讨论，暗示设计模式是遵从了设计原则，实际上他们并非同出一家。而且设计原则有很多种说法，这里我们分享Uncle Bob提出的最容易记忆的版本，SOLID 原则：</p><ul><li><strong>S</strong>ingle responsibility, 单一职责原则 SRP：就一个类而言，应该仅有一个引起它变化的原因。</li><li><strong>O</strong>pen-close, 开闭原则 OCP：软件实体应该对于扩展是开放的，对于修改是封闭的。</li><li><strong>L</strong>iskov substitution, 里氏代换原则 LSP。子类型必须能够替换掉它们的父类型。把父类实例替换成子类实例，程序行为不应该有变化。</li><li><strong>I</strong>nterface segregation, 接口隔离原则 ISP。<ul><li>一个类对另外一个类的依赖性应当是建立在最小的接口上的。</li><li>客户端程序不应该依赖它不需要的接口方法（功能）。</li></ul></li><li><strong>D</strong>ependency inverse, 依赖倒转原则 DIP：<ul><li>高层模块不应该依赖低层模块。两个都应该依赖抽象。</li><li>抽象不应该依赖细节，细节应该依赖抽象。</li></ul></li></ul><p>我们可以认为这些设计模式是解决设计问题思考的准绳，也可以认为他们只是一种理念。正如Uncle bob 所说：”The SOLID principles are not rules. They are not laws. They are not perfect truths… This is a good principle, it is good advice…”。总之，了解这些可以帮助我们把握思考方向，但不能帮我们解决问题。换言之，对于初学者而言，设计原则可能没有设计模式那样强的实战意义。</p><h2 id="批判之声"><a href="#批判之声" class="headerlink" title="批判之声"></a>批判之声</h2><p>关于设计模式的<strong>批判</strong>，源自于对其创立所处时代的主流编程语言的局限性的挑战，以及对于面向对象本身的质疑。有人认为设计模式的提出反映了Java和C++自身语言特性的缺失；也有认为如果灵活运用aspect-oriented-programming，就用不着搞出来23种之多啰啰嗦嗦的设计模式了。对此，笔者觉得纯粹的理论上的对错没那么重要，软件开发是科学和艺术的结合地带，而设计模式是一个时代开发者思考的精华沉淀，能给我们带来的不仅是具体方案，更多的是解决问题的思维方式，它们本身就存在于大量的编程实践中，GoF对他们进行了提炼和综述，这本身就是意义巨大的成果了，更何况他们已经成为工程师文化的一部分，成为了术语。例如，我们从Spring中既能看到AOP的应用、函数式编程的应用，也能看到建造者、工厂模式、策略等等的应用。编程大师应该是博学和不拘一格的，代码的艺术正在于灵活和适时的运用，囿于固执信仰而拒绝经典或者新知断不可取。</p><h1 id="其他常见疑问FAQ"><a href="#其他常见疑问FAQ" class="headerlink" title="其他常见疑问FAQ"></a>其他常见疑问FAQ</h1><p>Q: 设计模式和后续流行的的Reactive、函数式编程、AOP、IoC以及DI之间的关系是什么？</p><p>A: 总体上，这些是不同维度的概念，总结为下表：</p><table><thead><tr><th>概念</th><th>释义（译）</th><th>范畴</th></tr></thead><tbody><tr><td>设计模式</td><td>Software design pattern</td><td>软件设计的解决方案</td></tr><tr><td>IoC</td><td>控制反转 Inversion of control</td><td>软件架构层面的一种设计模式</td></tr><tr><td>DI</td><td>依赖注入 Dependency injection</td><td>一种设计模式</td></tr><tr><td>AOP</td><td>Aspect-oriented programming，面向切面的编程</td><td>编程范式（面向对象）</td></tr><tr><td>函数式编程</td><td>Functional programming</td><td>编程范式（声明式）</td></tr><tr><td>Reactive</td><td>Reactive programming, 响应式编程</td><td>编程范式（声明式）</td></tr><tr><td>微服务</td><td>Microservices</td><td>一种架构模式（面向服务的架构）</td></tr></tbody></table><p>Q: 是否还有其他设计模式？</p><p>A: 有的，随着软件开发实践的演化，有越来越多的设计模式被总结出来，只不过可能还没有一本经典将其整理入册。比如常见的锁的双重检查，也被认为是一种独立于语言的并发型设计模式。DI也是设计模式 Concurrency Patterns，其角色包括注入器Injector，服务Service，客户端Client和接口Interfaces。DI也是一种创建型Creational设计模式，其意图在于优化类之间依赖关系，因而和整个软件或模块的架构的相关性更密切。</p><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ul><li>Design Patterns, Elements of Reusable Object-Oriented Software</li><li><a href="https://en.wikipedia.org/wiki/Software_design_pattern">https://en.wikipedia.org/wiki/Software_design_pattern</a></li><li><a href="http://butunclebob.com/ArticleS.UncleBob.PrinciplesOfOod">http://butunclebob.com/ArticleS.UncleBob.PrinciplesOfOod</a></li><li><a href="https://en.wikipedia.org/wiki/SOLID">https://en.wikipedia.org/wiki/SOLID</a></li><li><a href="https://sites.google.com/site/unclebobconsultingllc/getting-a-solid-start">https://sites.google.com/site/unclebobconsultingllc/getting-a-solid-start</a></li><li><a href="https://en.wikipedia.org/wiki/Law_of_Demeter">https://en.wikipedia.org/wiki/Law_of_Demeter</a></li><li><a href="https://www.jianshu.com/p/8cbc4bf897cb">https://www.jianshu.com/p/8cbc4bf897cb</a></li><li><a href="https://coderanch.com/t/99717/engineering/Bridge-Facade-Pattern">https://coderanch.com/t/99717/engineering/Bridge-Facade-Pattern</a></li><li><a href="https://stackoverflow.com/questions/3477962/when-do-we-need-decorator-pattern">https://stackoverflow.com/questions/3477962/when-do-we-need-decorator-pattern</a></li><li><a href="https://stackoverflow.com/questions/6366385/use-cases-and-examples-of-gof-decorator-pattern-for-io">https://stackoverflow.com/questions/6366385/use-cases-and-examples-of-gof-decorator-pattern-for-io</a></li><li><a href="https://stackoverflow.com/questions/1673841/examples-of-gof-design-patterns-in-javas-core-libraries/">https://stackoverflow.com/questions/1673841/examples-of-gof-design-patterns-in-javas-core-libraries/</a></li></ul><h1 id="关于我"><a href="#关于我" class="headerlink" title="关于我"></a>关于我</h1><p>我是<a href="https://github.com/hydraxman">风云信步</a>，目前在微软中国担任研发经理。希望在这个空间和大家分享交流技术心得，职业生涯，团队和项目管理，趋势动态。旨在畅谈、分享和记录，不拘小节；但也不排除刨根问底、钻牛角尖。</p><p>本人热爱技术和打码，尤其享受用技术解决实际问题的过程和结果；相信创造力是顶级能力，是人价值的放大器。此外，本人专注于软件和代码质量、工程效率和研发能效方面多年，目前在微软和团队一起推动2023年新开源的项目<a href="https://github.com/microsoft/HydraLab">Hydra Lab</a>的完善与发展；欢迎和我在开源世界组队打码，造轮子 or 添砖加瓦。</p>]]></content>
    
    
    <categories>
      
      <category>代码手记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Code design</tag>
      
      <tag>Design Patterns</tag>
      
      <tag>GoF</tag>
      
      <tag>15分钟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Java bytecode and AOP</title>
    <link href="/2018/12/31/more-about-java-bytecode-and-aop/"/>
    <url>/2018/12/31/more-about-java-bytecode-and-aop/</url>
    
    <content type="html"><![CDATA[<h2 id="What-is-Java-bytecode"><a href="#What-is-Java-bytecode" class="headerlink" title="What is Java bytecode?"></a>What is Java bytecode?</h2><p>Java bytecode is the instruction set of the Java virtual machine (JVM). </p><p>From <a href="https://en.wikipedia.org/wiki/Java_bytecode">https://en.wikipedia.org/wiki/Java_bytecode</a>  </p><p>In a word, just like X86 and ARM or MIPS running on each ABI platform, Java bytecode is executed by JVM engine. And as a machine language defined by JVM specification, Java bytecode plays a much more fundamental part in Java ecosystem than Java language itself. The following picture can be the best case to cast light upon it. </p><p><img src="/2018/12/31/more-about-java-bytecode-and-aop/13.png" alt="JVM ecosystem"></p><p><a href="https://docs.oracle.com/javase/specs/index.html">https://docs.oracle.com/javase/specs/index.html</a> </p><span id="more"></span><p>JVM handles the platform independency. </p><p>A Java programmer does not need to be aware of or understand Java bytecode at all. However, as suggested in the IBM developerWorks journal, “Understanding bytecode and what bytecode is likely to be generated by a Java compiler helps the Java programmer in the same way that knowledge of assembly helps the C or C++ programmer.” </p><h2 id="An-anatomy-of-the-class-file"><a href="#An-anatomy-of-the-class-file" class="headerlink" title="An anatomy of the .class file"></a>An anatomy of the .class file</h2><p>Class file dissemble </p><p>Use this java source code as an example: </p><p>Java method data structure: </p><p><a href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html">https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html</a> </p><h2 id="Stack-Based-Architecture"><a href="#Stack-Based-Architecture" class="headerlink" title="Stack-Based Architecture?"></a>Stack-Based Architecture?</h2><p>All the instructions is centered by the Stack-Based Architecture and methodology of JVM. This largely simplifies the instruction set of JVM and therefore make it possible that the opcode size could be limited to 8 bit. </p><p>In JVM for each thread, a last-in-first-out (LIFO) stack, also known as its JVM stack, is allocated where Java frames are stored. Here is an illustration showing stacks for 3 threads. </p><p>A new Java frame is created each time a method is invoked and is destroyed when its method invocation completes. It is used to store data and partial results, as well as to perform dynamic linking, return values for methods, and dispatch exceptions. </p><h3 id="Operand-Stacks"><a href="#Operand-Stacks" class="headerlink" title="Operand Stacks"></a>Operand Stacks</h3><p>As opposed to a register-based architecture, stack based one will use stack data structure as its instruction executing and computing playground and notepad, which means each instruction execution will be companied with stack operations like pop and push. The operand stack is empty when the frame that contains it is created, and will normally be empty when the invokation of the corresponding method is completed. </p><h3 id="Local-Variables-table"><a href="#Local-Variables-table" class="headerlink" title="Local Variables table"></a>Local Variables table</h3><p>It is a bit reckless to jump to conclusion that JVM is stack-based as JVM also use local variable table during it bytecode execution, which make JVM a bit more register-based. Each frame contains an table of variables known as its local variables table. The length of the local variable array of a frame is determined at compile-time. </p><p>So based on this understanding, let’s take a look at a more complicated method, setServiceType(String): </p><p>Each frame for a method call has an “operand stack” and an array of “local variables”. </p><h3 id="Instruction-types"><a href="#Instruction-types" class="headerlink" title="Instruction types"></a>Instruction types</h3><p>The byte-long and 256 possible opcode instructions fall into a number of broad groups: </p><ul><li>Load and store (e.g. aload_0, istore) </li><li>Arithmetic andc (e.g logi. ladd, fcmpl) </li><li>Type conversion (e.g. i2b, d2i) </li><li>Object creation and manipulation (new, putfield) </li><li>Operand stack management (e.g. swap, dup2) </li><li>Control transfer (e.g. ifeq, goto) </li><li>Method invocation and return (e.g. invokespecial, areturn)</li></ul><table><thead><tr><th>Prefix&#x2F;suffix</th><th>Operand type</th></tr></thead><tbody><tr><td>i</td><td>integer</td></tr><tr><td>l</td><td>long</td></tr><tr><td>s</td><td>short</td></tr><tr><td>b</td><td>byte</td></tr><tr><td>c</td><td>character</td></tr><tr><td>f</td><td>float</td></tr><tr><td>d</td><td>double</td></tr><tr><td>a</td><td>reference</td></tr></tbody></table><p><a href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html">https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html</a> </p><h3 id="Bytecode-manipulation"><a href="#Bytecode-manipulation" class="headerlink" title="Bytecode manipulation"></a>Bytecode manipulation</h3><p>The most powerful and widely used manipulation tool: </p><p>ASM </p><p>Site: <a href="https://asm.ow2.io/">https://asm.ow2.io/</a> </p><p>Used in: </p><ul><li>OpenJDK </li><li>Groovy and Kotlin compiler</li><li>CGLIB </li><li>AspectJ </li><li>Gradle </li><li>……</li></ul><p>It is the fundament of compile-time AOP, basically by applying ASM API we can analyze and modify class file method call after source code compile. </p>]]></content>
    
    
    <categories>
      
      <category>代码手记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AOP</tag>
      
      <tag>面向切面</tag>
      
      <tag>Java</tag>
      
      <tag>JVM</tag>
      
      <tag>bytecode</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Aspect-Oriented Programming in Android</title>
    <link href="/2018/12/27/aop-in-android/"/>
    <url>/2018/12/27/aop-in-android/</url>
    
    <content type="html"><![CDATA[<h2 id="What-is-AOP-​"><a href="#What-is-AOP-​" class="headerlink" title="What is AOP?​"></a>What is AOP?​</h2><p>In computing, aspect-oriented programming (AOP) is a programming paradigm that aims to increase modularity by allowing the separation of cross-cutting concerns. It does so by adding additional behavior to existing code (an advice) without modifying the code itself, instead separately specifying which code is modified via a “pointcut” specification, such as “log all function calls when the function’s name begins with ‘set’”. This allows behaviors that are not central to the business logic (such as logging) to be added to a program without cluttering the code, core to the functionality. AOP forms a basis for aspect-oriented software development.</p><span id="more"></span><p>The Microsoft Transaction Server is considered to be the first major application of AOP followed by Enterprise JavaBeans.​</p><h3 id="Similar-concepts"><a href="#Similar-concepts" class="headerlink" title="Similar concepts:"></a>Similar concepts:</h3><ul><li>Proxy pattern</li><li>Interceptors &amp; Filters</li><li>Basic terminology:</li></ul><h3 id="Concerns"><a href="#Concerns" class="headerlink" title="Concerns"></a>Concerns</h3><p>Advice, Pointcut and Join Point compose an Aspect:​</p><ul><li>Primary concerns</li><li>Secondary and Cross-cutting concerns</li><li>Joint point</li><li>Advice</li><li>Pointcut<ul><li>Described by expressions: AspectJ Pointcut expressions</li><li>Described by annotations</li></ul></li><li>Aspect</li><li>Weaving</li><li>AOP processor i.e. the Weaver</li></ul><p><img src="/2018/12/27/aop-in-android/1.png" alt="Concepts"></p><h4 id="Weaving-timing"><a href="#Weaving-timing" class="headerlink" title="Weaving timing:"></a>Weaving timing:</h4><ul><li>At run-time</li><li>At load-time</li><li>At compile-time</li></ul><h2 id="Why-do-we-need-AOP"><a href="#Why-do-we-need-AOP" class="headerlink" title="Why do we need AOP?"></a>Why do we need AOP?</h2><p>In a word, AOP is an evolution and supplement of OOP</p><p><img src="/2018/12/27/aop-in-android/2.jpg" alt="AOP as a supplement"></p><p>General Benefits:</p><ul><li>Increase modularity and logic clarity and concentration</li><li>Less tangled code</li><li>Shorter code</li><li>Easier application maintenance and evolution</li><li>Applications that are easier to debug, refactor and modify</li><li>Code is more reusable in a shape of aspect</li><li>An idea of resolving complicated process</li><li>Application of the implementation: help to hook and inject third-party SDKs (So as to block malicious method calls or to monitor or study crucial process, like network communication)</li></ul><blockquote><p>Mastering AspectJ: Aspect-Oriented Programming in Java,  Joseph Gradecki, Nicholas. WILEY</p></blockquote><p>Practice Areas:</p><ul><li>Logging</li><li>Permission check</li><li>Performance Profiling</li><li>Data check</li><li>Thread status check</li></ul><h2 id="How-to-adopt-it"><a href="#How-to-adopt-it" class="headerlink" title="How to adopt it?"></a>How to adopt it?</h2><table><thead><tr><th>AOP Core Implementation</th><th>Basic Techniques</th><th>Weaving time</th></tr></thead><tbody><tr><td>Dynamic Proxy Pattern</td><td>Java Proxy API</td><td>Run-time</td></tr><tr><td>DexMaker</td><td>DexClassLoader API</td><td>Load-time</td></tr><tr><td>AspectJ</td><td>Java Bytecode Manipulation</td><td>Compile-time</td></tr></tbody></table><blockquote><p>AspectJ: AOP standard extension, the open-source projects Maintained by Eclipse Foundation </p></blockquote><p><a href="https://git.eclipse.org/c/aspectj/org.aspectj.git/">https://git.eclipse.org/c/aspectj/org.aspectj.git/</a></p><h2 id="Dark-side-True-Magic-or-Fancy-Stuff"><a href="#Dark-side-True-Magic-or-Fancy-Stuff" class="headerlink" title="Dark side: True Magic or Fancy Stuff?"></a>Dark side: True Magic or Fancy Stuff?</h2><p>“AOP considered harmful”:</p><p>Makes control flow obscured: Implicit AOP to Explicit AOP<br>Affect method stack trace: increase its depth<br>Require additional weaving time</p><blockquote><p>“AOP Considered Harmful”. uni-karlsruhe.de. 23 March 2016.</p></blockquote><p>Mitigation:</p><ul><li>prevent invisible code, better use Annotation and combine with DI technique</li><li>Appropriate use: it’s only a supplement and a way to simplify complicated structure and reuse components, not a software design principle.</li></ul><h2 id="More-about-AspectJ"><a href="#More-about-AspectJ" class="headerlink" title="More about AspectJ"></a>More about AspectJ</h2><p>Pointcut expression:</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs coq">execution(modifiers-<span class="hljs-built_in">pattern</span>? ret-type-<span class="hljs-built_in">pattern</span> declaring-type-<span class="hljs-built_in">pattern</span>? name-<span class="hljs-built_in">pattern</span>(param-<span class="hljs-built_in">pattern</span>) throws-<span class="hljs-built_in">pattern</span>?)<br></code></pre></td></tr></table></figure><p><a href="https://docs.spring.io/spring/docs/2.0.x/reference/aop.html">https://docs.spring.io/spring/docs/2.0.x/reference/aop.html</a></p><p><a href="https://howtodoinjava.com/spring-aop/aspectj-pointcut-expressions/">https://howtodoinjava.com/spring-aop/aspectj-pointcut-expressions/</a></p><p>As the return value is ignored, the method must be declared as void return.</p><p>Pointcut described by annotation:</p><p>Annotated Joint Point: the primary concern.</p><p>Check log outputs:</p><p>Other Possible Scenarios:</p><ul><li>@ProfilerTracker(BuildConfig.DEBUG)</li><li>@CallFrequencyLimit</li><li>@CheckPermission(“”), @RequirePermission(“”)</li></ul><p>How does it work? Technique Anatomy:​​​​​​​​​​​​​​<br>Weaving in Build-time:</p><p>Next session: Java Bytecode manipulation.</p><p>Other implementations:</p><ul><li>Based on the idea of AOP and DI (Dependency Injection), lots of Android opensource frameworks are created to help improve the code structure and modularity.</li></ul><p><a href="https://github.com/androidannotations/androidannotations">AndroidAnnotations</a></p><p><a href="https://github.com/JakeWharton/hugo">Hugo</a></p><p>OTHER REFERENCES<br><a href="https://fernandocejas.com/2014/08/03/aspect-oriented-programming-in-android/">https://fernandocejas.com/2014/08/03/aspect-oriented-programming-in-android/</a></p>]]></content>
    
    
    <categories>
      
      <category>代码手记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Android</tag>
      
      <tag>AOP</tag>
      
      <tag>面向切面</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>代码中的人文故事：从一个Java的“Bug”说起</title>
    <link href="/2018/07/13/java-calendar-story/"/>
    <url>/2018/07/13/java-calendar-story/</url>
    
    <content type="html"><![CDATA[<h2 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h2><p>这几日闲来无事撸代码，无意中发现一桩趣事。原以为是一个Java的bug，没想到经过一系列死磕，挖掘出了一段和中国历史乃至人类文明相关联的人文故事，不禁唏嘘感叹一番。</p><span id="more"></span><p>这件事的缘起很简单，我在实现计算两个日期天数距离逻辑的过程中，发现了一个很诡异的事情，同样的起始日期，用python和Java计算出的结果居然不一样！</p><p>例如，计算一个1990年1月1日到1990年9月4日之间的天数，用python计算如图：</p><p><img src="/2018/07/13/java-calendar-story/1.png" alt="clipboard.png"></p><p>得出天数为246。可以看到，python的API设计简单。</p><p>用Java计算则不同了，众所周知Java推荐的Calendar API不是一般的麻烦，实现函数如下：</p><p><img src="/2018/07/13/java-calendar-story/2.png" alt="clipboard.png"></p><p>按照这个逻辑测试如下：</p><p><img src="/2018/07/13/java-calendar-story/3.png" alt="clipboard.png"></p><p><img src="/2018/07/13/java-calendar-story/5.png" alt="clipboard.png"></p><p>WTF!?得出的天数居然是245天？为什么和Python算出来的不一样？我马上实际数了一下，应该是246天，Python算的结果是对的！</p><p>仔细核对了程序实现，没毛病啊？难道有精读损失？</p><h2 id="狐疑（懵逼）"><a href="#狐疑（懵逼）" class="headerlink" title="狐疑（懵逼）"></a>狐疑（懵逼）</h2><p>进而加入如下输出：</p><p><img src="/2018/07/13/java-calendar-story/6.png" alt="clipboard.png"></p><p><img src="/2018/07/13/java-calendar-story/7.png" alt="clipboard.png"></p><p>什么鬼？这0.0416666667天跑哪里去了？需知：</p><p><img src="/2018/07/13/java-calendar-story/8.png" alt="clipboard.png"></p><p>也就是说，Java计算的时间和实际正好差了一个小时！</p><p>无独有偶，各种百度后，居然发现了和我有类似疑问的兄弟：<br><a href="https://ask.csdn.net/questions/241889">https://ask.csdn.net/questions/241889</a><br>然而这个提问下并没有靠谱的答案！</p><p>这样看，似乎很像时区上出了问题，然而并不是，前后Calendar对象的时区完全一致！都是Asia&#x2F;Shanghai！</p><p>由此难免要想，难道Java代码有Bug？把这一个小时给吃了？好吃吗？啥味道？</p><p>然而，用同样的函数，计算990年1月1日到1990年12月4日之间的天数，有一切正常了！</p><p><img src="/2018/07/13/java-calendar-story/9.png" alt="clipboard.png"></p><p>心中万马奔腾啊！</p><p><img src="/2018/07/13/java-calendar-story/10.png" alt="clipboard.png"></p><p>经过一番探索，我又写了如下代码：</p><p><img src="/2018/07/13/java-calendar-story/11.png" alt="clipboard.png"></p><p>惊奇地发现：</p><p><img src="/2018/07/13/java-calendar-story/12.png" alt="clipboard.png"></p><p>进而又发现：</p><p><img src="/2018/07/13/java-calendar-story/13.png" alt="clipboard.png"></p><p>由此我灵机一动，又写了一段代码，找到从1900年至今所有当天长度非24小时的日期！</p><p><img src="/2018/07/13/java-calendar-story/14.png" alt="clipboard.png"></p><p>此中必有蹊跷！</p><h2 id="豁然"><a href="#豁然" class="headerlink" title="豁然"></a>豁然</h2><p>然而这对于没文化的我来说，实在是一件不可理喻的事情。只能从源码入手了！</p><p>找源码的过程就不再赘述了，总之，时间的偏移来自于一个zoneOffsets的数组，而这个数组中除了因为时区而产生的偏移外，还有一个神秘的DST_OFFSET！</p><p><img src="/2018/07/13/java-calendar-story/15.png" alt="clipboard.png"></p><p>找到这里，这个谜团即将揭晓了！</p><p>啥是DST_OFFSET呢？</p><p><img src="/2018/07/13/java-calendar-story/16.png" alt="clipboard.png"></p><p>没错，daylight saving offset，也就是夏令时！</p><p>也就是说，中国的1990年4月15日这天里，人为地将时间拨快了一个小时，1990年9月16日这天再拨慢回来。进一步说，中国的1990年4月15日这天确实是23个小时，1990年9月16日这天也确实是25小时，Java没搞错！</p><p>也就是说之前找到的所有非24小时的日期，都是中国政府（或国民政府）施行夏令时调整的日期，这段历史断断续续地持续了半个多世纪！而Java的Calendar API将其忠实地记录了下来。</p><p><img src="/2018/07/13/java-calendar-story/17.png" alt="clipboard.png"></p><p>关于夏令时详情见<a href="https://baike.baidu.com/item/%E5%A4%8F%E4%BB%A4%E6%97%B6/1809579?fr=aladdin">百度百科</a>。<br>哈哈哈，真相揭晓，好感慨好激动。所以说，这并不是Java的bug，而正是Java严谨的体现！Calendar API确实设计的很烂很不友好，但并不代表其中有bug，相反地，这也正体现了其中的工程师精神。</p><p>这就引出了一段已经被淡忘的历史，很多90年出生的朋友可以问问父母，90年和91年是我国至今为止实行夏令时的最后两年，我国曾经也想向美国等西欧国家学习，充分利用太阳下的时光！年轻的小朋友问问你们的父母，一定能勾起他们的一段回忆！</p><p>这就是隐藏在Java代码中的一段历史，一段已经被遗忘的人文故事！</p><p>想了解这段历史的同学可戳：</p><p><a href="https://mp.weixin.qq.com/s/V6Un2Kanwzcq898DDpdBvg">还记得大明湖畔的夏令时吗？</a></p><p>只要刨根问底，一定有意想不到的收获！感觉解决了个大谜团！</p>]]></content>
    
    
    <categories>
      
      <category>代码手记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Java</tag>
      
      <tag>夏令时</tag>
      
      <tag>历史</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一次Java字节码插桩实战</title>
    <link href="/2017/03/11/jvm-classcode-practice/"/>
    <url>/2017/03/11/jvm-classcode-practice/</url>
    
    <content type="html"><![CDATA[<blockquote><p>理解本文需要一定的Java字节码指令基础，可以阅读笔者的另一篇文章：<a href="https://segmentfault.com/a/1190000008606277">大话+图说：Java字节码指令——只为让你懂</a></p></blockquote><blockquote><p><strong>利用Android字节码插桩技术可以很方便地帮助我们实现很多手术刀式的代码设计，如无埋点统计上报、轻量级AOP等。下面我们就通过一次实战，把这门技术真正用起来。</strong></p></blockquote><h1 id="奇葩需求"><a href="#奇葩需求" class="headerlink" title="奇葩需求"></a>奇葩需求</h1><p>假设有这样一个需求，我们需要在本项目工程的所有组件（Activity&#x2F;Receiver&#x2F;Service&#x2F;Provider）的on系列生命周期类方法执行时，调用一个我们写好的方法，传入组件的实例对象，来对组件的相关状态进行监测，如何实现？</p><span id="more"></span><p>一般的思路有两种：</p><ol><li>通过Java继承体系，为我们实现的四大组件分别建立基类，在基类父方法里对监测方法进行调用。</li><li>通过Android API Hook技术，即通过动态代理等方法替换关键节点，抓住组件的节点方法并调用我们的监测方法。</li></ol><p>上面的第一种方法比较麻烦，而且控制力较弱，也无法顾及我们所依赖的Jar或者aar中的组件，比如小米推送中自带的Service和Receiver，是完全无法触及的。第二种方法则比较强大，但是需要考虑兼容性问题，技术实现上的成本也比较高，毕竟有一些生命周期的节点不好找，难免焦头烂额。</p><p>本文对此的实战即通过字节码插桩，在class文件编译成dex之前（同时也是proguard操作之前），遍历所有要编译的class文件并对其中符合条件的方法进行修改，注入我们要调用的监测方法的代码，从而实现这个需求。</p><p><a href="https://github.com/BryanSharp/hibeaver">HiBeaver</a> 是目前这方面比较完善的字节码插桩Gradle插件，目前最新的1.2.4版本支持通过通配符或正则表达式的方法来匹配目标类和目标方法，进行方法的批量插桩注入和修改，非常灵活易用。对于类似上文提出的需求，实现起来非常方便，唯一前提的仅仅是：知道所有组件的类的全名就可以了。</p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>好，基于这些，正式开始实战，牛刀小试一下：<br>首先建立一个工程，为便于演示，我们引入小米推送（接入方式不再赘述，详见<a href="http://dev.xiaomi.com/doc/?p=3080">小米推送文档</a>），然后完善代码到如下状态：</p><p><img src="/2017/03/11/jvm-classcode-practice/1.png" alt="图片描述"></p><p>MainActivity内容很简单，注册了小米推送，有一个TextView点击后可以跳转到SecondActivity，仅此而已。具体如下：</p><p><img src="/2017/03/11/jvm-classcode-practice/2.png" alt="图片描述"></p><p>SecondActivity中一切从简：</p><p><img src="/2017/03/11/jvm-classcode-practice/3.png" alt="图片描述"></p><p>至于DemoMessageReceiver这个类里完全依照小米推送接入文档中的配置，没有实质改动，不再贴出。<br>注意到还有一个MonitorUtil的类，内容如下：</p><p><img src="/2017/03/11/jvm-classcode-practice/4.png" alt="图片描述"></p><p>其中的monitorThis的方法就是我们打算在各个生命周期方法里插入的调用方法。</p><h1 id="开始实战"><a href="#开始实战" class="headerlink" title="开始实战"></a>开始实战</h1><p>下面我们就开始实现开头处提到的需求：通过字节码插桩的方法，本工程里的所有组件的生命周期方法return之前调用我们的monitorThis方法，传入组件实例等信息作为参数。</p><p>首先，要引入<a href="https://github.com/BryanSharp/hibeaver">HiBeaver</a>插件：<br>然后在项目的根build.gradle下面增加classpath如下：</p><p><img src="/2017/03/11/jvm-classcode-practice/5.png" alt="图片描述"></p><pre><code class="hljs">classpath &#39;com.bryansharp:hibeaver:1.2.4&#39;</code></pre><p>随后为我们工程的app&#x2F;build.gradle增加如下配置：</p><pre><code class="hljs">apply plugin: &#39;hiBeaver&#39;import com.bryansharp.gradle.hibeaver.utils.MethodLogAdapterimport org.objectweb.asm.ClassVisitorimport org.objectweb.asm.MethodVisitorimport org.objectweb.asm.OpcodeshiBeaver &#123;    modifyMatchMaps = [            //类名称匹配规则，*表示任意长度任意字符，|为分隔符，可以理解为或            &#39;*Activity|*Receiver|*Service|!android*&#39;: [                    //方法名匹配规则与类名类似，同时也支持正则表达式匹配（需要加r:）；adapter后为一个闭包，进行具体的修改                    [&#39;methodName&#39;: &#39;on**&#39;, &#39;methodDesc&#39;: null, &#39;adapter&#39;: &#123;                        //下面这些为闭包传入的参数，可以帮助我们进行方法过滤，以及根据方法参数来调整字节码修改方式                        ClassVisitor cv, int access, String name, String desc, String signature, String[] exceptions -&gt;                            //这里我们有了ClassVisitor实例，其实可以为类添加新的方法。                            MethodVisitor methodVisitor = cv.visitMethod(access, name, desc, signature, exceptions);                            MethodVisitor adapter = new MethodLogAdapter(methodVisitor) &#123;                                @Override                                void visitCode() &#123;                                    super.visitCode();                                    //实例对象入栈                                    methodVisitor.visitVarInsn(Opcodes.ALOAD, 0);                                    //下面两句我们将方法的名称和描述作为常量入栈                                    methodVisitor.visitLdcInsn(name);                                    methodVisitor.visitLdcInsn(desc);                                    //调用我们的静态方法                                    methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC,                                            //下面这个MethodLogAdapter.className2Path(String)为                                            // hibeaver插件提供的方法，可以将类名转为路径名                                            MethodLogAdapter.className2Path(&quot;bruce.com.testhibeaver.MonitorUtil&quot;),                                            &quot;monitorThis&quot;, &quot;(Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/Object;)V&quot;);                                &#125;                            &#125;                            return adapter;                    &#125;]            ]    ]&#125;</code></pre><p><a href="https://github.com/BryanSharp/hibeaver">HiBeaver</a>在类名和方法名的匹配上非常灵活，可以非常方便地实现批量匹配，除了完整匹配外，还支持通配符匹配和正则表达式匹配两种模式。通配符匹配模式中主要可以使用两种符号，即 | 和<em>，</em>表示任意长度（&gt;0）的任意字符，而|表示分隔符，这里可以理解为或。因此，上面的：</p><pre><code class="hljs">*Activity|*Receiver|*Service</code></pre><p>可以理解为，匹配任意全类名以Activity、Receiver或Service结尾的类。</p><p>一般来讲，我们的Android组件在命名上都会遵从这个规范，即组件类名以相应的组件名结尾，对于个别不遵从这个原则的，也可以通过|分隔符来把特殊情况纳入进去。</p><p>除此之外，如果存在更复杂的匹配规则，上述通配符已经无法满足，hiBeaver也支持正则表达式进行全类名匹配，只需要在表达式前加上“r:”就可以。比如：</p><pre><code class="hljs">r:.*D[a-zA-Z]*Client</code></pre><p>表示匹配符合“.*D[a-zA-Z]*Client”这个正则表达式的类名。</p><p>更进一步地，<a href="https://github.com/BryanSharp/hibeaver">HiBeaver</a> <strong>未来</strong> 还将支持根据类的继承关系进行匹配，比如：</p><pre><code class="hljs">&gt;ext&gt;android.support.v4.app.FragmentActivity</code></pre><p>表示匹配所有继承android.support.v4.app.FragmentActivity的类，而：</p><pre><code class="hljs">&gt;imp&gt;android.os.Handler.Callback</code></pre><p>表示匹配所有实现android.os.Handler.Callback接口的类。<br>不过，目前这两个特性还没有支持，仅提上了其项目的<a href="https://github.com/BryanSharp/hibeaver/issues/8">issue</a>中。<br>回到刚刚的配置中，下面的methodName方法的匹配规则与类名匹配用法一样，**和*是一样的效果，on**即表示名字以on开头的方法。<br>好了，编译运行工程，过程中在Gradle Console中可以看到hibeaver进行字节码插桩输出如下（局部）：</p><p><img src="/2017/03/11/jvm-classcode-practice/6.png" alt="图片描述"></p><p>程序运行起来，插桩成功，成功调用了monitorThis方法，但赫然发现输出如下：</p><p><img src="/2017/03/11/jvm-classcode-practice/7.png" alt="图片描述"></p><p>调用了三个onCreate和若干的onCreateView！这是为什么？我们的MainActivity也没有这个onCreateView的方法啊！</p><p>结合之前Gradle编译日志，在仔细一琢磨，突然明白了：</p><p><img src="/2017/03/11/jvm-classcode-practice/8.png" alt="图片描述"><br><img src="/2017/03/11/jvm-classcode-practice/8-1.png" alt="图片描述"><br><img src="/2017/03/11/jvm-classcode-practice/9.png" alt="图片描述"></p><p>原来，我们的*Activity规则会匹配所有的Activity结尾的类，包括一些android v4支持包中的类，什么AppCompatActivity、FragmentActivity等继承链上的Activity通通被hook了一遍，难怪会有那么多输出了，可辛苦了我们的monitorThis方法。</p><p>既然如此，如何是好？针对于当前的需求，我们当然不想匹配v4包里的组件类。</p><p>所幸的是，<a href="https://github.com/BryanSharp/hibeaver">HiBeaver</a>中还有另一种排除匹配，运用!符号改造如下即可：</p><pre><code class="hljs">*Activity|*Receiver|*Service|!android*</code></pre><p>这样就表示，匹配前三种之一（或的关系）且不匹配第四个android*的全类名。<br>改好后，再次运行，并点击跳转到SecondActivity：</p><p><img src="/2017/03/11/jvm-classcode-practice/10.png" alt="图片描述"></p><p>可以看到log输出一下子少多了，证明没有再注入v4包里的类，同时，小米的组件也被正常注入了，我把网断掉，可以看到小米的Receiver被唤起：</p><p><img src="/2017/03/11/jvm-classcode-practice/11.png" alt="图片描述"></p><p>再开启调试，打开网，断点也可以正常进入：</p><p><img src="/2017/03/11/jvm-classcode-practice/12.png" alt="图片描述"></p><p>同时，每次<a href="https://github.com/BryanSharp/hibeaver">HiBeaver</a>进行字节码插桩后还会把修改过、实际使用的字节码保存到build&#x2F;HiBeaver目录下，以便于查看：</p><p><img src="/2017/03/11/jvm-classcode-practice/13.png" alt="clipboard.png"></p><p>如下图为修改后的MainActivity类：</p><p><img src="/2017/03/11/jvm-classcode-practice/14.png" alt="clipboard.png"></p><p>修改后的小米推送里的某Receiver:</p><p><img src="/2017/03/11/jvm-classcode-practice/15.png" alt="clipboard.png"></p><p>这样，无论是进行节点控制还是研究其运行机制都大大地方便了。</p><blockquote><p><a href="https://github.com/BryanSharp/hibeaver">HiBeaver</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>代码手记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Android</tag>
      
      <tag>Gradle</tag>
      
      <tag>Java</tag>
      
      <tag>JVM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>白话Java字节码指令</title>
    <link href="/2017/03/07/jvm-classcode-tutorial/"/>
    <url>/2017/03/07/jvm-classcode-tutorial/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>随着Java开发技术不断被推到新的高度，对于Java程序员来讲越来越需要具备对更深入的基础性技术的理解，比如Java字节码指令。不然，可能很难深入理解一些时下的新框架、新技术，盲目一味追新也会越来越感乏力。</p><p>本文既不求照本宣科，亦不求炫技或著文立说，仅力图以最简明、最形象生动的方式，结合例子与实战，让小白也能搞懂这门看似复杂的技术概念。</p><span id="more"></span><h1 id="单刀直入"><a href="#单刀直入" class="headerlink" title="单刀直入"></a>单刀直入</h1><p>闲言碎语不要讲，先表一表，什么是Java字节码指令？简而言之，Java字节码指令就是Java虚拟机能够听得懂、可执行的指令，可以说是Jvm层面的汇编语言，或者说是Java代码的最小执行单元。<br>有点Java基础的人一定都知道，javac命令会将Java源文件编译成字节码文件，即.class文件，其中就包含了大量的字节码指令。因此可以将javac命令理解为一个翻译命令，将源文件翻译成Jvm可以执行的指令。<br>那么最直观的探究方法莫过于直接对比翻译前后的内容。<br>具体如何对比呢？就不得不用到Java为我们一直默默提供的一项利器，javap命令，它可以解析字节码，将字节码内部逻辑以可读的方式呈现出来。为了紧贴实战，我们直接在新建的Java工程里，写这样一个UserServiceImpl类，里面包含几个由简单到复杂的方法，以及一个名为serviceType的属性：<br><img src="/2017/03/07/jvm-classcode-tutorial/1.png" alt="UserServiceImpl.java" title="Title Text"></p><p>如图，以上方法，复杂度由低到高依次为：getServiceType&lt;setServiceType&lt;genToken&lt;login（以及一个实例代码块），后面我也会按照这个顺序解读其字节码指令的执行逻辑。<br>下面我们编译工程，然后在下图所示的目录(gradle编译工程)找到该类的字节码文件：<br><img src="/2017/03/07/jvm-classcode-tutorial/2.png" alt="UserServiceImpl.class path"></p><p>cd到这个路径下，运行javap命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">javap -v -p UserServiceImpl<br></code></pre></td></tr></table></figure><p>就可以观看到翻译版的Java字节码的胴体了！这里的-v意思是啰嗦模式，会输出全面的字节码信息，而-p是指涵盖所有成员。原字节码信息输出内容较多，基于本文的目标，取其一方法的内容，整理如下图：<br>方法1，getServiceType()：<br><img src="/2017/03/07/jvm-classcode-tutorial/3.png" alt="javap output for getServiceType"></p><p>这个getServiceType的方法应该是再简单不过的Java代码，翻译成字节码后也变成了三行，我们先来简单推理一下：第一句，aload_0不知所云，索性略过；第二行，getfield应该可以读懂，后面这个#8似乎是他的参数（实际上是对常量池的引用），&#x2F;&#x2F;后面注释的内容是javap给我们加上的，意思应该是#2的指向是”Field serviceType:Ljava&#x2F;lang&#x2F;String;”这个内容。<br>所以getfield这一行就是取出serviceType这个字段喽，so easy。areturn肯定就是return的意思，a的含义也先略过不表。总之就是取出serviceType字段然后return喽。  </p><p>那么现在的问题就是aload_0是什么意思了，看似多余，但仔细思考一下，似乎之前给getfield指令传入了“Field serviceType:Ljava&#x2F;lang&#x2F;String;”这样一个并不完整的参数，其后半部分的“Ljava&#x2F;lang&#x2F;String;”仅仅表示这个serviceType字段的类型是String，也就是说，整个参数里没有说是取的谁的serviceType字段啊！究竟是get谁的feild呢？  </p><blockquote><p>由此可以想到：aload操作一定是在为getfield指令准备了一个主体。</p></blockquote><p>实际上，再结合下面的局部变量表，aload_0中的0正是局部变量表里的Slot 0的含义。意思是将局部变量表里的Slot 0的东西压入操作数栈，这个Slot 0里的东西name正是this，也就是UserServiceImpl的实例，即getfield的主体。<br><img src="/2017/03/07/jvm-classcode-tutorial/4.png" alt="getServiceType core"></p><h1 id="大戏上演"><a href="#大戏上演" class="headerlink" title="大戏上演"></a>大戏上演</h1><p>好了，对于小白同学有些陌生的概念来了，啥是操作数栈？啥是局部变量表？<br>其实这两个东西理解好了，关于虚拟机指令就懂了一大半了。<br>那么，不妨删繁就简，由易入难，先讲一个这样的故事，故事起名叫：</p><p>Java方法之创世纪<br>话说Jvm大帝是神之旨意的履行者（Jvm大帝就是虚拟机，神就是开发者，神之旨意是开发者写好并编译后的字节码…），当Jvm大帝带领Java世界运行进入了一个新的方法后，会为这个方法在栈内存大陆上创造两个重要的领域：局部变量表和操作数栈。</p><p>要有栈。要有表。神说。</p><p>依照神之旨意，jvm大帝创造的局部变量表里一般会包含this指针（针对实例方法，静态方法当然无此）、方法的所有传入参数和方法中所开辟的本地变量。</p><p>那么操作数栈是干嘛用的呢？</p><p>我们再引入另外一个比喻，如果把运行Java方法理解为拍戏，那么局部变量表里的各个局部变量就是这部戏的核心主角，或者说领衔主演，而操作数栈正是这部戏的舞台。所谓操作数栈搭台，局部变量唱戏，是也。那么aload_0就是告诉Jvm导演（大帝已沦落为导演），请0号演员this同志登台（压栈），演后边的本子。<br>当然了，这个比喻并不完全恰当，因为操作数栈并不是“舞台”的结构，而是栈的结构。但是这个比喻可以很好地说明局部变量表和操作数栈之间的关系，以及aload_0的作用。</p><p>下面我们用一张图来演示一下getServiceType这个小剧本桥段所导演的故事：<br><img src="/2017/03/07/jvm-classcode-tutorial/5.png" alt="getServiceType code episode"></p><p>好吧这部剧虽然短的可怜，但已经基本把指令、操作数栈和局部变量表三者的关系演绎了出来。值得注意的是，getfield这条指令对操作数栈进行了复合操作，其流程可以示意如下图：<br><img src="/2017/03/07/jvm-classcode-tutorial/6.png" alt="getfield command"></p><p>后面我们将要接触到的许多指令都如此，指令内部执行了弹出—&gt;处理—&gt;压回的流程。<br>下面我们就来分析一个相对复杂一点的方法，setServiceType(String)，如下图：<br><img src="/2017/03/07/jvm-classcode-tutorial/7.png" alt="setServiceType(String) flow"></p><p>这里我们看到，变化主要有，指令多了一行，多进行了一次aload，getfield变成了putfield，areturn变成了return，仅此而已。另外领衔主演也就是局部变量表里多了一位，也就是方法的传入参数serviceType字符串对象了。其情节如下：<br><img src="/2017/03/07/jvm-classcode-tutorial/8.png" alt="Pilot of setServiceType"></p><p>这里，putfield只弹出栈内的操作数，而没有向操作数栈压回任何数据，而且执行putfield之前，栈内元素的位置也必须符合“值在上，主体在下”要求。<br>而最后的return仅表示方法结束，而不会像areturn一样返回栈顶元素。这也印证了setServiceType(String)方法没有返回参数。</p><h1 id="融会贯通"><a href="#融会贯通" class="headerlink" title="融会贯通"></a>融会贯通</h1><p>相信有了以上的讲解，大家对指令、操作数栈、局部变量表三者的运作关系有了一定认识，为了后边能够分析更复杂的方法，这里必须概括性地讲解一下更多的Java字节码指令。虽然Java字节码指令非常多，但其实常用的不外乎几个类别，先从这几个常用类别入手理解，便可渐入佳境。<br>关于字节码指令的分类，可以从两个维度进行：一是指令的功能，二是指令操作的数据类型。我们先从功能说起，指令主要可以分为如下几类：</p><ol><li><strong>存储和加载类指令</strong>：主要包括load系列指令、store系列指令和ldc、push系列指令，主要用于在局部变量表、操作数栈和常量池三者之间进行数据调度；（关于常量池前面没有特别讲解，这个也很简单，顾名思义，就是这个池子里放着各种常量，好比片场的道具库）</li><li><strong>对象操作指令</strong>（创建与读写访问）：比如我们刚刚的putfield和getfield就属于读写访问的指令，此外还有putstatic&#x2F;getstatic，还有new系列指令，以及instanceof等指令。</li><li><strong>操作数栈管理指令</strong>：如pop和dup，他们只对操作数栈进行操作。</li><li><strong>类型转换指令和运算指令</strong>：如add&#x2F;div&#x2F;l2i等系列指令，实际上这类指令一般也只对操作数栈进行操作。</li><li><strong>控制跳转指令</strong>：这类里包含常用的if系列指令以及goto类指令。</li><li><strong>方法调用和返回指令</strong>：主要包括invoke系列指令和return系列指令。这类指令也意味这一个方法空间的开辟和结束，即invoke会唤醒一个新的java方法小宇宙（新的栈和局部变量表），而return则意味着这个宇宙的结束回收。</li></ol><p>如下图，展示了各类指令的作用：<br><img src="/2017/03/07/jvm-classcode-tutorial/9.png" alt="Operator effect"></p><p>再从另外一个维度，即指令操作的数据类型来讲：指令开头或尾部的一些字母，就往往表明了它所能操作的数据类型：</p><ul><li>a对应对象，表示指令操作对象性数据，比如aload和astore、areturn等等。</li><li>i对应整形。也就有iload，istore等i系列指令。</li><li>f对应浮点型。</li><li>l对应long，b对应byte，d对应double，c对应char。</li><li>另外，ia对应int array，aa对应object array，da对应double array。不在一一赘述。</li></ul><p>了解了以上内容，我们再去看最后几个方法，应该就会容易理解很多了。<br>下面我们就直捣黄龙genToken这个方法(图中的颜色暗示了指令和方法调用之间的关系)：<br><img src="/2017/03/07/jvm-classcode-tutorial/10.png" alt="Pilot of genToken"></p><p>这个过程简单解读如下：</p><ol><li>new一个StringBuilder对象（在堆内存中开辟空间），并将其引用入栈，用于实现加号连接字符串功能（相当于C++中的运算符重载）；</li><li>dup复制栈顶的刚刚放入的引用，再次压栈，这时栈里有两个重复的内容，深度为2；</li><li>调用并弹出栈顶StringBuilder引用对象的<init>方法，栈深度为1；</li><li>（绿色部分）调用UUID.randomUUID()静态方法，结果压栈后弹出调用String的toString方法，再压栈，栈深度为2；</li><li>（黄色部分）将”-“和””字符压栈，此时栈深度为4，弹出（栈顶3个元素）调用replace方法，结果压栈，深度为2；<br>6.调用StringBuilder对象的append方法，结果压栈，深度为1；</li><li>（蓝色部分）将参数user压栈并调用hashCode方法，结果压栈，深度为2；</li><li>调用StringBuilder对象的append方法（此处和上面的append调用共同完成了加号功能，在图中为红色部分），结果压栈，深度为1，再调用toString方法后结果压栈，深度为1；</li><li>areturn返回栈顶对象。</li></ol><p>再看这个包含if跳转的方法login：<br><img src="/2017/03/07/jvm-classcode-tutorial/11.png" alt="Flow of login"></p><p>如上图，图中已经说明的比较全面了，不再赘述。值得一提的是，Java的这种基于栈结构的指令，在设计上有一种非常简洁的美感，指令与指令之间并没有较重的依赖，每条指令仅仅与操作数栈等领域内的数据发生关系，充满着某种平衡与秩序感。因此也必须注意，几乎每条指令的运行都有其前提，比如在invokevirtual或invokespecial指令执行前，必须保证操作数栈内提前按顺序压入好所需的操作数，否则就会发生问题。<br>关于最复杂的onCreate方法，就不再啰嗦解读了，读者可以前往我的github上的对应demo repo，进入tutorial分支，拉取源码和教程资源，或者自己写demo体验这一完整过程。</p><h1 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h1><p>关于实战，一是可以学习使用强大开源工具ASM.jar；二是，可以参考本人的另一篇文章：Java字节码修改神器HiBeaver：黑掉你的SDK以及一次Android字节码插桩实战，利用hibeaver这个助手，开发者可以非常灵活地对字节码进行修改，插入指令，hook代码，甚至建立一些简单的AOP框架，对于Java字节码学习大有裨益。<br>hibeaver完全开源，github项目地址：<a href="https://github.com/hydraxman/hibeaver">https://github.com/hydraxman/hibeaver</a></p><p>祝玩的愉快！<br>本文如有不妥之处，欢迎交流指正。</p><p>另外，本文为了尽可能地简明生动、直入核心，简化了很多概念和细节，读者须知实际情况的更为复杂。但相信在理解了本文以后，就可以抓住Java字节码指令的核心理念，也就算扣开虚拟机学习的大门并可以开始读书精进了。下面盗图一张（后有出处），可作拓展：<br><img src="/2017/03/07/jvm-classcode-tutorial/12.png" alt="More about JVM classcode"></p><p>关注最新技术分享和资讯：TechHome，技术人之家！</p>]]></content>
    
    
    <categories>
      
      <category>代码手记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Java</tag>
      
      <tag>JVM</tag>
      
      <tag>字节码</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Java字节码修改神器HiBeaver：黑掉你的SDK</title>
    <link href="/2017/02/26/java-classcode-edit-toolkit/"/>
    <url>/2017/02/26/java-classcode-edit-toolkit/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>有时候我们在Java开发过程中可能有这样的需求：需要研究或者修改工程依赖的Jar包中的一些逻辑，查看代码运行中Jar包代码内部的取值情况（比如了解SDK与其服务器通信的请求报文加密前的情况）。</p><span id="more"></span><p>这个需求类似于Hook。</p><p>但是往往这些依赖的Jar包中的代码已经被混淆过，删去了本地变量表和代码行号等debug信息，所以无法直接断点调试，其内部逻辑和运行情况也几乎无法触及，研究更难以下手。这时候，一般的办法有二：</p><ol><li>将Jar反解为Java源码，以module方式引入，便可自由修改调试；</li><li>修改字节码或者打包后的smali代码，实现想要的逻辑后再重新打包。</li></ol><p>这两种方法中，前者往往十分繁杂，尤其在混淆后逻辑变得极其复杂，几乎不可能完成；后者也很麻烦，工序较多，修改成本也比较高。</p><h1 id="插件：HiBeaver"><a href="#插件：HiBeaver" class="headerlink" title="插件：HiBeaver"></a>插件：HiBeaver</h1><p>Gradle编译插件hibeaver结合Java AOP编程中对于大名鼎鼎的ASM.jar的应用，和Android gradle 插件提供的最新的Transform API，在Apk编译环节中、class打包成dex之前，插入了中间环节，依据开发者的配置调用ASM API对项目所依赖的jar进行相应的修改，从而可以比较高效地实现上面的Hook需求。<br>源码地址：<a href="https://github.com/BryanSharp/hibeaver">https://github.com/hydraxman/hibeaver</a></p><p>（现在hiBeaver已经发布了1.2.7版本，支持轻量级AOP框架设计。）</p><p>唯一需要注意的是，运用好这个插件需要有一定的Java汇编指令基础，并了解基本的ASM3的使用方法：后者还是很简单的，而前者，关于Java汇编指令基础这块，对于事先不了解的同学，接触起来有一定难度，但是学一学这个其实非常有益处，对于理解Java的运行有很大的帮助。<br>闲话少说，先看看如何快速实践一把！关键看疗效！</p><p>关于汇编指令的资料可以参阅本人的文章：<a href="http://www.jianshu.com/p/a44f7e56e704">大话+图说：Java汇编指令——只为让你懂</a></p><h1 id="实战演练"><a href="#实战演练" class="headerlink" title="实战演练"></a>实战演练</h1><p>我们就先来尝试用这个Hook掉小米推送的SDK。</p><p>首先，在需要的工程的根项目gradle配置中加入以下内容：<br><img src="/2017/02/26/java-classcode-edit-toolkit/1.png" alt="图片描述"></p><p>如图所示，该插件上传到了jcenter中，只需引入classpath：</p><pre><code class="hljs">classpath &#39;com.bryansharp:HiBeaver:1.2.7&#39;</code></pre><p>这里需要注意的是，目前该插件仅支持Android gradle编译插件2.0及以上的版本。<br>然后，在你的App项目gradle配置底部或任意位置加入如下代码：</p><pre><code class="hljs">apply plugin: &#39;hiBeaver&#39;hiBeaver &#123;    //turn this on to make it print help content, default value is true    showHelp = true    //this flag will decide whether the log of the modifying process be printed or not, default value is false    keepQuiet = false    //this is a kit feature of the plugin, set it true to see the time consume of this build    watchTimeConsume = false    //this is the most important part    modifyMatchMaps = [:]&#125;</code></pre><p>然后，重新编译一下项目，会先去jitpack下载这个插件，开始编译后可以看到Android Studio的右下角的Gradle Console中，多输出了以下内容：<br><img src="/2017/02/26/java-classcode-edit-toolkit/2.png" alt="图片描述"></p><p>如果你看到了和我一样的内容，那说明初步配置成功。<br>可以看到，使用插件后会输出一段友好的帮助内容，还是中英文的，告诉我们可以直接拷贝作为初始配置，这个帮助输出也是可以关闭的。<br>下面我们正式开始尝试Hook小米推送SDK，首先，找出其业务逻辑中的一个节点。<br>首先，引入小米推送，这个过程不赘述了，blablabla，引入成功！<br>众所周知，使用小米推送需要先在代码中调用如下：</p><pre><code class="hljs">MiPushClient.registerPush(this, APP_ID, APP_KEY);</code></pre><p>这个代码应该会调起本地长连接的建立、注册服务器等流程。假如我们出于学习的目的，想研究其中的流程，试举一例，先从查看其反编译的代码开始，找一个切入的节点，如下：<br>首先进入查看MiPushClient.registerPush这个方法:<br><img src="/2017/02/26/java-classcode-edit-toolkit/3.png" alt="图片描述"><br><img src="/2017/02/26/java-classcode-edit-toolkit/4.png" alt="图片描述"></p><p>在initialize的方法中，找到一段逻辑如下：</p><p><img src="/2017/02/26/java-classcode-edit-toolkit/5.png" alt="图片描述"></p><p>进入a方法，来到了这个类：com.xiaomi.mipush.sdk.u中，发现：</p><p><img src="/2017/02/26/java-classcode-edit-toolkit/6.png" alt="图片描述"></p><p>下面如果我们想看看运行时前两个方法传入参数的值，就可以开始Hook了。该如何做呢？这个方法体内打Log输出所有的值吗？那样太麻烦了。我们可以这样做：<br>首先在我们项目的源码里新建一个静态方法，包含两个参数，如下图：</p><p><img src="/2017/02/26/java-classcode-edit-toolkit/7.png" alt="图片描述"></p><p>其后，我们只要在a方法中加入一段代码，调用我们的静态方法，并传入我们想查看的两个参数即可。<br>这就有赖于我们的hibeaver插件了，具体如何做呢？<br>我们可以先看看之前的帮助内容：</p><p><img src="/2017/02/26/java-classcode-edit-toolkit/8.png" alt="图片描述"></p><p>里面有提到一个the most important par，最重要的部分。没错，这个插件的核心就在于配置这个类型为Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;的传入量。<br>首先我们配置如下：</p><p><img src="/2017/02/26/java-classcode-edit-toolkit/9.png" alt="图片描述"></p><p>然后重新编译，发现输出log如下：</p><p><img src="/2017/02/26/java-classcode-edit-toolkit/10.png" alt="图片描述"></p><p>这样就输出这个u类的所有方法信息，用于后面进行配置。<br>再来看看刚刚的方法a：<br><img src="/2017/02/26/java-classcode-edit-toolkit/11.png" alt="图片描述"></p><p>是一个泛型方法，众所周知泛型只存在于编码阶段，编译后是没有泛型的，其实传入的参数的实际类型为org.apache.thrift.a，最终找到其方法描述应该为：</p><pre><code class="hljs">(Lorg/apache/thrift/a;Lcom/xiaomi/xmpush/thrift/a;ZLcom/xiaomi/xmpush/thrift/r;)V</code></pre><p>进一步配置：</p><p><img src="/2017/02/26/java-classcode-edit-toolkit/12.png" alt="图片描述"></p><p>然后重新编译，console输出新增revist部分，如下：</p><p><img src="/2017/02/26/java-classcode-edit-toolkit/13.png" alt="图片描述"></p><p>最后，我们增加如下代码，在其中植入我们的代码，调用刚刚的静态方法，并把对应值传递过来：<br>终极配置：</p><p><img src="/2017/02/26/java-classcode-edit-toolkit/14.png" alt="图片描述"></p><p>以上代码就不做详细解释了，相信有基础的都能明白，然后编译查看输出:</p><p><img src="/2017/02/26/java-classcode-edit-toolkit/14-1.png" alt="图片描述"></p><p>下面我们debug一下，看看是否可以成功在registerPush的运行流程中调用到我们的方法：</p><p><img src="/2017/02/26/java-classcode-edit-toolkit/15.png" alt="图片描述"><br><img src="/2017/02/26/java-classcode-edit-toolkit/15-1.png" alt="图片描述"><br>上面可以看到，无论是debug还是log输出都可以抓到想要的参数了。<br>因为小米推送是商业产品，这里不便于探索太多内容，但是通过hibeaver这个插件可以比较方便的进行类似的研究。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>hibeaver所体现的技术，并没有特别大的价值，仅仅作为工具来讲比较方便易用，有助于学习研究Jar中的逻辑，和学习应用Java汇编码。除此之外，还有几个应用场景：1.修改引用SDK中的一些bug或者提高其效率；2.获得必要的SDK的一些关键调用时机，通过hook建立回调；3.欺骗SDK、关闭或减少SDK中不受控制的网络传输。不一而足，还是很有趣、很有想象空间的。<br>目前存在的问题，如下，这个除了偶尔同步报错之外没有影响，编译正常：</p><p><img src="/2017/02/26/java-classcode-edit-toolkit/16.png" alt="图片描述"></p><p>还有，如果仅仅修改了gradle文件，不会触发更新，需要在代码上也进行任意修改方生效。</p><h2 id="关于项目"><a href="#关于项目" class="headerlink" title="关于项目"></a>关于项目</h2><p>hibeaver完全开源，大家可以自行查看其中代码，有大量的中文注释，对于学习gradle插件开发大有裨益。<br>github开源项目地址：<a href="https://github.com/BryanSharp/hibeaver">https://github.com/BryanSharp/hibeaver</a></p>]]></content>
    
    
    <categories>
      
      <category>代码手记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Android</tag>
      
      <tag>Gradle</tag>
      
      <tag>Java</tag>
      
      <tag>JVM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Gradle插件开发秘籍之断点调试（基于Intellij）</title>
    <link href="/2017/02/06/gradle-debug-tips/"/>
    <url>/2017/02/06/gradle-debug-tips/</url>
    
    <content type="html"><![CDATA[<p>Gradle插件开发这件事说大不大说小不小，但是对于有一定体量规模的Java项目来讲，从插件开发入手来思考解决问题，有的时候能找到意想不到的法门。所以说这是一门锦上添花的手艺。</p><span id="more"></span><p>废话少说，相信对于很多Gradle插件开发朋友们，开发过程中很大的一个痛点就是，插件的调试很痛苦，下面我就分享一下在这方面的心得。</p><h1 id="1-增加运行参数"><a href="#1-增加运行参数" class="headerlink" title="1. 增加运行参数"></a>1. 增加运行参数</h1><p>好吧这个很菜鸟，比如很常用参数的是–stacktrace，报错后会打印出堆栈信息</p><h1 id="2-Log输出控制"><a href="#2-Log输出控制" class="headerlink" title="2. Log输出控制"></a>2. Log输出控制</h1><p>这个不多说了，println就可以了，可以自己设置一些分级和flag。</p><h1 id="3-Attach-a-debugger！"><a href="#3-Attach-a-debugger！" class="headerlink" title="3. Attach a debugger！"></a>3. Attach a debugger！</h1><p>先上最终效果图：<br><img src="/2017/02/06/gradle-debug-tips/1.png" alt="图片描述"></p><p>如上图，是可以正常地设置断点调试和step into和step out、resume等等。<br>实现办法和原理：<br>大家都知道Gradle基于Groovy，而Groovy其实就是Java，所以也同样遵循JDWP协议，只是这个技巧似乎在国内的文章中没有人出来分享，我就在此分享给大家。<br>首先，在你要执行gradle命令的环境中加入如下环境变量（以Linux、MacOS为例）：</p><pre><code class="hljs">export GRADLE_OPTS=&quot;-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5005&quot;</code></pre><p>其中，address等号后面的参数就表示debugger要监听的端口，这里我们设置为5005。<br>然后执行gradle或gradlew任务，会发现有如下提示：</p><p><img src="/2017/02/06/gradle-debug-tips/2.png" alt="以debug模式运行gradle"></p><p>这时任务就不会继续执行了，挂起等待Debugger的handshake！<br>这时我们启动IDE，以Intellij为例，打开我们的gradle插件项目（包含正在运行的插件源码的项目），然后找到工具栏的执行区域，进入如下：</p><p><img src="/2017/02/06/gradle-debug-tips/3.png" alt="创建debugger"></p><p>在界面里添加一个运行项，Remote：</p><p><img src="/2017/02/06/gradle-debug-tips/4.png" alt="创建debugger"></p><p>需要配置的最核心参数就是如图所示的端口号，就是上文中的address:</p><p><img src="/2017/02/06/gradle-debug-tips/5.png" alt="配置debugger"></p><p>注意到下面有一个Search sources using …意思是从什么范围查找源码，保持默认就好了，这个debugger收到JDWP消息后会从当前工程中搜索源码，基于当前的源码进行与gradle命令行中的JDWP agent进行交互。</p><p>OK，如果插件源码中打好断点，执行到代码时就会挂起在相应位置了，大部分调试功能都很好使，大家可以尝试一下！这个技巧还是比较简单的，大家只要了解一下JDWP的核心原理，就可以理解上述过程了！</p><p>时间有限，如有不妥，欢迎指正！</p>]]></content>
    
    
    <categories>
      
      <category>代码手记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Gradle</tag>
      
      <tag>Debug</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
